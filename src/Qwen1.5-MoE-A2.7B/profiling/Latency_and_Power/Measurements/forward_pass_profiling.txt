Layer                                         Output Shape                   GPU Latency (ms)     CPU Latency (ms)     GPU Power (mW)       CPU Power (mW)      
===========================================================================================================================================================
model.embed_tokens                            torch.Size([1, 5, 2048])       15.814400            16.222954            311.424000           1245.184000         
model.rotary_emb                              torch.Size([1, 5, 128])        79.759842            80.271482            311.402667           1321.475137         
model.layers.0.input_layernorm                torch.Size([1, 5, 2048])       0.382368             1.549482             311.300923           1634.168615         
model.layers.0.self_attn.q_proj               torch.Size([1, 5, 2048])       1.004192             2.227783             389.120000           1847.560000         
model.layers.0.self_attn.k_proj               torch.Size([1, 5, 2048])       0.946752             2.752304             535.815111           2108.053333         
model.layers.0.self_attn.v_proj               torch.Size([1, 5, 2048])       0.988288             2.535343             738.640000           2273.544000         
model.layers.0.self_attn.o_proj               torch.Size([1, 5, 2048])       0.990304             2.806425             846.328889           2469.568000         
model.layers.0.post_attention_layernorm       torch.Size([1, 5, 2048])       0.437920             2.279520             891.814957           2621.395478         
model.layers.0.mlp.gate                       torch.Size([5, 60])            0.180512             1.638174             776.960000           2797.056000         
model.layers.0.mlp.experts.0.gate_proj        torch.Size([1, 1408])          0.611168             2.256632             811.491556           2917.781333         
model.layers.0.mlp.experts.0.act_fn           torch.Size([1, 1408])          1.512992             1.846313             839.116800           3106.560000         
model.layers.0.mlp.experts.0.up_proj          torch.Size([1, 1408])          0.601728             2.372265             880.298667           3313.664000         
model.layers.0.mlp.experts.0.down_proj        torch.Size([1, 2048])          1.135680             1.493454             931.968000           3416.864000         
model.layers.0.mlp.experts.1.gate_proj        torch.Size([0, 1408])          0.005632             1.548529             931.968000           3455.680000         
model.layers.0.mlp.experts.1.act_fn           torch.Size([0, 1408])          1.493088             1.787663             931.968000           3572.544000         
model.layers.0.mlp.experts.1.up_proj          torch.Size([0, 1408])          0.546976             0.927925             854.304000           3572.544000         
model.layers.0.mlp.experts.1.down_proj        torch.Size([0, 2048])          1.460640             1.742601             776.640000           3572.544000         
model.layers.0.mlp.experts.2.gate_proj        torch.Size([1, 1408])          1.013120             1.311779             776.640000           3571.256000         
model.layers.0.mlp.experts.2.act_fn           torch.Size([1, 1408])          0.341920             0.713110             776.640000           3571.072000         
model.layers.0.mlp.experts.2.up_proj          torch.Size([1, 1408])          0.604960             2.321720             834.888000           3571.072000         
model.layers.0.mlp.experts.2.down_proj        torch.Size([1, 2048])          1.033408             1.310110             931.680000           3571.072000         
model.layers.0.mlp.experts.3.gate_proj        torch.Size([1, 1408])          2.081216             2.400637             931.584000           3777.557333         
model.layers.0.mlp.experts.3.act_fn           torch.Size([1, 1408])          0.307584             0.680447             931.584000           3880.000000         
model.layers.0.mlp.experts.3.up_proj          torch.Size([1, 1408])          0.607008             2.350807             931.584000           4035.200000         
model.layers.0.mlp.experts.3.down_proj        torch.Size([1, 2048])          1.018592             1.292706             1048.032000          4015.800000         
model.layers.0.mlp.experts.4.gate_proj        torch.Size([0, 1408])          0.005600             1.389980             1055.795200          3911.040000         
model.layers.0.mlp.experts.4.act_fn           torch.Size([0, 1408])          0.005696             1.756668             931.584000           3880.000000         
model.layers.0.mlp.experts.4.up_proj          torch.Size([0, 1408])          0.005696             1.739025             931.584000           3880.800000         
model.layers.0.mlp.experts.4.down_proj        torch.Size([0, 2048])          0.005632             1.705885             931.584000           3881.600000         
model.layers.0.mlp.experts.5.gate_proj        torch.Size([0, 1408])          0.005856             1.517534             807.564800           3881.600000         
model.layers.0.mlp.experts.5.act_fn           torch.Size([0, 1408])          0.005440             1.760483             776.640000           3881.600000         
model.layers.0.mlp.experts.5.up_proj          torch.Size([0, 1408])          0.005376             1.666784             776.640000           3881.600000         
model.layers.0.mlp.experts.5.down_proj        torch.Size([0, 2048])          1.503360             1.804829             776.640000           3881.600000         
model.layers.0.mlp.experts.6.gate_proj        torch.Size([0, 1408])          0.005696             1.588821             737.808000           3881.600000         
model.layers.0.mlp.experts.6.act_fn           torch.Size([0, 1408])          0.005696             1.623631             621.312000           4036.864000         
model.layers.0.mlp.experts.6.up_proj          torch.Size([0, 1408])          1.493408             1.841545             621.312000           4036.864000         
model.layers.0.mlp.experts.6.down_proj        torch.Size([0, 2048])          0.481376             0.863314             621.312000           4130.022400         
model.layers.0.mlp.experts.7.gate_proj        torch.Size([0, 1408])          0.005632             1.611710             621.312000           4036.864000         
model.layers.0.mlp.experts.7.act_fn           torch.Size([0, 1408])          1.507520             1.831770             621.312000           4036.864000         
model.layers.0.mlp.experts.7.up_proj          torch.Size([0, 1408])          0.489984             0.868320             621.312000           4036.864000         
model.layers.0.mlp.experts.7.down_proj        torch.Size([0, 2048])          0.005696             1.716137             621.312000           3912.652800         
model.layers.0.mlp.experts.8.gate_proj        torch.Size([2, 1408])          2.164480             2.485514             621.312000           3804.368000         
model.layers.0.mlp.experts.8.act_fn           torch.Size([2, 1408])          0.426752             0.832796             621.312000           3765.920000         
model.layers.0.mlp.experts.8.up_proj          torch.Size([2, 1408])          0.683808             2.310753             673.088000           3745.130667         
model.layers.0.mlp.experts.8.down_proj        torch.Size([2, 2048])          1.497120             1.784801             798.829714           3726.336000         
model.layers.0.mlp.experts.9.gate_proj        torch.Size([0, 1408])          0.005792             1.580000             854.304000           3726.336000         
model.layers.0.mlp.experts.9.act_fn           torch.Size([0, 1408])          0.286816             0.676632             776.640000           3726.336000         
model.layers.0.mlp.experts.9.up_proj          torch.Size([0, 1408])          0.005824             1.724005             776.640000           3726.336000         
model.layers.0.mlp.experts.9.down_proj        torch.Size([0, 2048])          0.547072             0.918150             776.640000           3726.336000         
model.layers.0.mlp.experts.10.gate_proj       torch.Size([1, 1408])          0.903936             1.214743             776.640000           3862.192000         
model.layers.0.mlp.experts.10.act_fn          torch.Size([1, 1408])          0.316256             0.739336             776.640000           3881.600000         
model.layers.0.mlp.experts.10.up_proj         torch.Size([1, 1408])          0.607168             2.249956             798.829714           3815.058286         
model.layers.0.mlp.experts.10.down_proj       torch.Size([1, 2048])          1.048448             1.342058             931.913143           3815.058286         
model.layers.0.mlp.experts.11.gate_proj       torch.Size([0, 1408])          0.005696             1.669168             931.584000           3881.600000         
model.layers.0.mlp.experts.11.act_fn          torch.Size([0, 1408])          0.005664             1.796007             931.584000           4035.200000         
model.layers.0.mlp.experts.11.up_proj         torch.Size([0, 1408])          0.501536             0.883818             776.320000           4190.400000         
model.layers.0.mlp.experts.11.down_proj       torch.Size([0, 2048])          0.005696             1.230478             776.320000           4345.600000         
model.layers.0.mlp.experts.12.gate_proj       torch.Size([0, 1408])          0.005632             1.672029             776.320000           4345.600000         
model.layers.0.mlp.experts.12.act_fn          torch.Size([0, 1408])          1.480288             1.788855             776.320000           4345.600000         
model.layers.0.mlp.experts.12.up_proj         torch.Size([0, 1408])          1.492544             1.788139             698.688000           4500.800000         
model.layers.0.mlp.experts.12.down_proj       torch.Size([0, 2048])          0.484960             0.864983             621.056000           4501.171200         
model.layers.0.mlp.experts.13.gate_proj       torch.Size([0, 1408])          0.005600             1.665354             621.056000           4501.913600         
model.layers.0.mlp.experts.13.act_fn          torch.Size([0, 1408])          0.281408             0.674725             621.056000           4502.656000         
model.layers.0.mlp.experts.13.up_proj         torch.Size([0, 1408])          0.005696             1.735926             621.248000           4386.208000         
model.layers.0.mlp.experts.13.down_proj       torch.Size([0, 2048])          1.474208             1.826763             621.312000           4347.392000         
model.layers.0.mlp.experts.14.gate_proj       torch.Size([0, 1408])          0.005696             1.666546             621.312000           4269.760000         
model.layers.0.mlp.experts.14.act_fn          torch.Size([0, 1408])          0.310016             0.695467             621.312000           4192.128000         
model.layers.0.mlp.experts.14.up_proj         torch.Size([0, 1408])          0.005664             1.703978             543.648000           4192.128000         
model.layers.0.mlp.experts.14.down_proj       torch.Size([0, 2048])          1.486624             1.821756             465.984000           4192.128000         
model.layers.0.mlp.experts.15.gate_proj       torch.Size([1, 1408])          0.942304             1.237869             582.480000           4036.864000         
model.layers.0.mlp.experts.15.act_fn          torch.Size([1, 1408])          0.312992             0.692844             621.312000           4036.864000         
model.layers.0.mlp.experts.15.up_proj         torch.Size([1, 1408])          2.071392             2.354622             621.312000           4036.864000         
model.layers.0.mlp.experts.15.down_proj       torch.Size([1, 2048])          1.085664             1.374960             754.313143           3992.502857         
model.layers.0.mlp.experts.16.gate_proj       torch.Size([1, 1408])          2.069888             2.379417             820.681143           3968.685714         
model.layers.0.mlp.experts.16.act_fn          torch.Size([1, 1408])          0.314560             0.692129             931.584000           4004.160000         
model.layers.0.mlp.experts.16.up_proj         torch.Size([1, 1408])          0.600480             2.321959             912.176000           3938.200000         
model.layers.0.mlp.experts.16.down_proj       torch.Size([1, 2048])          1.068448             1.353502             931.584000           3880.000000         
model.layers.0.mlp.experts.17.gate_proj       torch.Size([1, 1408])          2.083680             2.384663             1020.306286          3880.000000         
model.layers.0.mlp.experts.17.act_fn          torch.Size([1, 1408])          0.350240             0.723362             1086.848000          3880.000000         
model.layers.0.mlp.experts.17.up_proj         torch.Size([1, 1408])          0.600960             2.342701             1086.848000          3880.000000         
model.layers.0.mlp.experts.17.down_proj       torch.Size([1, 2048])          1.103488             1.395464             1086.848000          3880.000000         
model.layers.0.mlp.experts.18.gate_proj       torch.Size([1, 1408])          2.076064             2.372980             1086.848000          3880.000000         
model.layers.0.mlp.experts.18.act_fn          torch.Size([1, 1408])          0.332832             0.712395             1086.848000          3880.000000         
model.layers.0.mlp.experts.18.up_proj         torch.Size([1, 1408])          0.604992             2.297878             1106.192000          3880.000000         
model.layers.0.mlp.experts.18.down_proj       torch.Size([1, 2048])          1.039232             1.387358             1164.000000          4034.368000         
model.layers.0.mlp.experts.19.gate_proj       torch.Size([0, 1408])          0.005632             1.607895             1138.133333          4059.392000         
model.layers.0.mlp.experts.19.act_fn          torch.Size([0, 1408])          0.280576             0.671864             1086.549333          4086.933333         
model.layers.0.mlp.experts.19.up_proj         torch.Size([0, 1408])          0.005664             1.774549             1086.848000          4035.200000         
model.layers.0.mlp.experts.19.down_proj       torch.Size([0, 2048])          1.504064             1.789093             931.584000           4035.200000         
model.layers.0.mlp.experts.20.gate_proj       torch.Size([1, 1408])          2.077248             2.428055             931.584000           4035.200000         
model.layers.0.mlp.experts.20.act_fn          torch.Size([1, 1408])          0.357024             0.732660             931.584000           4035.200000         
model.layers.0.mlp.experts.20.up_proj         torch.Size([1, 1408])          0.601536             2.281666             989.808000           3996.400000         
model.layers.0.mlp.experts.20.down_proj       torch.Size([1, 2048])          1.058944             1.340151             1086.848000          3880.000000         
model.layers.0.mlp.experts.21.gate_proj       torch.Size([0, 1408])          0.005664             1.608849             1086.848000          3880.000000         
model.layers.0.mlp.experts.21.act_fn          torch.Size([0, 1408])          0.281312             0.656128             1035.093333          3880.000000         
model.layers.0.mlp.experts.21.up_proj         torch.Size([0, 1408])          0.470432             0.837088             931.584000           3880.000000         
model.layers.0.mlp.experts.21.down_proj       torch.Size([0, 2048])          0.005696             1.678705             931.584000           3880.960000         
model.layers.0.mlp.experts.22.gate_proj       torch.Size([0, 1408])          0.005600             1.666784             900.531200           3757.388800         
model.layers.0.mlp.experts.22.act_fn          torch.Size([0, 1408])          0.291072             0.664711             776.320000           3829.845333         
model.layers.0.mlp.experts.22.up_proj         torch.Size([0, 1408])          1.465824             1.744747             776.560000           3765.152000         
model.layers.0.mlp.experts.22.down_proj       torch.Size([0, 2048])          1.493280             1.796007             776.640000           3757.388800         
model.layers.0.mlp.experts.23.gate_proj       torch.Size([1, 1408])          0.895296             1.247644             776.520000           3881.600000         
model.layers.0.mlp.experts.23.act_fn          torch.Size([1, 1408])          0.313504             0.686884             776.400000           3881.600000         
model.layers.0.mlp.experts.23.up_proj         torch.Size([1, 1408])          0.604448             2.315044             815.176000           3881.600000         
model.layers.0.mlp.experts.23.down_proj       torch.Size([1, 2048])          1.075040             1.375914             931.584000           3815.058286         
model.layers.0.mlp.experts.24.gate_proj       torch.Size([0, 1408])          0.005696             1.680374             931.584000           3765.152000         
model.layers.0.mlp.experts.24.act_fn          torch.Size([0, 1408])          0.282400             0.685215             931.584000           3881.600000         
model.layers.0.mlp.experts.24.up_proj         torch.Size([0, 1408])          0.005632             1.719952             838.553600           3819.494400         
model.layers.0.mlp.experts.24.down_proj       torch.Size([0, 2048])          0.005376             1.758337             776.640000           3726.336000         
model.layers.0.mlp.experts.25.gate_proj       torch.Size([0, 1408])          0.005632             1.694679             776.640000           3881.600000         
model.layers.0.mlp.experts.25.act_fn          torch.Size([0, 1408])          0.289696             0.668049             776.640000           4036.864000         
model.layers.0.mlp.experts.25.up_proj         torch.Size([0, 1408])          0.005760             1.752138             714.508800           4036.864000         
model.layers.0.mlp.experts.25.down_proj       torch.Size([0, 2048])          1.457696             1.754522             621.312000           4192.128000         
model.layers.0.mlp.experts.26.gate_proj       torch.Size([0, 1408])          0.005696             1.678944             621.312000           4114.496000         
model.layers.0.mlp.experts.26.act_fn          torch.Size([0, 1408])          0.280320             0.653267             621.312000           4036.864000         
model.layers.0.mlp.experts.26.up_proj         torch.Size([0, 1408])          0.005696             1.722097             621.312000           4036.864000         
model.layers.0.mlp.experts.26.down_proj       torch.Size([0, 2048])          0.469920             0.836849             621.312000           4036.864000         
model.layers.0.mlp.experts.27.gate_proj       torch.Size([0, 1408])          0.005696             1.673937             621.312000           3998.448000         
model.layers.0.mlp.experts.27.act_fn          torch.Size([0, 1408])          0.293728             0.659704             621.312000           3883.200000         
model.layers.0.mlp.experts.27.up_proj         torch.Size([0, 1408])          1.512000             1.803875             465.984000           3883.200000         
model.layers.0.mlp.experts.27.down_proj       torch.Size([0, 2048])          0.520000             0.883579             465.984000           4036.864000         
model.layers.0.mlp.experts.28.gate_proj       torch.Size([0, 1408])          0.005728             1.675606             465.984000           4114.496000         
model.layers.0.mlp.experts.28.act_fn          torch.Size([0, 1408])          0.323424             0.731945             465.984000           4192.128000         
model.layers.0.mlp.experts.28.up_proj         torch.Size([0, 1408])          0.005664             1.745701             465.984000           4099.302400         
model.layers.0.mlp.experts.28.down_proj       torch.Size([0, 2048])          0.455968             0.824690             465.984000           4038.528000         
model.layers.0.mlp.experts.29.gate_proj       torch.Size([0, 1408])          0.005728             1.708984             465.984000           4038.528000         
model.layers.0.mlp.experts.29.act_fn          torch.Size([0, 1408])          0.280384             0.674963             465.984000           4038.528000         
model.layers.0.mlp.experts.29.up_proj         torch.Size([0, 1408])          1.469920             1.752138             465.984000           4038.528000         
model.layers.0.mlp.experts.29.down_proj       torch.Size([0, 2048])          0.478112             0.845909             466.080000           4038.528000         
model.layers.0.mlp.experts.30.gate_proj       torch.Size([1, 1408])          2.072320             2.445936             466.008000           4019.112000         
model.layers.0.mlp.experts.30.act_fn          torch.Size([1, 1408])          0.310560             0.715256             465.984000           3945.331200         
model.layers.0.mlp.experts.30.up_proj         torch.Size([1, 1408])          2.053216             2.349138             604.053333           3883.200000         
model.layers.0.mlp.experts.30.down_proj       torch.Size([1, 2048])          1.066240             1.358509             640.728000           3881.800000         
model.layers.0.mlp.experts.31.gate_proj       torch.Size([0, 1408])          0.005696             1.654625             621.312000           3881.600000         
model.layers.0.mlp.experts.31.act_fn          torch.Size([0, 1408])          0.280000             0.670433             621.312000           3881.600000         
model.layers.0.mlp.experts.31.up_proj         torch.Size([0, 1408])          0.005632             1.706600             621.312000           3881.600000         
model.layers.0.mlp.experts.31.down_proj       torch.Size([0, 2048])          0.455136             0.821352             621.312000           4036.864000         
model.layers.0.mlp.experts.32.gate_proj       torch.Size([0, 1408])          0.005632             1.630306             621.312000           4036.864000         
model.layers.0.mlp.experts.32.act_fn          torch.Size([0, 1408])          0.282048             0.652552             621.312000           4192.128000         
model.layers.0.mlp.experts.32.up_proj         torch.Size([0, 1408])          1.461248             1.753807             582.480000           4075.680000         
model.layers.0.mlp.experts.32.down_proj       torch.Size([0, 2048])          0.476384             0.912428             465.984000           4075.680000         
model.layers.0.mlp.experts.33.gate_proj       torch.Size([1, 1408])          0.898816             1.202345             582.480000           4036.864000         
model.layers.0.mlp.experts.33.act_fn          torch.Size([1, 1408])          0.309632             0.687838             621.312000           4036.864000         
model.layers.0.mlp.experts.33.up_proj         torch.Size([1, 1408])          0.601184             2.337217             621.312000           4036.864000         
model.layers.0.mlp.experts.33.down_proj       torch.Size([1, 2048])          1.050016             1.349211             718.160000           3959.232000         
model.layers.0.mlp.experts.34.gate_proj       torch.Size([1, 1408])          0.875072             1.173496             776.320000           3903.780571         
model.layers.0.mlp.experts.34.act_fn          torch.Size([1, 1408])          0.301568             0.677824             776.320000           3881.600000         
model.layers.0.mlp.experts.34.up_proj         torch.Size([1, 1408])          0.607040             2.349854             815.136000           3881.200000         
model.layers.0.mlp.experts.34.down_proj       torch.Size([1, 2048])          1.015904             1.311064             931.584000           4013.028571         
model.layers.0.mlp.experts.35.gate_proj       torch.Size([0, 1408])          0.005664             1.664400             931.584000           4159.360000         
model.layers.0.mlp.experts.35.act_fn          torch.Size([0, 1408])          0.005664             1.811028             828.074667           4190.400000         
model.layers.0.mlp.experts.35.up_proj         torch.Size([0, 1408])          0.530816             0.937939             776.320000           4190.400000         
model.layers.0.mlp.experts.35.down_proj       torch.Size([0, 2048])          0.005632             1.769781             776.320000           4113.216000         
model.layers.0.mlp.experts.36.gate_proj       torch.Size([0, 1408])          0.005664             1.670599             776.320000           4130.022400         
model.layers.0.mlp.experts.36.act_fn          torch.Size([0, 1408])          0.278528             0.652075             776.320000           4036.864000         
model.layers.0.mlp.experts.36.up_proj         torch.Size([0, 1408])          0.005760             1.729012             621.209600           4036.864000         
model.layers.0.mlp.experts.36.down_proj       torch.Size([0, 2048])          0.005632             1.185894             621.312000           4036.864000         
model.layers.0.mlp.experts.37.gate_proj       torch.Size([0, 1408])          0.005824             1.596928             621.312000           3920.416000         
model.layers.0.mlp.experts.37.act_fn          torch.Size([0, 1408])          0.281152             0.652075             621.312000           3881.600000         
model.layers.0.mlp.experts.37.up_proj         torch.Size([0, 1408])          0.005664             1.754522             621.312000           3882.880000         
model.layers.0.mlp.experts.37.down_proj       torch.Size([0, 2048])          0.481568             0.862122             621.312000           3883.200000         
model.layers.0.mlp.experts.38.gate_proj       torch.Size([0, 1408])          0.005632             1.680374             504.816000           3922.032000         
model.layers.0.mlp.experts.38.act_fn          torch.Size([0, 1408])          0.298688             0.673056             465.984000           4037.418667         
model.layers.0.mlp.experts.38.up_proj         torch.Size([0, 1408])          1.476000             1.766682             465.984000           4036.864000         
model.layers.0.mlp.experts.38.down_proj       torch.Size([0, 2048])          0.005760             1.751184             465.984000           4130.355200         
model.layers.0.mlp.experts.39.gate_proj       torch.Size([0, 1408])          0.005632             1.669168             465.984000           4038.528000         
model.layers.0.mlp.experts.39.act_fn          torch.Size([0, 1408])          0.276832             0.648499             465.984000           4038.528000         
model.layers.0.mlp.experts.39.up_proj         torch.Size([0, 1408])          1.452768             1.747370             465.984000           3883.200000         
model.layers.0.mlp.experts.39.down_proj       torch.Size([0, 2048])          1.462336             1.744270             466.080000           3883.200000         
model.layers.0.mlp.experts.40.gate_proj       torch.Size([0, 1408])          0.005824             1.683474             466.176000           3883.200000         
model.layers.0.mlp.experts.40.act_fn          torch.Size([0, 1408])          0.294976             0.672340             466.176000           3883.200000         
model.layers.0.mlp.experts.40.up_proj         torch.Size([0, 1408])          0.005632             1.787424             466.176000           3883.200000         
model.layers.0.mlp.experts.40.down_proj       torch.Size([0, 2048])          0.005440             1.729488             466.176000           3883.200000         
model.layers.0.mlp.experts.41.gate_proj       torch.Size([0, 1408])          0.005760             1.569510             466.176000           3883.200000         
model.layers.0.mlp.experts.41.act_fn          torch.Size([0, 1408])          0.285504             0.666380             466.176000           3883.200000         
model.layers.0.mlp.experts.41.up_proj         torch.Size([0, 1408])          0.005664             1.763821             466.176000           3790.003200         
model.layers.0.mlp.experts.41.down_proj       torch.Size([0, 2048])          1.464064             1.794338             466.176000           3727.872000         
model.layers.0.mlp.experts.42.gate_proj       torch.Size([0, 1408])          0.005664             1.634836             466.176000           3727.872000         
model.layers.0.mlp.experts.42.act_fn          torch.Size([0, 1408])          0.356224             0.743151             466.176000           3883.200000         
model.layers.0.mlp.experts.42.up_proj         torch.Size([0, 1408])          0.509408             0.900745             341.862400           3883.200000         
model.layers.0.mlp.experts.42.down_proj       torch.Size([0, 2048])          0.509856             1.014948             310.784000           3821.068800         
model.layers.0.mlp.experts.43.gate_proj       torch.Size([1, 1408])          0.942048             1.277208             446.752000           3766.704000         
model.layers.0.mlp.experts.43.act_fn          torch.Size([1, 1408])          0.322240             0.755787             466.176000           3727.872000         
model.layers.0.mlp.experts.43.up_proj         torch.Size([1, 1408])          0.916928             1.206875             524.328000           3727.872000         
model.layers.0.mlp.experts.43.down_proj       torch.Size([1, 2048])          1.049792             1.331091             621.312000           3726.774857         
model.layers.0.mlp.experts.44.gate_proj       torch.Size([2, 1408])          1.000256             1.331568             737.808000           3726.336000         
model.layers.0.mlp.experts.44.act_fn          torch.Size([2, 1408])          0.319584             0.697374             776.640000           3726.336000         
model.layers.0.mlp.experts.44.up_proj         torch.Size([2, 1408])          0.959584             1.305819             776.640000           3726.336000         
model.layers.0.mlp.experts.44.down_proj       torch.Size([2, 2048])          1.429664             1.709223             873.400000           3861.592000         
model.layers.0.mlp.experts.45.gate_proj       torch.Size([0, 1408])          0.501664             0.885725             931.584000           3918.800000         
model.layers.0.mlp.experts.45.act_fn          torch.Size([0, 1408])          0.283808             0.648737             879.829333           4035.200000         
model.layers.0.mlp.experts.45.up_proj         torch.Size([0, 1408])          0.465696             0.832796             776.320000           4036.531200         
model.layers.0.mlp.experts.45.down_proj       torch.Size([0, 2048])          0.459264             0.845194             776.400000           4036.864000         
model.layers.0.mlp.experts.46.gate_proj       torch.Size([0, 1408])          0.528064             0.926256             776.640000           3959.232000         
model.layers.0.mlp.experts.46.act_fn          torch.Size([0, 1408])          0.374720             0.788450             776.640000           3881.600000         
model.layers.0.mlp.experts.46.up_proj         torch.Size([0, 1408])          0.486432             0.874519             652.377600           4036.864000         
model.layers.0.mlp.experts.46.down_proj       torch.Size([0, 2048])          0.631104             1.133442             621.312000           4005.811200         
model.layers.0.mlp.experts.47.gate_proj       torch.Size([1, 1408])          1.000832             1.379490             660.144000           3959.232000         
model.layers.0.mlp.experts.47.act_fn          torch.Size([1, 1408])          0.333056             0.727654             776.640000           3881.600000         
model.layers.0.mlp.experts.47.up_proj         torch.Size([1, 1408])          0.911456             1.223326             776.640000           3881.600000         
model.layers.0.mlp.experts.47.down_proj       torch.Size([1, 2048])          1.039712             1.344204             776.400000           3881.600000         
model.layers.0.mlp.experts.48.gate_proj       torch.Size([1, 1408])          0.928320             1.275778             892.768000           3668.112000         
model.layers.0.mlp.experts.48.act_fn          torch.Size([1, 1408])          0.328224             0.712395             931.680000           3571.072000         
model.layers.0.mlp.experts.48.up_proj         torch.Size([1, 1408])          0.924736             1.270294             931.632000           3571.072000         
model.layers.0.mlp.experts.48.down_proj       torch.Size([1, 2048])          1.089984             1.390934             931.584000           3570.152000         
model.layers.0.mlp.experts.49.gate_proj       torch.Size([0, 1408])          0.485152             0.913620             931.584000           3570.483200         
model.layers.0.mlp.experts.49.act_fn          torch.Size([0, 1408])          0.311744             0.693798             931.584000           3571.072000         
model.layers.0.mlp.experts.49.up_proj         torch.Size([0, 1408])          0.478112             0.857115             869.683200           3571.072000         
model.layers.0.mlp.experts.49.down_proj       torch.Size([0, 2048])          0.607808             1.057386             776.640000           3571.072000         
model.layers.0.mlp.experts.50.gate_proj       torch.Size([0, 1408])          0.601312             1.084805             776.640000           3571.072000         
model.layers.0.mlp.experts.50.act_fn          torch.Size([0, 1408])          0.336832             0.819683             776.640000           3571.072000         
model.layers.0.mlp.experts.50.up_proj         torch.Size([0, 1408])          0.537984             0.934601             776.640000           3571.072000         
model.layers.0.mlp.experts.50.down_proj       torch.Size([0, 2048])          0.619328             1.128197             621.312000           3571.072000         
model.layers.0.mlp.experts.51.gate_proj       torch.Size([0, 1408])          0.607392             1.062632             621.312000           3726.336000         
model.layers.0.mlp.experts.51.act_fn          torch.Size([0, 1408])          0.291456             0.676870             621.312000           3803.968000         
model.layers.0.mlp.experts.51.up_proj         torch.Size([0, 1408])          0.481120             0.856400             621.312000           3881.600000         
model.layers.0.mlp.experts.51.down_proj       torch.Size([0, 2048])          0.616128             1.075506             621.312000           3959.232000         
model.layers.0.mlp.experts.52.gate_proj       torch.Size([0, 1408])          0.612448             1.137733             621.312000           4005.811200         
model.layers.0.mlp.experts.52.act_fn          torch.Size([0, 1408])          0.302976             0.833273             621.312000           3933.354667         
model.layers.0.mlp.experts.52.up_proj         torch.Size([0, 1408])          0.531104             0.953197             465.984000           3882.560000         
model.layers.0.mlp.experts.52.down_proj       torch.Size([0, 2048])          0.633152             1.079559             465.984000           3883.200000         
model.layers.0.mlp.experts.53.gate_proj       torch.Size([0, 1408])          0.540320             0.989914             465.984000           3883.200000         
model.layers.0.mlp.experts.53.act_fn          torch.Size([0, 1408])          0.325568             0.763416             466.048000           3883.200000         
model.layers.0.mlp.experts.53.up_proj         torch.Size([0, 1408])          0.481920             0.847578             466.176000           3883.200000         
model.layers.0.mlp.experts.53.down_proj       torch.Size([0, 2048])          0.554432             0.970602             466.176000           3805.536000         
model.layers.0.mlp.experts.54.gate_proj       torch.Size([0, 1408])          0.488416             0.861406             466.176000           3758.937600         
model.layers.0.mlp.experts.54.act_fn          torch.Size([0, 1408])          0.338944             0.719547             466.176000           3727.872000         
model.layers.0.mlp.experts.54.up_proj         torch.Size([0, 1408])          0.467648             0.842810             466.176000           3766.704000         
model.layers.0.mlp.experts.54.down_proj       torch.Size([0, 2048])          0.469024             0.838041             466.176000           3728.486400         
model.layers.0.mlp.experts.55.gate_proj       torch.Size([0, 1408])          0.469824             0.911951             466.176000           3729.408000         
model.layers.0.mlp.experts.55.act_fn          torch.Size([0, 1408])          0.281152             0.645876             466.176000           3729.408000         
model.layers.0.mlp.experts.55.up_proj         torch.Size([0, 1408])          0.456256             0.821114             466.176000           3729.408000         
model.layers.0.mlp.experts.55.down_proj       torch.Size([0, 2048])          0.452288             0.816345             466.176000           3729.408000         
model.layers.0.mlp.experts.56.gate_proj       torch.Size([0, 1408])          0.470880             0.844002             466.176000           3729.408000         
model.layers.0.mlp.experts.56.act_fn          torch.Size([0, 1408])          0.274048             0.639915             466.176000           3729.408000         
model.layers.0.mlp.experts.56.up_proj         torch.Size([0, 1408])          0.454016             0.881672             466.176000           3729.408000         
model.layers.0.mlp.experts.56.down_proj       torch.Size([0, 2048])          0.451744             0.832796             388.480000           3690.560000         
model.layers.0.mlp.experts.57.gate_proj       torch.Size([0, 1408])          0.464032             0.871897             310.784000           3574.016000         
model.layers.0.mlp.experts.57.act_fn          torch.Size([0, 1408])          0.326016             0.697851             310.784000           3677.610667         
model.layers.0.mlp.experts.57.up_proj         torch.Size([0, 1408])          0.466880             0.830412             310.784000           3690.560000         
model.layers.0.mlp.experts.57.down_proj       torch.Size([0, 2048])          0.463520             0.840187             310.784000           3728.793600         
model.layers.0.mlp.experts.58.gate_proj       torch.Size([0, 1408])          0.556864             0.936031             310.784000           3883.200000         
model.layers.0.mlp.experts.58.act_fn          torch.Size([0, 1408])          0.273472             0.633717             310.784000           3883.200000         
model.layers.0.mlp.experts.58.up_proj         torch.Size([0, 1408])          0.456992             0.819683             310.784000           4038.528000         
model.layers.0.mlp.experts.58.down_proj       torch.Size([0, 2048])          0.452032             0.828743             310.784000           3999.696000         
model.layers.0.mlp.experts.59.gate_proj       torch.Size([0, 1408])          0.505952             0.878334             310.784000           3914.265600         
model.layers.0.mlp.experts.59.act_fn          torch.Size([0, 1408])          0.281408             0.669479             310.784000           3883.200000         
model.layers.0.mlp.experts.59.up_proj         torch.Size([0, 1408])          0.462304             0.870705             310.784000           3852.134400         
model.layers.0.mlp.experts.59.down_proj       torch.Size([0, 2048])          0.459904             0.834942             310.784000           3728.384000         
model.layers.0.mlp.shared_expert.gate_proj    torch.Size([5, 5632])          2.619040             2.938032             466.176000           3728.064000         
model.layers.0.mlp.shared_expert.act_fn       torch.Size([5, 5632])          0.338208             0.710726             652.377600           3726.950400         
model.layers.0.mlp.shared_expert.up_proj      torch.Size([5, 5632])          2.607456             2.930403             842.998857           3881.142857         
model.layers.0.mlp.shared_expert.down_proj    torch.Size([5, 2048])          2.715648             3.004074             1241.424000          4033.744000         
model.layers.0.mlp.shared_expert_gate         torch.Size([5, 1])             0.531232             0.920057             1551.360000          3955.552000         
model.layers.1.input_layernorm                torch.Size([1, 5, 2048])       1.066432             1.490831             1403.773091          3878.400000         
model.layers.1.self_attn.q_proj               torch.Size([1, 5, 2048])       1.436000             1.734257             1377.400000          3878.400000         
model.layers.1.self_attn.k_proj               torch.Size([1, 5, 2048])       1.419360             1.710176             1396.800000          3800.832000         
model.layers.1.self_attn.v_proj               torch.Size([1, 5, 2048])       1.381760             1.678228             1474.400000          3723.264000         
model.layers.1.self_attn.o_proj               torch.Size([1, 5, 2048])       1.275200             1.599312             1552.000000          3723.264000         
model.layers.1.post_attention_layernorm       torch.Size([1, 5, 2048])       0.921632             1.306057             1467.345455          3723.264000         
model.layers.1.mlp.gate                       torch.Size([5, 60])            0.572480             0.967979             1397.088000          3666.216000         
model.layers.1.mlp.experts.0.gate_proj        torch.Size([2, 1408])          0.999424             1.366138             1259.072000          3724.800000         
model.layers.1.mlp.experts.0.act_fn           torch.Size([2, 1408])          0.309536             0.711679             1241.702400          3880.000000         
model.layers.1.mlp.experts.0.up_proj          torch.Size([2, 1408])          0.958112             1.253605             1241.600000          3945.344000         
model.layers.1.mlp.experts.0.down_proj        torch.Size([2, 2048])          1.381568             1.683712             1338.600000          4033.536000         
model.layers.1.mlp.experts.1.gate_proj        torch.Size([0, 1408])          0.480128             0.949383             1319.200000          3878.800000         
model.layers.1.mlp.experts.1.act_fn           torch.Size([0, 1408])          0.282528             0.664711             1241.941333          3880.000000         
model.layers.1.mlp.experts.1.up_proj          torch.Size([0, 1408])          0.457440             0.828266             1242.112000          3880.000000         
model.layers.1.mlp.experts.1.down_proj        torch.Size([0, 2048])          0.451392             0.825644             1086.848000          3880.000000         
model.layers.1.mlp.experts.2.gate_proj        torch.Size([0, 1408])          0.475872             0.845432             1086.848000          3880.000000         
model.layers.1.mlp.experts.2.act_fn           torch.Size([0, 1408])          0.276704             0.670195             1086.848000          3880.000000         
model.layers.1.mlp.experts.2.up_proj          torch.Size([0, 1408])          0.465824             0.855446             931.584000           3880.800000         
model.layers.1.mlp.experts.2.down_proj        torch.Size([0, 2048])          0.455904             0.874281             931.584000           3881.600000         
model.layers.1.mlp.experts.3.gate_proj        torch.Size([0, 1408])          0.005632             1.271009             931.872000           3881.600000         
model.layers.1.mlp.experts.3.act_fn           torch.Size([0, 1408])          0.476128             0.866413             776.640000           3933.354667         
model.layers.1.mlp.experts.3.up_proj          torch.Size([0, 1408])          0.636864             1.014471             776.560000           4036.864000         
model.layers.1.mlp.experts.3.down_proj        torch.Size([0, 2048])          0.508864             0.911951             776.320000           4192.128000         
model.layers.1.mlp.experts.4.gate_proj        torch.Size([0, 1408])          0.757792             1.180410             776.640000           4114.496000         
model.layers.1.mlp.experts.4.act_fn           torch.Size([0, 1408])          0.325504             0.714540             737.808000           4036.864000         
model.layers.1.mlp.experts.4.up_proj          torch.Size([0, 1408])          1.132768             1.534700             621.312000           4036.864000         
model.layers.1.mlp.experts.4.down_proj        torch.Size([0, 2048])          0.560000             1.066446             621.312000           4036.864000         
model.layers.1.mlp.experts.5.gate_proj        torch.Size([0, 1408])          0.533888             0.939846             621.312000           4005.811200         
model.layers.1.mlp.experts.5.act_fn           torch.Size([0, 1408])          0.324768             0.746250             621.312000           3959.232000         
model.layers.1.mlp.experts.5.up_proj          torch.Size([0, 1408])          0.523168             0.898838             621.312000           3882.880000         
model.layers.1.mlp.experts.5.down_proj        torch.Size([0, 2048])          0.536000             0.913143             621.312000           3883.200000         
model.layers.1.mlp.experts.6.gate_proj        torch.Size([0, 1408])          0.493792             0.905752             621.440000           3883.200000         
model.layers.1.mlp.experts.6.act_fn           torch.Size([0, 1408])          0.306848             0.689983             621.568000           3883.200000         
model.layers.1.mlp.experts.6.up_proj          torch.Size([0, 1408])          0.485600             0.869513             466.176000           3883.200000         
model.layers.1.mlp.experts.6.down_proj        torch.Size([0, 2048])          0.551968             0.953197             466.080000           3960.864000         
model.layers.1.mlp.experts.7.gate_proj        torch.Size([0, 1408])          0.556128             0.977278             465.984000           4038.528000         
model.layers.1.mlp.experts.7.act_fn           torch.Size([0, 1408])          0.377088             0.783682             465.984000           4193.856000         
model.layers.1.mlp.experts.7.up_proj          torch.Size([0, 1408])          0.502624             0.908136             465.984000           4193.856000         
model.layers.1.mlp.experts.7.down_proj        torch.Size([0, 2048])          0.494496             0.912189             465.984000           4155.024000         
model.layers.1.mlp.experts.8.gate_proj        torch.Size([0, 1408])          0.524768             0.936747             465.984000           4077.360000         
model.layers.1.mlp.experts.8.act_fn           torch.Size([0, 1408])          0.289472             0.675917             465.984000           4038.528000         
model.layers.1.mlp.experts.8.up_proj          torch.Size([0, 1408])          0.481664             0.850439             466.137600           4038.528000         
model.layers.1.mlp.experts.8.down_proj        torch.Size([0, 2048])          0.493312             0.916004             466.176000           3922.032000         
model.layers.1.mlp.experts.9.gate_proj        torch.Size([0, 1408])          0.483936             0.856400             466.176000           3909.088000         
model.layers.1.mlp.experts.9.act_fn           torch.Size([0, 1408])          0.287424             0.752687             466.176000           3883.200000         
model.layers.1.mlp.experts.9.up_proj          torch.Size([0, 1408])          0.473984             0.853539             466.176000           3883.200000         
model.layers.1.mlp.experts.9.down_proj        torch.Size([0, 2048])          0.464032             0.841379             466.176000           3883.200000         
model.layers.1.mlp.experts.10.gate_proj       torch.Size([0, 1408])          0.508608             1.013041             466.176000           3883.200000         
model.layers.1.mlp.experts.10.act_fn          torch.Size([0, 1408])          0.330400             0.730038             466.176000           3883.200000         
model.layers.1.mlp.experts.10.up_proj         torch.Size([0, 1408])          0.486176             0.855684             466.176000           3883.200000         
model.layers.1.mlp.experts.10.down_proj       torch.Size([0, 2048])          0.547584             0.913382             466.176000           3883.200000         
model.layers.1.mlp.experts.11.gate_proj       torch.Size([0, 1408])          0.477120             0.909567             466.176000           3883.200000         
model.layers.1.mlp.experts.11.act_fn          torch.Size([0, 1408])          0.290912             0.675678             466.176000           3883.200000         
model.layers.1.mlp.experts.11.up_proj         torch.Size([0, 1408])          0.475552             0.909567             466.176000           3883.200000         
model.layers.1.mlp.experts.11.down_proj       torch.Size([0, 2048])          0.474560             0.837564             466.176000           3883.200000         
model.layers.1.mlp.experts.12.gate_proj       torch.Size([1, 1408])          0.965472             1.295328             466.176000           3805.536000         
model.layers.1.mlp.experts.12.act_fn          torch.Size([1, 1408])          0.333792             0.706196             466.176000           3758.937600         
model.layers.1.mlp.experts.12.up_proj         torch.Size([1, 1408])          0.900288             1.225948             582.592000           3727.872000         
model.layers.1.mlp.experts.12.down_proj       torch.Size([1, 2048])          1.097408             1.435757             660.144000           3726.912000         
model.layers.1.mlp.experts.13.gate_proj       torch.Size([0, 1408])          0.488544             0.865936             745.574400           3726.336000         
model.layers.1.mlp.experts.13.act_fn          torch.Size([0, 1408])          0.362592             0.727177             621.312000           3881.600000         
model.layers.1.mlp.experts.13.up_proj         torch.Size([0, 1408])          0.471712             0.837803             621.312000           4067.916800         
model.layers.1.mlp.experts.13.down_proj       torch.Size([0, 2048])          0.460256             0.826597             621.209600           4347.392000         
model.layers.1.mlp.experts.14.gate_proj       torch.Size([0, 1408])          0.501664             0.961781             621.056000           4502.656000         
model.layers.1.mlp.experts.14.act_fn          torch.Size([0, 1408])          0.291296             0.686169             621.056000           4554.410667         
model.layers.1.mlp.experts.14.up_proj         torch.Size([0, 1408])          0.465120             0.833273             621.158400           4502.656000         
model.layers.1.mlp.experts.14.down_proj       torch.Size([0, 2048])          0.459104             0.877142             621.312000           4378.444800         
model.layers.1.mlp.experts.15.gate_proj       torch.Size([0, 1408])          0.466592             0.840902             543.648000           4269.760000         
model.layers.1.mlp.experts.15.act_fn          torch.Size([0, 1408])          0.284032             0.650883             465.984000           4192.128000         
model.layers.1.mlp.experts.15.up_proj         torch.Size([0, 1408])          0.528544             0.887156             465.984000           4192.128000         
model.layers.1.mlp.experts.15.down_proj       torch.Size([0, 2048])          0.480288             0.857353             465.984000           4192.128000         
model.layers.1.mlp.experts.16.gate_proj       torch.Size([0, 1408])          0.463552             0.833273             465.984000           4114.496000         
model.layers.1.mlp.experts.16.act_fn          torch.Size([0, 1408])          0.338272             0.696898             465.984000           4036.864000         
model.layers.1.mlp.experts.16.up_proj         torch.Size([0, 1408])          0.461504             0.820875             465.984000           4038.528000         
model.layers.1.mlp.experts.16.down_proj       torch.Size([0, 2048])          0.486144             0.849009             465.984000           4038.528000         
model.layers.1.mlp.experts.17.gate_proj       torch.Size([0, 1408])          0.511200             0.938177             465.984000           3999.696000         
model.layers.1.mlp.experts.17.act_fn          torch.Size([0, 1408])          0.279648             0.656128             465.984000           4038.528000         
model.layers.1.mlp.experts.17.up_proj         torch.Size([0, 1408])          0.461152             0.825882             465.984000           3914.265600         
model.layers.1.mlp.experts.17.down_proj       torch.Size([0, 2048])          0.456128             0.878572             466.032000           3883.200000         
model.layers.1.mlp.experts.18.gate_proj       torch.Size([0, 1408])          0.469760             0.863552             466.176000           3883.200000         
model.layers.1.mlp.experts.18.act_fn          torch.Size([0, 1408])          0.270048             0.639200             466.176000           3883.200000         
model.layers.1.mlp.experts.18.up_proj         torch.Size([0, 1408])          0.511712             0.874043             466.176000           3805.536000         
model.layers.1.mlp.experts.18.down_proj       torch.Size([0, 2048])          0.442336             0.814199             466.176000           3766.704000         
model.layers.1.mlp.experts.19.gate_proj       torch.Size([0, 1408])          0.500608             0.866413             466.176000           3727.872000         
model.layers.1.mlp.experts.19.act_fn          torch.Size([0, 1408])          0.364480             0.729799             466.176000           3727.872000         
model.layers.1.mlp.experts.19.up_proj         torch.Size([0, 1408])          0.461248             0.823975             466.176000           3727.872000         
model.layers.1.mlp.experts.19.down_proj       torch.Size([0, 2048])          0.458368             0.824928             466.176000           3727.872000         
model.layers.1.mlp.experts.20.gate_proj       torch.Size([0, 1408])          0.530144             0.902414             466.176000           3883.200000         
model.layers.1.mlp.experts.20.act_fn          torch.Size([0, 1408])          0.284960             0.651598             466.176000           3883.200000         
model.layers.1.mlp.experts.20.up_proj         torch.Size([0, 1408])          0.496960             0.856638             466.176000           4007.462400         
model.layers.1.mlp.experts.20.down_proj       torch.Size([0, 2048])          0.464736             0.827074             466.080000           4038.528000         
model.layers.1.mlp.experts.21.gate_proj       torch.Size([0, 1408])          0.463328             0.836134             466.176000           4038.528000         
model.layers.1.mlp.experts.21.act_fn          torch.Size([0, 1408])          0.285984             0.644207             466.176000           4038.528000         
model.layers.1.mlp.experts.21.up_proj         torch.Size([0, 1408])          0.519072             0.877857             466.176000           3922.032000         
model.layers.1.mlp.experts.21.down_proj       torch.Size([0, 2048])          0.510720             0.887632             466.176000           3883.200000         
model.layers.1.mlp.experts.22.gate_proj       torch.Size([1, 1408])          0.928128             1.224041             466.056000           3883.200000         
model.layers.1.mlp.experts.22.act_fn          torch.Size([1, 1408])          0.490432             0.857592             465.984000           3883.200000         
model.layers.1.mlp.experts.22.up_proj         torch.Size([1, 1408])          0.903072             1.196146             576.932571           3882.285714         
model.layers.1.mlp.experts.22.down_proj       torch.Size([1, 2048])          1.054144             1.349211             660.144000           3842.784000         
model.layers.1.mlp.experts.23.gate_proj       torch.Size([1, 1408])          0.892512             1.192331             776.594286           3770.697143         
model.layers.1.mlp.experts.23.act_fn          torch.Size([1, 1408])          0.312128             0.679493             776.640000           3726.336000         
model.layers.1.mlp.experts.23.up_proj         torch.Size([1, 1408])          0.918720             1.212597             776.360000           3726.336000         
model.layers.1.mlp.experts.23.down_proj       torch.Size([1, 2048])          1.062432             1.371622             914.332444           3724.970667         
model.layers.1.mlp.experts.24.gate_proj       torch.Size([0, 1408])          0.479136             0.917435             931.584000           3725.414400         
model.layers.1.mlp.experts.24.act_fn          torch.Size([0, 1408])          0.288192             0.648499             931.584000           3726.336000         
model.layers.1.mlp.experts.24.up_proj         torch.Size([0, 1408])          0.469888             0.831604             776.640000           3726.336000         
model.layers.1.mlp.experts.24.down_proj       torch.Size([0, 2048])          0.449600             0.873804             776.640000           3726.336000         
model.layers.1.mlp.experts.25.gate_proj       torch.Size([0, 1408])          0.474432             0.839710             776.640000           3726.336000         
model.layers.1.mlp.experts.25.act_fn          torch.Size([0, 1408])          0.286944             0.646353             776.640000           3726.336000         
model.layers.1.mlp.experts.25.up_proj         torch.Size([0, 1408])          0.511360             0.874758             776.640000           3726.336000         
model.layers.1.mlp.experts.25.down_proj       torch.Size([0, 2048])          0.467552             0.828981             621.312000           3695.884800         
model.layers.1.mlp.experts.26.gate_proj       torch.Size([0, 1408])          0.494560             0.863075             621.312000           3727.872000         
model.layers.1.mlp.experts.26.act_fn          torch.Size([0, 1408])          0.342112             0.704288             621.312000           3727.872000         
model.layers.1.mlp.experts.26.up_proj         torch.Size([0, 1408])          0.460288             0.827789             621.312000           3727.872000         
model.layers.1.mlp.experts.26.down_proj       torch.Size([0, 2048])          0.465632             0.830173             621.312000           3882.800000         
model.layers.1.mlp.experts.27.gate_proj       torch.Size([0, 1408])          0.526496             0.894785             621.312000           3881.600000         
model.layers.1.mlp.experts.27.act_fn          torch.Size([0, 1408])          0.289216             0.654459             621.312000           3985.109333         
model.layers.1.mlp.experts.27.up_proj         torch.Size([0, 1408])          0.462528             0.855207             517.760000           3883.200000         
model.layers.1.mlp.experts.27.down_proj       torch.Size([0, 2048])          0.457024             0.821114             465.984000           3883.200000         
model.layers.1.mlp.experts.28.gate_proj       torch.Size([0, 1408])          0.465568             0.835657             466.060800           3883.200000         
model.layers.1.mlp.experts.28.act_fn          torch.Size([0, 1408])          0.267584             0.640869             466.176000           3883.200000         
model.layers.1.mlp.experts.28.up_proj         torch.Size([0, 1408])          0.493280             0.853539             466.176000           3844.368000         
model.layers.1.mlp.experts.28.down_proj       torch.Size([0, 2048])          0.494688             0.851393             466.176000           3766.704000         
model.layers.1.mlp.experts.29.gate_proj       torch.Size([1, 1408])          0.895104             1.198530             504.912000           3785.920000         
model.layers.1.mlp.experts.29.act_fn          torch.Size([1, 1408])          0.349600             0.714540             621.312000           3881.600000         
model.layers.1.mlp.experts.29.up_proj         torch.Size([1, 1408])          0.884384             1.173735             621.312000           3998.048000         
model.layers.1.mlp.experts.29.down_proj       torch.Size([1, 2048])          1.041120             1.353502             698.976000           4036.864000         
model.layers.1.mlp.experts.30.gate_proj       torch.Size([1, 1408])          0.865792             1.164675             776.400000           4035.408000         
model.layers.1.mlp.experts.30.act_fn          torch.Size([1, 1408])          0.288416             0.667572             776.320000           4035.200000         
model.layers.1.mlp.experts.30.up_proj         torch.Size([1, 1408])          0.857824             1.155138             834.544000           4035.200000         
model.layers.1.mlp.experts.30.down_proj       torch.Size([1, 2048])          1.046816             1.345873             931.584000           4035.200000         
model.layers.1.mlp.experts.31.gate_proj       torch.Size([1, 1408])          0.860928             1.186609             931.584000           4035.200000         
model.layers.1.mlp.experts.31.act_fn          torch.Size([1, 1408])          0.290368             0.660658             931.584000           4035.200000         
model.layers.1.mlp.experts.31.up_proj         torch.Size([1, 1408])          0.920000             1.236916             948.835556           3983.466667         
model.layers.1.mlp.experts.31.down_proj       torch.Size([1, 2048])          1.230272             1.591206             1067.440000          3880.000000         
model.layers.1.mlp.experts.32.gate_proj       torch.Size([0, 1408])          0.477024             0.853539             1048.032000          3880.000000         
model.layers.1.mlp.experts.32.act_fn          torch.Size([0, 1408])          0.343968             0.746727             931.584000           3880.000000         
model.layers.1.mlp.experts.32.up_proj         torch.Size([0, 1408])          0.529824             0.939131             931.584000           3880.000000         
model.layers.1.mlp.experts.32.down_proj       torch.Size([0, 2048])          0.482048             0.852823             931.584000           3880.000000         
model.layers.1.mlp.experts.33.gate_proj       torch.Size([0, 1408])          0.512224             0.941038             776.400000           4036.448000         
model.layers.1.mlp.experts.33.act_fn          torch.Size([0, 1408])          0.283456             0.686884             776.320000           4036.864000         
model.layers.1.mlp.experts.33.up_proj         torch.Size([0, 1408])          0.543264             0.960827             776.448000           4191.782400         
model.layers.1.mlp.experts.33.down_proj       torch.Size([0, 2048])          0.668416             1.103640             737.808000           4075.680000         
model.layers.1.mlp.experts.34.gate_proj       torch.Size([2, 1408])          1.059136             1.390457             759.381333           4036.864000         
model.layers.1.mlp.experts.34.act_fn          torch.Size([2, 1408])          0.345376             0.860453             776.640000           3974.758400         
model.layers.1.mlp.experts.34.up_proj         torch.Size([2, 1408])          0.978688             1.309872             776.533333           3881.600000         
model.layers.1.mlp.experts.34.down_proj       torch.Size([2, 2048])          1.400640             1.719236             873.360000           3880.800000         
model.layers.1.mlp.experts.35.gate_proj       torch.Size([1, 1408])          0.934752             1.297951             931.584000           3880.000000         
model.layers.1.mlp.experts.35.act_fn          torch.Size([1, 1408])          0.378112             0.767708             931.584000           3848.960000         
model.layers.1.mlp.experts.35.up_proj         torch.Size([1, 1408])          0.890912             1.194954             931.584000           3821.800000         
model.layers.1.mlp.experts.35.down_proj       torch.Size([1, 2048])          1.050752             1.368046             1020.242286          3924.342857         
model.layers.1.mlp.experts.36.gate_proj       torch.Size([1, 1408])          0.925728             1.245022             1086.400000          4188.909714         
model.layers.1.mlp.experts.36.act_fn          torch.Size([1, 1408])          0.335968             0.764132             1086.400000          4343.808000         
model.layers.1.mlp.experts.36.up_proj         torch.Size([1, 1408])          0.980480             1.475811             1086.400000          4343.808000         
model.layers.1.mlp.experts.36.down_proj       torch.Size([1, 2048])          1.060544             1.362324             1086.400000          4309.333333         
model.layers.1.mlp.experts.37.gate_proj       torch.Size([0, 1408])          0.497472             0.887871             1086.400000          4227.456000         
model.layers.1.mlp.experts.37.act_fn          torch.Size([0, 1408])          0.281312             0.643969             1086.400000          4189.248000         
model.layers.1.mlp.experts.37.up_proj         torch.Size([0, 1408])          0.452256             0.830889             931.392000           4190.400000         
model.layers.1.mlp.experts.37.down_proj       torch.Size([0, 2048])          0.500768             0.864744             931.584000           4112.800000         
model.layers.1.mlp.experts.38.gate_proj       torch.Size([0, 1408])          0.469024             0.881672             892.768000           4035.200000         
model.layers.1.mlp.experts.38.act_fn          torch.Size([0, 1408])          0.271648             0.638485             776.320000           4035.200000         
model.layers.1.mlp.experts.38.up_proj         torch.Size([0, 1408])          0.607040             1.036167             776.320000           4036.448000         
model.layers.1.mlp.experts.38.down_proj       torch.Size([0, 2048])          0.458656             0.833511             776.480000           4036.864000         
model.layers.1.mlp.experts.39.gate_proj       torch.Size([0, 1408])          0.457216             0.844002             776.640000           4036.864000         
model.layers.1.mlp.experts.39.act_fn          torch.Size([0, 1408])          0.273184             0.671864             673.088000           4192.128000         
model.layers.1.mlp.experts.39.up_proj         torch.Size([0, 1408])          0.480992             0.850439             621.312000           4192.128000         
model.layers.1.mlp.experts.39.down_proj       torch.Size([0, 2048])          0.450688             0.840187             621.312000           4192.128000         
model.layers.1.mlp.experts.40.gate_proj       torch.Size([0, 1408])          0.459648             0.839710             621.312000           4192.128000         
model.layers.1.mlp.experts.40.act_fn          torch.Size([0, 1408])          0.271776             0.634432             621.312000           4192.128000         
model.layers.1.mlp.experts.40.up_proj         torch.Size([0, 1408])          0.450272             0.813961             621.312000           4153.312000         
model.layers.1.mlp.experts.40.down_proj       torch.Size([0, 2048])          0.504896             0.895977             621.312000           4036.864000         
model.layers.1.mlp.experts.41.gate_proj       torch.Size([0, 1408])          0.460736             0.829458             504.816000           4036.864000         
model.layers.1.mlp.experts.41.act_fn          torch.Size([0, 1408])          0.275456             0.632048             465.984000           4036.864000         
model.layers.1.mlp.experts.41.up_proj         torch.Size([0, 1408])          0.514848             0.887156             465.984000           3999.280000         
model.layers.1.mlp.experts.41.down_proj       torch.Size([0, 2048])          0.451520             0.808477             465.984000           3883.200000         
model.layers.1.mlp.experts.42.gate_proj       torch.Size([1, 1408])          0.908576             1.307726             543.648000           3881.800000         
model.layers.1.mlp.experts.42.act_fn          torch.Size([1, 1408])          0.298688             0.667095             621.312000           3881.600000         
model.layers.1.mlp.experts.42.up_proj         torch.Size([1, 1408])          0.876768             1.173496             621.312000           3842.784000         
model.layers.1.mlp.experts.42.down_proj       torch.Size([1, 2048])          1.035104             1.334667             718.392000           3765.152000         
model.layers.1.mlp.experts.43.gate_proj       torch.Size([1, 1408])          0.884864             1.186609             776.400000           3881.600000         
model.layers.1.mlp.experts.43.act_fn          torch.Size([1, 1408])          0.295872             0.661135             776.640000           3881.600000         
model.layers.1.mlp.experts.43.up_proj         torch.Size([1, 1408])          0.859936             1.170635             776.640000           3847.096889         
model.layers.1.mlp.experts.43.down_proj       torch.Size([1, 2048])          1.009856             1.294136             892.808000           3724.992000         
model.layers.1.mlp.experts.44.gate_proj       torch.Size([1, 1408])          0.876320             1.167774             931.584000           3724.800000         
model.layers.1.mlp.experts.44.act_fn          torch.Size([1, 1408])          0.299424             0.676155             931.584000           3724.800000         
model.layers.1.mlp.experts.44.up_proj         torch.Size([1, 1408])          0.870496             1.155615             931.584000           3724.800000         
model.layers.1.mlp.experts.44.down_proj       torch.Size([1, 2048])          1.017888             1.308203             989.808000           3724.800000         
model.layers.1.mlp.experts.45.gate_proj       torch.Size([0, 1408])          0.464192             0.854492             1009.216000          3686.000000         
model.layers.1.mlp.experts.45.act_fn          torch.Size([0, 1408])          0.274528             0.696421             931.584000           3724.800000         
model.layers.1.mlp.experts.45.up_proj         torch.Size([0, 1408])          0.451360             0.827789             931.584000           3802.400000         
model.layers.1.mlp.experts.45.down_proj       torch.Size([0, 2048])          0.446208             0.823259             853.952000           3881.200000         
model.layers.1.mlp.experts.46.gate_proj       torch.Size([0, 1408])          0.508512             0.949144             776.320000           4036.448000         
model.layers.1.mlp.experts.46.act_fn          torch.Size([0, 1408])          0.302304             0.669003             776.320000           4036.864000         
model.layers.1.mlp.experts.46.up_proj         torch.Size([0, 1408])          0.455040             0.822544             776.576000           3912.652800         
model.layers.1.mlp.experts.46.down_proj       torch.Size([0, 2048])          0.451936             0.883579             714.508800           3881.600000         
model.layers.1.mlp.experts.47.gate_proj       torch.Size([0, 1408])          0.455552             0.825405             621.312000           3881.600000         
model.layers.1.mlp.experts.47.act_fn          torch.Size([0, 1408])          0.299072             0.660896             621.312000           3726.336000         
model.layers.1.mlp.experts.47.up_proj         torch.Size([0, 1408])          0.519328             0.880957             621.354667           3727.616000         
model.layers.1.mlp.experts.47.down_proj       torch.Size([0, 2048])          0.445856             0.818253             621.568000           3727.872000         
model.layers.1.mlp.experts.48.gate_proj       torch.Size([0, 1408])          0.457632             0.823975             621.568000           3727.872000         
model.layers.1.mlp.experts.48.act_fn          torch.Size([0, 1408])          0.332096             0.698090             621.568000           3727.872000         
model.layers.1.mlp.experts.48.up_proj         torch.Size([0, 1408])          0.455968             0.817776             466.176000           3727.872000         
model.layers.1.mlp.experts.48.down_proj       torch.Size([0, 2048])          0.448768             0.856876             466.176000           3650.208000         
model.layers.1.mlp.experts.49.gate_proj       torch.Size([0, 1408])          0.514464             0.885963             466.176000           3611.376000         
model.layers.1.mlp.experts.49.act_fn          torch.Size([0, 1408])          0.270112             0.634432             466.176000           3689.040000         
model.layers.1.mlp.experts.49.up_proj         torch.Size([0, 1408])          0.449536             0.813246             466.176000           3611.376000         
model.layers.1.mlp.experts.49.down_proj       torch.Size([0, 2048])          0.445248             0.809908             466.176000           3634.675200         
model.layers.1.mlp.experts.50.gate_proj       torch.Size([0, 1408])          0.492896             0.864029             466.176000           3603.609600         
model.layers.1.mlp.experts.50.act_fn          torch.Size([0, 1408])          0.272288             0.639200             466.176000           3572.544000         
model.layers.1.mlp.experts.50.up_proj         torch.Size([0, 1408])          0.447936             0.812292             466.176000           3572.544000         
model.layers.1.mlp.experts.50.down_proj       torch.Size([0, 2048])          0.446432             0.814199             466.176000           3572.544000         
model.layers.1.mlp.experts.51.gate_proj       torch.Size([0, 1408])          0.486944             0.872612             466.176000           3572.544000         
model.layers.1.mlp.experts.51.act_fn          torch.Size([0, 1408])          0.299712             0.665426             466.176000           3572.544000         
model.layers.1.mlp.experts.51.up_proj         torch.Size([0, 1408])          0.736000             1.098871             466.176000           3572.544000         
model.layers.1.mlp.experts.51.down_proj       torch.Size([0, 2048])          0.457792             0.835419             466.176000           3572.544000         
model.layers.1.mlp.experts.52.gate_proj       torch.Size([0, 1408])          0.514272             0.882149             466.176000           3603.609600         
model.layers.1.mlp.experts.52.act_fn          torch.Size([0, 1408])          0.269856             0.628948             466.176000           3727.872000         
model.layers.1.mlp.experts.52.up_proj         torch.Size([0, 1408])          0.476032             0.836134             466.176000           3960.864000         
model.layers.1.mlp.experts.52.down_proj       torch.Size([0, 2048])          0.448256             0.846386             388.480000           4155.024000         
model.layers.1.mlp.experts.53.gate_proj       torch.Size([0, 1408])          0.462624             0.828028             310.784000           4162.790400         
model.layers.1.mlp.experts.53.act_fn          torch.Size([0, 1408])          0.277888             0.639677             310.784000           4142.080000         
model.layers.1.mlp.experts.53.up_proj         torch.Size([0, 1408])          0.455264             0.817776             310.784000           4116.192000         
model.layers.1.mlp.experts.53.down_proj       torch.Size([0, 2048])          0.453440             0.829458             310.784000           4038.528000         
model.layers.1.mlp.experts.54.gate_proj       torch.Size([2, 1408])          0.981024             1.286030             446.680000           4038.528000         
model.layers.1.mlp.experts.54.act_fn          torch.Size([2, 1408])          0.357696             0.741005             465.984000           4038.528000         
model.layers.1.mlp.experts.54.up_proj         torch.Size([2, 1408])          0.938464             1.224756             524.232000           3959.648000         
model.layers.1.mlp.experts.54.down_proj       torch.Size([2, 2048])          1.392864             1.685619             660.144000           3881.600000         
model.layers.1.mlp.experts.55.gate_proj       torch.Size([2, 1408])          0.947872             1.262665             776.640000           3881.600000         
model.layers.1.mlp.experts.55.act_fn          torch.Size([2, 1408])          0.292640             0.661612             776.640000           3881.600000         
model.layers.1.mlp.experts.55.up_proj         torch.Size([2, 1408])          0.940896             1.290560             893.136000           3881.600000         
model.layers.1.mlp.experts.55.down_proj       torch.Size([2, 2048])          1.409632             1.701832             970.448000           3880.400000         
model.layers.1.mlp.experts.56.gate_proj       torch.Size([1, 1408])          0.908064             1.214027             1086.848000          3880.000000         
model.layers.1.mlp.experts.56.act_fn          torch.Size([1, 1408])          0.298944             0.674486             1086.848000          3880.000000         
model.layers.1.mlp.experts.56.up_proj         torch.Size([1, 1408])          0.867744             1.148701             1086.848000          3841.200000         
model.layers.1.mlp.experts.56.down_proj       torch.Size([1, 2048])          1.049216             1.347303             1086.848000          3783.000000         
model.layers.1.mlp.experts.57.gate_proj       torch.Size([0, 1408])          0.483616             0.915289             1086.848000          3724.800000         
model.layers.1.mlp.experts.57.act_fn          torch.Size([0, 1408])          0.279936             0.655651             1086.848000          3724.800000         
model.layers.1.mlp.experts.57.up_proj         torch.Size([0, 1408])          0.475488             0.839233             1086.848000          3725.952000         
model.layers.1.mlp.experts.57.down_proj       torch.Size([0, 2048])          0.457376             0.832796             931.891200           3726.336000         
model.layers.1.mlp.experts.58.gate_proj       torch.Size([0, 1408])          0.510048             0.881672             931.968000           3726.336000         
model.layers.1.mlp.experts.58.act_fn          torch.Size([0, 1408])          0.275616             0.671864             931.968000           3726.336000         
model.layers.1.mlp.experts.58.up_proj         torch.Size([0, 1408])          0.469504             0.837564             776.640000           3726.336000         
model.layers.1.mlp.experts.58.down_proj       torch.Size([0, 2048])          0.452544             0.890732             776.640000           3881.600000         
model.layers.1.mlp.experts.59.gate_proj       torch.Size([0, 1408])          0.495328             0.889063             776.640000           3881.600000         
model.layers.1.mlp.experts.59.act_fn          torch.Size([0, 1408])          0.306656             0.689745             776.640000           4036.864000         
model.layers.1.mlp.experts.59.up_proj         torch.Size([0, 1408])          0.482880             0.861883             660.144000           3959.232000         
model.layers.1.mlp.experts.59.down_proj       torch.Size([0, 2048])          0.453408             0.866652             621.312000           3920.416000         
model.layers.1.mlp.shared_expert.gate_proj    torch.Size([5, 5632])          2.666048             2.988100             793.735111           3881.244444         
model.layers.1.mlp.shared_expert.act_fn       torch.Size([5, 5632])          0.313504             0.673771             1086.848000          3880.000000         
model.layers.1.mlp.shared_expert.up_proj      torch.Size([5, 5632])          2.613888             2.912521             1175.277714          3879.314286         
model.layers.1.mlp.shared_expert.down_proj    torch.Size([5, 2048])          2.721376             3.020525             1551.576000          3838.832000         
model.layers.1.mlp.shared_expert_gate         torch.Size([5, 1])             0.555744             0.925064             1772.982857          3876.800000         
model.layers.2.input_layernorm                torch.Size([1, 5, 2048])       0.916800             1.346588             1632.621714          4017.420190         
model.layers.2.self_attn.q_proj               torch.Size([1, 5, 2048])       1.341888             1.640081             1620.309333          3963.690667         
model.layers.2.self_attn.k_proj               torch.Size([1, 5, 2048])       1.293152             1.591206             1706.496000          3876.800000         
model.layers.2.self_attn.v_proj               torch.Size([1, 5, 2048])       1.251008             1.545906             1725.888000          3876.800000         
model.layers.2.self_attn.o_proj               torch.Size([1, 5, 2048])       1.265792             1.573324             1809.920000          3876.800000         
model.layers.2.post_attention_layernorm       torch.Size([1, 5, 2048])       0.919904             1.318932             1706.657524          3848.240762         
model.layers.2.mlp.gate                       torch.Size([5, 60])            0.567744             0.950813             1552.000000          3723.264000         
model.layers.2.mlp.experts.0.gate_proj        torch.Size([1, 1408])          0.893376             1.198053             1552.000000          3723.264000         
model.layers.2.mlp.experts.0.act_fn           torch.Size([1, 1408])          0.302464             0.688553             1520.960000          3723.878400         
model.layers.2.mlp.experts.0.up_proj          torch.Size([1, 1408])          0.858208             1.147032             1396.800000          3724.800000         
model.layers.2.mlp.experts.0.down_proj        torch.Size([1, 2048])          1.057056             1.350641             1493.800000          3724.224000         
model.layers.2.mlp.experts.1.gate_proj        torch.Size([0, 1408])          0.467840             0.849009             1427.840000          3848.332800         
model.layers.2.mlp.experts.1.act_fn           torch.Size([0, 1408])          0.279392             0.648260             1396.800000          3880.000000         
model.layers.2.mlp.experts.1.up_proj          torch.Size([0, 1408])          0.454976             0.838995             1280.400000          4035.200000         
model.layers.2.mlp.experts.1.down_proj        torch.Size([0, 2048])          0.593568             1.007795             1241.856000          4035.200000         
model.layers.2.mlp.experts.2.gate_proj        torch.Size([0, 1408])          0.540928             0.921249             1125.664000          4035.200000         
model.layers.2.mlp.experts.2.act_fn           torch.Size([0, 1408])          0.319040             0.694513             1086.848000          3983.466667         
model.layers.2.mlp.experts.2.up_proj          torch.Size([0, 1408])          0.466464             0.840664             1086.848000          3957.600000         
model.layers.2.mlp.experts.2.down_proj        torch.Size([0, 2048])          0.473984             0.875235             962.636800           3881.600000         
model.layers.2.mlp.experts.3.gate_proj        torch.Size([0, 1408])          0.461312             0.831604             931.584000           3881.600000         
model.layers.2.mlp.experts.3.act_fn           torch.Size([0, 1408])          0.337632             0.728846             931.968000           3842.784000         
model.layers.2.mlp.experts.3.up_proj          torch.Size([0, 1408])          0.452160             0.812531             931.968000           3842.784000         
model.layers.2.mlp.experts.3.down_proj        torch.Size([0, 2048])          0.475424             0.850677             776.640000           3803.968000         
model.layers.2.mlp.experts.4.gate_proj        torch.Size([0, 1408])          0.522208             0.890017             776.640000           3726.336000         
model.layers.2.mlp.experts.4.act_fn           torch.Size([0, 1408])          0.279008             0.639915             776.640000           3881.600000         
model.layers.2.mlp.experts.4.up_proj          torch.Size([0, 1408])          0.456768             0.816822             776.640000           4036.864000         
model.layers.2.mlp.experts.4.down_proj        torch.Size([0, 2048])          0.452256             0.823975             776.640000           4153.312000         
model.layers.2.mlp.experts.5.gate_proj        torch.Size([0, 1408])          0.458176             0.842810             660.144000           4075.680000         
model.layers.2.mlp.experts.5.act_fn           torch.Size([0, 1408])          0.271712             0.633478             621.312000           4036.864000         
model.layers.2.mlp.experts.5.up_proj          torch.Size([0, 1408])          0.447392             0.875473             621.312000           4036.864000         
model.layers.2.mlp.experts.5.down_proj        torch.Size([0, 2048])          0.447776             0.824690             621.312000           3975.078400         
model.layers.2.mlp.experts.6.gate_proj        torch.Size([0, 1408])          0.460000             0.857353             621.312000           3908.544000         
model.layers.2.mlp.experts.6.act_fn           torch.Size([0, 1408])          0.269920             0.688076             621.312000           3883.200000         
model.layers.2.mlp.experts.6.up_proj          torch.Size([0, 1408])          0.788896             1.184225             621.312000           3883.200000         
model.layers.2.mlp.experts.6.down_proj        torch.Size([0, 2048])          0.519680             0.912428             621.363200           3883.200000         
model.layers.2.mlp.experts.7.gate_proj        torch.Size([0, 1408])          0.477408             0.930071             621.568000           3883.200000         
model.layers.2.mlp.experts.7.act_fn           torch.Size([0, 1408])          0.274560             0.659943             621.568000           3883.200000         
model.layers.2.mlp.experts.7.up_proj          torch.Size([0, 1408])          0.502368             0.866413             621.568000           3883.200000         
model.layers.2.mlp.experts.7.down_proj        torch.Size([0, 2048])          0.509792             0.906706             621.568000           3883.200000         
model.layers.2.mlp.experts.8.gate_proj        torch.Size([0, 1408])          0.476576             0.863791             517.760000           4038.528000         
model.layers.2.mlp.experts.8.act_fn           torch.Size([0, 1408])          0.277632             0.665665             465.984000           4038.528000         
model.layers.2.mlp.experts.8.up_proj          torch.Size([0, 1408])          0.529088             0.891924             465.984000           4193.856000         
model.layers.2.mlp.experts.8.down_proj        torch.Size([0, 2048])          0.460832             0.819206             465.984000           4100.659200         
model.layers.2.mlp.experts.9.gate_proj        torch.Size([0, 1408])          0.481248             0.853300             466.032000           4038.528000         
model.layers.2.mlp.experts.9.act_fn           torch.Size([0, 1408])          0.288352             0.720739             466.048000           4038.528000         
model.layers.2.mlp.experts.9.up_proj          torch.Size([0, 1408])          0.469344             0.826597             466.176000           4038.528000         
model.layers.2.mlp.experts.9.down_proj        torch.Size([0, 2048])          0.464512             0.823975             466.176000           3960.864000         
model.layers.2.mlp.experts.10.gate_proj       torch.Size([0, 1408])          0.473696             0.929117             466.176000           3922.032000         
model.layers.2.mlp.experts.10.act_fn          torch.Size([0, 1408])          0.287744             0.674486             466.176000           3934.976000         
model.layers.2.mlp.experts.10.up_proj         torch.Size([0, 1408])          0.462816             0.822067             466.176000           4038.528000         
model.layers.2.mlp.experts.10.down_proj       torch.Size([0, 2048])          0.461120             0.880957             466.176000           3976.396800         
model.layers.2.mlp.experts.11.gate_proj       torch.Size([0, 1408])          0.475392             0.845194             466.176000           3883.200000         
model.layers.2.mlp.experts.11.act_fn          torch.Size([0, 1408])          0.269664             0.646591             466.176000           3883.200000         
model.layers.2.mlp.experts.11.up_proj         torch.Size([0, 1408])          0.464960             0.880480             466.176000           3883.200000         
model.layers.2.mlp.experts.11.down_proj       torch.Size([0, 2048])          0.467648             0.833035             466.176000           3883.200000         
model.layers.2.mlp.experts.12.gate_proj       torch.Size([0, 1408])          0.474432             0.851870             466.176000           3976.396800         
model.layers.2.mlp.experts.12.act_fn          torch.Size([0, 1408])          0.272896             0.700951             466.176000           3883.200000         
model.layers.2.mlp.experts.12.up_proj         torch.Size([0, 1408])          0.462048             0.824213             466.176000           3922.032000         
model.layers.2.mlp.experts.12.down_proj       torch.Size([0, 2048])          0.457760             0.818729             466.176000           3883.200000         
model.layers.2.mlp.experts.13.gate_proj       torch.Size([0, 1408])          0.521248             0.905752             466.176000           3883.200000         
model.layers.2.mlp.experts.13.act_fn          torch.Size([0, 1408])          0.281600             0.677109             466.176000           3883.200000         
model.layers.2.mlp.experts.13.up_proj         torch.Size([0, 1408])          0.460736             0.825405             466.176000           3883.200000         
model.layers.2.mlp.experts.13.down_proj       torch.Size([0, 2048])          0.455296             0.815392             466.176000           3805.536000         
model.layers.2.mlp.experts.14.gate_proj       torch.Size([1, 1408])          0.944448             1.255035             524.448000           3727.872000         
model.layers.2.mlp.experts.14.act_fn          torch.Size([1, 1408])          0.349280             0.715494             621.568000           3727.872000         
model.layers.2.mlp.experts.14.up_proj         torch.Size([1, 1408])          0.914816             1.207829             621.504000           3766.704000         
model.layers.2.mlp.experts.14.down_proj       torch.Size([1, 2048])          1.011616             1.307249             757.224000           3881.600000         
model.layers.2.mlp.experts.15.gate_proj       torch.Size([1, 1408])          0.867360             1.163483             865.398857           4036.864000         
model.layers.2.mlp.experts.15.act_fn          torch.Size([1, 1408])          0.342048             0.709295             931.814400           4192.128000         
model.layers.2.mlp.experts.15.up_proj         torch.Size([1, 1408])          0.883776             1.176834             931.632000           4094.464000         
model.layers.2.mlp.experts.15.down_proj       torch.Size([1, 2048])          1.017856             1.322031             989.808000           4035.200000         
model.layers.2.mlp.experts.16.gate_proj       torch.Size([0, 1408])          0.459872             0.847101             1024.742400          4004.160000         
model.layers.2.mlp.experts.16.act_fn          torch.Size([0, 1408])          0.272608             0.636816             931.584000           3983.466667         
model.layers.2.mlp.experts.16.up_proj         torch.Size([0, 1408])          0.476416             0.836611             931.584000           4097.280000         
model.layers.2.mlp.experts.16.down_proj       torch.Size([0, 2048])          0.451072             0.840902             931.584000           4306.800000         
model.layers.2.mlp.experts.17.gate_proj       torch.Size([1, 1408])          0.863456             1.194000             914.332444           4466.311111         
model.layers.2.mlp.experts.17.act_fn          torch.Size([1, 1408])          0.301184             0.665903             931.584000           4407.680000         
model.layers.2.mlp.experts.17.up_proj         torch.Size([1, 1408])          0.858208             1.152992             931.584000           4345.600000         
model.layers.2.mlp.experts.17.down_proj       torch.Size([1, 2048])          1.058720             1.365423             1009.216000          4268.000000         
model.layers.2.mlp.experts.18.gate_proj       torch.Size([0, 1408])          0.471776             0.861168             1086.848000          4190.400000         
model.layers.2.mlp.experts.18.act_fn          torch.Size([0, 1408])          0.273920             0.658751             931.584000           4190.400000         
model.layers.2.mlp.experts.18.up_proj         torch.Size([0, 1408])          0.462176             0.852108             931.584000           4112.800000         
model.layers.2.mlp.experts.18.down_proj       torch.Size([0, 2048])          0.452864             0.819683             931.584000           4075.248000         
model.layers.2.mlp.experts.19.gate_proj       torch.Size([0, 1408])          0.460288             0.846863             900.595200           4036.864000         
model.layers.2.mlp.experts.19.act_fn          torch.Size([0, 1408])          0.275744             0.655174             776.640000           4036.864000         
model.layers.2.mlp.experts.19.up_proj         torch.Size([0, 1408])          0.460576             0.837803             776.640000           4005.811200         
model.layers.2.mlp.experts.19.down_proj       torch.Size([0, 2048])          0.456352             0.829697             776.640000           3881.600000         
model.layers.2.mlp.experts.20.gate_proj       torch.Size([0, 1408])          0.460320             0.882626             776.640000           3881.600000         
model.layers.2.mlp.experts.20.act_fn          torch.Size([0, 1408])          0.300448             0.674248             776.640000           3881.600000         
model.layers.2.mlp.experts.20.up_proj         torch.Size([0, 1408])          0.476512             0.849962             737.808000           3882.000000         
model.layers.2.mlp.experts.20.down_proj       torch.Size([0, 2048])          0.499424             0.870705             621.312000           3883.200000         
model.layers.2.mlp.experts.21.gate_proj       torch.Size([0, 1408])          0.463840             0.849962             621.312000           3881.600000         
model.layers.2.mlp.experts.21.act_fn          torch.Size([0, 1408])          0.281856             0.656366             621.312000           4036.864000         
model.layers.2.mlp.experts.21.up_proj         torch.Size([0, 1408])          0.529920             0.924349             621.312000           4036.864000         
model.layers.2.mlp.experts.21.down_proj       torch.Size([0, 2048])          0.717600             1.091957             621.312000           4269.760000         
model.layers.2.mlp.experts.22.gate_proj       torch.Size([2, 1408])          0.972480             1.293182             655.829333           4192.128000         
model.layers.2.mlp.experts.22.act_fn          torch.Size([2, 1408])          0.303552             0.681400             776.640000           4192.128000         
model.layers.2.mlp.experts.22.up_proj         torch.Size([2, 1408])          0.942176             1.256704             776.640000           4088.618667         
model.layers.2.mlp.experts.22.down_proj       torch.Size([2, 2048])          1.394048             1.683950             892.896000           4036.864000         
model.layers.2.mlp.experts.23.gate_proj       torch.Size([0, 1408])          0.461472             0.854492             931.737600           3974.758400         
model.layers.2.mlp.experts.23.act_fn          torch.Size([0, 1408])          0.327200             0.688553             931.968000           3881.600000         
model.layers.2.mlp.experts.23.up_proj         torch.Size([0, 1408])          0.455168             0.820398             931.968000           3881.600000         
model.layers.2.mlp.experts.23.down_proj       torch.Size([0, 2048])          0.448512             0.812531             776.640000           3881.600000         
model.layers.2.mlp.experts.24.gate_proj       torch.Size([0, 1408])          0.534528             0.918627             776.640000           3881.600000         
model.layers.2.mlp.experts.24.act_fn          torch.Size([0, 1408])          0.270912             0.638485             776.640000           3881.600000         
model.layers.2.mlp.experts.24.up_proj         torch.Size([0, 1408])          0.449024             0.833511             776.640000           3788.441600         
model.layers.2.mlp.experts.24.down_proj       torch.Size([0, 2048])          0.444864             0.815630             776.640000           3765.536000         
model.layers.2.mlp.experts.25.gate_proj       torch.Size([1, 1408])          0.915616             1.279593             776.640000           3726.336000         
model.layers.2.mlp.experts.25.act_fn          torch.Size([1, 1408])          0.335712             0.710011             776.640000           3726.336000         
model.layers.2.mlp.experts.25.up_proj         torch.Size([1, 1408])          0.990784             1.306534             776.640000           3726.336000         
model.layers.2.mlp.experts.25.down_proj       torch.Size([1, 2048])          1.044512             1.399279             931.968000           3726.336000         
model.layers.2.mlp.experts.26.gate_proj       torch.Size([0, 1408])          0.492448             0.907183             931.968000           3726.336000         
model.layers.2.mlp.experts.26.act_fn          torch.Size([0, 1408])          0.316096             0.709772             931.968000           3726.336000         
model.layers.2.mlp.experts.26.up_proj         torch.Size([0, 1408])          0.525408             0.926256             931.968000           3726.336000         
model.layers.2.mlp.experts.26.down_proj       torch.Size([0, 2048])          0.518624             1.006126             776.640000           3726.336000         
model.layers.2.mlp.experts.27.gate_proj       torch.Size([0, 1408])          0.498400             0.915051             776.640000           3665.740800         
model.layers.2.mlp.experts.27.act_fn          torch.Size([0, 1408])          0.296960             0.743866             776.640000           3727.872000         
model.layers.2.mlp.experts.27.up_proj         torch.Size([0, 1408])          0.490496             0.885010             776.640000           3805.536000         
model.layers.2.mlp.experts.27.down_proj       torch.Size([0, 2048])          0.516224             0.927448             737.808000           3881.600000         
model.layers.2.mlp.experts.28.gate_proj       torch.Size([0, 1408])          0.508288             0.959396             621.312000           3998.048000         
model.layers.2.mlp.experts.28.act_fn          torch.Size([0, 1408])          0.348672             0.742197             621.312000           4037.418667         
model.layers.2.mlp.experts.28.up_proj         torch.Size([0, 1408])          0.514272             0.931501             621.312000           3921.616000         
model.layers.2.mlp.experts.28.down_proj       torch.Size([0, 2048])          0.514368             0.880480             621.312000           3883.200000         
model.layers.2.mlp.experts.29.gate_proj       torch.Size([0, 1408])          0.480960             0.846863             621.312000           3883.200000         
model.layers.2.mlp.experts.29.act_fn          torch.Size([0, 1408])          0.281984             0.651121             621.312000           3883.200000         
model.layers.2.mlp.experts.29.up_proj         torch.Size([0, 1408])          0.543520             0.902653             621.440000           3883.200000         
model.layers.2.mlp.experts.29.down_proj       torch.Size([0, 2048])          0.455680             0.833273             582.720000           3844.368000         
model.layers.2.mlp.experts.30.gate_proj       torch.Size([0, 1408])          0.470080             0.838041             466.176000           3727.872000         
model.layers.2.mlp.experts.30.act_fn          torch.Size([0, 1408])          0.276800             0.666618             466.176000           3883.200000         
model.layers.2.mlp.experts.30.up_proj         torch.Size([0, 1408])          0.484320             0.864744             466.176000           3960.864000         
model.layers.2.mlp.experts.30.down_proj       torch.Size([0, 2048])          0.453792             0.832081             466.176000           3976.396800         
model.layers.2.mlp.experts.31.gate_proj       torch.Size([1, 1408])          0.940832             1.276493             524.448000           3902.616000         
model.layers.2.mlp.experts.31.act_fn          torch.Size([1, 1408])          0.311296             0.691175             621.312000           3883.200000         
model.layers.2.mlp.experts.31.up_proj         torch.Size([1, 1408])          0.881984             1.185179             621.312000           3883.200000         
model.layers.2.mlp.experts.31.down_proj       torch.Size([1, 2048])          1.038144             1.328230             718.392000           3882.000000         
model.layers.2.mlp.experts.32.gate_proj       torch.Size([1, 1408])          0.907296             1.244068             776.640000           3881.600000         
model.layers.2.mlp.experts.32.act_fn          torch.Size([1, 1408])          0.313952             0.680685             776.640000           3881.600000         
model.layers.2.mlp.experts.32.up_proj         torch.Size([1, 1408])          0.870944             1.148224             815.424000           3823.376000         
model.layers.2.mlp.experts.32.down_proj       torch.Size([1, 2048])          1.022528             1.301289             931.584000           3745.744000         
model.layers.2.mlp.experts.33.gate_proj       torch.Size([0, 1408])          0.475456             0.868797             931.584000           3726.336000         
model.layers.2.mlp.experts.33.act_fn          torch.Size([0, 1408])          0.275648             0.640392             931.968000           3726.336000         
model.layers.2.mlp.experts.33.up_proj         torch.Size([0, 1408])          0.527040             0.890255             815.472000           3726.336000         
model.layers.2.mlp.experts.33.down_proj       torch.Size([0, 2048])          0.448160             0.827789             776.640000           3819.494400         
model.layers.2.mlp.experts.34.gate_proj       torch.Size([0, 1408])          0.474944             0.844240             776.640000           3881.600000         
model.layers.2.mlp.experts.34.act_fn          torch.Size([0, 1408])          0.306336             0.725269             776.640000           3985.109333         
model.layers.2.mlp.experts.34.up_proj         torch.Size([0, 1408])          0.492128             0.859022             698.976000           4036.864000         
model.layers.2.mlp.experts.34.down_proj       torch.Size([0, 2048])          0.481216             0.843763             621.312000           4036.864000         
model.layers.2.mlp.experts.35.gate_proj       torch.Size([1, 1408])          0.913568             1.230717             679.560000           4036.864000         
model.layers.2.mlp.experts.35.act_fn          torch.Size([1, 1408])          0.297440             0.667095             776.640000           4036.864000         
model.layers.2.mlp.experts.35.up_proj         torch.Size([1, 1408])          0.866240             1.168966             776.640000           3978.640000         
model.layers.2.mlp.experts.35.down_proj       torch.Size([1, 2048])          1.048832             1.335621             815.176000           3881.600000         
model.layers.2.mlp.experts.36.gate_proj       torch.Size([2, 1408])          0.972320             1.265526             931.584000           3880.200000         
model.layers.2.mlp.experts.36.act_fn          torch.Size([2, 1408])          0.300640             0.688553             931.584000           3880.000000         
model.layers.2.mlp.experts.36.up_proj         torch.Size([2, 1408])          0.941760             1.225948             931.584000           3880.000000         
model.layers.2.mlp.experts.36.down_proj       torch.Size([2, 2048])          1.374880             1.665115             1028.624000          3880.000000         
model.layers.2.mlp.experts.37.gate_proj       torch.Size([2, 1408])          0.937280             1.226425             1086.568000          4035.200000         
model.layers.2.mlp.experts.37.act_fn          torch.Size([2, 1408])          0.392992             0.762939             1086.400000          4151.600000         
model.layers.2.mlp.experts.37.up_proj         torch.Size([2, 1408])          0.941984             1.230001             1086.400000          4188.672000         
model.layers.2.mlp.experts.37.down_proj       torch.Size([2, 2048])          1.374624             1.670837             1155.377778          4136.960000         
model.layers.2.mlp.experts.38.gate_proj       torch.Size([0, 1408])          0.465984             0.859261             1164.000000          4034.368000         
model.layers.2.mlp.experts.38.act_fn          torch.Size([0, 1408])          0.276928             0.642776             1086.549333          4035.200000         
model.layers.2.mlp.experts.38.up_proj         torch.Size([0, 1408])          0.521248             0.900269             1086.848000          4035.200000         
model.layers.2.mlp.experts.38.down_proj       torch.Size([0, 2048])          0.454912             0.834942             1009.216000          3996.400000         
model.layers.2.mlp.experts.39.gate_proj       torch.Size([1, 1408])          0.926208             1.226902             950.992000           3938.200000         
model.layers.2.mlp.experts.39.act_fn          torch.Size([1, 1408])          0.347840             0.726700             962.636800           3880.000000         
model.layers.2.mlp.experts.39.up_proj         torch.Size([1, 1408])          0.905920             1.195669             1009.216000          3880.000000         
model.layers.2.mlp.experts.39.down_proj       torch.Size([1, 2048])          1.019104             1.346827             1086.848000          3880.000000         
model.layers.2.mlp.experts.40.gate_proj       torch.Size([0, 1408])          0.474784             0.845432             1086.848000          3880.000000         
model.layers.2.mlp.experts.40.act_fn          torch.Size([0, 1408])          0.280512             0.643253             1035.093333          4035.200000         
model.layers.2.mlp.experts.40.up_proj         torch.Size([0, 1408])          0.543808             0.905275             931.584000           4035.200000         
model.layers.2.mlp.experts.40.down_proj       torch.Size([0, 2048])          0.489504             0.870705             931.584000           4190.400000         
model.layers.2.mlp.experts.41.gate_proj       torch.Size([0, 1408])          0.468832             0.859261             853.952000           4074.000000         
model.layers.2.mlp.experts.41.act_fn          torch.Size([0, 1408])          0.278624             0.645876             776.320000           4036.309333         
model.layers.2.mlp.experts.41.up_proj         torch.Size([0, 1408])          0.459968             0.848055             776.560000           4036.864000         
model.layers.2.mlp.experts.41.down_proj       torch.Size([0, 2048])          0.463616             0.833750             776.640000           4036.864000         
model.layers.2.mlp.experts.42.gate_proj       torch.Size([0, 1408])          0.497152             0.889778             776.640000           4036.864000         
model.layers.2.mlp.experts.42.act_fn          torch.Size([0, 1408])          0.274336             0.643492             673.088000           4036.864000         
model.layers.2.mlp.experts.42.up_proj         torch.Size([0, 1408])          0.457216             0.838995             621.312000           3974.758400         
model.layers.2.mlp.experts.42.down_proj       torch.Size([0, 2048])          0.522016             0.886679             621.312000           3912.652800         
model.layers.2.mlp.experts.43.gate_proj       torch.Size([0, 1408])          0.465472             0.850201             621.312000           3881.600000         
model.layers.2.mlp.experts.43.act_fn          torch.Size([0, 1408])          0.379776             0.789165             621.312000           3881.600000         
model.layers.2.mlp.experts.43.up_proj         torch.Size([0, 1408])          0.563168             0.931501             621.312000           3882.000000         
model.layers.2.mlp.experts.43.down_proj       torch.Size([0, 2048])          0.494816             0.863552             621.312000           3882.400000         
model.layers.2.mlp.experts.44.gate_proj       torch.Size([0, 1408])          0.463456             0.845432             621.312000           3883.200000         
model.layers.2.mlp.experts.44.act_fn          torch.Size([0, 1408])          0.270784             0.649214             465.984000           3883.200000         
model.layers.2.mlp.experts.44.up_proj         torch.Size([0, 1408])          0.463552             0.825405             465.984000           3883.200000         
model.layers.2.mlp.experts.44.down_proj       torch.Size([0, 2048])          0.461504             0.823736             466.176000           3883.200000         
model.layers.2.mlp.experts.45.gate_proj       torch.Size([0, 1408])          0.472064             0.850201             466.176000           3883.200000         
model.layers.2.mlp.experts.45.act_fn          torch.Size([0, 1408])          0.271392             0.646830             466.176000           3883.200000         
model.layers.2.mlp.experts.45.up_proj         torch.Size([0, 1408])          0.461952             0.835419             466.176000           3852.134400         
model.layers.2.mlp.experts.45.down_proj       torch.Size([0, 2048])          0.510272             0.868082             466.176000           3758.937600         
model.layers.2.mlp.experts.46.gate_proj       torch.Size([0, 1408])          0.487360             0.874043             466.176000           3727.872000         
model.layers.2.mlp.experts.46.act_fn          torch.Size([0, 1408])          0.297152             0.658989             466.176000           3727.872000         
model.layers.2.mlp.experts.46.up_proj         torch.Size([0, 1408])          0.539968             0.920773             466.176000           3727.872000         
model.layers.2.mlp.experts.46.down_proj       torch.Size([0, 2048])          0.467680             0.830412             466.176000           3727.872000         
model.layers.2.mlp.experts.47.gate_proj       torch.Size([0, 1408])          0.468256             0.854254             466.176000           3844.368000         
model.layers.2.mlp.experts.47.act_fn          torch.Size([0, 1408])          0.325312             0.688791             466.176000           3883.200000         
model.layers.2.mlp.experts.47.up_proj         torch.Size([0, 1408])          0.456864             0.831127             466.176000           3922.032000         
model.layers.2.mlp.experts.47.down_proj       torch.Size([0, 2048])          0.454624             0.832081             466.176000           4038.528000         
model.layers.2.mlp.experts.48.gate_proj       torch.Size([0, 1408])          0.467840             0.912666             466.176000           4038.528000         
model.layers.2.mlp.experts.48.act_fn          torch.Size([0, 1408])          0.273824             0.637293             466.176000           4038.528000         
model.layers.2.mlp.experts.48.up_proj         torch.Size([0, 1408])          0.454688             0.832319             466.176000           3945.331200         
model.layers.2.mlp.experts.48.down_proj       torch.Size([0, 2048])          0.449568             0.826120             466.176000           3883.200000         
model.layers.2.mlp.experts.49.gate_proj       torch.Size([0, 1408])          0.494848             0.887871             466.176000           3883.200000         
model.layers.2.mlp.experts.49.act_fn          torch.Size([0, 1408])          0.300576             0.668287             466.176000           3883.200000         
model.layers.2.mlp.experts.49.up_proj         torch.Size([0, 1408])          0.515136             0.946522             466.176000           3852.134400         
model.layers.2.mlp.experts.49.down_proj       torch.Size([0, 2048])          0.469696             0.833988             466.176000           3758.937600         
model.layers.2.mlp.experts.50.gate_proj       torch.Size([0, 1408])          0.456864             0.843763             372.940800           3727.872000         
model.layers.2.mlp.experts.50.act_fn          torch.Size([0, 1408])          0.270592             0.693798             466.176000           3727.872000         
model.layers.2.mlp.experts.50.up_proj         torch.Size([0, 1408])          0.487840             0.857592             310.784000           3727.872000         
model.layers.2.mlp.experts.50.down_proj       torch.Size([0, 2048])          0.448800             0.859022             310.784000           3727.872000         
model.layers.2.mlp.experts.51.gate_proj       torch.Size([1, 1408])          0.951424             1.247406             446.752000           3727.872000         
model.layers.2.mlp.experts.51.act_fn          torch.Size([1, 1408])          0.308576             0.678301             466.176000           3727.872000         
model.layers.2.mlp.experts.51.up_proj         torch.Size([1, 1408])          0.868416             1.148224             524.416000           3727.872000         
model.layers.2.mlp.experts.51.down_proj       torch.Size([1, 2048])          1.088480             1.394510             621.312000           3726.912000         
model.layers.2.mlp.experts.52.gate_proj       torch.Size([1, 1408])          0.871136             1.164913             759.381333           3726.336000         
model.layers.2.mlp.experts.52.act_fn          torch.Size([1, 1408])          0.346176             0.713587             776.640000           3726.336000         
model.layers.2.mlp.experts.52.up_proj         torch.Size([1, 1408])          0.859680             1.140118             776.640000           3590.480000         
model.layers.2.mlp.experts.52.down_proj       torch.Size([1, 2048])          1.041696             1.322985             862.933333           3622.826667         
model.layers.2.mlp.experts.53.gate_proj       torch.Size([0, 1408])          0.474816             0.853539             893.136000           3571.072000         
model.layers.2.mlp.experts.53.act_fn          torch.Size([0, 1408])          0.283200             0.650406             776.640000           3571.072000         
model.layers.2.mlp.experts.53.up_proj         torch.Size([0, 1408])          0.475328             0.833511             776.640000           3726.336000         
model.layers.2.mlp.experts.53.down_proj       torch.Size([0, 2048])          0.462848             0.844479             776.640000           3829.845333         
model.layers.2.mlp.experts.54.gate_proj       torch.Size([0, 1408])          0.475072             0.875711             737.808000           3881.600000         
model.layers.2.mlp.experts.54.act_fn          torch.Size([0, 1408])          0.283040             0.643253             621.312000           4036.864000         
model.layers.2.mlp.experts.54.up_proj         torch.Size([0, 1408])          1.578048             1.939774             621.312000           3920.416000         
model.layers.2.mlp.experts.54.down_proj       torch.Size([0, 2048])          0.479552             0.861168             621.312000           3881.600000         
model.layers.2.mlp.experts.55.gate_proj       torch.Size([0, 1408])          0.468000             0.849962             621.312000           3882.000000         
model.layers.2.mlp.experts.55.act_fn          torch.Size([0, 1408])          0.288864             0.677109             621.312000           3882.666667         
model.layers.2.mlp.experts.55.up_proj         torch.Size([0, 1408])          0.466784             0.850916             621.312000           3883.200000         
model.layers.2.mlp.experts.55.down_proj       torch.Size([0, 2048])          0.457536             0.860214             621.312000           3883.200000         
model.layers.2.mlp.experts.56.gate_proj       torch.Size([1, 1408])          0.931744             1.234293             621.312000           3785.352000         
model.layers.2.mlp.experts.56.act_fn          torch.Size([1, 1408])          0.299040             0.664234             621.312000           3726.336000         
model.layers.2.mlp.experts.56.up_proj         torch.Size([1, 1408])          0.903328             1.190186             660.144000           3726.336000         
model.layers.2.mlp.experts.56.down_proj       torch.Size([1, 2048])          1.022240             1.304626             776.640000           3726.336000         
model.layers.2.mlp.experts.57.gate_proj       torch.Size([0, 1408])          0.486688             0.862360             776.640000           3726.336000         
model.layers.2.mlp.experts.57.act_fn          torch.Size([0, 1408])          0.275808             0.651836             776.640000           3726.336000         
model.layers.2.mlp.experts.57.up_proj         torch.Size([0, 1408])          0.466016             0.828028             776.640000           3726.336000         
model.layers.2.mlp.experts.57.down_proj       torch.Size([0, 2048])          0.495744             0.872612             660.144000           3687.520000         
model.layers.2.mlp.experts.58.gate_proj       torch.Size([1, 1408])          0.927936             1.239538             724.864000           3571.072000         
model.layers.2.mlp.experts.58.act_fn          torch.Size([1, 1408])          0.302656             0.718832             776.640000           3571.072000         
model.layers.2.mlp.experts.58.up_proj         torch.Size([1, 1408])          0.865728             1.146793             776.640000           3668.112000         
model.layers.2.mlp.experts.58.down_proj       torch.Size([1, 2048])          1.021984             1.300573             854.304000           3629.296000         
model.layers.2.mlp.experts.59.gate_proj       torch.Size([1, 1408])          0.918048             1.211166             931.968000           3571.072000         
model.layers.2.mlp.experts.59.act_fn          torch.Size([1, 1408])          0.296352             0.679731             931.968000           3571.072000         
model.layers.2.mlp.experts.59.up_proj         torch.Size([1, 1408])          0.864256             1.172066             931.968000           3571.072000         
model.layers.2.mlp.experts.59.down_proj       torch.Size([1, 2048])          1.007136             1.287699             998.290286           3613.942857         
model.layers.2.mlp.shared_expert.gate_proj    torch.Size([5, 5632])          2.603424             2.900839             1131.136000          3724.361143         
model.layers.2.mlp.shared_expert.act_fn       torch.Size([5, 5632])          0.326112             0.692844             1396.800000          3878.400000         
model.layers.2.mlp.shared_expert.up_proj      torch.Size([5, 5632])          2.611616             2.904177             1573.778286          3899.181714         
model.layers.2.mlp.shared_expert.down_proj    torch.Size([5, 2048])          2.714240             3.036022             1938.488000          4011.040000         
model.layers.2.mlp.shared_expert_gate         torch.Size([5, 1])             0.513088             0.925303             2038.089143          3941.632000         
model.layers.3.input_layernorm                torch.Size([1, 5, 2048])       0.966176             1.360416             1847.899826          3889.931130         
model.layers.3.self_attn.q_proj               torch.Size([1, 5, 2048])       1.372992             1.664400             1706.496000          3838.032000         
model.layers.3.self_attn.k_proj               torch.Size([1, 5, 2048])       1.380480             1.727104             1745.280000          3779.880000         
model.layers.3.self_attn.v_proj               torch.Size([1, 5, 2048])       1.254336             1.560450             1842.240000          3915.568000         
model.layers.3.self_attn.o_proj               torch.Size([1, 5, 2048])       1.265632             1.583338             1861.632000          4031.872000         
model.layers.3.post_attention_layernorm       torch.Size([1, 5, 2048])       0.910272             1.294136             1746.966261          3924.552348         
model.layers.3.mlp.gate                       torch.Size([5, 60])            0.551264             0.928640             1552.000000          3878.400000         
model.layers.3.mlp.experts.0.gate_proj        torch.Size([0, 1408])          0.489344             0.920296             1489.920000          3878.400000         
model.layers.3.mlp.experts.0.act_fn           torch.Size([0, 1408])          0.284864             0.666618             1396.800000          3880.000000         
model.layers.3.mlp.experts.0.up_proj          torch.Size([0, 1408])          0.475264             0.838518             1358.272000          3763.600000         
model.layers.3.mlp.experts.0.down_proj        torch.Size([0, 2048])          0.478144             0.903368             1242.112000          3724.800000         
model.layers.3.mlp.experts.1.gate_proj        torch.Size([1, 1408])          0.906976             1.235008             1242.112000          3724.800000         
model.layers.3.mlp.experts.1.act_fn           torch.Size([1, 1408])          0.309984             0.700951             1242.112000          3724.800000         
model.layers.3.mlp.experts.1.up_proj          torch.Size([1, 1408])          0.874496             1.228333             1242.112000          3724.800000         
model.layers.3.mlp.experts.1.down_proj        torch.Size([1, 2048])          1.015968             1.303196             1242.112000          3724.800000         
model.layers.3.mlp.experts.2.gate_proj        torch.Size([0, 1408])          0.524192             0.901222             1242.112000          3724.800000         
model.layers.3.mlp.experts.2.act_fn           torch.Size([0, 1408])          0.292032             0.663996             1242.112000          3776.533333         
model.layers.3.mlp.experts.2.up_proj          torch.Size([0, 1408])          0.481888             0.849724             1164.480000          3880.000000         
model.layers.3.mlp.experts.2.down_proj        torch.Size([0, 2048])          0.527008             0.891924             1086.848000          3983.466667         
model.layers.3.mlp.experts.3.gate_proj        torch.Size([1, 1408])          0.869568             1.177073             1086.848000          4035.200000         
model.layers.3.mlp.experts.3.act_fn           torch.Size([1, 1408])          0.345600             0.712872             1086.848000          4035.200000         
model.layers.3.mlp.experts.3.up_proj          torch.Size([1, 1408])          0.904192             1.240253             1086.848000          3977.000000         
model.layers.3.mlp.experts.3.down_proj        torch.Size([1, 2048])          1.009216             1.295805             1173.105778          3880.000000         
model.layers.3.mlp.experts.4.gate_proj        torch.Size([1, 1408])          0.871520             1.173258             1242.112000          3880.000000         
model.layers.3.mlp.experts.4.act_fn           torch.Size([1, 1408])          0.317600             0.687838             1242.112000          3880.000000         
model.layers.3.mlp.experts.4.up_proj          torch.Size([1, 1408])          0.901792             1.173019             1242.112000          3880.000000         
model.layers.3.mlp.experts.4.down_proj        torch.Size([1, 2048])          1.032768             1.325130             1242.112000          3835.657143         
model.layers.3.mlp.experts.5.gate_proj        torch.Size([1, 1408])          0.861184             1.179934             1319.528000          3821.400000         
model.layers.3.mlp.experts.5.act_fn           torch.Size([1, 1408])          0.303264             0.689030             1241.600000          4033.536000         
model.layers.3.mlp.experts.5.up_proj          torch.Size([1, 1408])          0.859360             1.136541             1241.600000          4033.536000         
model.layers.3.mlp.experts.5.down_proj        torch.Size([1, 2048])          1.025600             1.315594             1319.200000          4188.672000         
model.layers.3.mlp.experts.6.gate_proj        torch.Size([0, 1408])          0.481824             0.861645             1303.680000          4095.590400         
model.layers.3.mlp.experts.6.act_fn           torch.Size([0, 1408])          0.274560             0.648737             1241.600000          4034.645333         
model.layers.3.mlp.experts.6.up_proj          torch.Size([0, 1408])          0.525984             0.889540             1241.600000          4035.200000         
model.layers.3.mlp.experts.6.down_proj        torch.Size([0, 2048])          0.455360             0.841379             1086.848000          4035.200000         
model.layers.3.mlp.experts.7.gate_proj        torch.Size([1, 1408])          0.926144             1.219511             1086.848000          3918.800000         
model.layers.3.mlp.experts.7.act_fn           torch.Size([1, 1408])          0.324384             0.699043             1086.848000          3880.000000         
model.layers.3.mlp.experts.7.up_proj          torch.Size([1, 1408])          0.927520             1.233339             1086.848000          3880.000000         
model.layers.3.mlp.experts.7.down_proj        torch.Size([1, 2048])          1.023904             1.334906             1183.888000          3860.600000         
model.layers.3.mlp.experts.8.gate_proj        torch.Size([0, 1408])          0.490080             0.895262             1203.296000          3724.800000         
model.layers.3.mlp.experts.8.act_fn           torch.Size([0, 1408])          0.297952             0.659704             1086.848000          3880.000000         
model.layers.3.mlp.experts.8.up_proj          torch.Size([0, 1408])          0.528672             0.890017             1086.848000          3918.800000         
model.layers.3.mlp.experts.8.down_proj        torch.Size([0, 2048])          0.492512             0.896931             1035.093333          4035.200000         
model.layers.3.mlp.experts.9.gate_proj        torch.Size([0, 1408])          0.485088             0.926256             931.584000           4138.666667         
model.layers.3.mlp.experts.9.act_fn           torch.Size([0, 1408])          0.284128             0.658035             931.584000           4140.373333         
model.layers.3.mlp.experts.9.up_proj          torch.Size([0, 1408])          0.472352             0.838995             931.584000           4067.916800         
model.layers.3.mlp.experts.9.down_proj        torch.Size([0, 2048])          0.489696             0.858307             854.032000           4036.864000         
model.layers.3.mlp.experts.10.gate_proj       torch.Size([0, 1408])          0.484576             0.860929             776.640000           4036.864000         
model.layers.3.mlp.experts.10.act_fn          torch.Size([0, 1408])          0.294464             0.663042             776.640000           3985.109333         
model.layers.3.mlp.experts.10.up_proj         torch.Size([0, 1408])          0.496704             0.904322             776.640000           3881.600000         
model.layers.3.mlp.experts.10.down_proj       torch.Size([0, 2048])          0.521312             0.887156             776.640000           3820.108800         
model.layers.3.mlp.experts.11.gate_proj       torch.Size([0, 1408])          0.508832             0.896454             737.808000           3727.872000         
model.layers.3.mlp.experts.11.act_fn          torch.Size([0, 1408])          0.325760             0.743151             621.312000           3727.872000         
model.layers.3.mlp.experts.11.up_proj         torch.Size([0, 1408])          0.463808             0.851870             621.312000           3727.872000         
model.layers.3.mlp.experts.11.down_proj       torch.Size([0, 2048])          0.474336             0.836849             621.312000           3727.872000         
model.layers.3.mlp.experts.12.gate_proj       torch.Size([0, 1408])          0.557632             0.939846             621.465600           3727.872000         
model.layers.3.mlp.experts.12.act_fn          torch.Size([0, 1408])          0.294240             0.655651             621.568000           3727.872000         
model.layers.3.mlp.experts.12.up_proj         torch.Size([0, 1408])          0.475168             0.834227             621.376000           3727.872000         
model.layers.3.mlp.experts.12.down_proj       torch.Size([0, 2048])          0.471744             0.829935             621.568000           3727.872000         
model.layers.3.mlp.experts.13.gate_proj       torch.Size([1, 1408])          0.917088             1.266241             621.440000           3727.872000         
model.layers.3.mlp.experts.13.act_fn          torch.Size([1, 1408])          0.301344             0.672579             621.312000           3727.872000         
model.layers.3.mlp.experts.13.up_proj         torch.Size([1, 1408])          0.876192             1.212358             757.224000           3726.912000         
model.layers.3.mlp.experts.13.down_proj       torch.Size([1, 2048])          1.021536             1.313686             834.888000           3726.336000         
model.layers.3.mlp.experts.14.gate_proj       torch.Size([0, 1408])          0.509440             0.950336             900.902400           3664.230400         
model.layers.3.mlp.experts.14.act_fn          torch.Size([0, 1408])          0.313408             0.684023             776.640000           3648.704000         
model.layers.3.mlp.experts.14.up_proj         torch.Size([0, 1408])          0.517216             0.885963             776.640000           3687.520000         
model.layers.3.mlp.experts.14.down_proj       torch.Size([0, 2048])          0.583264             0.977755             776.640000           3649.952000         
model.layers.3.mlp.experts.15.gate_proj       torch.Size([0, 1408])          0.599232             1.134157             776.640000           3757.388800         
model.layers.3.mlp.experts.15.act_fn          torch.Size([0, 1408])          0.364320             0.796080             776.640000           3881.600000         
model.layers.3.mlp.experts.15.up_proj         torch.Size([0, 1408])          0.594688             1.008272             683.443200           3912.652800         
model.layers.3.mlp.experts.15.down_proj       torch.Size([0, 2048])          0.471744             0.894547             621.312000           4036.864000         
model.layers.3.mlp.experts.16.gate_proj       torch.Size([0, 1408])          0.552800             1.058578             621.312000           3985.642667         
model.layers.3.mlp.experts.16.act_fn          torch.Size([0, 1408])          0.303936             0.686646             621.312000           3882.666667         
model.layers.3.mlp.experts.16.up_proj         torch.Size([0, 1408])          0.459168             0.819206             621.312000           3883.200000         
model.layers.3.mlp.experts.16.down_proj       torch.Size([0, 2048])          0.453024             0.885010             621.312000           3883.200000         
model.layers.3.mlp.experts.17.gate_proj       torch.Size([0, 1408])          0.546048             1.009226             621.363200           3883.200000         
model.layers.3.mlp.experts.17.act_fn          torch.Size([0, 1408])          0.295488             0.659943             621.482667           3779.648000         
model.layers.3.mlp.experts.17.up_proj         torch.Size([0, 1408])          0.472448             0.883341             621.568000           3779.648000         
model.layers.3.mlp.experts.17.down_proj       torch.Size([0, 2048])          0.467968             0.866652             621.568000           3727.872000         
model.layers.3.mlp.experts.18.gate_proj       torch.Size([1, 1408])          0.922144             1.299620             621.440000           3727.872000         
model.layers.3.mlp.experts.18.act_fn          torch.Size([1, 1408])          0.353856             0.727177             621.312000           3727.872000         
model.layers.3.mlp.experts.18.up_proj         torch.Size([1, 1408])          0.942144             1.237154             698.976000           3842.976000         
model.layers.3.mlp.experts.18.down_proj       torch.Size([1, 2048])          1.080000             1.363277             798.637714           4081.225143         
model.layers.3.mlp.experts.19.gate_proj       torch.Size([1, 1408])          0.885088             1.195192             912.176000           4306.800000         
model.layers.3.mlp.experts.19.act_fn          torch.Size([1, 1408])          0.320512             0.782251             931.584000           4345.600000         
model.layers.3.mlp.experts.19.up_proj         torch.Size([1, 1408])          0.897056             1.182795             931.584000           4287.400000         
model.layers.3.mlp.experts.19.down_proj       torch.Size([1, 2048])          1.025408             1.302004             1028.624000          4190.400000         
model.layers.3.mlp.experts.20.gate_proj       torch.Size([0, 1408])          0.467040             0.854731             1086.848000          4151.600000         
model.layers.3.mlp.experts.20.act_fn          torch.Size([0, 1408])          0.278752             0.640631             931.584000           4138.666667         
model.layers.3.mlp.experts.20.up_proj         torch.Size([0, 1408])          0.455808             0.901222             931.584000           4036.032000         
model.layers.3.mlp.experts.20.down_proj       torch.Size([0, 2048])          0.468288             0.832081             931.584000           4036.864000         
model.layers.3.mlp.experts.21.gate_proj       torch.Size([1, 1408])          0.930112             1.267910             931.584000           3959.232000         
model.layers.3.mlp.experts.21.act_fn          torch.Size([1, 1408])          0.388864             0.826836             931.584000           4036.864000         
model.layers.3.mlp.experts.21.up_proj         torch.Size([1, 1408])          0.959264             1.333952             931.584000           4079.780571         
model.layers.3.mlp.experts.21.down_proj       torch.Size([1, 2048])          1.236576             1.675844             1060.746667          4190.400000         
model.layers.3.mlp.experts.22.gate_proj       torch.Size([0, 1408])          0.553856             0.990868             1086.400000          4190.400000         
model.layers.3.mlp.experts.22.act_fn          torch.Size([0, 1408])          0.300352             0.676870             931.200000           4190.400000         
model.layers.3.mlp.experts.22.up_proj         torch.Size([0, 1408])          0.563840             1.000404             931.584000           4190.400000         
model.layers.3.mlp.experts.22.down_proj       torch.Size([0, 2048])          0.517472             0.916719             931.584000           4036.309333         
model.layers.3.mlp.experts.23.gate_proj       torch.Size([0, 1408])          0.522048             0.899792             892.768000           4036.864000         
model.layers.3.mlp.experts.23.act_fn          torch.Size([0, 1408])          0.306912             0.688553             776.320000           4036.864000         
model.layers.3.mlp.experts.23.up_proj         torch.Size([0, 1408])          0.475040             0.835657             776.320000           3959.232000         
model.layers.3.mlp.experts.23.down_proj       torch.Size([0, 2048])          0.472736             0.833988             776.480000           3881.600000         
model.layers.3.mlp.experts.24.gate_proj       torch.Size([0, 1408])          0.736928             1.108646             776.640000           3881.600000         
model.layers.3.mlp.experts.24.act_fn          torch.Size([0, 1408])          0.346624             0.757217             776.640000           3881.600000         
model.layers.3.mlp.experts.24.up_proj         torch.Size([0, 1408])          0.464032             0.877142             776.640000           3842.784000         
model.layers.3.mlp.experts.24.down_proj       torch.Size([0, 2048])          0.452832             0.819683             621.312000           3881.600000         
model.layers.3.mlp.experts.25.gate_proj       torch.Size([1, 1408])          0.926752             1.251936             718.392000           3803.968000         
model.layers.3.mlp.experts.25.act_fn          torch.Size([1, 1408])          0.400832             0.865459             776.640000           3842.784000         
model.layers.3.mlp.experts.25.up_proj         torch.Size([1, 1408])          0.938016             1.225948             776.640000           3784.560000         
model.layers.3.mlp.experts.25.down_proj       torch.Size([1, 2048])          1.029600             1.411200             854.072000           3726.336000         
model.layers.3.mlp.experts.26.gate_proj       torch.Size([0, 1408])          0.602688             1.043797             931.584000           3726.336000         
model.layers.3.mlp.experts.26.act_fn          torch.Size([0, 1408])          0.320704             0.759125             776.480000           3726.336000         
model.layers.3.mlp.experts.26.up_proj         torch.Size([0, 1408])          0.488352             0.852346             776.640000           3726.336000         
model.layers.3.mlp.experts.26.down_proj       torch.Size([0, 2048])          0.476256             0.925064             776.640000           3726.336000         
model.layers.3.mlp.experts.27.gate_proj       torch.Size([1, 1408])          0.944160             1.330137             776.640000           3726.336000         
model.layers.3.mlp.experts.27.act_fn          torch.Size([1, 1408])          0.481152             0.993729             776.640000           3726.336000         
model.layers.3.mlp.experts.27.up_proj         torch.Size([1, 1408])          0.961344             1.315117             834.888000           3726.336000         
model.layers.3.mlp.experts.27.down_proj       torch.Size([1, 2048])          1.105472             1.438856             931.632000           3764.952000         
model.layers.3.mlp.experts.28.gate_proj       torch.Size([0, 1408])          0.541728             0.986576             931.584000           3880.800000         
model.layers.3.mlp.experts.28.act_fn          torch.Size([0, 1408])          0.300960             0.701666             931.584000           4036.864000         
model.layers.3.mlp.experts.28.up_proj         torch.Size([0, 1408])          0.665728             1.074553             815.136000           4036.864000         
model.layers.3.mlp.experts.28.down_proj       torch.Size([0, 2048])          0.545600             0.972748             776.320000           4075.680000         
model.layers.3.mlp.experts.29.gate_proj       torch.Size([0, 1408])          0.545408             0.919104             776.320000           4036.864000         
model.layers.3.mlp.experts.29.act_fn          torch.Size([0, 1408])          0.287104             0.683784             776.320000           4036.864000         
model.layers.3.mlp.experts.29.up_proj         torch.Size([0, 1408])          0.490912             0.855684             737.808000           4036.864000         
model.layers.3.mlp.experts.29.down_proj       torch.Size([0, 2048])          0.446336             0.847340             621.312000           3920.416000         
model.layers.3.mlp.experts.30.gate_proj       torch.Size([0, 1408])          0.467648             0.839949             621.312000           3881.600000         
model.layers.3.mlp.experts.30.act_fn          torch.Size([0, 1408])          0.287968             0.649214             621.312000           3881.600000         
model.layers.3.mlp.experts.30.up_proj         torch.Size([0, 1408])          0.467712             0.823021             621.312000           3881.600000         
model.layers.3.mlp.experts.30.down_proj       torch.Size([0, 2048])          0.487392             0.903845             621.312000           4036.864000         
model.layers.3.mlp.experts.31.gate_proj       torch.Size([1, 1408])          0.938752             1.260996             621.248000           4114.496000         
model.layers.3.mlp.experts.31.act_fn          torch.Size([1, 1408])          0.416448             1.030207             621.056000           4067.916800         
model.layers.3.mlp.experts.31.up_proj         torch.Size([1, 1408])          1.021408             1.383066             659.912000           4036.864000         
model.layers.3.mlp.experts.31.down_proj       torch.Size([1, 2048])          1.096128             1.522541             776.568889           3985.109333         
model.layers.3.mlp.experts.32.gate_proj       torch.Size([0, 1408])          0.734656             1.351118             776.560000           3920.416000         
model.layers.3.mlp.experts.32.act_fn          torch.Size([0, 1408])          0.417344             1.053572             776.640000           3881.600000         
model.layers.3.mlp.experts.32.up_proj         torch.Size([0, 1408])          0.711392             1.306772             776.640000           3881.600000         
model.layers.3.mlp.experts.32.down_proj       torch.Size([0, 2048])          0.647840             1.193523             737.808000           3881.600000         
model.layers.3.mlp.experts.33.gate_proj       torch.Size([1, 1408])          0.913568             1.281261             737.808000           3881.600000         
model.layers.3.mlp.experts.33.act_fn          torch.Size([1, 1408])          0.423200             0.832796             776.640000           3881.600000         
model.layers.3.mlp.experts.33.up_proj         torch.Size([1, 1408])          0.888416             1.211166             776.640000           3823.376000         
model.layers.3.mlp.experts.33.down_proj       torch.Size([1, 2048])          1.042144             1.344442             862.933333           3726.336000         
model.layers.3.mlp.experts.34.gate_proj       torch.Size([0, 1408])          0.476128             0.874758             900.902400           3726.336000         
model.layers.3.mlp.experts.34.act_fn          torch.Size([0, 1408])          0.286368             0.655413             776.640000           3726.336000         
model.layers.3.mlp.experts.34.up_proj         torch.Size([0, 1408])          0.546944             0.916958             776.640000           3881.600000         
model.layers.3.mlp.experts.34.down_proj       torch.Size([0, 2048])          0.487584             0.867844             776.640000           3920.416000         
model.layers.3.mlp.experts.35.gate_proj       torch.Size([1, 1408])          0.891328             1.203060             776.480000           4036.864000         
model.layers.3.mlp.experts.35.act_fn          torch.Size([1, 1408])          0.353856             0.724554             776.320000           4036.864000         
model.layers.3.mlp.experts.35.up_proj         torch.Size([1, 1408])          0.907488             1.206875             776.320000           4036.864000         
model.layers.3.mlp.experts.35.down_proj       torch.Size([1, 2048])          1.023712             1.342773             892.768000           4035.408000         
model.layers.3.mlp.experts.36.gate_proj       torch.Size([0, 1408])          0.487744             0.916719             931.584000           3931.733333         
model.layers.3.mlp.experts.36.act_fn          torch.Size([0, 1408])          0.284608             0.704050             931.584000           3933.354667         
model.layers.3.mlp.experts.36.up_proj         torch.Size([0, 1408])          0.529248             0.973225             776.320000           3881.600000         
model.layers.3.mlp.experts.36.down_proj       torch.Size([0, 2048])          0.563744             0.976562             776.560000           3881.600000         
model.layers.3.mlp.experts.37.gate_proj       torch.Size([0, 1408])          0.580352             1.006603             776.640000           3881.600000         
model.layers.3.mlp.experts.37.act_fn          torch.Size([0, 1408])          0.280096             0.646591             776.640000           3829.845333         
model.layers.3.mlp.experts.37.up_proj         torch.Size([0, 1408])          0.479488             0.864983             660.144000           3881.600000         
model.layers.3.mlp.experts.37.down_proj       torch.Size([0, 2048])          0.451008             0.836134             621.312000           4036.864000         
model.layers.3.mlp.experts.38.gate_proj       torch.Size([0, 1408])          0.502976             0.895977             621.312000           4192.128000         
model.layers.3.mlp.experts.38.act_fn          torch.Size([0, 1408])          0.275744             0.669003             621.312000           4192.128000         
model.layers.3.mlp.experts.38.up_proj         torch.Size([0, 1408])          0.452416             0.819445             621.312000           4098.969600         
model.layers.3.mlp.experts.38.down_proj       torch.Size([0, 2048])          0.451808             0.832796             621.312000           4037.973333         
model.layers.3.mlp.experts.39.gate_proj       torch.Size([0, 1408])          0.492608             0.869989             621.312000           4038.528000         
model.layers.3.mlp.experts.39.act_fn          torch.Size([0, 1408])          0.280384             0.720501             465.984000           4038.528000         
model.layers.3.mlp.experts.39.up_proj         torch.Size([0, 1408])          0.464032             0.835896             465.984000           3999.696000         
model.layers.3.mlp.experts.39.down_proj       torch.Size([0, 2048])          0.455328             0.854492             466.176000           3883.200000         
model.layers.3.mlp.experts.40.gate_proj       torch.Size([1, 1408])          0.946816             1.268864             552.362667           3883.200000         
model.layers.3.mlp.experts.40.act_fn          torch.Size([1, 1408])          0.316352             0.720501             621.312000           3883.200000         
model.layers.3.mlp.experts.40.up_proj         torch.Size([1, 1408])          0.889984             1.199722             621.312000           3883.200000         
model.layers.3.mlp.experts.40.down_proj       torch.Size([1, 2048])          1.070336             1.395464             710.070857           3881.828571         
model.layers.3.mlp.experts.41.gate_proj       torch.Size([0, 1408])          0.472992             0.851154             776.640000           3959.232000         
model.layers.3.mlp.experts.41.act_fn          torch.Size([0, 1408])          0.270560             0.700951             776.640000           4036.864000         
model.layers.3.mlp.experts.41.up_proj         torch.Size([0, 1408])          0.453120             0.849724             698.976000           4075.680000         
model.layers.3.mlp.experts.41.down_proj       torch.Size([0, 2048])          0.477568             0.856400             621.312000           4153.312000         
model.layers.3.mlp.experts.42.gate_proj       torch.Size([1, 1408])          0.927456             1.239538             665.691429           4125.586286         
model.layers.3.mlp.experts.42.act_fn          torch.Size([1, 1408])          0.289984             0.672817             776.512000           4036.864000         
model.layers.3.mlp.experts.42.up_proj         torch.Size([1, 1408])          0.892384             1.183271             776.440000           4036.864000         
model.layers.3.mlp.experts.42.down_proj       torch.Size([1, 2048])          1.052608             1.364708             815.136000           4036.864000         
model.layers.3.mlp.experts.43.gate_proj       torch.Size([0, 1408])          0.510752             0.915289             853.952000           3959.232000         
model.layers.3.mlp.experts.43.act_fn          torch.Size([0, 1408])          0.284160             0.665426             776.320000           3881.600000         
model.layers.3.mlp.experts.43.up_proj         torch.Size([0, 1408])          0.464192             0.836849             776.480000           3881.600000         
model.layers.3.mlp.experts.43.down_proj       torch.Size([0, 2048])          0.469088             0.834465             776.640000           3881.600000         
model.layers.3.mlp.experts.44.gate_proj       torch.Size([0, 1408])          0.480992             0.910282             776.640000           3881.600000         
model.layers.3.mlp.experts.44.act_fn          torch.Size([0, 1408])          0.283616             0.672817             621.312000           3881.600000         
model.layers.3.mlp.experts.44.up_proj         torch.Size([0, 1408])          0.483328             0.881910             621.312000           3819.494400         
model.layers.3.mlp.experts.44.down_proj       torch.Size([0, 2048])          0.522112             0.887156             621.312000           3803.968000         
model.layers.3.mlp.experts.45.gate_proj       torch.Size([0, 1408])          0.475840             0.852108             621.312000           3882.000000         
model.layers.3.mlp.experts.45.act_fn          torch.Size([0, 1408])          0.293184             0.673771             621.312000           3883.200000         
model.layers.3.mlp.experts.45.up_proj         torch.Size([0, 1408])          0.467552             0.898361             621.312000           3883.200000         
model.layers.3.mlp.experts.45.down_proj       torch.Size([0, 2048])          0.464000             0.860929             621.312000           3883.200000         
model.layers.3.mlp.experts.46.gate_proj       torch.Size([1, 1408])          0.898784             1.206398             621.312000           3824.952000         
model.layers.3.mlp.experts.46.act_fn          torch.Size([1, 1408])          0.300096             0.689030             621.312000           3727.872000         
model.layers.3.mlp.experts.46.up_proj         torch.Size([1, 1408])          0.872640             1.195669             660.144000           3726.528000         
model.layers.3.mlp.experts.46.down_proj       torch.Size([1, 2048])          1.002560             1.289129             776.640000           3726.336000         
model.layers.3.mlp.experts.47.gate_proj       torch.Size([0, 1408])          0.477248             0.854731             776.640000           3726.336000         
model.layers.3.mlp.experts.47.act_fn          torch.Size([0, 1408])          0.279712             0.644207             776.640000           3726.336000         
model.layers.3.mlp.experts.47.up_proj         torch.Size([0, 1408])          0.475296             0.899553             776.640000           3726.336000         
model.layers.3.mlp.experts.47.down_proj       torch.Size([0, 2048])          0.453312             0.819683             652.377600           3881.600000         
model.layers.3.mlp.experts.48.gate_proj       torch.Size([0, 1408])          0.484160             0.862360             621.312000           3998.048000         
model.layers.3.mlp.experts.48.act_fn          torch.Size([0, 1408])          0.281536             0.648499             621.312000           4036.864000         
model.layers.3.mlp.experts.48.up_proj         torch.Size([0, 1408])          0.464064             0.828266             621.312000           4036.864000         
model.layers.3.mlp.experts.48.down_proj       torch.Size([0, 2048])          0.459552             0.827312             621.312000           4036.864000         
model.layers.3.mlp.experts.49.gate_proj       torch.Size([0, 1408])          0.472704             0.849009             621.312000           4036.864000         
model.layers.3.mlp.experts.49.act_fn          torch.Size([0, 1408])          0.287008             0.651121             621.312000           4036.864000         
model.layers.3.mlp.experts.49.up_proj         torch.Size([0, 1408])          0.496096             0.854969             582.480000           3960.448000         
model.layers.3.mlp.experts.49.down_proj       torch.Size([0, 2048])          0.535040             0.893354             465.984000           3883.200000         
model.layers.3.mlp.experts.50.gate_proj       torch.Size([0, 1408])          0.470144             0.841618             465.984000           3883.200000         
model.layers.3.mlp.experts.50.act_fn          torch.Size([0, 1408])          0.286080             0.652313             466.032000           3883.200000         
model.layers.3.mlp.experts.50.up_proj         torch.Size([0, 1408])          0.525312             0.887156             466.176000           3883.200000         
model.layers.3.mlp.experts.50.down_proj       torch.Size([0, 2048])          0.459712             0.819445             466.176000           3844.368000         
model.layers.3.mlp.experts.51.gate_proj       torch.Size([1, 1408])          0.876352             1.207829             504.888000           3766.704000         
model.layers.3.mlp.experts.51.act_fn          torch.Size([1, 1408])          0.305920             0.693560             621.312000           3727.872000         
model.layers.3.mlp.experts.51.up_proj         torch.Size([1, 1408])          0.868672             1.159906             621.312000           3796.209778         
model.layers.3.mlp.experts.51.down_proj       torch.Size([1, 2048])          1.015840             1.305580             718.392000           3862.192000         
model.layers.3.mlp.experts.52.gate_proj       torch.Size([1, 1408])          0.875424             1.203060             776.640000           3743.587556         
model.layers.3.mlp.experts.52.act_fn          torch.Size([1, 1408])          0.312800             0.685215             776.640000           3726.336000         
model.layers.3.mlp.experts.52.up_proj         torch.Size([1, 1408])          0.891872             1.257420             820.772571           3726.336000         
model.layers.3.mlp.experts.52.down_proj       torch.Size([1, 2048])          1.002816             1.306534             931.584000           3726.336000         
model.layers.3.mlp.experts.53.gate_proj       torch.Size([0, 1408])          0.499232             0.884295             931.584000           3726.336000         
model.layers.3.mlp.experts.53.act_fn          torch.Size([0, 1408])          0.282784             0.648260             931.584000           3726.336000         
model.layers.3.mlp.experts.53.up_proj         torch.Size([0, 1408])          0.460288             0.848532             815.472000           3726.336000         
model.layers.3.mlp.experts.53.down_proj       torch.Size([0, 2048])          0.525216             0.904083             776.640000           3726.336000         
model.layers.3.mlp.experts.54.gate_proj       torch.Size([0, 1408])          0.466432             0.854492             776.640000           3726.336000         
model.layers.3.mlp.experts.54.act_fn          torch.Size([0, 1408])          0.273600             0.635624             776.640000           3726.336000         
model.layers.3.mlp.experts.54.up_proj         torch.Size([0, 1408])          0.514976             0.898123             660.144000           3881.600000         
model.layers.3.mlp.experts.54.down_proj       torch.Size([0, 2048])          0.465696             0.831842             621.312000           3959.232000         
model.layers.3.mlp.experts.55.gate_proj       torch.Size([0, 1408])          0.456096             0.832319             621.312000           4005.811200         
model.layers.3.mlp.experts.55.act_fn          torch.Size([0, 1408])          0.274304             0.693321             621.312000           3933.354667         
model.layers.3.mlp.experts.55.up_proj         torch.Size([0, 1408])          0.459936             0.831127             621.312000           3882.800000         
model.layers.3.mlp.experts.55.down_proj       torch.Size([0, 2048])          0.487072             0.862598             621.312000           3883.200000         
model.layers.3.mlp.experts.56.gate_proj       torch.Size([0, 1408])          0.456192             0.879765             621.312000           3883.200000         
model.layers.3.mlp.experts.56.act_fn          torch.Size([0, 1408])          0.274656             0.646830             465.984000           3883.200000         
model.layers.3.mlp.experts.56.up_proj         torch.Size([0, 1408])          0.446784             0.805616             466.032000           3883.200000         
model.layers.3.mlp.experts.56.down_proj       torch.Size([0, 2048])          0.455872             0.892639             466.128000           3805.536000         
model.layers.3.mlp.experts.57.gate_proj       torch.Size([0, 1408])          0.499808             0.874043             466.176000           3844.368000         
model.layers.3.mlp.experts.57.act_fn          torch.Size([0, 1408])          0.296352             0.661373             466.176000           3779.648000         
model.layers.3.mlp.experts.57.up_proj         torch.Size([0, 1408])          0.509920             0.888109             466.176000           3727.872000         
model.layers.3.mlp.experts.57.down_proj       torch.Size([0, 2048])          0.464160             0.823975             466.176000           3727.872000         
model.layers.3.mlp.experts.58.gate_proj       torch.Size([1, 1408])          0.887424             1.191854             505.024000           3727.872000         
model.layers.3.mlp.experts.58.act_fn          torch.Size([1, 1408])          0.313408             0.678301             621.568000           3727.872000         
model.layers.3.mlp.experts.58.up_proj         torch.Size([1, 1408])          0.894624             1.187086             621.385143           3727.872000         
model.layers.3.mlp.experts.58.down_proj       torch.Size([1, 2048])          1.052480             1.365185             718.392000           3726.336000         
model.layers.3.mlp.experts.59.gate_proj       torch.Size([0, 1408])          0.466624             0.841618             776.640000           3726.336000         
model.layers.3.mlp.experts.59.act_fn          torch.Size([0, 1408])          0.274080             0.633001             776.640000           3726.336000         
model.layers.3.mlp.experts.59.up_proj         torch.Size([0, 1408])          0.509504             0.872850             621.312000           3688.272000         
model.layers.3.mlp.experts.59.down_proj       torch.Size([0, 2048])          0.455648             0.854254             621.312000           3650.208000         
model.layers.3.mlp.shared_expert.gate_proj    torch.Size([5, 5632])          2.603552             2.909660             798.774857           3571.282286         
model.layers.3.mlp.shared_expert.act_fn       torch.Size([5, 5632])          0.291424             0.674009             1086.848000          3569.968000         
model.layers.3.mlp.shared_expert.up_proj      torch.Size([5, 5632])          2.553696             2.857447             1276.359111          3569.272889         
model.layers.3.mlp.shared_expert.down_proj    torch.Size([5, 2048])          2.678400             2.984047             1629.160000          3664.704000         
model.layers.3.mlp.shared_expert_gate         torch.Size([5, 1])             0.561088             0.931740             1728.658286          3788.873143         
model.layers.4.input_layernorm                torch.Size([1, 5, 2048])       0.975744             1.359224             1582.579200          3886.156800         
model.layers.4.self_attn.q_proj               torch.Size([1, 5, 2048])       1.457472             1.781940             1532.520000          3878.400000         
model.layers.4.self_attn.k_proj               torch.Size([1, 5, 2048])       1.327648             1.626253             1551.360000          3878.400000         
model.layers.4.self_attn.v_proj               torch.Size([1, 5, 2048])       1.386496             1.707077             1648.320000          3878.400000         
model.layers.4.self_attn.o_proj               torch.Size([1, 5, 2048])       1.308544             1.625061             1706.496000          3820.224000         
model.layers.4.post_attention_layernorm       torch.Size([1, 5, 2048])       0.921856             1.298904             1613.414400          3870.643200         
model.layers.4.mlp.gate                       torch.Size([5, 60])            0.519584             0.898123             1507.200000          4033.536000         
model.layers.4.mlp.experts.0.gate_proj        torch.Size([0, 1408])          0.542880             1.041651             1396.800000          3955.968000         
model.layers.4.mlp.experts.0.act_fn           torch.Size([0, 1408])          0.324416             0.724554             1396.800000          3982.357333         
model.layers.4.mlp.experts.0.up_proj          torch.Size([0, 1408])          0.464224             0.831366             1241.600000          3918.800000         
model.layers.4.mlp.experts.0.down_proj        torch.Size([0, 2048])          0.522848             0.895977             1241.770667          3880.000000         
model.layers.4.mlp.experts.1.gate_proj        torch.Size([1, 1408])          0.902688             1.215935             1224.860444          3880.000000         
model.layers.4.mlp.experts.1.act_fn           torch.Size([1, 1408])          0.298848             0.668526             1242.009600          3880.000000         
model.layers.4.mlp.experts.1.up_proj          torch.Size([1, 1408])          0.852864             1.234770             1241.941333          3880.000000         
model.layers.4.mlp.experts.1.down_proj        torch.Size([1, 2048])          1.035008             1.322985             1241.600000          3880.000000         
model.layers.4.mlp.experts.2.gate_proj        torch.Size([0, 1408])          0.466016             0.837564             1241.941333          3880.000000         
model.layers.4.mlp.experts.2.act_fn           torch.Size([0, 1408])          0.295904             0.660419             1242.112000          3828.266667         
model.layers.4.mlp.experts.2.up_proj          torch.Size([0, 1408])          0.468032             0.830650             1086.848000          3786.880000         
model.layers.4.mlp.experts.2.down_proj        torch.Size([0, 2048])          0.508576             0.872135             1086.848000          3819.174400         
model.layers.4.mlp.experts.3.gate_proj        torch.Size([1, 1408])          0.875104             1.199245             1086.848000          3726.336000         
model.layers.4.mlp.experts.3.act_fn           torch.Size([1, 1408])          0.301376             0.679731             1086.848000          3803.968000         
model.layers.4.mlp.experts.3.up_proj          torch.Size([1, 1408])          0.858112             1.217842             1086.848000          3880.400000         
model.layers.4.mlp.experts.3.down_proj        torch.Size([1, 2048])          1.003072             1.294613             1164.480000          4035.200000         
model.layers.4.mlp.experts.4.gate_proj        torch.Size([0, 1408])          0.508448             0.889540             1164.480000          4035.200000         
model.layers.4.mlp.experts.4.act_fn           torch.Size([0, 1408])          0.276128             0.665188             1086.848000          4035.200000         
model.layers.4.mlp.experts.4.up_proj          torch.Size([0, 1408])          0.460736             0.820398             1086.848000          4035.200000         
model.layers.4.mlp.experts.4.down_proj        torch.Size([0, 2048])          0.507296             0.872374             1048.032000          3881.200000         
model.layers.4.mlp.experts.5.gate_proj        torch.Size([0, 1408])          0.465184             0.888586             931.680000           3881.600000         
model.layers.4.mlp.experts.5.act_fn           torch.Size([0, 1408])          0.274688             0.673532             931.840000           3881.600000         
model.layers.4.mlp.experts.5.up_proj          torch.Size([0, 1408])          0.513792             0.908136             931.968000           3881.600000         
model.layers.4.mlp.experts.5.down_proj        torch.Size([0, 2048])          0.475424             0.840187             931.968000           3881.600000         
model.layers.4.mlp.experts.6.gate_proj        torch.Size([1, 1408])          0.876288             1.177311             931.968000           3862.192000         
model.layers.4.mlp.experts.6.act_fn           torch.Size([1, 1408])          0.326048             0.713825             931.968000           3842.784000         
model.layers.4.mlp.experts.6.up_proj          torch.Size([1, 1408])          0.919168             1.227617             931.728000           3919.800000         
model.layers.4.mlp.experts.6.down_proj        torch.Size([1, 2048])          1.036256             1.345873             1052.344889          4035.200000         
model.layers.4.mlp.experts.7.gate_proj        torch.Size([0, 1408])          0.499008             0.893593             1086.848000          4074.000000         
model.layers.4.mlp.experts.7.act_fn           torch.Size([0, 1408])          0.285760             0.689507             1035.093333          4035.200000         
model.layers.4.mlp.experts.7.up_proj          torch.Size([0, 1408])          0.560000             0.936747             931.584000           4035.200000         
model.layers.4.mlp.experts.7.down_proj        torch.Size([0, 2048])          0.488032             0.865936             931.584000           4036.448000         
model.layers.4.mlp.experts.8.gate_proj        torch.Size([0, 1408])          0.516512             0.896215             931.968000           3998.048000         
model.layers.4.mlp.experts.8.act_fn           torch.Size([0, 1408])          0.322048             0.684500             931.968000           3881.600000         
model.layers.4.mlp.experts.8.up_proj          torch.Size([0, 1408])          0.474880             0.845671             776.640000           3881.600000         
model.layers.4.mlp.experts.8.down_proj        torch.Size([0, 2048])          0.465312             0.823975             776.640000           3881.600000         
model.layers.4.mlp.experts.9.gate_proj        torch.Size([0, 1408])          0.489600             0.883818             776.640000           3881.600000         
model.layers.4.mlp.experts.9.act_fn           torch.Size([0, 1408])          0.296096             0.654936             776.640000           3881.600000         
model.layers.4.mlp.experts.9.up_proj          torch.Size([0, 1408])          0.468384             0.854015             776.640000           3881.600000         
model.layers.4.mlp.experts.9.down_proj        torch.Size([0, 2048])          0.551808             0.915289             776.640000           3881.600000         
model.layers.4.mlp.experts.10.gate_proj       torch.Size([1, 1408])          0.893472             1.204967             776.640000           3985.109333         
model.layers.4.mlp.experts.10.act_fn          torch.Size([1, 1408])          0.291872             0.671148             776.640000           4036.864000         
model.layers.4.mlp.experts.10.up_proj         torch.Size([1, 1408])          0.878112             1.265526             821.019429           4169.453714         
model.layers.4.mlp.experts.10.down_proj       torch.Size([1, 2048])          1.024320             1.344442             931.584000           4146.057143         
model.layers.4.mlp.experts.11.gate_proj       torch.Size([1, 1408])          0.888032             1.197100             1028.624000          4054.600000         
model.layers.4.mlp.experts.11.act_fn          torch.Size([1, 1408])          0.313376             0.725985             1086.848000          4035.200000         
model.layers.4.mlp.experts.11.up_proj         torch.Size([1, 1408])          0.901344             1.194477             1086.848000          4035.200000         
model.layers.4.mlp.experts.11.down_proj       torch.Size([1, 2048])          1.013536             1.309872             1131.209143          3968.685714         
model.layers.4.mlp.experts.12.gate_proj       torch.Size([0, 1408])          0.473696             0.862837             1125.664000          3880.000000         
model.layers.4.mlp.experts.12.act_fn          torch.Size([0, 1408])          0.680224             1.052380             1086.848000          3880.000000         
model.layers.4.mlp.experts.12.up_proj         torch.Size([0, 1408])          0.487776             0.863791             1086.848000          3880.000000         
model.layers.4.mlp.experts.12.down_proj       torch.Size([0, 2048])          0.514752             0.888586             993.689600           3880.960000         
model.layers.4.mlp.experts.13.gate_proj       torch.Size([1, 1408])          0.910240             1.208782             989.808000           3823.376000         
model.layers.4.mlp.experts.13.act_fn          torch.Size([1, 1408])          0.299872             0.720501             1086.848000          3726.336000         
model.layers.4.mlp.experts.13.up_proj         torch.Size([1, 1408])          0.878112             1.181364             1067.440000          3861.792000         
model.layers.4.mlp.experts.13.down_proj       torch.Size([1, 2048])          1.005664             1.300812             1086.792000          3880.000000         
model.layers.4.mlp.experts.14.gate_proj       torch.Size([0, 1408])          0.552544             0.937462             1086.736000          3880.400000         
model.layers.4.mlp.experts.14.act_fn          torch.Size([0, 1408])          0.340608             0.718355             1086.848000          3881.600000         
model.layers.4.mlp.experts.14.up_proj         torch.Size([0, 1408])          0.525952             0.900984             1086.848000          3726.336000         
model.layers.4.mlp.experts.14.down_proj       torch.Size([0, 2048])          0.664736             1.099825             962.636800           3757.388800         
model.layers.4.mlp.experts.15.gate_proj       torch.Size([1, 1408])          0.902720             1.249790             989.808000           3726.336000         
model.layers.4.mlp.experts.15.act_fn          torch.Size([1, 1408])          0.343840             0.805616             1086.848000          3726.336000         
model.layers.4.mlp.experts.15.up_proj         torch.Size([1, 1408])          0.915424             1.242876             1086.848000          3726.336000         
model.layers.4.mlp.experts.15.down_proj       torch.Size([1, 2048])          1.041632             1.342773             1106.256000          3726.144000         
model.layers.4.mlp.experts.16.gate_proj       torch.Size([1, 1408])          0.881056             1.227140             1242.112000          3724.800000         
model.layers.4.mlp.experts.16.act_fn          torch.Size([1, 1408])          0.330208             0.712633             1242.112000          3880.000000         
model.layers.4.mlp.experts.16.up_proj         torch.Size([1, 1408])          0.871680             1.168728             1242.112000          3880.000000         
model.layers.4.mlp.experts.16.down_proj       torch.Size([1, 2048])          1.013888             1.304626             1241.892571          4035.200000         
model.layers.4.mlp.experts.17.gate_proj       torch.Size([1, 1408])          0.898752             1.210690             1308.114286          4035.200000         
model.layers.4.mlp.experts.17.act_fn          torch.Size([1, 1408])          0.306528             0.722408             1334.720000          4035.200000         
model.layers.4.mlp.experts.17.up_proj         torch.Size([1, 1408])          0.856704             1.156807             1330.285714          3924.342857         
model.layers.4.mlp.experts.17.down_proj       torch.Size([1, 2048])          1.005696             1.293421             1396.800000          3880.000000         
model.layers.4.mlp.experts.18.gate_proj       torch.Size([1, 1408])          0.894112             1.189470             1396.800000          3879.314286         
model.layers.4.mlp.experts.18.act_fn          torch.Size([1, 1408])          0.311296             0.769138             1396.800000          3880.000000         
model.layers.4.mlp.experts.18.up_proj         torch.Size([1, 1408])          0.869120             1.157522             1396.800000          3880.000000         
model.layers.4.mlp.experts.18.down_proj       torch.Size([1, 2048])          0.998208             1.298904             1435.600000          3878.800000         
model.layers.4.mlp.experts.19.gate_proj       torch.Size([1, 1408])          0.903616             1.196146             1552.000000          3820.224000         
model.layers.4.mlp.experts.19.act_fn          torch.Size([1, 1408])          0.294688             0.713587             1513.200000          3840.400000         
model.layers.4.mlp.experts.19.up_proj         torch.Size([1, 1408])          0.860160             1.142025             1441.142857          3856.237714         
model.layers.4.mlp.experts.19.down_proj       torch.Size([1, 2048])          1.017760             1.303434             1552.000000          3839.616000         
model.layers.4.mlp.experts.20.gate_proj       torch.Size([0, 1408])          0.475712             0.932455             1513.200000          3762.816000         
model.layers.4.mlp.experts.20.act_fn          torch.Size([0, 1408])          0.274240             0.648260             1396.800000          3776.533333         
model.layers.4.mlp.experts.20.up_proj         torch.Size([0, 1408])          0.482368             0.861406             1366.208000          3724.800000         
model.layers.4.mlp.experts.20.down_proj       torch.Size([0, 2048])          0.455616             0.822067             1242.112000          3724.800000         
model.layers.4.mlp.experts.21.gate_proj       torch.Size([0, 1408])          0.459040             0.846386             1242.112000          3880.000000         
model.layers.4.mlp.experts.21.act_fn          torch.Size([0, 1408])          0.269376             0.645876             1086.848000          4035.200000         
model.layers.4.mlp.experts.21.up_proj         torch.Size([0, 1408])          0.455200             0.851631             1086.848000          4151.600000         
model.layers.4.mlp.experts.21.down_proj       torch.Size([0, 2048])          0.533632             0.903130             1086.848000          4345.600000         
model.layers.4.mlp.experts.22.gate_proj       torch.Size([0, 1408])          0.458624             0.834465             931.584000           4268.000000         
model.layers.4.mlp.experts.22.act_fn          torch.Size([0, 1408])          0.268896             0.643015             931.584000           4190.400000         
model.layers.4.mlp.experts.22.up_proj         torch.Size([0, 1408])          0.520320             0.881195             931.584000           4306.800000         
model.layers.4.mlp.experts.22.down_proj       torch.Size([0, 2048])          0.450656             0.829697             931.584000           4345.600000         
model.layers.4.mlp.experts.23.gate_proj       torch.Size([0, 1408])          0.508800             0.881433             776.320000           4345.600000         
model.layers.4.mlp.experts.23.act_fn          torch.Size([0, 1408])          0.272288             0.648975             776.320000           4346.197333         
model.layers.4.mlp.experts.23.up_proj         torch.Size([0, 1408])          0.454784             0.828266             776.320000           4347.392000         
model.layers.4.mlp.experts.23.down_proj       torch.Size([0, 2048])          0.447168             0.827074             776.576000           4254.233600         
model.layers.4.mlp.experts.24.gate_proj       torch.Size([0, 1408])          0.470784             0.847101             776.640000           4192.128000         
model.layers.4.mlp.experts.24.act_fn          torch.Size([0, 1408])          0.289632             0.657082             776.640000           4192.128000         
model.layers.4.mlp.experts.24.up_proj         torch.Size([0, 1408])          0.478240             0.868320             660.144000           4114.496000         
model.layers.4.mlp.experts.24.down_proj       torch.Size([0, 2048])          0.514496             0.890017             621.312000           4036.864000         
model.layers.4.mlp.experts.25.gate_proj       torch.Size([1, 1408])          0.919648             1.225948             698.976000           4036.864000         
model.layers.4.mlp.experts.25.act_fn          torch.Size([1, 1408])          0.295776             0.659704             776.640000           3974.758400         
model.layers.4.mlp.experts.25.up_proj         torch.Size([1, 1408])          0.872256             1.256704             776.640000           3920.416000         
model.layers.4.mlp.experts.25.down_proj       torch.Size([1, 2048])          1.015200             1.310349             842.861714           3881.600000         
model.layers.4.mlp.experts.26.gate_proj       torch.Size([0, 1408])          0.481856             0.862122             931.584000           3881.600000         
model.layers.4.mlp.experts.26.act_fn          torch.Size([0, 1408])          0.280640             0.646830             776.320000           3881.600000         
model.layers.4.mlp.experts.26.up_proj         torch.Size([0, 1408])          0.469728             0.829697             776.480000           3881.600000         
model.layers.4.mlp.experts.26.down_proj       torch.Size([0, 2048])          0.526752             0.890255             776.640000           3819.494400         
model.layers.4.mlp.experts.27.gate_proj       torch.Size([0, 1408])          0.494688             0.867128             776.640000           3765.152000         
model.layers.4.mlp.experts.27.act_fn          torch.Size([0, 1408])          0.283872             0.641108             776.640000           3726.336000         
model.layers.4.mlp.experts.27.up_proj         torch.Size([0, 1408])          0.524992             0.880957             621.312000           3726.336000         
model.layers.4.mlp.experts.27.down_proj       torch.Size([0, 2048])          0.462368             0.819921             621.312000           3727.488000         
model.layers.4.mlp.experts.28.gate_proj       torch.Size([0, 1408])          0.484992             0.865936             621.312000           3727.872000         
model.layers.4.mlp.experts.28.act_fn          torch.Size([0, 1408])          0.292448             0.738621             621.312000           3727.872000         
model.layers.4.mlp.experts.28.up_proj         torch.Size([0, 1408])          0.463424             0.852585             621.465600           3634.675200         
model.layers.4.mlp.experts.28.down_proj       torch.Size([0, 2048])          0.463616             0.822306             621.568000           3665.740800         
model.layers.4.mlp.experts.29.gate_proj       torch.Size([0, 1408])          0.469600             0.894547             590.489600           3727.872000         
model.layers.4.mlp.experts.29.act_fn          torch.Size([0, 1408])          0.294272             0.669718             466.176000           3831.424000         
model.layers.4.mlp.experts.29.up_proj         torch.Size([0, 1408])          0.462656             0.826836             466.128000           3883.200000         
model.layers.4.mlp.experts.29.down_proj       torch.Size([0, 2048])          0.465536             0.901461             465.984000           3999.696000         
model.layers.4.mlp.experts.30.gate_proj       torch.Size([1, 1408])          0.882944             1.189232             543.648000           3960.064000         
model.layers.4.mlp.experts.30.act_fn          torch.Size([1, 1408])          0.291328             0.672579             621.312000           3881.600000         
model.layers.4.mlp.experts.30.up_proj         torch.Size([1, 1408])          0.917920             1.221657             621.312000           3881.600000         
model.layers.4.mlp.experts.30.down_proj       torch.Size([1, 2048])          1.011968             1.298428             707.605333           3743.587556         
model.layers.4.mlp.experts.31.gate_proj       torch.Size([0, 1408])          0.469312             0.894547             776.640000           3726.336000         
model.layers.4.mlp.experts.31.act_fn          torch.Size([0, 1408])          0.271040             0.647783             776.640000           3726.336000         
model.layers.4.mlp.experts.31.up_proj         torch.Size([0, 1408])          0.450208             0.826836             660.144000           3803.968000         
model.layers.4.mlp.experts.31.down_proj       torch.Size([0, 2048])          0.463200             0.826120             621.312000           3881.600000         
model.layers.4.mlp.experts.32.gate_proj       torch.Size([0, 1408])          0.498112             0.879765             621.312000           3998.048000         
model.layers.4.mlp.experts.32.act_fn          torch.Size([0, 1408])          0.286112             0.651836             621.312000           3985.109333         
model.layers.4.mlp.experts.32.up_proj         torch.Size([0, 1408])          0.526912             0.894785             621.312000           3882.000000         
model.layers.4.mlp.experts.32.down_proj       torch.Size([0, 2048])          0.457408             0.821114             621.312000           3766.704000         
model.layers.4.mlp.experts.33.gate_proj       torch.Size([0, 1408])          0.488384             0.863791             582.592000           3727.872000         
model.layers.4.mlp.experts.33.act_fn          torch.Size([0, 1408])          0.345696             0.708342             466.176000           3727.872000         
model.layers.4.mlp.experts.33.up_proj         torch.Size([0, 1408])          0.468480             0.855923             466.176000           3727.872000         
model.layers.4.mlp.experts.33.down_proj       torch.Size([0, 2048])          0.483264             0.841856             466.176000           3727.872000         
model.layers.4.mlp.experts.34.gate_proj       torch.Size([0, 1408])          0.540576             0.909328             466.176000           3727.872000         
model.layers.4.mlp.experts.34.act_fn          torch.Size([0, 1408])          0.281568             0.641823             466.176000           3727.872000         
model.layers.4.mlp.experts.34.up_proj         torch.Size([0, 1408])          0.476512             0.849962             466.176000           3727.872000         
model.layers.4.mlp.experts.34.down_proj       torch.Size([0, 2048])          0.457760             0.823736             466.176000           3727.872000         
model.layers.4.mlp.experts.35.gate_proj       torch.Size([0, 1408])          0.507552             0.878811             466.176000           3727.872000         
model.layers.4.mlp.experts.35.act_fn          torch.Size([0, 1408])          0.282688             0.648499             466.176000           3572.544000         
model.layers.4.mlp.experts.35.up_proj         torch.Size([0, 1408])          0.473184             0.901937             466.176000           3727.872000         
model.layers.4.mlp.experts.35.down_proj       torch.Size([0, 2048])          0.456928             0.819206             466.176000           3844.368000         
model.layers.4.mlp.experts.36.gate_proj       torch.Size([0, 1408])          0.470272             0.835896             466.176000           3883.200000         
model.layers.4.mlp.experts.36.act_fn          torch.Size([0, 1408])          0.281984             0.746489             466.176000           4038.528000         
model.layers.4.mlp.experts.36.up_proj         torch.Size([0, 1408])          0.480096             0.877857             466.176000           4038.528000         
model.layers.4.mlp.experts.36.down_proj       torch.Size([0, 2048])          0.481856             0.854492             466.176000           4038.528000         
model.layers.4.mlp.experts.37.gate_proj       torch.Size([0, 1408])          0.528480             0.895262             466.176000           3960.864000         
model.layers.4.mlp.experts.37.act_fn          torch.Size([0, 1408])          0.284640             0.644922             466.176000           3883.200000         
model.layers.4.mlp.experts.37.up_proj         torch.Size([0, 1408])          0.467552             0.831842             466.176000           3922.032000         
model.layers.4.mlp.experts.37.down_proj       torch.Size([0, 2048])          0.455936             0.817776             466.176000           3883.200000         
model.layers.4.mlp.experts.38.gate_proj       torch.Size([0, 1408])          0.480224             0.851154             466.176000           3790.003200         
model.layers.4.mlp.experts.38.act_fn          torch.Size([0, 1408])          0.284736             0.646353             466.176000           3727.872000         
model.layers.4.mlp.experts.38.up_proj         torch.Size([0, 1408])          0.468768             0.835896             349.632000           3728.640000         
model.layers.4.mlp.experts.38.down_proj       torch.Size([0, 2048])          0.457152             0.820637             310.784000           3805.536000         
model.layers.4.mlp.experts.39.gate_proj       torch.Size([0, 1408])          0.478912             0.846624             310.784000           3999.696000         
model.layers.4.mlp.experts.39.act_fn          torch.Size([0, 1408])          0.292256             0.658512             310.784000           4038.528000         
model.layers.4.mlp.experts.39.up_proj         torch.Size([0, 1408])          0.476448             0.867367             310.784000           4038.528000         
model.layers.4.mlp.experts.39.down_proj       torch.Size([0, 2048])          0.460352             0.823021             310.784000           4038.528000         
model.layers.4.mlp.experts.40.gate_proj       torch.Size([1, 1408])          0.896544             1.190424             466.128000           4019.112000         
model.layers.4.mlp.experts.40.act_fn          torch.Size([1, 1408])          0.299872             0.684738             465.984000           4038.528000         
model.layers.4.mlp.experts.40.up_proj         torch.Size([1, 1408])          0.914112             1.215219             543.648000           3980.280000         
model.layers.4.mlp.experts.40.down_proj       torch.Size([1, 2048])          1.120480             1.554966             621.312000           3881.600000         
model.layers.4.mlp.experts.41.gate_proj       torch.Size([1, 1408])          0.957888             1.371861             742.122667           3881.600000         
model.layers.4.mlp.experts.41.act_fn          torch.Size([1, 1408])          0.431584             0.968695             776.640000           3881.600000         
model.layers.4.mlp.experts.41.up_proj         torch.Size([1, 1408])          1.028960             1.634598             776.640000           3881.600000         
model.layers.4.mlp.experts.41.down_proj       torch.Size([1, 2048])          1.147936             1.607418             854.160000           3881.600000         
model.layers.4.mlp.experts.42.gate_proj       torch.Size([0, 1408])          0.576800             0.998020             931.584000           3881.600000         
model.layers.4.mlp.experts.42.act_fn          torch.Size([0, 1408])          0.387552             0.830412             776.320000           4036.864000         
model.layers.4.mlp.experts.42.up_proj         torch.Size([0, 1408])          0.494112             0.879526             776.320000           4036.864000         
model.layers.4.mlp.experts.42.down_proj       torch.Size([0, 2048])          0.459488             0.890970             776.384000           4067.916800         
model.layers.4.mlp.experts.43.gate_proj       torch.Size([1, 1408])          0.905600             1.290083             776.355556           4036.864000         
model.layers.4.mlp.experts.43.act_fn          torch.Size([1, 1408])          0.308896             0.673771             776.320000           4036.864000         
model.layers.4.mlp.experts.43.up_proj         torch.Size([1, 1408])          0.872832             1.166821             776.320000           4036.388571         
model.layers.4.mlp.experts.43.down_proj       torch.Size([1, 2048])          1.066720             1.364708             912.176000           4015.800000         
model.layers.4.mlp.experts.44.gate_proj       torch.Size([0, 1408])          0.464512             0.854731             931.584000           3918.800000         
model.layers.4.mlp.experts.44.act_fn          torch.Size([0, 1408])          0.311168             0.671625             931.584000           3880.000000         
model.layers.4.mlp.experts.44.up_proj         torch.Size([0, 1408])          0.479552             0.839233             776.320000           3881.600000         
model.layers.4.mlp.experts.44.down_proj       torch.Size([0, 2048])          0.495232             0.854015             776.576000           3881.600000         
model.layers.4.mlp.experts.45.gate_proj       torch.Size([0, 1408])          0.459872             0.835657             776.640000           3881.600000         
model.layers.4.mlp.experts.45.act_fn          torch.Size([0, 1408])          0.275904             0.630379             776.640000           3881.600000         
model.layers.4.mlp.experts.45.up_proj         torch.Size([0, 1408])          0.546336             0.922441             698.976000           3803.968000         
model.layers.4.mlp.experts.45.down_proj       torch.Size([0, 2048])          0.485728             0.848770             621.312000           3765.152000         
model.layers.4.mlp.experts.46.gate_proj       torch.Size([1, 1408])          0.872864             1.254797             687.881143           3881.600000         
model.layers.4.mlp.experts.46.act_fn          torch.Size([1, 1408])          0.299520             0.667572             776.640000           3881.600000         
model.layers.4.mlp.experts.46.up_proj         torch.Size([1, 1408])          0.865536             1.167059             776.560000           3881.600000         
model.layers.4.mlp.experts.46.down_proj       torch.Size([1, 2048])          1.061696             1.358747             795.728000           3823.376000         
model.layers.4.mlp.experts.47.gate_proj       torch.Size([0, 1408])          0.470240             0.868082             815.136000           3765.152000         
model.layers.4.mlp.experts.47.act_fn          torch.Size([0, 1408])          0.274688             0.643253             776.560000           3726.336000         
model.layers.4.mlp.experts.47.up_proj         torch.Size([0, 1408])          0.460608             0.830412             776.640000           3726.336000         
model.layers.4.mlp.experts.47.down_proj       torch.Size([0, 2048])          0.455520             0.822067             776.640000           3726.336000         
model.layers.4.mlp.experts.48.gate_proj       torch.Size([0, 1408])          0.489920             0.940323             776.640000           3726.336000         
model.layers.4.mlp.experts.48.act_fn          torch.Size([0, 1408])          0.270304             0.631094             621.312000           3726.336000         
model.layers.4.mlp.experts.48.up_proj         torch.Size([0, 1408])          0.464320             0.837803             621.312000           3727.872000         
model.layers.4.mlp.experts.48.down_proj       torch.Size([0, 2048])          0.447520             0.805855             621.312000           3820.428800         
model.layers.4.mlp.experts.49.gate_proj       torch.Size([1, 1408])          0.942624             1.275063             643.501714           3925.961143         
model.layers.4.mlp.experts.49.act_fn          torch.Size([1, 1408])          0.300352             0.716686             698.976000           4036.864000         
model.layers.4.mlp.experts.49.up_proj         torch.Size([1, 1408])          0.894080             1.181602             754.450286           4081.225143         
model.layers.4.mlp.experts.49.down_proj       torch.Size([1, 2048])          1.044256             1.343727             793.749333           4035.754667         
model.layers.4.mlp.experts.50.gate_proj       torch.Size([0, 1408])          0.488992             0.967741             807.500800           4004.160000         
model.layers.4.mlp.experts.50.act_fn          torch.Size([0, 1408])          0.297760             0.674009             776.640000           3933.354667         
model.layers.4.mlp.experts.50.up_proj         torch.Size([0, 1408])          0.480096             0.890493             776.640000           3920.416000         
model.layers.4.mlp.experts.50.down_proj       torch.Size([0, 2048])          0.476096             0.870705             776.640000           3881.600000         
model.layers.4.mlp.experts.51.gate_proj       torch.Size([0, 1408])          0.460768             0.850677             776.640000           3881.600000         
model.layers.4.mlp.experts.51.act_fn          torch.Size([0, 1408])          0.277664             0.645638             621.312000           3881.600000         
model.layers.4.mlp.experts.51.up_proj         torch.Size([0, 1408])          0.458496             0.819921             621.312000           3881.600000         
model.layers.4.mlp.experts.51.down_proj       torch.Size([0, 2048])          0.481760             0.854254             621.312000           3881.600000         
model.layers.4.mlp.experts.52.gate_proj       torch.Size([1, 1408])          0.891424             1.294851             660.144000           3862.192000         
model.layers.4.mlp.experts.52.act_fn          torch.Size([1, 1408])          0.372704             0.737906             776.640000           3881.600000         
model.layers.4.mlp.experts.52.up_proj         torch.Size([1, 1408])          0.881568             1.181841             776.640000           3765.152000         
model.layers.4.mlp.experts.52.down_proj       torch.Size([1, 2048])          1.027456             1.333237             811.157333           3795.342222         
model.layers.4.mlp.experts.53.gate_proj       torch.Size([1, 1408])          0.900960             1.228094             931.968000           3725.952000         
model.layers.4.mlp.experts.53.act_fn          torch.Size([1, 1408])          0.296608             0.685453             931.968000           3725.952000         
model.layers.4.mlp.experts.53.up_proj         torch.Size([1, 1408])          0.856576             1.145601             931.748571           3725.019429         
model.layers.4.mlp.experts.53.down_proj       torch.Size([1, 2048])          1.025792             1.321793             989.808000           3724.800000         
model.layers.4.mlp.experts.54.gate_proj       torch.Size([0, 1408])          0.542528             0.946999             970.400000           3724.800000         
model.layers.4.mlp.experts.54.act_fn          torch.Size([0, 1408])          0.280000             0.671864             931.712000           3725.824000         
model.layers.4.mlp.experts.54.up_proj         torch.Size([0, 1408])          0.464448             0.853777             931.968000           3726.336000         
model.layers.4.mlp.experts.54.down_proj       torch.Size([0, 2048])          0.448928             0.811338             869.836800           3695.283200         
model.layers.4.mlp.experts.55.gate_proj       torch.Size([0, 1408])          0.456576             0.837803             776.640000           3726.336000         
model.layers.4.mlp.experts.55.act_fn          torch.Size([0, 1408])          0.272000             0.648022             776.640000           3842.784000         
model.layers.4.mlp.experts.55.up_proj         torch.Size([0, 1408])          0.466752             0.854969             776.640000           3881.600000         
model.layers.4.mlp.experts.55.down_proj       torch.Size([0, 2048])          0.485664             0.913143             737.808000           3959.232000         
model.layers.4.mlp.experts.56.gate_proj       torch.Size([0, 1408])          0.469088             0.841379             621.312000           4036.864000         
model.layers.4.mlp.experts.56.act_fn          torch.Size([0, 1408])          0.271616             0.649452             621.312000           4036.864000         
model.layers.4.mlp.experts.56.up_proj         torch.Size([0, 1408])          0.452352             0.827312             621.312000           4036.864000         
model.layers.4.mlp.experts.56.down_proj       torch.Size([0, 2048])          0.447072             0.823259             621.312000           3959.232000         
model.layers.4.mlp.experts.57.gate_proj       torch.Size([0, 1408])          0.482464             0.914812             621.312000           3882.400000         
model.layers.4.mlp.experts.57.act_fn          torch.Size([0, 1408])          0.276736             0.655174             621.312000           3883.200000         
model.layers.4.mlp.experts.57.up_proj         torch.Size([0, 1408])          0.453312             0.820160             621.312000           3883.200000         
model.layers.4.mlp.experts.57.down_proj       torch.Size([0, 2048])          0.449440             0.826120             466.099200           3883.200000         
model.layers.4.mlp.experts.58.gate_proj       torch.Size([0, 1408])          0.480096             0.863075             466.176000           3844.368000         
model.layers.4.mlp.experts.58.act_fn          torch.Size([0, 1408])          0.301248             0.677824             466.176000           3883.200000         
model.layers.4.mlp.experts.58.up_proj         torch.Size([0, 1408])          0.505120             0.866175             466.176000           3790.003200         
model.layers.4.mlp.experts.58.down_proj       torch.Size([0, 2048])          0.526400             0.907183             466.176000           3727.872000         
model.layers.4.mlp.experts.59.gate_proj       torch.Size([0, 1408])          0.473440             0.844002             466.176000           3727.872000         
model.layers.4.mlp.experts.59.act_fn          torch.Size([0, 1408])          0.272800             0.646591             466.176000           3727.872000         
model.layers.4.mlp.experts.59.up_proj         torch.Size([0, 1408])          0.525824             0.890732             466.176000           3727.872000         
model.layers.4.mlp.experts.59.down_proj       torch.Size([0, 2048])          0.448160             0.822067             466.176000           3727.872000         
model.layers.4.mlp.shared_expert.gate_proj    torch.Size([5, 5632])          2.625728             2.940178             586.887111           3727.189333         
model.layers.4.mlp.shared_expert.act_fn       torch.Size([5, 5632])          0.322720             0.693083             869.836800           3726.336000         
model.layers.4.mlp.shared_expert.up_proj      torch.Size([5, 5632])          2.600768             2.890587             1017.870222          3725.312000         
model.layers.4.mlp.shared_expert.down_proj    torch.Size([5, 2048])          2.677792             2.966166             1586.247111          3722.922667         
model.layers.4.mlp.shared_expert_gate         torch.Size([5, 1])             0.570592             0.942945             1751.021714          3722.825143         
model.layers.5.input_layernorm                torch.Size([1, 5, 2048])       0.887616             1.323462             1611.123810          3612.452571         
model.layers.5.self_attn.q_proj               torch.Size([1, 5, 2048])       1.417664             1.716614             1552.000000          3703.872000         
model.layers.5.self_attn.k_proj               torch.Size([1, 5, 2048])       1.223456             1.531839             1552.000000          3878.400000         
model.layers.5.self_attn.v_proj               torch.Size([1, 5, 2048])       1.393472             1.694679             1667.712000          3994.752000         
model.layers.5.self_attn.o_proj               torch.Size([1, 5, 2048])       1.317664             1.635790             1706.496000          3897.792000         
model.layers.5.post_attention_layernorm       torch.Size([1, 5, 2048])       0.879456             1.302481             1636.366545          3864.296727         
model.layers.5.mlp.gate                       torch.Size([5, 60])            0.518432             0.908375             1552.000000          3790.857143         
model.layers.5.mlp.experts.0.gate_proj        torch.Size([0, 1408])          0.511136             0.908136             1396.800000          3724.800000         
model.layers.5.mlp.experts.0.act_fn           torch.Size([0, 1408])          0.296416             0.664473             1396.992000          3776.533333         
model.layers.5.mlp.experts.0.up_proj          torch.Size([0, 1408])          0.460576             0.839233             1241.984000          3880.000000         
model.layers.5.mlp.experts.0.down_proj        torch.Size([0, 2048])          0.521152             0.890255             1242.112000          4004.160000         
model.layers.5.mlp.experts.1.gate_proj        torch.Size([0, 1408])          0.459360             0.849485             1125.664000          3996.400000         
model.layers.5.mlp.experts.1.act_fn           torch.Size([0, 1408])          0.273984             0.674248             1086.848000          4035.200000         
model.layers.5.mlp.experts.1.up_proj          torch.Size([0, 1408])          0.508736             0.912428             1086.848000          3919.600000         
model.layers.5.mlp.experts.1.down_proj        torch.Size([0, 2048])          0.644768             1.012325             993.689600           3881.600000         
model.layers.5.mlp.experts.2.gate_proj        torch.Size([1, 1408])          0.880896             1.176596             1028.624000          3881.600000         
model.layers.5.mlp.experts.2.act_fn           torch.Size([1, 1408])          0.310496             0.683546             1086.848000          3881.600000         
model.layers.5.mlp.experts.2.up_proj          torch.Size([1, 1408])          0.917312             1.203775             1086.848000          3880.888889         
model.layers.5.mlp.experts.2.down_proj        torch.Size([1, 2048])          1.037632             1.323223             1125.664000          3821.800000         
model.layers.5.mlp.experts.3.gate_proj        torch.Size([0, 1408])          0.472576             0.864744             1164.480000          3763.600000         
model.layers.5.mlp.experts.3.act_fn           torch.Size([0, 1408])          0.283456             0.675678             1086.848000          3725.312000         
model.layers.5.mlp.experts.3.up_proj          torch.Size([0, 1408])          0.479968             0.899792             1086.960000          3726.336000         
model.layers.5.mlp.experts.3.down_proj        torch.Size([0, 2048])          0.468960             0.837564             1048.464000          3726.336000         
model.layers.5.mlp.experts.4.gate_proj        torch.Size([0, 1408])          0.500608             0.944614             931.968000           3726.336000         
model.layers.5.mlp.experts.4.act_fn           torch.Size([0, 1408])          0.314240             0.705004             931.968000           3726.336000         
model.layers.5.mlp.experts.4.up_proj          torch.Size([0, 1408])          0.502432             0.889540             931.968000           3788.441600         
model.layers.5.mlp.experts.4.down_proj        torch.Size([0, 2048])          0.497632             0.872135             893.136000           3881.600000         
model.layers.5.mlp.experts.5.gate_proj        torch.Size([0, 1408])          0.471328             0.877380             776.640000           4036.864000         
model.layers.5.mlp.experts.5.act_fn           torch.Size([0, 1408])          0.280768             0.719070             776.640000           4036.864000         
model.layers.5.mlp.experts.5.up_proj          torch.Size([0, 1408])          0.502976             0.864983             776.640000           4036.864000         
model.layers.5.mlp.experts.5.down_proj        torch.Size([0, 2048])          0.470304             0.904560             776.640000           3998.048000         
model.layers.5.mlp.experts.6.gate_proj        torch.Size([0, 1408])          0.501632             0.892639             776.640000           3881.600000         
model.layers.5.mlp.experts.6.act_fn           torch.Size([0, 1408])          0.275360             0.647783             776.640000           3881.600000         
model.layers.5.mlp.experts.6.up_proj          torch.Size([0, 1408])          0.456448             0.825167             660.144000           3881.600000         
model.layers.5.mlp.experts.6.down_proj        torch.Size([0, 2048])          0.453344             0.833273             621.312000           3882.800000         
model.layers.5.mlp.experts.7.gate_proj        torch.Size([0, 1408])          0.478048             0.890493             621.312000           3883.200000         
model.layers.5.mlp.experts.7.act_fn           torch.Size([0, 1408])          0.289984             0.677824             621.482667           3883.200000         
model.layers.5.mlp.experts.7.up_proj          torch.Size([0, 1408])          0.478336             0.854254             621.568000           3883.200000         
model.layers.5.mlp.experts.7.down_proj        torch.Size([0, 2048])          0.461984             0.837326             621.440000           3883.200000         
model.layers.5.mlp.experts.8.gate_proj        torch.Size([0, 1408])          0.483360             0.862122             621.312000           4037.696000         
model.layers.5.mlp.experts.8.act_fn           torch.Size([0, 1408])          0.298592             0.679493             621.312000           4036.864000         
model.layers.5.mlp.experts.8.up_proj          torch.Size([0, 1408])          0.449472             0.823021             621.312000           4075.680000         
model.layers.5.mlp.experts.8.down_proj        torch.Size([0, 2048])          0.448256             0.881433             621.312000           4075.680000         
model.layers.5.mlp.experts.9.gate_proj        torch.Size([1, 1408])          0.923328             1.224995             679.560000           4036.864000         
model.layers.5.mlp.experts.9.act_fn           torch.Size([1, 1408])          0.329920             0.761271             776.640000           4036.864000         
model.layers.5.mlp.experts.9.up_proj          torch.Size([1, 1408])          0.913600             1.206398             815.472000           4036.864000         
model.layers.5.mlp.experts.9.down_proj        torch.Size([1, 2048])          1.023488             1.312971             954.157714           3948.141714         
model.layers.5.mlp.experts.10.gate_proj       torch.Size([1, 1408])          0.877568             1.172304             1087.072000          3881.400000         
model.layers.5.mlp.experts.10.act_fn          torch.Size([1, 1408])          0.294272             0.658751             1087.072000          3881.600000         
model.layers.5.mlp.experts.10.up_proj         torch.Size([1, 1408])          0.865472             1.177549             1153.389714          3880.914286         
model.layers.5.mlp.experts.10.down_proj       torch.Size([1, 2048])          1.028640             1.321554             1242.112000          3860.600000         
model.layers.5.mlp.experts.11.gate_proj       torch.Size([2, 1408])          0.948416             1.246452             1377.968000          3880.000000         
model.layers.5.mlp.experts.11.act_fn          torch.Size([2, 1408])          0.298560             0.678062             1397.376000          3880.000000         
model.layers.5.mlp.experts.11.up_proj         torch.Size([2, 1408])          0.943456             1.232862             1397.376000          4035.200000         
model.layers.5.mlp.experts.11.down_proj       torch.Size([2, 2048])          1.381216             1.680613             1485.568000          4122.660571         
model.layers.5.mlp.experts.12.gate_proj       torch.Size([1, 1408])          0.872480             1.170397             1552.000000          4068.010667         
model.layers.5.mlp.experts.12.act_fn          torch.Size([1, 1408])          0.318432             0.755310             1552.000000          4033.536000         
model.layers.5.mlp.experts.12.up_proj         torch.Size([1, 1408])          0.903456             1.191854             1552.000000          4033.536000         
model.layers.5.mlp.experts.12.down_proj       torch.Size([1, 2048])          1.013056             1.315117             1620.977778          3878.400000         
model.layers.5.mlp.experts.13.gate_proj       torch.Size([0, 1408])          0.504256             0.901461             1583.040000          3878.400000         
model.layers.5.mlp.experts.13.act_fn          torch.Size([0, 1408])          0.279936             0.663519             1552.000000          3880.000000         
model.layers.5.mlp.experts.13.up_proj         torch.Size([0, 1408])          0.532928             0.908613             1459.353600          3880.000000         
model.layers.5.mlp.experts.13.down_proj       torch.Size([0, 2048])          0.475808             0.836849             1397.376000          3817.920000         
model.layers.5.mlp.experts.14.gate_proj       torch.Size([0, 1408])          0.477280             0.852585             1280.928000          3724.800000         
model.layers.5.mlp.experts.14.act_fn          torch.Size([0, 1408])          0.371040             0.751019             1242.112000          3724.800000         
model.layers.5.mlp.experts.14.up_proj         torch.Size([0, 1408])          0.500640             0.860214             1211.059200          3726.028800         
model.layers.5.mlp.experts.14.down_proj       torch.Size([0, 2048])          0.496992             0.887394             1086.848000          3881.600000         
model.layers.5.mlp.experts.15.gate_proj       torch.Size([1, 1408])          0.882976             1.237392             1138.602667          3864.348444         
model.layers.5.mlp.experts.15.act_fn          torch.Size([1, 1408])          0.311680             0.677347             1242.112000          3803.968000         
model.layers.5.mlp.experts.15.up_proj         torch.Size([1, 1408])          0.877856             1.168966             1222.704000          3764.576000         
model.layers.5.mlp.experts.15.down_proj       torch.Size([1, 2048])          1.046560             1.385212             1286.473143          3724.800000         
model.layers.5.mlp.experts.16.gate_proj       torch.Size([0, 1408])          0.493888             0.875711             1319.744000          3724.800000         
model.layers.5.mlp.experts.16.act_fn          torch.Size([0, 1408])          0.288928             0.683784             1242.112000          3724.800000         
model.layers.5.mlp.experts.16.up_proj         torch.Size([0, 1408])          0.480544             0.846386             1242.112000          3726.028800         
model.layers.5.mlp.experts.16.down_proj       torch.Size([0, 2048])          0.470464             0.832319             1125.888000          3726.336000         
model.layers.5.mlp.experts.17.gate_proj       torch.Size([0, 1408])          0.508928             0.881910             1087.296000          3726.336000         
model.layers.5.mlp.experts.17.act_fn          torch.Size([0, 1408])          0.270944             0.646830             1087.296000          3726.336000         
model.layers.5.mlp.experts.17.up_proj         torch.Size([0, 1408])          0.473536             0.841379             1087.296000          3881.600000         
model.layers.5.mlp.experts.17.down_proj       torch.Size([0, 2048])          0.524928             0.891924             931.968000           3881.600000         
model.layers.5.mlp.experts.18.gate_proj       torch.Size([1, 1408])          0.865056             1.177549             989.952000           4036.864000         
model.layers.5.mlp.experts.18.act_fn          torch.Size([1, 1408])          0.341728             0.709534             1086.848000          4036.864000         
model.layers.5.mlp.experts.18.up_proj         torch.Size([1, 1408])          0.905120             1.205444             1086.848000          4016.832000         
model.layers.5.mlp.experts.18.down_proj       torch.Size([1, 2048])          1.050240             1.350403             1197.750857          3968.923429         
model.layers.5.mlp.experts.19.gate_proj       torch.Size([0, 1408])          0.464288             0.845671             1242.112000          3918.800000         
model.layers.5.mlp.experts.19.act_fn          torch.Size([0, 1408])          0.313440             0.701666             1242.112000          4035.200000         
model.layers.5.mlp.experts.19.up_proj         torch.Size([0, 1408])          0.507776             0.877380             1086.848000          4035.616000         
model.layers.5.mlp.experts.19.down_proj       torch.Size([0, 2048])          0.513344             0.873566             1086.848000          3920.416000         
model.layers.5.mlp.experts.20.gate_proj       torch.Size([0, 1408])          0.484224             0.852823             1086.937600          3881.600000         
model.layers.5.mlp.experts.20.act_fn          torch.Size([0, 1408])          0.272128             0.649929             1035.520000          3881.600000         
model.layers.5.mlp.experts.20.up_proj         torch.Size([0, 1408])          0.526944             0.892401             931.968000           3881.600000         
model.layers.5.mlp.experts.20.down_proj       torch.Size([0, 2048])          0.461472             0.828266             931.968000           3881.600000         
model.layers.5.mlp.experts.21.gate_proj       torch.Size([0, 1408])          0.467008             0.864267             931.968000           3842.784000         
model.layers.5.mlp.experts.21.act_fn          torch.Size([0, 1408])          0.274656             0.743389             931.968000           3881.600000         
model.layers.5.mlp.experts.21.up_proj         torch.Size([0, 1408])          0.471424             0.859737             893.136000           3842.784000         
model.layers.5.mlp.experts.21.down_proj       torch.Size([0, 2048])          0.483872             0.843763             776.640000           3757.388800         
model.layers.5.mlp.experts.22.gate_proj       torch.Size([1, 1408])          0.887840             1.199722             893.136000           3726.336000         
model.layers.5.mlp.experts.22.act_fn          torch.Size([1, 1408])          0.309440             0.674725             931.968000           3726.336000         
model.layers.5.mlp.experts.22.up_proj         torch.Size([1, 1408])          0.886304             1.248121             966.485333           3726.336000         
model.layers.5.mlp.experts.22.down_proj       torch.Size([1, 2048])          1.048832             1.359940             1104.248889          3726.336000         
model.layers.5.mlp.experts.23.gate_proj       torch.Size([1, 1408])          0.878144             1.214266             1224.860444          3726.336000         
model.layers.5.mlp.experts.23.act_fn          torch.Size([1, 1408])          0.321568             0.714779             1242.112000          3726.336000         
model.layers.5.mlp.experts.23.up_proj         torch.Size([1, 1408])          0.880608             1.173258             1242.112000          3726.336000         
model.layers.5.mlp.experts.23.down_proj       torch.Size([1, 2048])          1.021152             1.307487             1358.560000          3724.800000         
model.layers.5.mlp.experts.24.gate_proj       torch.Size([0, 1408])          0.510592             0.892878             1397.376000          3931.733333         
model.layers.5.mlp.experts.24.act_fn          torch.Size([0, 1408])          0.283648             0.652075             1242.112000          4138.666667         
model.layers.5.mlp.experts.24.up_proj         torch.Size([0, 1408])          0.478496             0.903845             1241.600000          4345.600000         
model.layers.5.mlp.experts.24.down_proj       torch.Size([0, 2048])          0.463776             0.823736             1086.400000          4539.600000         
model.layers.5.mlp.experts.25.gate_proj       torch.Size([1, 1408])          0.891968             1.205206             1144.600000          4500.800000         
model.layers.5.mlp.experts.25.act_fn          torch.Size([1, 1408])          0.344032             0.712872             1241.600000          4500.800000         
model.layers.5.mlp.experts.25.up_proj         torch.Size([1, 1408])          0.907296             1.205921             1219.428571          4367.771429         
model.layers.5.mlp.experts.25.down_proj       torch.Size([1, 2048])          1.037248             1.330376             1241.600000          4287.184000         
model.layers.5.mlp.experts.26.gate_proj       torch.Size([0, 1408])          0.470368             0.847816             1241.600000          4190.400000         
model.layers.5.mlp.experts.26.act_fn          torch.Size([0, 1408])          0.303680             0.684023             1138.432000          4190.400000         
model.layers.5.mlp.experts.26.up_proj         torch.Size([0, 1408])          0.507712             0.928640             1086.848000          4138.666667         
model.layers.5.mlp.experts.26.down_proj       torch.Size([0, 2048])          0.494144             0.856161             1086.848000          4074.000000         
model.layers.5.mlp.experts.27.gate_proj       torch.Size([1, 1408])          0.865280             1.169920             1067.440000          4035.200000         
model.layers.5.mlp.experts.27.act_fn          torch.Size([1, 1408])          0.322816             0.696421             1086.848000          4035.200000         
model.layers.5.mlp.experts.27.up_proj         torch.Size([1, 1408])          0.874112             1.163244             1086.848000          3977.000000         
model.layers.5.mlp.experts.27.down_proj       torch.Size([1, 2048])          1.010720             1.331091             1086.848000          3946.514286         
model.layers.5.mlp.experts.28.gate_proj       torch.Size([0, 1408])          0.472000             0.858307             1086.848000          3880.000000         
model.layers.5.mlp.experts.28.act_fn          torch.Size([0, 1408])          0.272960             0.640392             1086.848000          3880.000000         
model.layers.5.mlp.experts.28.up_proj         torch.Size([0, 1408])          0.517888             0.894785             962.636800           3881.600000         
model.layers.5.mlp.experts.28.down_proj       torch.Size([0, 2048])          0.463584             0.844002             931.584000           3881.600000         
model.layers.5.mlp.experts.29.gate_proj       torch.Size([0, 1408])          0.488064             0.869513             931.872000           3881.600000         
model.layers.5.mlp.experts.29.act_fn          torch.Size([0, 1408])          0.272768             0.632524             828.416000           3881.600000         
model.layers.5.mlp.experts.29.up_proj         torch.Size([0, 1408])          0.464288             0.852585             776.640000           3726.336000         
model.layers.5.mlp.experts.29.down_proj       torch.Size([0, 2048])          0.449728             0.820637             776.640000           3765.152000         
model.layers.5.mlp.experts.30.gate_proj       torch.Size([0, 1408])          0.468960             0.861645             776.640000           3727.104000         
model.layers.5.mlp.experts.30.act_fn          torch.Size([0, 1408])          0.277856             0.639439             776.640000           3727.872000         
model.layers.5.mlp.experts.30.up_proj         torch.Size([0, 1408])          0.714496             1.113176             673.088000           3883.200000         
model.layers.5.mlp.experts.30.down_proj       torch.Size([0, 2048])          0.486528             0.901222             621.312000           3883.200000         
model.layers.5.mlp.experts.31.gate_proj       torch.Size([0, 1408])          0.468960             0.836372             621.312000           4036.864000         
model.layers.5.mlp.experts.31.act_fn          torch.Size([0, 1408])          0.272992             0.649452             621.312000           4036.864000         
model.layers.5.mlp.experts.31.up_proj         torch.Size([0, 1408])          0.464128             0.881195             621.312000           4038.195200         
model.layers.5.mlp.experts.31.down_proj       torch.Size([0, 2048])          0.466752             0.863552             621.312000           3999.696000         
model.layers.5.mlp.experts.32.gate_proj       torch.Size([0, 1408])          0.492800             0.873327             621.312000           3883.200000         
model.layers.5.mlp.experts.32.act_fn          torch.Size([0, 1408])          0.280544             0.662088             465.984000           3883.200000         
model.layers.5.mlp.experts.32.up_proj         torch.Size([0, 1408])          0.469216             0.834703             466.080000           3883.200000         
model.layers.5.mlp.experts.32.down_proj       torch.Size([0, 2048])          0.469312             0.834227             466.176000           3883.200000         
model.layers.5.mlp.experts.33.gate_proj       torch.Size([1, 1408])          0.913984             1.220942             554.797714           3882.971429         
model.layers.5.mlp.experts.33.act_fn          torch.Size([1, 1408])          0.311904             0.709295             621.312000           4036.864000         
model.layers.5.mlp.experts.33.up_proj         torch.Size([1, 1408])          0.909280             1.198769             621.312000           4036.864000         
model.layers.5.mlp.experts.33.down_proj       torch.Size([1, 2048])          1.017056             1.330137             737.808000           4036.864000         
model.layers.5.mlp.experts.34.gate_proj       torch.Size([0, 1408])          0.469376             0.844717             776.640000           4036.864000         
model.layers.5.mlp.experts.34.act_fn          torch.Size([0, 1408])          0.272128             0.635862             776.640000           4036.864000         
model.layers.5.mlp.experts.34.up_proj         torch.Size([0, 1408])          0.455488             0.823975             737.808000           4036.864000         
model.layers.5.mlp.experts.34.down_proj       torch.Size([0, 2048])          0.452224             0.890732             621.312000           3881.600000         
model.layers.5.mlp.experts.35.gate_proj       torch.Size([0, 1408])          0.461280             0.843763             621.312000           3920.416000         
model.layers.5.mlp.experts.35.act_fn          torch.Size([0, 1408])          0.271392             0.638962             621.312000           3881.600000         
model.layers.5.mlp.experts.35.up_proj         torch.Size([0, 1408])          0.456928             0.816822             621.312000           3881.600000         
model.layers.5.mlp.experts.35.down_proj       torch.Size([0, 2048])          0.499200             0.871658             621.312000           3882.800000         
model.layers.5.mlp.experts.36.gate_proj       torch.Size([0, 1408])          0.467552             0.848770             621.312000           3883.200000         
model.layers.5.mlp.experts.36.act_fn          torch.Size([0, 1408])          0.277088             0.643969             621.482667           3883.200000         
model.layers.5.mlp.experts.36.up_proj         torch.Size([0, 1408])          0.517696             0.903606             582.720000           3883.200000         
model.layers.5.mlp.experts.36.down_proj       torch.Size([0, 2048])          0.474272             0.842810             466.176000           3805.536000         
model.layers.5.mlp.experts.37.gate_proj       torch.Size([0, 1408])          0.490688             0.872850             466.176000           3727.872000         
model.layers.5.mlp.experts.37.act_fn          torch.Size([0, 1408])          0.304032             0.692368             466.176000           3883.200000         
model.layers.5.mlp.experts.37.up_proj         torch.Size([0, 1408])          0.456992             0.833750             466.176000           3883.200000         
model.layers.5.mlp.experts.37.down_proj       torch.Size([0, 2048])          0.456384             0.816107             466.176000           4038.528000         
model.layers.5.mlp.experts.38.gate_proj       torch.Size([0, 1408])          0.454720             0.828028             466.080000           4038.528000         
model.layers.5.mlp.experts.38.act_fn          torch.Size([0, 1408])          0.276512             0.651598             466.112000           4038.528000         
model.layers.5.mlp.experts.38.up_proj         torch.Size([0, 1408])          0.459104             0.824451             466.176000           4038.528000         
model.layers.5.mlp.experts.38.down_proj       torch.Size([0, 2048])          0.502048             0.884533             466.176000           3914.265600         
model.layers.5.mlp.experts.39.gate_proj       torch.Size([0, 1408])          0.455808             0.844479             466.176000           3883.200000         
model.layers.5.mlp.experts.39.act_fn          torch.Size([0, 1408])          0.269504             0.630617             466.176000           3883.200000         
model.layers.5.mlp.experts.39.up_proj         torch.Size([0, 1408])          0.517568             0.905752             466.176000           3844.368000         
model.layers.5.mlp.experts.39.down_proj       torch.Size([0, 2048])          0.476608             0.865698             466.176000           3727.872000         
model.layers.5.mlp.experts.40.gate_proj       torch.Size([0, 1408])          0.617888             1.063108             466.176000           3727.872000         
model.layers.5.mlp.experts.40.act_fn          torch.Size([0, 1408])          0.345344             0.760555             466.176000           3727.872000         
model.layers.5.mlp.experts.40.up_proj         torch.Size([0, 1408])          0.534336             0.956535             466.176000           3805.536000         
model.layers.5.mlp.experts.40.down_proj       torch.Size([0, 2048])          0.521920             0.944853             466.176000           3914.265600         
model.layers.5.mlp.experts.41.gate_proj       torch.Size([0, 1408])          0.508736             0.931025             466.176000           4038.528000         
model.layers.5.mlp.experts.41.act_fn          torch.Size([0, 1408])          0.282208             0.682354             466.176000           4038.528000         
model.layers.5.mlp.experts.41.up_proj         torch.Size([0, 1408])          0.461568             0.837564             466.176000           4038.528000         
model.layers.5.mlp.experts.41.down_proj       torch.Size([0, 2048])          0.459104             0.851154             466.176000           4038.528000         
model.layers.5.mlp.experts.42.gate_proj       torch.Size([1, 1408])          0.914144             1.254082             466.121143           4016.338286         
model.layers.5.mlp.experts.42.act_fn          torch.Size([1, 1408])          0.337568             0.830173             466.022400           3883.200000         
model.layers.5.mlp.experts.42.up_proj         torch.Size([1, 1408])          0.938208             1.244068             535.040000           3883.200000         
model.layers.5.mlp.experts.42.down_proj       torch.Size([1, 2048])          1.078752             1.387596             621.312000           3881.955556         
model.layers.5.mlp.experts.43.gate_proj       torch.Size([1, 1408])          0.885376             1.188517             754.450286           3881.600000         
model.layers.5.mlp.experts.43.act_fn          torch.Size([1, 1408])          0.326240             0.696898             776.640000           3881.600000         
model.layers.5.mlp.experts.43.up_proj         torch.Size([1, 1408])          0.892640             1.244068             776.640000           3803.968000         
model.layers.5.mlp.experts.43.down_proj       torch.Size([1, 2048])          1.049152             1.351595             862.848000           3881.600000         
model.layers.5.mlp.experts.44.gate_proj       torch.Size([0, 1408])          0.459904             0.853062             931.584000           4036.864000         
model.layers.5.mlp.experts.44.act_fn          torch.Size([0, 1408])          0.271936             0.645876             776.320000           4036.864000         
model.layers.5.mlp.experts.44.up_proj         torch.Size([0, 1408])          0.450208             0.830173             776.320000           4088.618667         
model.layers.5.mlp.experts.44.down_proj       torch.Size([0, 2048])          0.519040             0.904560             776.560000           4153.312000         
model.layers.5.mlp.experts.45.gate_proj       torch.Size([0, 1408])          0.465056             0.850201             776.640000           4036.864000         
model.layers.5.mlp.experts.45.act_fn          torch.Size([0, 1408])          0.279008             0.653982             673.088000           4036.864000         
model.layers.5.mlp.experts.45.up_proj         torch.Size([0, 1408])          0.519584             0.890970             621.312000           4036.864000         
model.layers.5.mlp.experts.45.down_proj       torch.Size([0, 2048])          0.465120             0.822783             621.312000           3882.400000         
model.layers.5.mlp.experts.46.gate_proj       torch.Size([1, 1408])          0.881120             1.201868             621.312000           3882.057143         
model.layers.5.mlp.experts.46.act_fn          torch.Size([1, 1408])          0.388832             0.833750             621.312000           3881.600000         
model.layers.5.mlp.experts.46.up_proj         torch.Size([1, 1408])          0.920256             1.286507             737.808000           3823.376000         
model.layers.5.mlp.experts.46.down_proj       torch.Size([1, 2048])          1.056160             1.376867             776.640000           3745.744000         
model.layers.5.mlp.experts.47.gate_proj       torch.Size([1, 1408])          0.938848             1.316786             880.106667           3726.336000         
model.layers.5.mlp.experts.47.act_fn          torch.Size([1, 1408])          0.451392             1.062393             931.680000           3726.336000         
model.layers.5.mlp.experts.47.up_proj         torch.Size([1, 1408])          0.979680             1.409292             931.638857           3770.240000         
model.layers.5.mlp.experts.47.down_proj       torch.Size([1, 2048])          1.088064             1.405239             931.584000           3857.828571         
model.layers.5.mlp.experts.48.gate_proj       torch.Size([0, 1408])          0.601248             1.024485             931.584000           3802.784000         
model.layers.5.mlp.experts.48.act_fn          torch.Size([0, 1408])          0.360896             0.875473             931.584000           3726.336000         
model.layers.5.mlp.experts.48.up_proj         torch.Size([0, 1408])          0.520576             0.916481             869.478400           3757.388800         
model.layers.5.mlp.experts.48.down_proj       torch.Size([0, 2048])          0.480576             0.871420             776.640000           3726.336000         
model.layers.5.mlp.experts.49.gate_proj       torch.Size([0, 1408])          0.467392             0.868797             776.640000           3726.336000         
model.layers.5.mlp.experts.49.act_fn          torch.Size([0, 1408])          0.287232             0.654697             776.640000           3726.336000         
model.layers.5.mlp.experts.49.up_proj         torch.Size([0, 1408])          0.486112             0.849962             776.640000           3726.336000         
model.layers.5.mlp.experts.49.down_proj       torch.Size([0, 2048])          0.553984             0.916481             621.312000           3726.950400         
model.layers.5.mlp.experts.50.gate_proj       torch.Size([2, 1408])          1.063808             1.303673             707.605333           3674.752000         
model.layers.5.mlp.experts.50.act_fn          torch.Size([2, 1408])          0.406496             0.899076             776.640000           3726.336000         
model.layers.5.mlp.experts.50.up_proj         torch.Size([2, 1408])          1.006720             1.322031             776.604444           3864.348444         
model.layers.5.mlp.experts.50.down_proj       torch.Size([2, 2048])          1.434304             1.763105             853.952000           3939.408000         
model.layers.5.mlp.experts.51.gate_proj       torch.Size([0, 1408])          0.508416             0.901461             931.584000           4036.032000         
model.layers.5.mlp.experts.51.act_fn          torch.Size([0, 1408])          0.312800             0.673294             931.584000           3985.109333         
model.layers.5.mlp.experts.51.up_proj         torch.Size([0, 1408])          0.516576             0.936747             776.320000           3881.600000         
model.layers.5.mlp.experts.51.down_proj       torch.Size([0, 2048])          0.448672             0.819683             776.512000           3912.652800         
model.layers.5.mlp.experts.52.gate_proj       torch.Size([0, 1408])          0.466400             0.831842             776.640000           3881.600000         
model.layers.5.mlp.experts.52.act_fn          torch.Size([0, 1408])          0.281856             0.641823             776.640000           3881.600000         
model.layers.5.mlp.experts.52.up_proj         torch.Size([0, 1408])          0.457280             0.842333             660.144000           3765.920000         
model.layers.5.mlp.experts.52.down_proj       torch.Size([0, 2048])          0.632608             1.000881             621.312000           3727.872000         
model.layers.5.mlp.experts.53.gate_proj       torch.Size([1, 1408])          0.907424             1.246929             665.691429           3726.994286         
model.layers.5.mlp.experts.53.act_fn          torch.Size([1, 1408])          0.313056             0.676155             776.640000           3726.336000         
model.layers.5.mlp.experts.53.up_proj         torch.Size([1, 1408])          0.891136             1.216412             776.640000           3726.336000         
model.layers.5.mlp.experts.53.down_proj       torch.Size([1, 2048])          1.056256             1.409054             815.472000           3726.336000         
model.layers.5.mlp.experts.54.gate_proj       torch.Size([0, 1408])          0.709536             1.202583             854.304000           3726.336000         
model.layers.5.mlp.experts.54.act_fn          torch.Size([0, 1408])          0.314848             0.747919             776.640000           3726.336000         
model.layers.5.mlp.experts.54.up_proj         torch.Size([0, 1408])          0.536640             0.976562             776.640000           3726.336000         
model.layers.5.mlp.experts.54.down_proj       torch.Size([0, 2048])          0.591680             1.005173             776.640000           3726.336000         
model.layers.5.mlp.experts.55.gate_proj       torch.Size([0, 1408])          0.580416             0.989914             776.640000           3726.336000         
model.layers.5.mlp.experts.55.act_fn          torch.Size([0, 1408])          0.320032             0.710249             621.312000           3726.848000         
model.layers.5.mlp.experts.55.up_proj         torch.Size([0, 1408])          0.479392             0.836611             621.312000           3727.872000         
model.layers.5.mlp.experts.55.down_proj       torch.Size([0, 2048])          0.452480             0.823259             621.312000           3727.872000         
model.layers.5.mlp.experts.56.gate_proj       torch.Size([0, 1408])          0.628512             1.059771             621.440000           3689.040000         
model.layers.5.mlp.experts.56.act_fn          torch.Size([0, 1408])          0.281696             0.644207             621.568000           3676.096000         
model.layers.5.mlp.experts.56.up_proj         torch.Size([0, 1408])          0.462464             0.828505             621.568000           3689.040000         
model.layers.5.mlp.experts.56.down_proj       torch.Size([0, 2048])          0.516448             0.973940             621.568000           3611.376000         
model.layers.5.mlp.experts.57.gate_proj       torch.Size([0, 1408])          0.461440             0.844479             528.332800           3727.872000         
model.layers.5.mlp.experts.57.act_fn          torch.Size([0, 1408])          0.285536             0.689030             466.176000           3883.200000         
model.layers.5.mlp.experts.57.up_proj         torch.Size([0, 1408])          0.551936             0.917912             466.176000           3883.200000         
model.layers.5.mlp.experts.57.down_proj       torch.Size([0, 2048])          0.469120             0.827312             465.984000           4038.528000         
model.layers.5.mlp.experts.58.gate_proj       torch.Size([0, 1408])          0.477216             0.851393             466.080000           3999.696000         
model.layers.5.mlp.experts.58.act_fn          torch.Size([0, 1408])          0.339104             0.740290             466.176000           3934.976000         
model.layers.5.mlp.experts.58.up_proj         torch.Size([0, 1408])          0.481792             0.848532             466.176000           3883.200000         
model.layers.5.mlp.experts.58.down_proj       torch.Size([0, 2048])          0.501760             0.870705             466.176000           3883.200000         
model.layers.5.mlp.experts.59.gate_proj       torch.Size([0, 1408])          0.476320             0.914097             466.176000           3883.200000         
model.layers.5.mlp.experts.59.act_fn          torch.Size([0, 1408])          0.289120             0.645876             466.176000           3883.200000         
model.layers.5.mlp.experts.59.up_proj         torch.Size([0, 1408])          0.463264             0.819683             466.176000           3883.200000         
model.layers.5.mlp.experts.59.down_proj       torch.Size([0, 2048])          0.456768             0.870466             466.176000           3805.536000         
model.layers.5.mlp.shared_expert.gate_proj    torch.Size([5, 5632])          2.645568             2.955198             601.944000           3727.104000         
model.layers.5.mlp.shared_expert.act_fn       torch.Size([5, 5632])          0.350432             0.732899             893.136000           3726.336000         
model.layers.5.mlp.shared_expert.up_proj      torch.Size([5, 5632])          2.630176             2.926588             989.848000           3725.184000         
model.layers.5.mlp.shared_expert.down_proj    torch.Size([5, 2048])          2.702464             3.019810             1430.997333          3723.605333         
model.layers.5.mlp.shared_expert_gate         torch.Size([5, 1])             0.660800             1.149893             1617.846857          3723.264000         
model.layers.6.input_layernorm                torch.Size([1, 5, 2048])       0.929824             1.305580             1487.333333          3665.704000         
model.layers.6.self_attn.q_proj               torch.Size([1, 5, 2048])       1.404864             1.728773             1416.200000          3569.600000         
model.layers.6.self_attn.k_proj               torch.Size([1, 5, 2048])       1.358624             1.690865             1513.200000          3569.416000         
model.layers.6.self_attn.v_proj               torch.Size([1, 5, 2048])       1.256736             1.557350             1552.000000          3568.128000         
model.layers.6.self_attn.o_proj               torch.Size([1, 5, 2048])       1.309504             1.623631             1629.248000          3568.128000         
model.layers.6.post_attention_layernorm       torch.Size([1, 5, 2048])       1.219168             1.618385             1576.505263          3593.562947         
model.layers.6.mlp.gate                       torch.Size([5, 60])            0.603808             1.038313             1396.800000          3724.800000         
model.layers.6.mlp.experts.0.gate_proj        torch.Size([0, 1408])          0.630784             1.178026             1334.720000          3880.000000         
model.layers.6.mlp.experts.0.act_fn           torch.Size([0, 1408])          0.338752             0.727177             1241.600000          3880.000000         
model.layers.6.mlp.experts.0.up_proj          torch.Size([0, 1408])          0.487584             0.890970             1242.112000          3880.000000         
model.layers.6.mlp.experts.0.down_proj        torch.Size([0, 2048])          0.655232             1.167059             1125.664000          3880.000000         
model.layers.6.mlp.experts.1.gate_proj        torch.Size([0, 1408])          0.520736             0.944138             1086.848000          3881.600000         
model.layers.6.mlp.experts.1.act_fn           torch.Size([0, 1408])          0.327296             0.799417             1086.848000          3881.600000         
model.layers.6.mlp.experts.1.up_proj          torch.Size([0, 1408])          0.467936             0.831366             993.689600           3757.388800         
model.layers.6.mlp.experts.1.down_proj        torch.Size([0, 2048])          0.477920             0.888824             931.776000           3726.336000         
model.layers.6.mlp.experts.2.gate_proj        torch.Size([0, 1408])          0.593760             1.041174             931.660800           3881.600000         
model.layers.6.mlp.experts.2.act_fn           torch.Size([0, 1408])          0.391168             0.839710             931.968000           3881.600000         
model.layers.6.mlp.experts.2.up_proj          torch.Size([0, 1408])          0.584608             0.982761             815.296000           4036.864000         
model.layers.6.mlp.experts.2.down_proj        torch.Size([0, 2048])          0.468928             0.843048             776.640000           3959.232000         
model.layers.6.mlp.experts.3.gate_proj        torch.Size([1, 1408])          0.982784             1.368046             828.416000           3881.600000         
model.layers.6.mlp.experts.3.act_fn           torch.Size([1, 1408])          0.373696             0.813961             931.968000           3881.600000         
model.layers.6.mlp.experts.3.up_proj          torch.Size([1, 1408])          0.909120             1.208544             931.797333           3881.600000         
model.layers.6.mlp.experts.3.down_proj        torch.Size([1, 2048])          1.146848             1.507044             998.125714           3792.877714         
model.layers.6.mlp.experts.4.gate_proj        torch.Size([0, 1408])          0.493792             0.874281             1086.848000          3765.152000         
model.layers.6.mlp.experts.4.act_fn           torch.Size([0, 1408])          0.520928             0.894070             931.584000           3726.336000         
model.layers.6.mlp.experts.4.up_proj          torch.Size([0, 1408])          0.494752             0.868797             931.872000           3726.336000         
model.layers.6.mlp.experts.4.down_proj        torch.Size([0, 2048])          0.470688             0.888586             931.968000           3726.336000         
model.layers.6.mlp.experts.5.gate_proj        torch.Size([0, 1408])          0.459808             0.909328             931.968000           3726.336000         
model.layers.6.mlp.experts.5.act_fn           torch.Size([0, 1408])          0.277056             0.654697             880.192000           3726.336000         
model.layers.6.mlp.experts.5.up_proj          torch.Size([0, 1408])          0.454784             0.818729             776.640000           3726.336000         
model.layers.6.mlp.experts.5.down_proj        torch.Size([0, 2048])          0.450528             0.822067             776.640000           3727.104000         
model.layers.6.mlp.experts.6.gate_proj        torch.Size([0, 1408])          0.467776             0.864983             776.640000           3727.872000         
model.layers.6.mlp.experts.6.act_fn           torch.Size([0, 1408])          0.277600             0.656605             776.640000           3881.600000         
model.layers.6.mlp.experts.6.up_proj          torch.Size([0, 1408])          0.460896             0.880480             776.640000           3881.600000         
model.layers.6.mlp.experts.6.down_proj        torch.Size([0, 2048])          0.444256             0.813246             737.808000           4036.864000         
model.layers.6.mlp.experts.7.gate_proj        torch.Size([0, 1408])          0.475168             0.837803             621.312000           4036.864000         
model.layers.6.mlp.experts.7.act_fn           torch.Size([0, 1408])          0.280992             0.687599             621.312000           4036.864000         
model.layers.6.mlp.experts.7.up_proj          torch.Size([0, 1408])          0.515232             0.881672             621.312000           3960.448000         
model.layers.6.mlp.experts.7.down_proj        torch.Size([0, 2048])          0.454368             0.862122             621.312000           3883.200000         
model.layers.6.mlp.experts.8.gate_proj        torch.Size([1, 1408])          0.966208             1.279116             698.976000           3883.000000         
model.layers.6.mlp.experts.8.act_fn           torch.Size([1, 1408])          0.296448             0.661850             776.640000           3882.133333         
model.layers.6.mlp.experts.8.up_proj          torch.Size([1, 1408])          0.879264             1.182795             776.640000           3882.200000         
model.layers.6.mlp.experts.8.down_proj        torch.Size([1, 2048])          1.065856             1.389265             893.136000           3862.192000         
model.layers.6.mlp.experts.9.gate_proj        torch.Size([0, 1408])          0.476992             0.844002             931.968000           3788.441600         
model.layers.6.mlp.experts.9.act_fn           torch.Size([0, 1408])          0.286944             0.719786             931.968000           3881.600000         
model.layers.6.mlp.experts.9.up_proj          torch.Size([0, 1408])          0.466464             0.830173             931.968000           4036.864000         
model.layers.6.mlp.experts.9.down_proj        torch.Size([0, 2048])          0.452064             0.814438             776.640000           4114.496000         
model.layers.6.mlp.experts.10.gate_proj       torch.Size([0, 1408])          0.546912             0.913620             776.640000           4192.128000         
model.layers.6.mlp.experts.10.act_fn          torch.Size([0, 1408])          0.284288             0.641108             776.640000           4140.373333         
model.layers.6.mlp.experts.10.up_proj         torch.Size([0, 1408])          0.480384             0.835180             776.640000           4067.916800         
model.layers.6.mlp.experts.10.down_proj       torch.Size([0, 2048])          0.469024             0.827551             776.640000           4036.864000         
model.layers.6.mlp.experts.11.gate_proj       torch.Size([1, 1408])          0.942784             1.263142             776.640000           4036.864000         
model.layers.6.mlp.experts.11.act_fn          torch.Size([1, 1408])          0.340736             0.771761             776.640000           3959.232000         
model.layers.6.mlp.experts.11.up_proj         torch.Size([1, 1408])          0.978304             1.296043             854.304000           3901.008000         
model.layers.6.mlp.experts.11.down_proj       torch.Size([1, 2048])          1.022912             1.316309             951.384000           3881.600000         
model.layers.6.mlp.experts.12.gate_proj       torch.Size([0, 1408])          0.533056             0.896931             931.968000           3842.784000         
model.layers.6.mlp.experts.12.act_fn          torch.Size([0, 1408])          0.330400             0.693321             931.968000           3803.968000         
model.layers.6.mlp.experts.12.up_proj         torch.Size([0, 1408])          0.502976             0.865221             931.968000           3757.388800         
model.layers.6.mlp.experts.12.down_proj       torch.Size([0, 2048])          0.489152             0.844955             931.968000           3881.600000         
model.layers.6.mlp.experts.13.gate_proj       torch.Size([0, 1408])          0.468992             0.832081             776.640000           3920.416000         
model.layers.6.mlp.experts.13.act_fn          torch.Size([0, 1408])          0.269152             0.639439             776.640000           4036.864000         
model.layers.6.mlp.experts.13.up_proj         torch.Size([0, 1408])          0.466016             0.835896             776.640000           4140.373333         
model.layers.6.mlp.experts.13.down_proj       torch.Size([0, 2048])          0.471648             0.845671             776.640000           4036.864000         
model.layers.6.mlp.experts.14.gate_proj       torch.Size([0, 1408])          0.486304             0.866175             776.640000           3943.705600         
model.layers.6.mlp.experts.14.act_fn          torch.Size([0, 1408])          0.293344             0.714064             776.640000           3882.666667         
model.layers.6.mlp.experts.14.up_proj         torch.Size([0, 1408])          0.484704             0.855446             698.976000           3882.800000         
model.layers.6.mlp.experts.14.down_proj       torch.Size([0, 2048])          0.460416             0.816107             621.312000           3883.200000         
model.layers.6.mlp.experts.15.gate_proj       torch.Size([0, 1408])          0.547936             0.912189             621.312000           3883.200000         
model.layers.6.mlp.experts.15.act_fn          torch.Size([0, 1408])          0.322688             0.686169             621.482667           3779.648000         
model.layers.6.mlp.experts.15.up_proj         torch.Size([0, 1408])          0.502432             0.864744             621.568000           3727.872000         
model.layers.6.mlp.experts.15.down_proj       torch.Size([0, 2048])          0.466304             0.820875             621.568000           3727.872000         
model.layers.6.mlp.experts.16.gate_proj       torch.Size([1, 1408])          0.886848             1.194239             660.272000           3727.872000         
model.layers.6.mlp.experts.16.act_fn          torch.Size([1, 1408])          0.313472             0.673771             776.640000           3727.872000         
model.layers.6.mlp.experts.16.up_proj         torch.Size([1, 1408])          0.902688             1.198769             776.640000           3770.916571         
model.layers.6.mlp.experts.16.down_proj       torch.Size([1, 2048])          1.048480             1.342773             873.720000           3881.600000         
model.layers.6.mlp.experts.17.gate_proj       torch.Size([0, 1408])          0.469984             0.920773             931.968000           3765.152000         
model.layers.6.mlp.experts.17.act_fn          torch.Size([0, 1408])          0.273856             0.631094             931.968000           3726.336000         
model.layers.6.mlp.experts.17.up_proj         torch.Size([0, 1408])          0.450080             0.806808             854.304000           3765.152000         
model.layers.6.mlp.experts.17.down_proj       torch.Size([0, 2048])          0.462336             0.861645             776.640000           3727.104000         
model.layers.6.mlp.experts.18.gate_proj       torch.Size([1, 1408])          0.876544             1.173973             854.304000           3726.336000         
model.layers.6.mlp.experts.18.act_fn          torch.Size([1, 1408])          0.297888             0.675440             931.968000           3726.336000         
model.layers.6.mlp.experts.18.up_proj         torch.Size([1, 1408])          0.860320             1.155376             931.968000           3726.336000         
model.layers.6.mlp.experts.18.down_proj       torch.Size([1, 2048])          1.033440             1.332045             990.216000           3687.520000         
model.layers.6.mlp.experts.19.gate_proj       torch.Size([2, 1408])          0.978336             1.316547             1086.897778          3726.336000         
model.layers.6.mlp.experts.19.act_fn          torch.Size([2, 1408])          0.316320             0.680447             1086.848000          3819.494400         
model.layers.6.mlp.experts.19.up_proj         torch.Size([2, 1408])          0.936224             1.224279             1086.848000          3881.200000         
model.layers.6.mlp.experts.19.down_proj       torch.Size([2, 2048])          1.380192             1.666546             1219.931429          4013.028571         
model.layers.6.mlp.experts.20.gate_proj       torch.Size([0, 1408])          0.474624             0.846386             1242.112000          3983.466667         
model.layers.6.mlp.experts.20.act_fn          torch.Size([0, 1408])          0.272032             0.701189             1242.112000          3931.733333         
model.layers.6.mlp.experts.20.up_proj         torch.Size([0, 1408])          0.451392             0.815630             1164.480000          3919.600000         
model.layers.6.mlp.experts.20.down_proj       torch.Size([0, 2048])          0.445984             0.822544             1086.848000          3881.600000         
model.layers.6.mlp.experts.21.gate_proj       torch.Size([0, 1408])          0.554592             0.926018             1086.848000          3881.600000         
model.layers.6.mlp.experts.21.act_fn          torch.Size([0, 1408])          0.319456             0.683546             1035.221333          3881.600000         
model.layers.6.mlp.experts.21.up_proj         torch.Size([0, 1408])          0.495040             0.852346             931.968000           3881.600000         
model.layers.6.mlp.experts.21.down_proj       torch.Size([0, 2048])          0.448704             0.826597             931.968000           3850.547200         
model.layers.6.mlp.experts.22.gate_proj       torch.Size([1, 1408])          0.879200             1.178980             931.968000           3674.581333         
model.layers.6.mlp.experts.22.act_fn          torch.Size([1, 1408])          0.296384             0.678301             931.968000           3571.072000         
model.layers.6.mlp.experts.22.up_proj         torch.Size([1, 1408])          0.879200             1.184940             990.216000           3551.664000         
model.layers.6.mlp.experts.22.down_proj       torch.Size([1, 2048])          1.052864             1.345634             1087.296000          3526.710857         
model.layers.6.mlp.experts.23.gate_proj       torch.Size([0, 1408])          0.502624             0.941515             1087.296000          3415.808000         
model.layers.6.mlp.experts.23.act_fn          torch.Size([0, 1408])          0.306464             0.677586             1087.296000          3571.072000         
model.layers.6.mlp.experts.23.up_proj         torch.Size([0, 1408])          0.469312             0.826359             1048.464000          3532.256000         
model.layers.6.mlp.experts.23.down_proj       torch.Size([0, 2048])          0.450304             0.807524             931.968000           3571.072000         
model.layers.6.mlp.experts.24.gate_proj       torch.Size([0, 1408])          0.511104             0.899076             931.968000           3532.256000         
model.layers.6.mlp.experts.24.act_fn          torch.Size([0, 1408])          0.285568             0.681162             931.968000           3572.053333         
model.layers.6.mlp.experts.24.up_proj         torch.Size([0, 1408])          0.476704             0.833750             893.136000           3572.544000         
model.layers.6.mlp.experts.24.down_proj       torch.Size([0, 2048])          0.476160             0.888109             776.880000           3533.712000         
model.layers.6.mlp.experts.25.gate_proj       torch.Size([0, 1408])          0.469952             0.838041             776.960000           3494.880000         
model.layers.6.mlp.experts.25.act_fn          torch.Size([0, 1408])          0.285504             0.654459             776.960000           3572.544000         
model.layers.6.mlp.experts.25.up_proj         torch.Size([0, 1408])          0.483520             0.894785             776.960000           3572.544000         
model.layers.6.mlp.experts.25.down_proj       torch.Size([0, 2048])          0.471040             0.826120             776.960000           3727.872000         
model.layers.6.mlp.experts.26.gate_proj       torch.Size([0, 1408])          0.456096             0.834227             621.568000           3727.872000         
model.layers.6.mlp.experts.26.act_fn          torch.Size([0, 1408])          0.266560             0.642776             621.397333           3883.200000         
model.layers.6.mlp.experts.26.up_proj         torch.Size([0, 1408])          0.443328             0.813484             621.440000           3883.200000         
model.layers.6.mlp.experts.26.down_proj       torch.Size([0, 2048])          0.450048             0.809193             621.568000           3883.200000         
model.layers.6.mlp.experts.27.gate_proj       torch.Size([0, 1408])          0.450688             0.869989             621.568000           3844.368000         
model.layers.6.mlp.experts.27.act_fn          torch.Size([0, 1408])          0.293184             0.666618             621.568000           3883.200000         
model.layers.6.mlp.experts.27.up_proj         torch.Size([0, 1408])          0.475840             0.842333             621.440000           3999.696000         
model.layers.6.mlp.experts.27.down_proj       torch.Size([0, 2048])          0.518752             0.893831             582.480000           4192.992000         
model.layers.6.mlp.experts.28.gate_proj       torch.Size([0, 1408])          0.450304             0.837088             465.984000           4316.339200         
model.layers.6.mlp.experts.28.act_fn          torch.Size([0, 1408])          0.275904             0.645638             465.984000           4347.392000         
model.layers.6.mlp.experts.28.up_proj         torch.Size([0, 1408])          0.500608             0.875711             465.984000           4269.760000         
model.layers.6.mlp.experts.28.down_proj       torch.Size([0, 2048])          0.468000             0.844479             465.984000           4192.128000         
model.layers.6.mlp.experts.29.gate_proj       torch.Size([0, 1408])          0.488192             0.856638             465.984000           4193.856000         
model.layers.6.mlp.experts.29.act_fn          torch.Size([0, 1408])          0.314976             0.674248             465.984000           4193.856000         
model.layers.6.mlp.experts.29.up_proj         torch.Size([0, 1408])          0.444032             0.798225             465.984000           4155.024000         
model.layers.6.mlp.experts.29.down_proj       torch.Size([0, 2048])          0.454368             0.836134             466.176000           4038.528000         
model.layers.6.mlp.experts.30.gate_proj       torch.Size([0, 1408])          0.510720             0.872374             466.176000           4038.528000         
model.layers.6.mlp.experts.30.act_fn          torch.Size([0, 1408])          0.303520             0.657558             466.176000           4038.528000         
model.layers.6.mlp.experts.30.up_proj         torch.Size([0, 1408])          0.478112             0.831127             466.176000           3960.864000         
model.layers.6.mlp.experts.30.down_proj       torch.Size([0, 2048])          0.450400             0.829697             466.176000           3883.200000         
model.layers.6.mlp.experts.31.gate_proj       torch.Size([0, 1408])          0.449024             0.814438             466.176000           3883.200000         
model.layers.6.mlp.experts.31.act_fn          torch.Size([0, 1408])          0.267872             0.626087             466.176000           3883.200000         
model.layers.6.mlp.experts.31.up_proj         torch.Size([0, 1408])          0.444704             0.815153             466.176000           3883.200000         
model.layers.6.mlp.experts.31.down_proj       torch.Size([0, 2048])          0.471712             0.841141             466.176000           3805.536000         
model.layers.6.mlp.experts.32.gate_proj       torch.Size([0, 1408])          0.470048             0.865459             466.176000           3727.872000         
model.layers.6.mlp.experts.32.act_fn          torch.Size([0, 1408])          0.276640             0.699759             466.176000           3727.872000         
model.layers.6.mlp.experts.32.up_proj         torch.Size([0, 1408])          0.460672             0.833273             466.176000           3883.200000         
model.layers.6.mlp.experts.32.down_proj       torch.Size([0, 2048])          0.454208             0.822067             466.176000           4038.528000         
model.layers.6.mlp.experts.33.gate_proj       torch.Size([0, 1408])          0.531200             0.934124             466.176000           4038.528000         
model.layers.6.mlp.experts.33.act_fn          torch.Size([0, 1408])          0.279808             0.667334             466.176000           4038.528000         
model.layers.6.mlp.experts.33.up_proj         torch.Size([0, 1408])          0.482400             0.837803             466.176000           4038.528000         
model.layers.6.mlp.experts.33.down_proj       torch.Size([0, 2048])          0.445792             0.801086             435.097600           4038.528000         
model.layers.6.mlp.experts.34.gate_proj       torch.Size([0, 1408])          0.487424             0.883102             427.328000           3960.864000         
model.layers.6.mlp.experts.34.act_fn          torch.Size([0, 1408])          0.268000             0.650167             414.378667           3934.976000         
model.layers.6.mlp.experts.34.up_proj         torch.Size([0, 1408])          0.467776             0.835419             310.784000           3922.032000         
model.layers.6.mlp.experts.34.down_proj       torch.Size([0, 2048])          0.462720             0.841618             310.784000           3883.200000         
model.layers.6.mlp.experts.35.gate_proj       torch.Size([0, 1408])          0.453120             0.842094             310.784000           4038.528000         
model.layers.6.mlp.experts.35.act_fn          torch.Size([0, 1408])          0.268736             0.675917             310.784000           4038.528000         
model.layers.6.mlp.experts.35.up_proj         torch.Size([0, 1408])          0.470464             0.842810             310.784000           4193.856000         
model.layers.6.mlp.experts.35.down_proj       torch.Size([0, 2048])          0.450400             0.815630             310.784000           4077.360000         
model.layers.6.mlp.experts.36.gate_proj       torch.Size([0, 1408])          0.536768             0.900745             310.784000           4038.528000         
model.layers.6.mlp.experts.36.act_fn          torch.Size([0, 1408])          0.295456             0.653505             310.784000           4038.528000         
model.layers.6.mlp.experts.36.up_proj         torch.Size([0, 1408])          0.477152             0.833511             310.784000           3999.696000         
model.layers.6.mlp.experts.36.down_proj       torch.Size([0, 2048])          0.449408             0.821114             310.784000           3945.331200         
model.layers.6.mlp.experts.37.gate_proj       torch.Size([1, 1408])          0.909632             1.215935             466.176000           3883.200000         
model.layers.6.mlp.experts.37.act_fn          torch.Size([1, 1408])          0.295104             0.678539             466.176000           3883.200000         
model.layers.6.mlp.experts.37.up_proj         torch.Size([1, 1408])          0.903616             1.191139             524.416000           3883.200000         
model.layers.6.mlp.experts.37.down_proj       torch.Size([1, 2048])          1.026592             1.314878             621.312000           3779.136000         
model.layers.6.mlp.experts.38.gate_proj       torch.Size([0, 1408])          0.516768             0.904083             621.312000           3726.950400         
model.layers.6.mlp.experts.38.act_fn          torch.Size([0, 1408])          0.275296             0.633478             621.312000           3727.872000         
model.layers.6.mlp.experts.38.up_proj         torch.Size([0, 1408])          0.451744             0.824213             621.376000           3727.872000         
model.layers.6.mlp.experts.38.down_proj       torch.Size([0, 2048])          0.441152             0.810623             621.568000           3727.872000         
model.layers.6.mlp.experts.39.gate_proj       torch.Size([1, 1408])          0.908416             1.251221             621.348571           3859.867429         
model.layers.6.mlp.experts.39.act_fn          torch.Size([1, 1408])          0.298944             0.662804             621.312000           3881.600000         
model.layers.6.mlp.experts.39.up_proj         torch.Size([1, 1408])          0.863488             1.164913             687.881143           4036.864000         
model.layers.6.mlp.experts.39.down_proj       torch.Size([1, 2048])          1.017664             1.306295             776.355556           4036.864000         
model.layers.6.mlp.experts.40.gate_proj       torch.Size([1, 1408])          0.874976             1.167059             853.952000           4036.240000         
model.layers.6.mlp.experts.40.act_fn          torch.Size([1, 1408])          0.439616             0.803947             931.584000           4036.448000         
model.layers.6.mlp.experts.40.up_proj         torch.Size([1, 1408])          0.861952             1.154900             931.584000           3946.989714         
model.layers.6.mlp.experts.40.down_proj       torch.Size([1, 2048])          1.012416             1.294613             931.584000           3880.000000         
model.layers.6.mlp.experts.41.gate_proj       torch.Size([0, 1408])          0.498752             0.870228             931.584000           3880.000000         
model.layers.6.mlp.experts.41.act_fn          torch.Size([0, 1408])          0.292736             0.665903             931.584000           3881.066667         
model.layers.6.mlp.experts.41.up_proj         torch.Size([0, 1408])          0.467360             0.824213             931.584000           3881.600000         
model.layers.6.mlp.experts.41.down_proj       torch.Size([0, 2048])          0.464128             0.822306             815.136000           3881.600000         
model.layers.6.mlp.experts.42.gate_proj       torch.Size([3, 1408])          0.978208             1.276731             853.952000           4036.032000         
model.layers.6.mlp.experts.42.act_fn          torch.Size([3, 1408])          0.308416             0.719786             931.584000           4151.600000         
model.layers.6.mlp.experts.42.up_proj         torch.Size([3, 1408])          0.967104             1.270056             931.584000           4190.400000         
model.layers.6.mlp.experts.42.down_proj       torch.Size([3, 2048])          1.376032             1.661777             989.808000           4190.400000         
model.layers.6.mlp.experts.43.gate_proj       torch.Size([0, 1408])          0.457568             0.842333             1048.032000          4074.000000         
model.layers.6.mlp.experts.43.act_fn          torch.Size([0, 1408])          0.270464             0.711918             931.584000           4035.200000         
model.layers.6.mlp.experts.43.up_proj         torch.Size([0, 1408])          0.456480             0.843048             931.584000           4036.032000         
model.layers.6.mlp.experts.43.down_proj       torch.Size([0, 2048])          0.458432             0.843048             931.584000           3959.232000         
model.layers.6.mlp.experts.44.gate_proj       torch.Size([0, 1408])          0.509440             0.892162             776.533333           3881.600000         
model.layers.6.mlp.experts.44.act_fn          torch.Size([0, 1408])          0.267424             0.645161             776.640000           3881.600000         
model.layers.6.mlp.experts.44.up_proj         torch.Size([0, 1408])          0.442560             0.821114             776.640000           3881.600000         
model.layers.6.mlp.experts.44.down_proj       torch.Size([0, 2048])          0.439616             0.819683             776.640000           3881.600000         
model.layers.6.mlp.experts.45.gate_proj       torch.Size([1, 1408])          0.859872             1.168013             776.640000           3862.192000         
model.layers.6.mlp.experts.45.act_fn          torch.Size([1, 1408])          0.294016             0.672579             776.640000           3881.600000         
model.layers.6.mlp.experts.45.up_proj         torch.Size([1, 1408])          0.860096             1.145601             776.497778           4002.360889         
model.layers.6.mlp.experts.45.down_proj       torch.Size([1, 2048])          1.011200             1.314163             873.360000           4036.032000         
model.layers.6.mlp.experts.46.gate_proj       torch.Size([0, 1408])          0.475968             0.919104             931.584000           4152.448000         
model.layers.6.mlp.experts.46.act_fn          torch.Size([0, 1408])          0.273504             0.639200             776.320000           4140.373333         
model.layers.6.mlp.experts.46.up_proj         torch.Size([0, 1408])          0.455136             0.831604             776.320000           4036.864000         
model.layers.6.mlp.experts.46.down_proj       torch.Size([0, 2048])          0.449024             0.810623             776.480000           4036.864000         
model.layers.6.mlp.experts.47.gate_proj       torch.Size([1, 1408])          0.922752             1.247168             776.360000           4036.864000         
model.layers.6.mlp.experts.47.act_fn          torch.Size([1, 1408])          0.325248             0.692844             776.320000           4036.864000         
model.layers.6.mlp.experts.47.up_proj         torch.Size([1, 1408])          0.903392             1.203060             810.823111           3967.857778         
model.layers.6.mlp.experts.47.down_proj       torch.Size([1, 2048])          1.028576             1.320601             931.584000           3880.228571         
model.layers.6.mlp.experts.48.gate_proj       torch.Size([0, 1408])          0.470016             0.899076             931.584000           3880.000000         
model.layers.6.mlp.experts.48.act_fn          torch.Size([0, 1408])          0.270080             0.648022             931.584000           3881.600000         
model.layers.6.mlp.experts.48.up_proj         torch.Size([0, 1408])          0.446944             0.815868             815.216000           3881.600000         
model.layers.6.mlp.experts.48.down_proj       torch.Size([0, 2048])          0.441376             0.818491             776.640000           3765.152000         
model.layers.6.mlp.experts.49.gate_proj       torch.Size([0, 1408])          0.523040             0.900984             776.640000           3765.152000         
model.layers.6.mlp.experts.49.act_fn          torch.Size([0, 1408])          0.279904             0.676394             776.640000           3881.600000         
model.layers.6.mlp.experts.49.up_proj         torch.Size([0, 1408])          0.494208             0.882864             737.808000           3881.600000         
model.layers.6.mlp.experts.49.down_proj       torch.Size([0, 2048])          0.483968             0.926256             621.312000           3881.600000         
model.layers.6.mlp.experts.50.gate_proj       torch.Size([0, 1408])          0.462976             0.852108             621.312000           3881.600000         
model.layers.6.mlp.experts.50.act_fn          torch.Size([0, 1408])          0.270016             0.669718             621.312000           3881.600000         
model.layers.6.mlp.experts.50.up_proj         torch.Size([0, 1408])          0.489344             0.926256             621.312000           3882.400000         
model.layers.6.mlp.experts.50.down_proj       torch.Size([0, 2048])          0.470624             0.831604             621.312000           3844.368000         
model.layers.6.mlp.experts.51.gate_proj       torch.Size([1, 1408])          0.880128             1.185417             621.312000           3746.520000         
model.layers.6.mlp.experts.51.act_fn          torch.Size([1, 1408])          0.290656             0.654936             621.312000           3726.336000         
model.layers.6.mlp.experts.51.up_proj         torch.Size([1, 1408])          0.855392             1.139402             687.881143           3726.336000         
model.layers.6.mlp.experts.51.down_proj       torch.Size([1, 2048])          1.036160             1.334190             776.640000           3726.336000         
model.layers.6.mlp.experts.52.gate_proj       torch.Size([1, 1408])          0.852896             1.151562             873.624000           3784.560000         
model.layers.6.mlp.experts.52.act_fn          torch.Size([1, 1408])          0.304960             0.665903             931.584000           3881.600000         
model.layers.6.mlp.experts.52.up_proj         torch.Size([1, 1408])          0.878144             1.232147             931.584000           3900.600000         
model.layers.6.mlp.experts.52.down_proj       torch.Size([1, 2048])          1.009504             1.296759             931.584000           4035.200000         
model.layers.6.mlp.experts.53.gate_proj       torch.Size([1, 1408])          0.863264             1.156092             1000.590222          4035.200000         
model.layers.6.mlp.experts.53.act_fn          torch.Size([1, 1408])          0.301600             0.682116             1035.093333          4035.200000         
model.layers.6.mlp.experts.53.up_proj         torch.Size([1, 1408])          0.860864             1.152039             1048.032000          3938.200000         
model.layers.6.mlp.experts.53.down_proj       torch.Size([1, 2048])          1.021472             1.305342             1086.798222          3880.000000         
model.layers.6.mlp.experts.54.gate_proj       torch.Size([0, 1408])          0.509152             0.885248             1086.848000          3880.000000         
model.layers.6.mlp.experts.54.act_fn          torch.Size([0, 1408])          0.669088             1.098156             1035.093333          3880.000000         
model.layers.6.mlp.experts.54.up_proj         torch.Size([0, 1408])          0.466976             0.850439             931.584000           3880.000000         
model.layers.6.mlp.experts.54.down_proj       torch.Size([0, 2048])          0.459264             0.828028             931.584000           3880.800000         
model.layers.6.mlp.experts.55.gate_proj       torch.Size([0, 1408])          0.461312             0.846624             931.584000           3819.494400         
model.layers.6.mlp.experts.55.act_fn          torch.Size([0, 1408])          0.277184             0.665903             776.640000           3726.336000         
model.layers.6.mlp.experts.55.up_proj         torch.Size([0, 1408])          0.485280             0.856161             776.640000           3571.072000         
model.layers.6.mlp.experts.55.down_proj       torch.Size([0, 2048])          0.525664             0.906944             776.640000           3572.544000         
model.layers.6.mlp.experts.56.gate_proj       torch.Size([1, 1408])          0.907168             1.279354             776.640000           3572.544000         
model.layers.6.mlp.experts.56.act_fn          torch.Size([1, 1408])          0.383072             0.849962             776.640000           3572.544000         
model.layers.6.mlp.experts.56.up_proj         torch.Size([1, 1408])          0.890592             1.183748             776.640000           3571.399111         
model.layers.6.mlp.experts.56.down_proj       torch.Size([1, 2048])          1.032064             1.378775             873.720000           3571.072000         
model.layers.6.mlp.experts.57.gate_proj       torch.Size([0, 1408])          0.482848             0.858545             931.968000           3571.072000         
model.layers.6.mlp.experts.57.act_fn          torch.Size([0, 1408])          0.299168             0.700474             776.640000           3571.072000         
model.layers.6.mlp.experts.57.up_proj         torch.Size([0, 1408])          0.515040             0.911713             776.640000           3571.660800         
model.layers.6.mlp.experts.57.down_proj       torch.Size([0, 2048])          0.496608             0.901937             776.640000           3572.544000         
model.layers.6.mlp.experts.58.gate_proj       torch.Size([0, 1408])          0.487904             0.867367             776.640000           3572.544000         
model.layers.6.mlp.experts.58.act_fn          torch.Size([0, 1408])          0.329408             0.701427             776.640000           3572.544000         
model.layers.6.mlp.experts.58.up_proj         torch.Size([0, 1408])          0.468064             0.827312             621.312000           3572.544000         
model.layers.6.mlp.experts.58.down_proj       torch.Size([0, 2048])          0.461504             0.829220             621.312000           3727.872000         
model.layers.6.mlp.experts.59.gate_proj       torch.Size([0, 1408])          0.516288             0.883579             621.312000           3844.368000         
model.layers.6.mlp.experts.59.act_fn          torch.Size([0, 1408])          0.268704             0.642538             621.312000           3883.200000         
model.layers.6.mlp.experts.59.up_proj         torch.Size([0, 1408])          0.468032             0.828028             621.312000           3883.200000         
model.layers.6.mlp.experts.59.down_proj       torch.Size([0, 2048])          0.460064             0.820160             621.312000           3883.200000         
model.layers.6.mlp.shared_expert.gate_proj    torch.Size([5, 5632])          2.578816             2.905846             679.560000           3882.000000         
model.layers.6.mlp.shared_expert.act_fn       torch.Size([5, 5632])          0.379872             0.740528             931.584000           3880.400000         
model.layers.6.mlp.shared_expert.up_proj      torch.Size([5, 5632])          2.604896             2.902508             1183.560000          3879.400000         
model.layers.6.mlp.shared_expert.down_proj    torch.Size([5, 2048])          2.736224             3.080845             1570.896000          3858.616000         
model.layers.6.mlp.shared_expert_gate         torch.Size([5, 1])             0.584160             0.971556             1732.352000          3748.597333         
model.layers.7.input_layernorm                torch.Size([1, 5, 2048])       37.382687            37.978172            1095.954824          3555.321725         
model.layers.7.self_attn.q_proj               torch.Size([1, 5, 2048])       127.162880           127.796888           776.921865           3228.823876         
model.layers.7.self_attn.k_proj               torch.Size([1, 5, 2048])       128.546082           129.166842           762.338667           3186.607667         
model.layers.7.self_attn.v_proj               torch.Size([1, 5, 2048])       124.601059           125.340223           760.922984           3155.257427         
model.layers.7.self_attn.o_proj               torch.Size([1, 5, 2048])       119.022270           119.858503           760.144400           3444.448400         
model.layers.7.post_attention_layernorm       torch.Size([1, 5, 2048])       15.385984            16.046762            647.867170           3314.343849         
model.layers.7.mlp.gate                       torch.Size([5, 60])            13.881408            14.415503            475.499520           3321.122560         
model.layers.7.mlp.experts.0.gate_proj        torch.Size([0, 1408])          86.698082            87.185144            556.025500           3218.597000         
model.layers.7.mlp.experts.0.act_fn           torch.Size([0, 1408])          0.341440             0.785351             621.568000           3261.888000         
model.layers.7.mlp.experts.0.up_proj          torch.Size([0, 1408])          76.549118            77.130318            621.568000           3116.040180         
model.layers.7.mlp.experts.0.down_proj        torch.Size([0, 2048])          84.816544            85.615158            593.895452           3028.226192         
model.layers.7.mlp.experts.1.gate_proj        torch.Size([0, 1408])          90.723587            92.025995            568.640928           3063.156406         
model.layers.7.mlp.experts.1.act_fn           torch.Size([0, 1408])          0.696960             1.739740             621.312000           3417.216000         
model.layers.7.mlp.experts.1.up_proj          torch.Size([0, 1408])          83.781471            84.738255            553.101427           3135.887664         
model.layers.7.mlp.experts.1.down_proj        torch.Size([0, 2048])          85.563202            86.526155            566.464454           3146.218213         
model.layers.7.mlp.experts.2.gate_proj        torch.Size([0, 1408])          88.922852            89.962244            551.166500           3054.902500         
model.layers.7.mlp.experts.2.act_fn           torch.Size([0, 1408])          0.712032             1.627922             621.568000           3261.888000         
model.layers.7.mlp.experts.2.up_proj          torch.Size([0, 1408])          82.418015            83.226204            550.681772           3041.651544         
model.layers.7.mlp.experts.2.down_proj        torch.Size([0, 2048])          85.585953            86.414337            561.977863           3140.014904         
model.layers.7.mlp.experts.3.gate_proj        torch.Size([1, 1408])          89.967392            90.940475            578.569078           3247.566979         
model.layers.7.mlp.experts.3.act_fn           torch.Size([1, 1408])          0.778016             1.658916             621.568000           3292.953600         
model.layers.7.mlp.experts.3.up_proj          torch.Size([1, 1408])          86.519875            87.394953            621.547886           3223.147429         
model.layers.7.mlp.experts.3.down_proj        torch.Size([1, 2048])          86.038780            86.721897            621.552941           3132.828706         
model.layers.7.mlp.experts.4.gate_proj        torch.Size([1, 1408])          90.698723            91.257572            621.550412           3022.374595         
model.layers.7.mlp.experts.4.act_fn           torch.Size([1, 1408])          0.690496             1.337051             621.568000           3106.560000         
model.layers.7.mlp.experts.4.up_proj          torch.Size([1, 1408])          84.522942            85.164785            621.542612           3166.894017         
model.layers.7.mlp.experts.4.down_proj        torch.Size([1, 2048])          91.294624            91.983557            621.372235           3278.434958         
model.layers.7.mlp.experts.5.gate_proj        torch.Size([0, 1408])          89.518272            90.306759            621.428736           3245.632512         
model.layers.7.mlp.experts.5.act_fn           torch.Size([0, 1408])          0.005664             1.294374             621.312000           3416.746667         
model.layers.7.mlp.experts.5.up_proj          torch.Size([0, 1408])          83.671616            84.097624            583.217493           3180.324267         
model.layers.7.mlp.experts.5.down_proj        torch.Size([0, 2048])          92.417534            93.029976            621.568000           3162.686924         
model.layers.7.mlp.experts.6.gate_proj        torch.Size([1, 1408])          90.720322            91.355324            621.568000           3053.607273         
model.layers.7.mlp.experts.6.act_fn           torch.Size([1, 1408])          0.774784             1.661777             621.568000           3106.560000         
model.layers.7.mlp.experts.6.up_proj          torch.Size([1, 1408])          90.820770            91.709852            621.562740           3055.715068         
model.layers.7.mlp.experts.6.down_proj        torch.Size([1, 2048])          90.786461            91.476679            621.518507           3263.714133         
model.layers.7.mlp.experts.7.gate_proj        torch.Size([0, 1408])          91.800354            92.515230            621.448072           3289.734919         
model.layers.7.mlp.experts.7.act_fn           torch.Size([0, 1408])          0.561440             1.274109             621.312000           3571.072000         
model.layers.7.mlp.experts.7.up_proj          torch.Size([0, 1408])          84.265411            84.980011            621.532496           3239.136234         
model.layers.7.mlp.experts.7.down_proj        torch.Size([0, 2048])          77.237633            77.748060            606.379308           3132.253353         
model.layers.7.mlp.experts.8.gate_proj        torch.Size([0, 1408])          82.058495            82.571983            564.094247           3025.843726         
model.layers.7.mlp.experts.8.act_fn           torch.Size([0, 1408])          0.005664             1.271009             621.568000           2951.232000         
model.layers.7.mlp.experts.8.up_proj          torch.Size([0, 1408])          82.934685            83.304644            551.536225           3134.092169         
model.layers.7.mlp.experts.8.down_proj        torch.Size([0, 2048])          82.950142            83.443880            549.176986           3147.228055         
model.layers.7.mlp.experts.9.gate_proj        torch.Size([1, 1408])          84.010109            84.822178            591.326222           3161.605778         
model.layers.7.mlp.experts.9.act_fn           torch.Size([1, 1408])          0.681408             1.423359             621.568000           3223.056000         
model.layers.7.mlp.experts.9.up_proj          torch.Size([1, 1408])          91.890686            92.681408            621.437867           3172.574400         
model.layers.7.mlp.experts.9.down_proj        torch.Size([1, 2048])          91.612862            92.272520            621.447168           3125.165568         
model.layers.7.mlp.experts.10.gate_proj       torch.Size([0, 1408])          84.389725            84.951878            621.534968           3072.713806         
model.layers.7.mlp.experts.10.act_fn          torch.Size([0, 1408])          0.554624             1.293898             621.312000           3674.581333         
model.layers.7.mlp.experts.10.up_proj         torch.Size([0, 1408])          84.755295            85.372448            621.382621           3566.575669         
model.layers.7.mlp.experts.10.down_proj       torch.Size([0, 2048])          84.511459            84.947824            560.602585           3273.895385         
model.layers.7.mlp.experts.11.gate_proj       torch.Size([0, 1408])          84.877823            85.677147            540.293584           3043.773423         
model.layers.7.mlp.experts.11.act_fn          torch.Size([0, 1408])          0.435936             0.901461             621.568000           3261.888000         
model.layers.7.mlp.experts.11.up_proj         torch.Size([0, 1408])          76.948128            77.486515            544.992432           3018.240000         
model.layers.7.mlp.experts.11.down_proj       torch.Size([0, 2048])          75.507011            76.032877            571.508832           3009.919570         
model.layers.7.mlp.experts.12.gate_proj       torch.Size([0, 1408])          87.494461            87.972641            545.651298           3140.955359         
model.layers.7.mlp.experts.12.act_fn          torch.Size([0, 1408])          0.461824             0.934839             621.568000           3106.560000         
model.layers.7.mlp.experts.12.up_proj         torch.Size([0, 1408])          84.131615            84.555626            544.384883           3217.967669         
model.layers.7.mlp.experts.12.down_proj       torch.Size([0, 2048])          91.940033            92.301130            564.375111           3112.046222         
model.layers.7.mlp.experts.13.gate_proj       torch.Size([0, 1408])          88.133087            88.652611            558.154449           3055.010395         
model.layers.7.mlp.experts.13.act_fn          torch.Size([0, 1408])          0.672384             1.545668             621.568000           3106.560000         
model.layers.7.mlp.experts.13.up_proj         torch.Size([0, 1408])          87.530365            88.112831            541.867636           3067.549091         
model.layers.7.mlp.experts.13.down_proj       torch.Size([0, 2048])          81.580032            82.243443            572.722286           3155.721600         
model.layers.7.mlp.experts.14.gate_proj       torch.Size([1, 1408])          90.211998            91.097832            574.450105           3422.140211         
model.layers.7.mlp.experts.14.act_fn          torch.Size([1, 1408])          0.631968             1.552582             621.312000           3571.440000         
model.layers.7.mlp.experts.14.up_proj         torch.Size([1, 1408])          91.478783            92.170238            621.460879           3236.550809         
model.layers.7.mlp.experts.14.down_proj       torch.Size([1, 2048])          87.471008            88.044405            621.522411           3093.868274         
model.layers.7.mlp.experts.15.gate_proj       torch.Size([0, 1408])          86.515167            87.148666            621.568000           3057.752693         
model.layers.7.mlp.experts.15.act_fn          torch.Size([0, 1408])          0.450944             1.049519             621.568000           3261.888000         
model.layers.7.mlp.experts.15.up_proj         torch.Size([0, 1408])          81.020447            81.537724            621.568000           3073.803755         
model.layers.7.mlp.experts.15.down_proj       torch.Size([0, 2048])          83.980286            84.398508            565.841214           3194.400662         
model.layers.7.mlp.experts.16.gate_proj       torch.Size([0, 1408])          91.916962            92.603207            565.165037           3263.038578         
model.layers.7.mlp.experts.16.act_fn          torch.Size([0, 1408])          0.651872             1.422167             621.312000           3417.216000         
model.layers.7.mlp.experts.16.up_proj         torch.Size([0, 1408])          84.035553            84.600925            558.339531           3125.850924         
model.layers.7.mlp.experts.16.down_proj       torch.Size([0, 2048])          83.233185            83.890200            569.041127           3107.653859         
model.layers.7.mlp.experts.17.gate_proj       torch.Size([0, 1408])          85.209023            85.686445            565.846952           2935.979255         
model.layers.7.mlp.experts.17.act_fn          torch.Size([0, 1408])          0.577056             1.338243             621.568000           2952.448000         
model.layers.7.mlp.experts.17.up_proj         torch.Size([0, 1408])          84.456642            85.133314            553.248681           3136.617305         
model.layers.7.mlp.experts.17.down_proj       torch.Size([0, 2048])          81.606750            82.169294            575.250000           3515.231000         
model.layers.7.mlp.experts.18.gate_proj       torch.Size([0, 1408])          85.858208            86.576700            573.008000           3187.460000         
model.layers.7.mlp.experts.18.act_fn          torch.Size([0, 1408])          0.608576             1.414776             621.568000           3106.560000         
model.layers.7.mlp.experts.18.up_proj         torch.Size([0, 1408])          88.295647            88.863850            553.914340           3096.026558         
model.layers.7.mlp.experts.18.down_proj       torch.Size([0, 2048])          82.835075            83.562851            583.283014           3053.008232         
model.layers.7.mlp.experts.19.gate_proj       torch.Size([1, 1408])          86.206947            86.780310            597.878675           3074.776159         
model.layers.7.mlp.experts.19.act_fn          torch.Size([1, 1408])          0.446624             0.892162             621.312000           3417.216000         
model.layers.7.mlp.experts.19.up_proj         torch.Size([1, 1408])          77.728386            78.266621            621.435762           3297.891179         
model.layers.7.mlp.experts.19.down_proj       torch.Size([1, 2048])          80.922302            81.468105            621.497379           3247.962041         
model.layers.7.mlp.experts.20.gate_proj       torch.Size([0, 1408])          86.277695            86.788654            621.553678           3136.973874         
model.layers.7.mlp.experts.20.act_fn          torch.Size([0, 1408])          0.421728             0.851154             621.568000           3417.216000         
model.layers.7.mlp.experts.20.up_proj         torch.Size([0, 1408])          82.052734            82.565546            567.656490           3064.535946         
model.layers.7.mlp.experts.20.down_proj       torch.Size([0, 2048])          80.848541            81.259966            571.884844           3000.591673         
model.layers.7.mlp.experts.21.gate_proj       torch.Size([0, 1408])          89.499619            90.126038            569.400686           3153.158400         
model.layers.7.mlp.experts.21.act_fn          torch.Size([0, 1408])          0.355264             0.745535             621.568000           3106.560000         
model.layers.7.mlp.experts.21.up_proj         torch.Size([0, 1408])          83.105186            83.529472            522.093714           3453.550150         
model.layers.7.mlp.experts.21.down_proj       torch.Size([0, 2048])          87.177216            88.670015            533.575065           3729.639896         
model.layers.7.mlp.experts.22.gate_proj       torch.Size([0, 1408])          91.006241            91.693878            564.960914           3210.851657         
model.layers.7.mlp.experts.22.act_fn          torch.Size([0, 1408])          0.636128             1.191854             621.568000           3106.560000         
model.layers.7.mlp.experts.22.up_proj         torch.Size([0, 1408])          90.819740            91.351032            563.296000           3104.438118         
model.layers.7.mlp.experts.22.down_proj       torch.Size([0, 2048])          81.337021            81.972599            571.905778           3165.024444         
model.layers.7.mlp.experts.23.gate_proj       torch.Size([0, 1408])          94.842529            95.345497            580.182561           3210.484489         
model.layers.7.mlp.experts.23.act_fn          torch.Size([0, 1408])          0.331968             0.718594             621.312000           3533.712000         
model.layers.7.mlp.experts.23.up_proj         torch.Size([0, 1408])          145.787109           146.255970           554.602146           3239.157073         
model.layers.7.mlp.experts.23.down_proj       torch.Size([0, 2048])          135.797882           136.532307           575.281021           3035.153248         
model.layers.7.mlp.experts.24.gate_proj       torch.Size([0, 1408])          163.102631           163.756371           553.805972           2961.741521         
model.layers.7.mlp.experts.24.act_fn          torch.Size([0, 1408])          0.353472             0.745535             621.568000           3106.560000         
model.layers.7.mlp.experts.24.up_proj         torch.Size([0, 1408])          135.424774           136.013985           549.985135           2971.713816         
model.layers.7.mlp.experts.24.down_proj       torch.Size([0, 2048])          132.943237           134.511232           564.769545           3154.086841         
model.layers.7.mlp.experts.25.gate_proj       torch.Size([0, 1408])          142.601349           143.323183           561.137778           3195.178222         
model.layers.7.mlp.experts.25.act_fn          torch.Size([0, 1408])          0.457696             1.284122             621.568000           3261.888000         
model.layers.7.mlp.experts.25.up_proj         torch.Size([0, 1408])          153.658463           154.077530           549.307042           3242.173746         
model.layers.7.mlp.experts.25.down_proj       torch.Size([0, 2048])          143.172546           143.683434           520.348800           3833.558800         
model.layers.7.mlp.experts.26.gate_proj       torch.Size([0, 1408])          147.475098           148.821115           561.125333           3185.502222         
model.layers.7.mlp.experts.26.act_fn          torch.Size([0, 1408])          0.005536             1.271009             621.568000           3261.888000         
model.layers.7.mlp.experts.26.up_proj         torch.Size([0, 1408])          160.898849           162.228823           543.895671           3118.036164         
model.layers.7.mlp.experts.26.down_proj       torch.Size([0, 2048])          151.493881           153.213024           548.104216           3181.365622         
model.layers.7.mlp.experts.27.gate_proj       torch.Size([0, 1408])          130.362457           131.922245           565.920865           3077.719351         
model.layers.7.mlp.experts.27.act_fn          torch.Size([0, 1408])          0.005728             1.244068             621.568000           3313.664000         
model.layers.7.mlp.experts.27.up_proj         torch.Size([0, 1408])          129.380386           130.703688           542.286367           3095.397878         
model.layers.7.mlp.experts.27.down_proj       torch.Size([0, 2048])          125.484032           126.790524           569.415890           3111.879452         
model.layers.7.mlp.experts.28.gate_proj       torch.Size([0, 1408])          148.263779           149.929762           571.210152           3124.970372         
model.layers.7.mlp.experts.28.act_fn          torch.Size([0, 1408])          0.005600             1.344681             621.568000           3106.560000         
model.layers.7.mlp.experts.28.up_proj         torch.Size([0, 1408])          132.141083           132.529497           546.495565           3202.901769         
model.layers.7.mlp.experts.28.down_proj       torch.Size([0, 2048])          129.962845           130.430698           563.312000           3115.403556         
model.layers.7.mlp.experts.29.gate_proj       torch.Size([0, 1408])          145.705948           146.381140           572.405410           3033.052086         
model.layers.7.mlp.experts.29.act_fn          torch.Size([0, 1408])          0.608352             1.544714             621.568000           3106.560000         
model.layers.7.mlp.experts.29.up_proj         torch.Size([0, 1408])          132.816132           133.347988           533.733878           3201.924354         
model.layers.7.mlp.experts.29.down_proj       torch.Size([0, 2048])          134.309021           135.037899           503.035163           3658.240372         
model.layers.7.mlp.experts.30.gate_proj       torch.Size([1, 1408])          102.059265           102.600813           589.527233           3390.357918         
model.layers.7.mlp.experts.30.act_fn          torch.Size([1, 1408])          0.422880             0.914097             621.312000           3417.216000         
model.layers.7.mlp.experts.30.up_proj         torch.Size([1, 1408])          79.671936            80.192327            621.552602           3190.647338         
model.layers.7.mlp.experts.30.down_proj       torch.Size([1, 2048])          87.038818            87.489367            621.568000           3064.066577         
model.layers.7.mlp.experts.31.gate_proj       torch.Size([0, 1408])          87.861565            88.303566            621.568000           3073.457311         
model.layers.7.mlp.experts.31.act_fn          torch.Size([0, 1408])          0.521728             1.081228             621.568000           3261.888000         
model.layers.7.mlp.experts.31.up_proj         torch.Size([0, 1408])          82.561340            83.043814            621.589041           3046.458740         
model.layers.7.mlp.experts.31.down_proj       torch.Size([0, 2048])          80.296288            80.757618            569.056221           3123.225600         
model.layers.7.mlp.experts.32.gate_proj       torch.Size([0, 1408])          91.383553            91.848850            561.313959           3117.888435         
model.layers.7.mlp.experts.32.act_fn          torch.Size([0, 1408])          0.677216             1.435757             621.568000           3261.888000         
model.layers.7.mlp.experts.32.up_proj         torch.Size([0, 1408])          82.969315            83.672047            561.969534           3143.444603         
model.layers.7.mlp.experts.32.down_proj       torch.Size([0, 2048])          85.532578            86.198092            566.798507           3017.379413         
model.layers.7.mlp.experts.33.gate_proj       torch.Size([1, 1408])          89.327805            90.283394            593.895452           3054.429370         
model.layers.7.mlp.experts.33.act_fn          torch.Size([1, 1408])          0.748800             1.662970             621.568000           3261.888000         
model.layers.7.mlp.experts.33.up_proj         torch.Size([1, 1408])          84.043137            84.758043            621.428053           3231.794347         
model.layers.7.mlp.experts.33.down_proj       torch.Size([1, 2048])          77.641312            78.178883            621.167590           3919.679179         
model.layers.7.mlp.experts.34.gate_proj       torch.Size([0, 1408])          91.379005            91.891527            621.365333           3513.686400         
model.layers.7.mlp.experts.34.act_fn          torch.Size([0, 1408])          0.468480             1.062632             621.568000           3106.560000         
model.layers.7.mlp.experts.34.up_proj         torch.Size([0, 1408])          83.737053            84.256649            560.521143           3197.537829         
model.layers.7.mlp.experts.34.down_proj       torch.Size([0, 2048])          84.648163            85.045815            573.085696           3114.229760         
model.layers.7.mlp.experts.35.gate_proj       torch.Size([0, 1408])          92.524384            93.256712            612.462248           3195.048175         
model.layers.7.mlp.experts.35.act_fn          torch.Size([0, 1408])          0.650752             1.499176             621.568000           3261.888000         
model.layers.7.mlp.experts.35.up_proj         torch.Size([0, 1408])          82.913597            83.517790            559.606725           3183.417971         
model.layers.7.mlp.experts.35.down_proj       torch.Size([0, 2048])          92.831039            93.388557            579.277497           3211.168653         
model.layers.7.mlp.experts.36.gate_proj       torch.Size([0, 1408])          75.091042            75.685501            569.392584           3067.392467         
model.layers.7.mlp.experts.36.act_fn          torch.Size([0, 1408])          0.492960             1.093149             621.568000           3106.560000         
model.layers.7.mlp.experts.36.up_proj         torch.Size([0, 1408])          84.490143            85.038662            563.975161           3078.896783         
model.layers.7.mlp.experts.36.down_proj       torch.Size([0, 2048])          81.774590            82.204103            575.543614           3066.541903         
model.layers.7.mlp.experts.37.gate_proj       torch.Size([0, 1408])          88.957855            89.550495            600.378182           3221.879273         
model.layers.7.mlp.experts.37.act_fn          torch.Size([0, 1408])          0.568384             1.179457             621.568000           3417.216000         
model.layers.7.mlp.experts.37.up_proj         torch.Size([0, 1408])          85.885155            86.584568            556.912640           3230.922752         
model.layers.7.mlp.experts.37.down_proj       torch.Size([0, 2048])          78.318176            78.861237            536.950550           3429.308134         
model.layers.7.mlp.experts.38.gate_proj       torch.Size([3, 1408])          81.257980            81.907034            570.216149           3618.905839         
model.layers.7.mlp.experts.38.act_fn          torch.Size([3, 1408])          0.840672             1.687288             621.312000           3456.048000         
model.layers.7.mlp.experts.38.up_proj         torch.Size([3, 1408])          82.364548            83.053350            621.544229           3156.486857         
model.layers.7.mlp.experts.38.down_proj       torch.Size([3, 2048])          83.948799            84.608078            639.441455           3238.781355         
model.layers.7.mlp.experts.39.gate_proj       torch.Size([0, 1408])          97.879967            98.472118            624.284829           3281.235027         
model.layers.7.mlp.experts.39.act_fn          torch.Size([0, 1408])          0.409952             0.914812             621.568000           3417.216000         
model.layers.7.mlp.experts.39.up_proj         torch.Size([0, 1408])          85.602013            85.979223            621.568000           3236.000000         
model.layers.7.mlp.experts.39.down_proj       torch.Size([0, 2048])          83.794144            84.238291            585.626993           3111.093116         
model.layers.7.mlp.experts.40.gate_proj       torch.Size([0, 1408])          84.129219            84.795237            593.895452           3018.675726         
model.layers.7.mlp.experts.40.act_fn          torch.Size([0, 1408])          0.586848             1.491547             621.568000           3106.560000         
model.layers.7.mlp.experts.40.up_proj         torch.Size([0, 1408])          82.549698            83.234310            562.587095           3088.916555         
model.layers.7.mlp.experts.40.down_proj       torch.Size([0, 2048])          94.734146            95.430374            597.748788           3207.466511         
model.layers.7.mlp.experts.41.gate_proj       torch.Size([0, 1408])          86.627838            87.270260            557.085605           3197.440871         
model.layers.7.mlp.experts.41.act_fn          torch.Size([0, 1408])          0.334592             0.746965             621.568000           3261.888000         
model.layers.7.mlp.experts.41.up_proj         torch.Size([0, 1408])          80.638908            81.051350            554.657168           3083.506920         
model.layers.7.mlp.experts.41.down_proj       torch.Size([0, 2048])          79.474274            79.904795            572.329915           3141.841127         
model.layers.7.mlp.experts.42.gate_proj       torch.Size([1, 1408])          86.368927            87.070942            571.078515           3826.807952         
model.layers.7.mlp.experts.42.act_fn          torch.Size([1, 1408])          0.693472             1.093388             621.312000           3726.336000         
model.layers.7.mlp.experts.42.up_proj         torch.Size([1, 1408])          87.308899            87.997437            621.508789           3360.062694         
model.layers.7.mlp.experts.42.down_proj       torch.Size([1, 2048])          92.775841            93.696833            621.450492           3264.434361         
model.layers.7.mlp.experts.43.gate_proj       torch.Size([0, 1408])          89.308640            90.345860            621.522149           3228.272239         
model.layers.7.mlp.experts.43.act_fn          torch.Size([0, 1408])          0.575328             1.425266             621.568000           3106.560000         
model.layers.7.mlp.experts.43.up_proj         torch.Size([0, 1408])          83.126556            83.903790            621.568000           3146.534118         
model.layers.7.mlp.experts.43.down_proj       torch.Size([0, 2048])          86.920929            87.509632            576.732349           3021.344215         
model.layers.7.mlp.experts.44.gate_proj       torch.Size([1, 1408])          87.804642            88.587523            598.608322           3138.098255         
model.layers.7.mlp.experts.44.act_fn          torch.Size([1, 1408])          0.708096             1.488447             621.568000           3261.888000         
model.layers.7.mlp.experts.44.up_proj         torch.Size([1, 1408])          83.906242            84.810734            621.506207           3237.064828         
model.layers.7.mlp.experts.44.down_proj       torch.Size([1, 2048])          87.971680            88.636875            621.562846           3163.895839         
model.layers.7.mlp.experts.45.gate_proj       torch.Size([0, 1408])          87.688126            88.575602            621.578894           2997.947461         
model.layers.7.mlp.experts.45.act_fn          torch.Size([0, 1408])          0.393696             0.991821             621.568000           3106.560000         
model.layers.7.mlp.experts.45.up_proj         torch.Size([0, 1408])          83.188095            83.633900            581.893447           3068.530383         
model.layers.7.mlp.experts.45.down_proj       torch.Size([0, 2048])          84.282883            84.784985            565.636235           3043.256000         
model.layers.7.mlp.experts.46.gate_proj       torch.Size([1, 1408])          91.316574            91.983318            587.667892           3818.632216         
model.layers.7.mlp.experts.46.act_fn          torch.Size([1, 1408])          0.444480             0.876188             621.056000           4036.864000         
model.layers.7.mlp.experts.46.up_proj         torch.Size([1, 1408])          96.031677            96.522331            621.295304           3697.756290         
model.layers.7.mlp.experts.46.down_proj       torch.Size([1, 2048])          86.659004            87.245703            621.559409           3132.647517         
model.layers.7.mlp.experts.47.gate_proj       torch.Size([0, 1408])          97.728477            98.276377            621.568000           3029.714853         
model.layers.7.mlp.experts.47.act_fn          torch.Size([0, 1408])          0.548768             1.314402             621.568000           3313.664000         
model.layers.7.mlp.experts.47.up_proj         torch.Size([0, 1408])          107.784897           108.301640           604.554277           3117.897810         
model.layers.7.mlp.experts.47.down_proj       torch.Size([0, 2048])          83.325859            83.818197            606.024862           3248.744862         
model.layers.7.mlp.experts.48.gate_proj       torch.Size([0, 1408])          91.261986            91.756821            568.739840           3161.709653         
model.layers.7.mlp.experts.48.act_fn          torch.Size([0, 1408])          0.704768             1.461267             621.568000           3106.560000         
model.layers.7.mlp.experts.48.up_proj         torch.Size([0, 1408])          87.810913            88.481665            575.525926           3156.721778         
model.layers.7.mlp.experts.48.down_proj       torch.Size([0, 2048])          95.541054            96.149921            621.568000           3085.677576         
model.layers.7.mlp.experts.49.gate_proj       torch.Size([0, 1408])          85.555939            86.028814            597.991283           3066.297821         
model.layers.7.mlp.experts.49.act_fn          torch.Size([0, 1408])          0.333600             0.772953             621.568000           3106.560000         
model.layers.7.mlp.experts.49.up_proj         torch.Size([0, 1408])          81.306465            81.663132            574.022687           3119.755463         
model.layers.7.mlp.experts.49.down_proj       torch.Size([0, 2048])          81.651520            82.284927            576.252000           3116.869333         
model.layers.7.mlp.experts.50.gate_proj       torch.Size([1, 1408])          87.602531            88.473797            588.190455           3512.959559         
model.layers.7.mlp.experts.50.act_fn          torch.Size([1, 1408])          0.775936             1.566410             621.056000           4345.600000         
model.layers.7.mlp.experts.50.up_proj         torch.Size([1, 1408])          88.679108            89.569807            597.609756           3811.544585         
model.layers.7.mlp.experts.50.down_proj       torch.Size([1, 2048])          83.203522            83.974123            621.542761           3173.244394         
model.layers.7.mlp.experts.51.gate_proj       torch.Size([0, 1408])          88.355331            88.964939            621.568000           3102.129304         
model.layers.7.mlp.experts.51.act_fn          torch.Size([0, 1408])          0.620000             1.347065             621.568000           3261.888000         
model.layers.7.mlp.experts.51.up_proj         torch.Size([0, 1408])          87.965057            88.620186            620.465929           3223.350922         
model.layers.7.mlp.experts.51.down_proj       torch.Size([0, 2048])          84.395805            84.935427            592.501871           3235.179281         
model.layers.7.mlp.experts.52.gate_proj       torch.Size([0, 1408])          86.517059            87.191820            584.569905           3135.106177         
model.layers.7.mlp.experts.52.act_fn          torch.Size([0, 1408])          0.324800             0.713825             621.568000           3106.560000         
model.layers.7.mlp.experts.52.up_proj         torch.Size([0, 1408])          85.577568            86.043119            570.597839           3034.354453         
model.layers.7.mlp.experts.52.down_proj       torch.Size([0, 2048])          83.008163            83.498240            573.384828           2978.336221         
model.layers.7.mlp.experts.53.gate_proj       torch.Size([0, 1408])          84.269920            84.670782            570.511217           3112.333874         
model.layers.7.mlp.experts.53.act_fn          torch.Size([0, 1408])          0.957472             1.724482             621.568000           3106.560000         
model.layers.7.mlp.experts.53.up_proj         torch.Size([0, 1408])          84.530304            85.093498            550.346667           3218.938222         
model.layers.7.mlp.experts.53.down_proj       torch.Size([0, 2048])          84.490845            85.042953            584.097589           3170.453787         
model.layers.7.mlp.experts.54.gate_proj       torch.Size([0, 1408])          87.019997            87.736130            612.444754           3263.013565         
model.layers.7.mlp.experts.54.act_fn          torch.Size([0, 1408])          0.505120             0.912428             621.312000           3417.216000         
model.layers.7.mlp.experts.54.up_proj         torch.Size([0, 1408])          85.126625            85.574865            506.995737           3580.338587         
model.layers.7.mlp.experts.54.down_proj       torch.Size([0, 2048])          93.430687            93.952894            576.178667           3350.276000         
model.layers.7.mlp.experts.55.gate_proj       torch.Size([0, 1408])          114.900764           115.724564           607.849412           3235.713412         
model.layers.7.mlp.experts.55.act_fn          torch.Size([0, 1408])          0.663104             1.424074             621.568000           3313.664000         
model.layers.7.mlp.experts.55.up_proj         torch.Size([0, 1408])          125.745346           126.293898           573.008000           3291.012000         
model.layers.7.mlp.experts.55.down_proj       torch.Size([0, 2048])          97.327293            98.028421            609.522109           3182.518078         
model.layers.7.mlp.experts.56.gate_proj       torch.Size([0, 1408])          122.209663           122.687578           607.241078           3074.768794         
model.layers.7.mlp.experts.56.act_fn          torch.Size([0, 1408])          0.380096             0.814915             621.568000           3261.888000         
model.layers.7.mlp.experts.56.up_proj         torch.Size([0, 1408])          108.772125           109.159946           591.417313           3145.971582         
model.layers.7.mlp.experts.56.down_proj       torch.Size([0, 2048])          95.777313            96.412420            608.811940           3188.870209         
model.layers.7.mlp.experts.57.gate_proj       torch.Size([2, 1408])          94.944290            95.478535            591.304312           3141.125403         
model.layers.7.mlp.experts.57.act_fn          torch.Size([2, 1408])          0.454208             0.860691             621.568000           3106.560000         
model.layers.7.mlp.experts.57.up_proj         torch.Size([2, 1408])          94.676544            95.150471            621.577783           3085.005860         
model.layers.7.mlp.experts.57.down_proj       torch.Size([2, 2048])          107.897186           108.347654           648.194098           3153.667672         
model.layers.7.mlp.experts.58.gate_proj       torch.Size([2, 1408])          102.512253           103.150129           622.699481           3198.962321         
model.layers.7.mlp.experts.58.act_fn          torch.Size([2, 1408])          0.718336             1.471996             621.056000           4036.864000         
model.layers.7.mlp.experts.58.up_proj         torch.Size([2, 1408])          91.930466            92.814445            621.307937           3587.721143         
model.layers.7.mlp.experts.58.down_proj       torch.Size([2, 2048])          100.075394           100.793123           621.519324           3169.952901         
model.layers.7.mlp.experts.59.gate_proj       torch.Size([1, 1408])          85.880257            86.370468            621.389445           3337.373042         
model.layers.7.mlp.experts.59.act_fn          torch.Size([1, 1408])          0.432032             0.933409             621.312000           3386.150400         
model.layers.7.mlp.experts.59.up_proj         torch.Size([1, 1408])          78.989059            79.409838            621.512258           3191.739871         
model.layers.7.mlp.experts.59.down_proj       torch.Size([1, 2048])          79.137535            79.650640            621.550933           3138.920000         
model.layers.7.mlp.shared_expert.gate_proj    torch.Size([5, 5632])          341.833710           342.232227           675.527273           3017.843200         
model.layers.7.mlp.shared_expert.act_fn       torch.Size([5, 5632])          0.428928             0.838757             776.320000           3724.800000         
model.layers.7.mlp.shared_expert.up_proj      torch.Size([5, 5632])          332.360199           332.833052           678.393295           3065.917410         
model.layers.7.mlp.shared_expert.down_proj    torch.Size([5, 2048])          312.070282           312.762260           694.817032           3476.627375         
model.layers.7.mlp.shared_expert_gate         torch.Size([5, 1])             11.640928            12.490034            638.870710           3596.442839         
model.layers.8.input_layernorm                torch.Size([1, 5, 2048])       9.500864             10.137081            497.254400           3392.410764         
model.layers.8.self_attn.q_proj               torch.Size([1, 5, 2048])       133.429596           134.207487           570.897959           3083.430531         
model.layers.8.self_attn.k_proj               torch.Size([1, 5, 2048])       123.535713           124.030828           621.583407           3159.932444         
model.layers.8.self_attn.v_proj               torch.Size([1, 5, 2048])       128.338715           128.869057           621.587412           3167.878066         
model.layers.8.self_attn.o_proj               torch.Size([1, 5, 2048])       114.414368           115.154982           621.595326           3053.677303         
model.layers.8.post_attention_layernorm       torch.Size([1, 5, 2048])       13.694752            14.412165            594.941000           3061.161000         
model.layers.8.mlp.gate                       torch.Size([5, 60])            15.688128            16.329765            466.362182           3126.675394         
model.layers.8.mlp.experts.0.gate_proj        torch.Size([0, 1408])          87.108131            87.529898            557.059270           3040.551708         
model.layers.8.mlp.experts.0.act_fn           torch.Size([0, 1408])          0.616352             1.399517             621.568000           3417.216000         
model.layers.8.mlp.experts.0.up_proj          torch.Size([0, 1408])          87.410881            88.235617            621.568000           3195.001550         
model.layers.8.mlp.experts.0.down_proj        torch.Size([0, 2048])          79.327423            79.790354            547.576839           3557.914406         
model.layers.8.mlp.experts.1.gate_proj        torch.Size([0, 1408])          85.719971            86.234808            525.326476           3571.319238         
model.layers.8.mlp.experts.1.act_fn           torch.Size([0, 1408])          0.344160             0.769854             621.568000           3261.888000         
model.layers.8.mlp.experts.1.up_proj          torch.Size([0, 1408])          90.616608            91.148138            554.935839           3079.143087         
model.layers.8.mlp.experts.1.down_proj        torch.Size([0, 2048])          145.479141           145.960808           583.538068           3030.287673         
model.layers.8.mlp.experts.2.gate_proj        torch.Size([0, 1408])          142.202560           142.730713           579.390171           3140.504686         
model.layers.8.mlp.experts.2.act_fn           torch.Size([0, 1408])          0.363904             0.768900             621.568000           3572.544000         
model.layers.8.mlp.experts.2.up_proj          torch.Size([0, 1408])          152.596634           153.021097           552.370000           3299.506500         
model.layers.8.mlp.experts.2.down_proj        torch.Size([0, 2048])          145.388229           146.120787           561.645595           3116.007739         
model.layers.8.mlp.experts.3.gate_proj        torch.Size([0, 1408])          143.609146           144.184351           578.227374           3113.981388         
model.layers.8.mlp.experts.3.act_fn           torch.Size([0, 1408])          0.373792             0.915289             621.568000           3106.560000         
model.layers.8.mlp.experts.3.up_proj          torch.Size([0, 1408])          123.690559           124.115944           564.100822           3038.158466         
model.layers.8.mlp.experts.3.down_proj        torch.Size([0, 2048])          147.375519           147.805691           579.022466           3132.462904         
model.layers.8.mlp.experts.4.gate_proj        torch.Size([1, 1408])          146.579239           147.127867           594.912438           3192.960000         
model.layers.8.mlp.experts.4.act_fn           torch.Size([1, 1408])          0.403264             0.803709             621.568000           3261.888000         
model.layers.8.mlp.experts.4.up_proj          torch.Size([1, 1408])          142.825317           143.253565           621.568000           3142.658319         
model.layers.8.mlp.experts.4.down_proj        torch.Size([1, 2048])          147.620026           148.416281           621.552485           3205.532315         
model.layers.8.mlp.experts.5.gate_proj        torch.Size([0, 1408])          150.997345           151.758909           582.378539           3519.294850         
model.layers.8.mlp.experts.5.act_fn           torch.Size([0, 1408])          0.626976             1.405954             621.568000           3261.888000         
model.layers.8.mlp.experts.5.up_proj          torch.Size([0, 1408])          123.653763           124.397516           547.184676           3178.156620         
model.layers.8.mlp.experts.5.down_proj        torch.Size([0, 2048])          133.297729           133.795261           553.391568           3065.129514         
model.layers.8.mlp.experts.6.gate_proj        torch.Size([0, 1408])          145.899292           146.402836           556.545816           3133.366922         
model.layers.8.mlp.experts.6.act_fn           torch.Size([0, 1408])          1.031104             1.923800             621.568000           3184.224000         
model.layers.8.mlp.experts.6.up_proj          torch.Size([0, 1408])          143.045914           143.733263           552.163413           3082.132053         
model.layers.8.mlp.experts.6.down_proj        torch.Size([0, 2048])          135.634369           136.135340           561.781622           3032.631351         
model.layers.8.mlp.experts.7.gate_proj        torch.Size([1, 1408])          140.265472           140.854120           591.757589           3094.384658         
model.layers.8.mlp.experts.7.act_fn           torch.Size([1, 1408])          0.647328             1.220942             621.363200           3417.216000         
model.layers.8.mlp.experts.7.up_proj          torch.Size([1, 1408])          135.246109           136.024237           621.566282           3183.003060         
model.layers.8.mlp.experts.7.down_proj        torch.Size([1, 2048])          137.389053           138.168573           621.504985           3296.538092         
model.layers.8.mlp.experts.8.gate_proj        torch.Size([1, 1408])          135.543655           136.227369           621.532903           3155.453935         
model.layers.8.mlp.experts.8.act_fn           torch.Size([1, 1408])          0.493312             0.959635             621.312000           3417.216000         
model.layers.8.mlp.experts.8.up_proj          torch.Size([1, 1408])          90.949791            91.477156            621.547683           3182.991238         
model.layers.8.mlp.experts.8.down_proj        torch.Size([1, 2048])          81.081406            81.667185            621.381246           3321.067541         
model.layers.8.mlp.experts.9.gate_proj        torch.Size([0, 1408])          85.545952            85.942745            621.284280           3783.914803         
model.layers.8.mlp.experts.9.act_fn           torch.Size([0, 1408])          0.593824             1.324177             621.568000           3417.216000         
model.layers.8.mlp.experts.9.up_proj          torch.Size([0, 1408])          90.806236            91.441154            559.071356           3153.092725         
model.layers.8.mlp.experts.9.down_proj        torch.Size([0, 2048])          86.291168            86.783409            585.737846           3088.634182         
model.layers.8.mlp.experts.10.gate_proj       torch.Size([0, 1408])          89.433792            89.987516            577.345272           3048.559894         
model.layers.8.mlp.experts.10.act_fn          torch.Size([0, 1408])          0.453216             1.041174             621.568000           3106.560000         
model.layers.8.mlp.experts.10.up_proj         torch.Size([0, 1408])          83.036514            83.549261            561.921855           3083.291826         
model.layers.8.mlp.experts.10.down_proj       torch.Size([0, 2048])          84.000702            84.600210            573.616000           3119.549176         
model.layers.8.mlp.experts.11.gate_proj       torch.Size([0, 1408])          99.832321            100.430727           586.195862           3166.962759         
model.layers.8.mlp.experts.11.act_fn          torch.Size([0, 1408])          1.327520             2.113342             621.568000           3417.216000         
model.layers.8.mlp.experts.11.up_proj         torch.Size([0, 1408])          88.726212            89.358091            551.590146           3224.296689         
model.layers.8.mlp.experts.11.down_proj       torch.Size([0, 2048])          82.827492            83.321333            564.769545           3182.058372         
model.layers.8.mlp.experts.12.gate_proj       torch.Size([0, 1408])          91.070465            91.540098            579.570162           3060.981622         
model.layers.8.mlp.experts.12.act_fn          torch.Size([0, 1408])          0.446176             1.066208             621.568000           3106.560000         
model.layers.8.mlp.experts.12.up_proj         torch.Size([0, 1408])          85.326782            85.772514            555.534270           3066.337297         
model.layers.8.mlp.experts.12.down_proj       torch.Size([0, 2048])          81.771362            82.419395            562.474667           3284.757333         
model.layers.8.mlp.experts.13.gate_proj       torch.Size([0, 1408])          91.776062            92.281342            507.538286           3582.667528         
model.layers.8.mlp.experts.13.act_fn          torch.Size([0, 1408])          0.635424             1.329184             543.696000           3533.712000         
model.layers.8.mlp.experts.13.up_proj         torch.Size([0, 1408])          92.025566            92.579603            532.725895           3107.297263         
model.layers.8.mlp.experts.13.down_proj       torch.Size([0, 2048])          84.576447            85.578442            583.015724           3038.843586         
model.layers.8.mlp.experts.14.gate_proj       torch.Size([1, 1408])          90.699394            91.578722            587.963924           3000.562548         
model.layers.8.mlp.experts.14.act_fn          torch.Size([1, 1408])          0.692768             1.502991             621.568000           3261.888000         
model.layers.8.mlp.experts.14.up_proj         torch.Size([1, 1408])          86.025536            86.786985            621.568000           3215.521433         
model.layers.8.mlp.experts.14.down_proj       torch.Size([1, 2048])          83.328445            84.048510            621.566305           3213.557828         
model.layers.8.mlp.experts.15.gate_proj       torch.Size([1, 1408])          91.817986            92.586517            621.562703           3090.768772         
model.layers.8.mlp.experts.15.act_fn          torch.Size([1, 1408])          0.586112             1.418114             621.568000           3261.888000         
model.layers.8.mlp.experts.15.up_proj         torch.Size([1, 1408])          83.473251            83.997250            621.568000           3129.675907         
model.layers.8.mlp.experts.15.down_proj       torch.Size([1, 2048])          81.424896            81.976891            621.568000           2987.832526         
model.layers.8.mlp.experts.16.gate_proj       torch.Size([0, 1408])          86.287231            86.953163            621.585323           3128.991278         
model.layers.8.mlp.experts.16.act_fn          torch.Size([0, 1408])          0.376768             0.830173             621.568000           3261.888000         
model.layers.8.mlp.experts.16.up_proj         torch.Size([0, 1408])          89.384003            89.792490            621.556451           3217.778526         
model.layers.8.mlp.experts.16.down_proj       torch.Size([0, 2048])          86.011169            86.391449            568.176716           3216.927522         
model.layers.8.mlp.experts.17.gate_proj       torch.Size([1, 1408])          87.268448            87.959766            563.365012           3587.762892         
model.layers.8.mlp.experts.17.act_fn          torch.Size([1, 1408])          0.524288             0.987291             621.312000           3726.336000         
model.layers.8.mlp.experts.17.up_proj         torch.Size([1, 1408])          85.296608            85.760355            621.528747           3333.227947         
model.layers.8.mlp.experts.17.down_proj       torch.Size([1, 2048])          90.065758            90.761423            621.527040           3150.350080         
model.layers.8.mlp.experts.18.gate_proj       torch.Size([2, 1408])          88.764610            89.675188            621.510531           3220.752980         
model.layers.8.mlp.experts.18.act_fn          torch.Size([2, 1408])          0.660576             1.413345             621.312000           3417.216000         
model.layers.8.mlp.experts.18.up_proj         torch.Size([2, 1408])          84.319679            85.155964            621.549595           3201.217673         
model.layers.8.mlp.experts.18.down_proj       torch.Size([2, 2048])          87.767326            88.874817            637.039754           3125.677292         
model.layers.8.mlp.experts.19.gate_proj       torch.Size([0, 1408])          83.403038            83.899021            622.665986           3067.444652         
model.layers.8.mlp.experts.19.act_fn          torch.Size([0, 1408])          0.005632             1.214266             621.568000           3261.888000         
model.layers.8.mlp.experts.19.up_proj         torch.Size([0, 1408])          77.549057            77.967405            589.384312           3075.954286         
model.layers.8.mlp.experts.19.down_proj       torch.Size([0, 2048])          85.730370            86.137533            570.827755           3184.346558         
model.layers.8.mlp.experts.20.gate_proj       torch.Size([0, 1408])          90.906845            91.505051            565.459556           3178.584889         
model.layers.8.mlp.experts.20.act_fn          torch.Size([0, 1408])          0.630368             1.406670             621.568000           3261.888000         
model.layers.8.mlp.experts.20.up_proj         torch.Size([0, 1408])          86.373726            87.039709            546.564354           3037.700354         
model.layers.8.mlp.experts.20.down_proj       torch.Size([0, 2048])          86.151939            86.828470            575.363459           3066.156541         
model.layers.8.mlp.experts.21.gate_proj       torch.Size([0, 1408])          94.074814            94.758987            519.686857           3515.758476         
model.layers.8.mlp.experts.21.act_fn          torch.Size([0, 1408])          0.407584             0.926733             621.312000           4088.618667         
model.layers.8.mlp.experts.21.up_proj         torch.Size([0, 1408])          91.260643            91.728926            544.851111           3541.774667         
model.layers.8.mlp.experts.21.down_proj       torch.Size([0, 2048])          83.337761            84.187269            566.464454           3252.109617         
model.layers.8.mlp.experts.22.gate_proj       torch.Size([0, 1408])          87.714211            88.491201            567.612444           3164.860444         
model.layers.8.mlp.experts.22.act_fn          torch.Size([0, 1408])          0.581632             1.289368             621.568000           3106.560000         
model.layers.8.mlp.experts.22.up_proj         torch.Size([0, 1408])          91.061501            91.623545            552.751543           3156.936229         
model.layers.8.mlp.experts.22.down_proj       torch.Size([0, 2048])          84.577057            85.178137            558.216000           2986.142316         
model.layers.8.mlp.experts.23.gate_proj       torch.Size([1, 1408])          82.976738            83.457470            588.771155           3106.983211         
model.layers.8.mlp.experts.23.act_fn          torch.Size([1, 1408])          0.429088             0.852108             621.568000           3106.560000         
model.layers.8.mlp.experts.23.up_proj         torch.Size([1, 1408])          80.147873            80.686808            621.564493           3192.988493         
model.layers.8.mlp.experts.23.down_proj       torch.Size([1, 2048])          82.342140            82.890749            621.568000           3117.705915         
model.layers.8.mlp.experts.24.gate_proj       torch.Size([0, 1408])          85.440002            85.920572            621.568000           3091.699117         
model.layers.8.mlp.experts.24.act_fn          torch.Size([0, 1408])          0.005472             1.295090             621.568000           3106.560000         
model.layers.8.mlp.experts.24.up_proj         torch.Size([0, 1408])          92.880768            93.436956            575.510069           3084.544000         
model.layers.8.mlp.experts.24.down_proj       torch.Size([0, 2048])          83.646049            84.026814            592.658286           3195.607314         
model.layers.8.mlp.experts.25.gate_proj       torch.Size([1, 1408])          85.410530            85.892677            562.053430           3614.032679         
model.layers.8.mlp.experts.25.act_fn          torch.Size([1, 1408])          0.410272             0.836372             621.056000           4345.600000         
model.layers.8.mlp.experts.25.up_proj         torch.Size([1, 1408])          82.852158            83.455801            621.399230           3607.638281         
model.layers.8.mlp.experts.25.down_proj       torch.Size([1, 2048])          82.722435            83.459139            621.576258           3072.985187         
model.layers.8.mlp.experts.26.gate_proj       torch.Size([0, 1408])          91.707809            92.314959            621.690880           2948.873387         
model.layers.8.mlp.experts.26.act_fn          torch.Size([0, 1408])          0.635776             1.405478             621.568000           3106.560000         
model.layers.8.mlp.experts.26.up_proj         torch.Size([0, 1408])          81.094749            81.884861            580.297846           3094.199049         
model.layers.8.mlp.experts.26.down_proj       torch.Size([0, 2048])          76.532448            77.062368            574.650105           3120.716632         
model.layers.8.mlp.experts.27.gate_proj       torch.Size([1, 1408])          83.387360            83.976984            595.873260           3214.188850         
model.layers.8.mlp.experts.27.act_fn          torch.Size([1, 1408])          0.473376             1.005650             621.568000           3261.888000         
model.layers.8.mlp.experts.27.up_proj         torch.Size([1, 1408])          84.134529            84.823608            621.587692           3095.259897         
model.layers.8.mlp.experts.27.down_proj       torch.Size([1, 2048])          86.895233            87.621927            621.553678           3077.517874         
model.layers.8.mlp.experts.28.gate_proj       torch.Size([1, 1408])          93.024284            93.637705            621.563624           3134.439385         
model.layers.8.mlp.experts.28.act_fn          torch.Size([1, 1408])          0.607264             1.203299             621.568000           3145.392000         
model.layers.8.mlp.experts.28.up_proj         torch.Size([1, 1408])          86.019203            86.569548            621.510000           3281.304000         
model.layers.8.mlp.experts.28.down_proj       torch.Size([1, 2048])          81.508865            82.206964            621.454689           3285.577967         
model.layers.8.mlp.experts.29.gate_proj       torch.Size([0, 1408])          90.017853            90.662479            621.491363           3386.410395         
model.layers.8.mlp.experts.29.act_fn          torch.Size([0, 1408])          0.315104             0.705719             621.312000           4036.864000         
model.layers.8.mlp.experts.29.up_proj         torch.Size([0, 1408])          84.590622            84.985733            580.223152           3758.968371         
model.layers.8.mlp.experts.29.down_proj       torch.Size([0, 2048])          84.435585            84.961653            573.681096           3147.192986         
model.layers.8.mlp.experts.30.gate_proj       torch.Size([0, 1408])          89.035484            89.458466            585.488225           3142.020056         
model.layers.8.mlp.experts.30.act_fn          torch.Size([0, 1408])          0.520608             1.119137             621.568000           3261.888000         
model.layers.8.mlp.experts.30.up_proj         torch.Size([0, 1408])          86.458305            86.973906            570.890440           3222.605617         
model.layers.8.mlp.experts.30.down_proj       torch.Size([0, 2048])          80.795296            81.366539            577.324444           3215.893778         
model.layers.8.mlp.experts.31.gate_proj       torch.Size([0, 1408])          87.571388            88.067055            588.115556           3132.934222         
model.layers.8.mlp.experts.31.act_fn          torch.Size([0, 1408])          0.419648             0.927448             621.568000           3106.560000         
model.layers.8.mlp.experts.31.up_proj         torch.Size([0, 1408])          81.981537            82.466364            560.331320           3052.320653         
model.layers.8.mlp.experts.31.down_proj       torch.Size([0, 2048])          91.199646            91.705322            613.381818           3039.074909         
model.layers.8.mlp.experts.32.gate_proj       torch.Size([0, 1408])          89.713600            90.490818            573.200954           3169.620344         
model.layers.8.mlp.experts.32.act_fn          torch.Size([0, 1408])          0.862752             1.689434             621.568000           3417.216000         
model.layers.8.mlp.experts.32.up_proj         torch.Size([0, 1408])          85.812798            86.395025            557.296552           3151.397959         
model.layers.8.mlp.experts.32.down_proj       torch.Size([0, 2048])          83.927711            84.563494            571.905707           3037.120853         
model.layers.8.mlp.experts.33.gate_proj       torch.Size([0, 1408])          86.865059            87.561846            583.769946           3209.412324         
model.layers.8.mlp.experts.33.act_fn          torch.Size([0, 1408])          0.474720             1.057625             621.397333           3417.216000         
model.layers.8.mlp.experts.33.up_proj         torch.Size([0, 1408])          82.527519            83.045959            528.544831           3711.815896         
model.layers.8.mlp.experts.33.down_proj       torch.Size([0, 2048])          82.261375            82.683802            592.255038           3452.171549         
model.layers.8.mlp.experts.34.gate_proj       torch.Size([1, 1408])          88.934753            90.637922            603.199556           3234.062222         
model.layers.8.mlp.experts.34.act_fn          torch.Size([1, 1408])          0.479392             0.949383             621.568000           3261.888000         
model.layers.8.mlp.experts.34.up_proj         torch.Size([1, 1408])          81.103905            81.607103            621.568000           3236.624109         
model.layers.8.mlp.experts.34.down_proj       torch.Size([1, 2048])          77.239777            77.677727            621.568000           3124.429191         
model.layers.8.mlp.experts.35.gate_proj       torch.Size([0, 1408])          85.055840            85.531950            621.588555           3051.402277         
model.layers.8.mlp.experts.35.act_fn          torch.Size([0, 1408])          0.594816             1.364231             621.568000           3106.560000         
model.layers.8.mlp.experts.35.up_proj         torch.Size([0, 1408])          91.280579            91.873169            621.568000           3171.777842         
model.layers.8.mlp.experts.35.down_proj       torch.Size([0, 2048])          80.331329            81.066370            590.243914           3202.040173         
model.layers.8.mlp.experts.36.gate_proj       torch.Size([0, 1408])          92.128990            92.586756            572.805856           3243.008837         
model.layers.8.mlp.experts.36.act_fn          torch.Size([0, 1408])          0.430240             0.891209             621.568000           3261.888000         
model.layers.8.mlp.experts.36.up_proj         torch.Size([0, 1408])          91.378014            91.782570            564.598331           3116.177957         
model.layers.8.mlp.experts.36.down_proj       torch.Size([0, 2048])          88.235268            88.956118            594.594222           3032.979556         
model.layers.8.mlp.experts.37.gate_proj       torch.Size([0, 1408])          88.765312            89.378357            581.498066           3064.203020         
model.layers.8.mlp.experts.37.act_fn          torch.Size([0, 1408])          0.611008             1.484156             621.397333           3572.544000         
model.layers.8.mlp.experts.37.up_proj         torch.Size([0, 1408])          94.452225            94.971895            518.512400           3579.982000         
model.layers.8.mlp.experts.37.down_proj       torch.Size([0, 2048])          92.605728            93.227148            543.763892           3726.150919         
model.layers.8.mlp.experts.38.gate_proj       torch.Size([0, 1408])          90.841408            91.284275            573.134130           3171.516260         
model.layers.8.mlp.experts.38.act_fn          torch.Size([0, 1408])          0.327264             0.749350             621.568000           3417.216000         
model.layers.8.mlp.experts.38.up_proj         torch.Size([0, 1408])          85.688126            86.128950            540.887385           3099.422769         
model.layers.8.mlp.experts.38.down_proj       torch.Size([0, 2048])          89.807327            90.253115            579.188364           3167.430266         
model.layers.8.mlp.experts.39.gate_proj       torch.Size([0, 1408])          91.185440            91.822147            571.544548           3220.396274         
model.layers.8.mlp.experts.39.act_fn          torch.Size([0, 1408])          0.453248             0.882864             621.568000           3106.560000         
model.layers.8.mlp.experts.39.up_proj         torch.Size([0, 1408])          80.695457            81.085920            567.654748           3275.058503         
model.layers.8.mlp.experts.39.down_proj       torch.Size([0, 2048])          87.391266            87.865114            548.866723           3104.070355         
model.layers.8.mlp.experts.40.gate_proj       torch.Size([0, 1408])          90.218781            90.715408            573.291243           3081.949405         
model.layers.8.mlp.experts.40.act_fn          torch.Size([0, 1408])          0.527936             1.157284             621.568000           3107.840000         
model.layers.8.mlp.experts.40.up_proj         torch.Size([0, 1408])          83.959869            84.576130            567.310904           3072.968767         
model.layers.8.mlp.experts.40.down_proj       torch.Size([0, 2048])          86.429764            87.007761            568.305985           3104.805372         
model.layers.8.mlp.experts.41.gate_proj       torch.Size([2, 1408])          89.267166            90.064049            593.768229           3196.806400         
model.layers.8.mlp.experts.41.act_fn          torch.Size([2, 1408])          0.696288             1.441002             621.312000           3571.072000         
model.layers.8.mlp.experts.41.up_proj         torch.Size([2, 1408])          90.153954            90.728760            612.689093           3587.302559         
model.layers.8.mlp.experts.41.down_proj       torch.Size([2, 2048])          77.498398            78.110933            616.508820           3618.280547         
model.layers.8.mlp.experts.42.gate_proj       torch.Size([0, 1408])          90.723839            91.256380            621.568000           3134.279452         
model.layers.8.mlp.experts.42.act_fn          torch.Size([0, 1408])          0.357792             0.743389             621.568000           3106.560000         
model.layers.8.mlp.experts.42.up_proj         torch.Size([0, 1408])          94.902206            95.256329            577.537362           3153.322667         
model.layers.8.mlp.experts.42.down_proj       torch.Size([0, 2048])          84.183556            84.835291            580.837517           3132.792055         
model.layers.8.mlp.experts.43.gate_proj       torch.Size([1, 1408])          94.057922            94.848156            589.265455           3209.012779         
model.layers.8.mlp.experts.43.act_fn          torch.Size([1, 1408])          0.706752             1.566410             621.568000           3106.560000         
model.layers.8.mlp.experts.43.up_proj         torch.Size([1, 1408])          87.616508            88.219881            621.568000           3092.277647         
model.layers.8.mlp.experts.43.down_proj       torch.Size([1, 2048])          87.779388            88.317633            621.568000           3043.926588         
model.layers.8.mlp.experts.44.gate_proj       torch.Size([0, 1408])          88.002144            88.600874            621.614362           2989.891528         
model.layers.8.mlp.experts.44.act_fn          torch.Size([0, 1408])          0.651008             1.427889             621.568000           3417.216000         
model.layers.8.mlp.experts.44.up_proj         torch.Size([0, 1408])          87.568222            88.526964            621.568000           3243.389033         
model.layers.8.mlp.experts.44.down_proj       torch.Size([0, 2048])          84.000511            84.627390            604.421297           3250.104497         
model.layers.8.mlp.experts.45.gate_proj       torch.Size([0, 1408])          87.447006            88.071108            589.638137           3210.821260         
model.layers.8.mlp.experts.45.act_fn          torch.Size([0, 1408])          0.318720             0.730753             621.568000           3261.888000         
model.layers.8.mlp.experts.45.up_proj         torch.Size([0, 1408])          87.638527            88.120699            545.279205           3346.796124         
model.layers.8.mlp.experts.45.down_proj       torch.Size([0, 2048])          75.279518            76.613903            535.213268           3657.075902         
model.layers.8.mlp.experts.46.gate_proj       torch.Size([0, 1408])          135.618591           136.194706           579.852027           3305.714685         
model.layers.8.mlp.experts.46.act_fn          torch.Size([0, 1408])          0.005536             1.296282             621.568000           3106.560000         
model.layers.8.mlp.experts.46.up_proj         torch.Size([0, 1408])          153.531097           154.172182           556.317440           3243.618987         
model.layers.8.mlp.experts.46.down_proj       torch.Size([0, 2048])          151.602951           152.073622           581.954577           3140.273826         
model.layers.8.mlp.experts.47.gate_proj       torch.Size([0, 1408])          161.014557           161.538363           585.733818           3105.896727         
model.layers.8.mlp.experts.47.act_fn          torch.Size([0, 1408])          0.414144             0.833273             621.568000           3106.560000         
model.layers.8.mlp.experts.47.up_proj         torch.Size([0, 1408])          142.200607           142.607212           571.559517           3065.393826         
model.layers.8.mlp.experts.47.down_proj       torch.Size([0, 2048])          157.044067           157.719851           606.420140           3146.219413         
model.layers.8.mlp.experts.48.gate_proj       torch.Size([0, 1408])          162.754562           163.868189           561.320000           3231.851368         
model.layers.8.mlp.experts.48.act_fn          torch.Size([0, 1408])          0.658560             1.517773             621.568000           3417.216000         
model.layers.8.mlp.experts.48.up_proj         torch.Size([0, 1408])          144.150940           144.751787           557.339307           3223.042560         
model.layers.8.mlp.experts.48.down_proj       torch.Size([0, 2048])          135.071838           135.523319           572.317838           3042.176432         
model.layers.8.mlp.experts.49.gate_proj       torch.Size([0, 1408])          156.889114           157.390594           594.034411           2933.946301         
model.layers.8.mlp.experts.49.act_fn          torch.Size([0, 1408])          0.828160             1.881599             621.568000           3106.560000         
model.layers.8.mlp.experts.49.up_proj         torch.Size([0, 1408])          155.109436           155.810595           549.288000           3132.009778         
model.layers.8.mlp.experts.49.down_proj       torch.Size([0, 2048])          150.510788           151.380062           520.459414           3813.949962         
model.layers.8.mlp.experts.50.gate_proj       torch.Size([0, 1408])          135.814880           136.230946           581.568444           3510.717333         
model.layers.8.mlp.experts.50.act_fn          torch.Size([0, 1408])          0.818368             1.436710             621.568000           3417.216000         
model.layers.8.mlp.experts.50.up_proj         torch.Size([0, 1408])          126.814339           127.351046           554.877852           3145.979705         
model.layers.8.mlp.experts.50.down_proj       torch.Size([0, 2048])          148.142212           148.778677           595.118298           3088.703092         
model.layers.8.mlp.experts.51.gate_proj       torch.Size([1, 1408])          147.117538           147.826672           596.010105           3135.252632         
model.layers.8.mlp.experts.51.act_fn          torch.Size([1, 1408])          0.051072             1.611948             621.568000           3106.560000         
model.layers.8.mlp.experts.51.up_proj         torch.Size([1, 1408])          140.722687           142.085552           621.561081           3185.273514         
model.layers.8.mlp.experts.51.down_proj       torch.Size([1, 2048])          127.858688           129.703522           621.568000           3203.765265         
model.layers.8.mlp.experts.52.gate_proj       torch.Size([1, 1408])          152.296249           154.212952           621.568000           3176.048842         
model.layers.8.mlp.experts.52.act_fn          torch.Size([1, 1408])          0.055872             1.329422             621.568000           3106.560000         
model.layers.8.mlp.experts.52.up_proj         torch.Size([1, 1408])          132.446854           133.812904           621.594122           3076.179592         
model.layers.8.mlp.experts.52.down_proj       torch.Size([1, 2048])          80.686493            82.577705            621.572063           3098.197333         
model.layers.8.mlp.experts.53.gate_proj       torch.Size([0, 1408])          89.351555            90.695381            621.509246           3208.613770         
model.layers.8.mlp.experts.53.act_fn          torch.Size([0, 1408])          0.005728             1.396656             621.568000           3300.720000         
model.layers.8.mlp.experts.53.up_proj         torch.Size([0, 1408])          93.820702            95.398426            621.520658           3250.619616         
model.layers.8.mlp.experts.53.down_proj       torch.Size([0, 2048])          87.583778            89.139938            533.176195           3979.261268         
model.layers.8.mlp.experts.54.gate_proj       torch.Size([0, 1408])          86.520477            88.009357            563.651531           3558.320552         
model.layers.8.mlp.experts.54.act_fn          torch.Size([0, 1408])          0.644320             1.487017             621.568000           3261.888000         
model.layers.8.mlp.experts.54.up_proj         torch.Size([0, 1408])          86.422562            87.023020            575.928392           3230.880224         
model.layers.8.mlp.experts.54.down_proj       torch.Size([0, 2048])          89.165215            89.818478            581.916248           3172.447338         
model.layers.8.mlp.experts.55.gate_proj       torch.Size([0, 1408])          91.150978            91.766834            571.801935           3207.738980         
model.layers.8.mlp.experts.55.act_fn          torch.Size([0, 1408])          0.638624             1.436472             621.568000           3468.992000         
model.layers.8.mlp.experts.55.up_proj         torch.Size([0, 1408])          83.965347            84.795237            560.715189           3272.202294         
model.layers.8.mlp.experts.55.down_proj       torch.Size([0, 2048])          81.170433            81.824780            582.817333           3059.997778         
model.layers.8.mlp.experts.56.gate_proj       torch.Size([0, 1408])          81.868225            82.341671            570.971307           3008.186453         
model.layers.8.mlp.experts.56.act_fn          torch.Size([0, 1408])          0.369568             0.756264             621.568000           3261.888000         
model.layers.8.mlp.experts.56.up_proj         torch.Size([0, 1408])          77.734848            78.165531            568.063559           3039.078841         
model.layers.8.mlp.experts.56.down_proj       torch.Size([0, 2048])          84.349182            85.618496            563.435741           3175.032633         
model.layers.8.mlp.experts.57.gate_proj       torch.Size([0, 1408])          88.915489            89.451075            584.359662           3320.956394         
model.layers.8.mlp.experts.57.act_fn          torch.Size([0, 1408])          0.351264             0.750065             621.568000           3106.560000         
model.layers.8.mlp.experts.57.up_proj         torch.Size([0, 1408])          85.412254            85.801601            564.769545           3253.318179         
model.layers.8.mlp.experts.57.down_proj       torch.Size([0, 2048])          81.726013            82.404613            532.694857           3432.117610         
model.layers.8.mlp.experts.58.gate_proj       torch.Size([1, 1408])          91.917091            92.582464            568.018454           3690.701350         
model.layers.8.mlp.experts.58.act_fn          torch.Size([1, 1408])          0.478080             1.331091             621.568000           3137.625600         
model.layers.8.mlp.experts.58.up_proj         torch.Size([1, 1408])          86.351234            86.850166            621.516058           3353.058783         
model.layers.8.mlp.experts.58.down_proj       torch.Size([1, 2048])          82.063713            82.735062            621.524385           3229.854341         
model.layers.8.mlp.experts.59.gate_proj       torch.Size([1, 1408])          97.614525            98.429441            621.568000           3169.039579         
model.layers.8.mlp.experts.59.act_fn          torch.Size([1, 1408])          0.636352             1.403570             621.568000           3106.560000         
model.layers.8.mlp.experts.59.up_proj         torch.Size([1, 1408])          84.133507            84.782839            621.585297           3118.337297         
model.layers.8.mlp.experts.59.down_proj       torch.Size([1, 2048])          92.307037            92.757702            621.568000           3113.159405         
model.layers.8.mlp.shared_expert.gate_proj    torch.Size([5, 5632])          334.095490           334.606171           694.471059           3194.002667         
model.layers.8.mlp.shared_expert.act_fn       torch.Size([5, 5632])          0.605792             1.080036             776.640000           3415.808000         
model.layers.8.mlp.shared_expert.up_proj      torch.Size([5, 5632])          323.698151           324.155331           704.486062           3176.547607         
model.layers.8.mlp.shared_expert.down_proj    torch.Size([5, 2048])          315.445282           316.009045           635.101366           3251.867259         
model.layers.8.mlp.shared_expert_gate         torch.Size([5, 1])             10.142208            10.675907            645.504000           3464.816356         
model.layers.9.input_layernorm                torch.Size([1, 5, 2048])       13.752512            14.371872            528.398080           3194.429440         
model.layers.9.self_attn.q_proj               torch.Size([1, 5, 2048])       126.915649           127.578974           578.621427           3149.997668         
model.layers.9.self_attn.k_proj               torch.Size([1, 5, 2048])       136.077179           136.828661           621.571640           3093.632303         
model.layers.9.self_attn.v_proj               torch.Size([1, 5, 2048])       126.667328           127.475023           621.533034           3283.103532         
model.layers.9.self_attn.o_proj               torch.Size([1, 5, 2048])       118.653442           119.439125           621.578299           3083.608644         
model.layers.9.post_attention_layernorm       torch.Size([1, 5, 2048])       16.466528            17.236710            601.550452           3087.130839         
model.layers.9.mlp.gate                       torch.Size([5, 60])            16.140768            16.790390            466.312615           3024.167385         
model.layers.9.mlp.experts.0.gate_proj        torch.Size([0, 1408])          88.224129            88.703871            569.842992           3170.293593         
model.layers.9.mlp.experts.0.act_fn           torch.Size([0, 1408])          0.503072             1.217127             621.568000           3417.216000         
model.layers.9.mlp.experts.0.up_proj          torch.Size([0, 1408])          89.330177            89.845657            621.450847           3383.906169         
model.layers.9.mlp.experts.0.down_proj        torch.Size([0, 2048])          86.047523            86.523771            576.659242           3725.900549         
model.layers.9.mlp.experts.1.gate_proj        torch.Size([0, 1408])          86.944611            87.625742            596.837959           3514.431559         
model.layers.9.mlp.experts.1.act_fn           torch.Size([0, 1408])          0.451808             0.941038             621.568000           3261.888000         
model.layers.9.mlp.experts.1.up_proj          torch.Size([0, 1408])          79.237724            79.789877            568.321790           3181.594853         
model.layers.9.mlp.experts.1.down_proj        torch.Size([0, 2048])          78.149376            78.535318            614.800696           3116.187826         
model.layers.9.mlp.experts.2.gate_proj        torch.Size([0, 1408])          91.129341            91.693401            567.651265           3263.008653         
model.layers.9.mlp.experts.2.act_fn           torch.Size([0, 1408])          0.647968             1.442671             621.568000           3417.216000         
model.layers.9.mlp.experts.2.up_proj          torch.Size([0, 1408])          83.430496            84.066629            562.771027           3320.660757         
model.layers.9.mlp.experts.2.down_proj        torch.Size([0, 2048])          91.832703            92.226267            544.367702           3097.700174         
model.layers.9.mlp.experts.3.gate_proj        torch.Size([1, 1408])          88.696480            89.377403            584.040993           3019.136418         
model.layers.9.mlp.experts.3.act_fn           torch.Size([1, 1408])          0.614528             1.344919             621.568000           3417.216000         
model.layers.9.mlp.experts.3.up_proj          torch.Size([1, 1408])          81.574303            82.381010            621.568000           3062.572408         
model.layers.9.mlp.experts.3.down_proj        torch.Size([1, 2048])          84.085793            85.044861            621.568000           3167.816113         
model.layers.9.mlp.experts.4.gate_proj        torch.Size([0, 1408])          87.849922            88.604689            621.560986           3246.993534         
model.layers.9.mlp.experts.4.act_fn           torch.Size([0, 1408])          0.571200             1.206160             621.568000           3106.560000         
model.layers.9.mlp.experts.4.up_proj          torch.Size([0, 1408])          83.737251            84.424496            553.954687           3260.702290         
model.layers.9.mlp.experts.4.down_proj        torch.Size([0, 2048])          89.007683            89.680672            516.572000           3460.342400         
model.layers.9.mlp.experts.5.gate_proj        torch.Size([0, 1408])          88.082748            88.533401            542.699947           3665.986987         
model.layers.9.mlp.experts.5.act_fn           torch.Size([0, 1408])          0.428256             0.875950             621.568000           3210.112000         
model.layers.9.mlp.experts.5.up_proj          torch.Size([0, 1408])          80.677185            81.099987            549.339493           3328.613408         
model.layers.9.mlp.experts.5.down_proj        torch.Size([0, 2048])          82.156609            82.665920            577.188571           3208.241633         
model.layers.9.mlp.experts.6.gate_proj        torch.Size([1, 1408])          91.441826            92.106342            612.427294           3166.086118         
model.layers.9.mlp.experts.6.act_fn           torch.Size([1, 1408])          0.475072             0.877380             621.568000           3106.560000         
model.layers.9.mlp.experts.6.up_proj          torch.Size([1, 1408])          83.929886            84.520817            621.568000           3090.470937         
model.layers.9.mlp.experts.6.down_proj        torch.Size([1, 2048])          86.087807            86.786747            621.568000           3081.231781         
model.layers.9.mlp.experts.7.gate_proj        torch.Size([1, 1408])          89.097374            89.604616            621.498182           3150.245818         
model.layers.9.mlp.experts.7.act_fn           torch.Size([1, 1408])          0.421408             0.910759             621.568000           3261.888000         
model.layers.9.mlp.experts.7.up_proj          torch.Size([1, 1408])          87.038177            87.702990            621.511716           3260.755064         
model.layers.9.mlp.experts.7.down_proj        torch.Size([1, 2048])          87.290077            87.963820            621.555973           3126.604886         
model.layers.9.mlp.experts.8.gate_proj        torch.Size([0, 1408])          92.486755            93.276501            621.568000           3108.110521         
model.layers.9.mlp.experts.8.act_fn           torch.Size([0, 1408])          0.571680             1.303673             621.568000           3261.888000         
model.layers.9.mlp.experts.8.up_proj          torch.Size([0, 1408])          85.722687            86.459160            621.669295           3106.152058         
model.layers.9.mlp.experts.8.down_proj        torch.Size([0, 2048])          83.915039            84.376812            513.980049           3577.736296         
model.layers.9.mlp.experts.9.gate_proj        torch.Size([1, 1408])          92.118912            92.697382            548.810225           3693.146509         
model.layers.9.mlp.experts.9.act_fn           torch.Size([1, 1408])          0.412864             0.786066             621.312000           3572.544000         
model.layers.9.mlp.experts.9.up_proj          torch.Size([1, 1408])          79.236290            79.819441            621.471193           3302.351597         
model.layers.9.mlp.experts.9.down_proj        torch.Size([1, 2048])          82.978813            83.681583            621.530870           3104.544733         
model.layers.9.mlp.experts.10.gate_proj       torch.Size([1, 1408])          89.555038            90.192080            621.549714           3136.197079         
model.layers.9.mlp.experts.10.act_fn          torch.Size([1, 1408])          0.447040             0.855207             621.465600           3417.216000         
model.layers.9.mlp.experts.10.up_proj         torch.Size([1, 1408])          82.664963            83.246231            621.557760           3178.632192         
model.layers.9.mlp.experts.10.down_proj       torch.Size([1, 2048])          82.619072            83.318233            621.414400           3317.328000         
model.layers.9.mlp.experts.11.gate_proj       torch.Size([0, 1408])          84.678078            85.226536            621.501630           3252.650667         
model.layers.9.mlp.experts.11.act_fn          torch.Size([0, 1408])          0.433184             1.002073             621.568000           3261.888000         
model.layers.9.mlp.experts.11.up_proj         torch.Size([0, 1408])          86.476578            86.935997            617.159716           3176.109844         
model.layers.9.mlp.experts.11.down_proj       torch.Size([0, 2048])          87.626595            88.371992            579.284463           3090.061061         
model.layers.9.mlp.experts.12.gate_proj       torch.Size([0, 1408])          91.512321            92.172861            562.440272           2996.122122         
model.layers.9.mlp.experts.12.act_fn          torch.Size([0, 1408])          0.677056             1.464367             621.568000           3106.560000         
model.layers.9.mlp.experts.12.up_proj         torch.Size([0, 1408])          104.402336           105.010986           562.394558           3140.911456         
model.layers.9.mlp.experts.12.down_proj       torch.Size([0, 2048])          84.417633            85.004091            563.341061           3344.037442         
model.layers.9.mlp.experts.13.gate_proj       torch.Size([0, 1408])          88.185600            88.649511            490.032762           3907.924190         
model.layers.9.mlp.experts.13.act_fn          torch.Size([0, 1408])          0.699872             1.324654             569.770667           3520.768000         
model.layers.9.mlp.experts.13.up_proj         torch.Size([0, 1408])          88.775070            89.396954            545.525106           3229.111830         
model.layers.9.mlp.experts.13.down_proj       torch.Size([0, 2048])          89.630463            90.233803            551.693139           3040.459444         
model.layers.9.mlp.experts.14.gate_proj       torch.Size([0, 1408])          91.294884            91.737747            567.971453           3057.163511         
model.layers.9.mlp.experts.14.act_fn          torch.Size([0, 1408])          0.492032             1.100779             621.397333           3572.544000         
model.layers.9.mlp.experts.14.up_proj         torch.Size([0, 1408])          93.423424            93.891144            539.464686           3183.850971         
model.layers.9.mlp.experts.14.down_proj       torch.Size([0, 2048])          88.266113            88.687658            553.779544           3200.719034         
model.layers.9.mlp.experts.15.gate_proj       torch.Size([0, 1408])          89.868034            90.553761            564.625067           3059.938133         
model.layers.9.mlp.experts.15.act_fn          torch.Size([0, 1408])          0.640832             1.437426             621.568000           3261.888000         
model.layers.9.mlp.experts.15.up_proj         torch.Size([0, 1408])          87.794205            88.328362            523.787221           2954.318545         
model.layers.9.mlp.experts.15.down_proj       torch.Size([0, 2048])          88.904671            89.593649            561.760405           2963.148152         
model.layers.9.mlp.experts.16.gate_proj       torch.Size([1, 1408])          87.697731            89.465857            586.049829           3142.332800         
model.layers.9.mlp.experts.16.act_fn          torch.Size([1, 1408])          0.056064             1.381159             621.568000           3106.560000         
model.layers.9.mlp.experts.16.up_proj         torch.Size([1, 1408])          79.563553            80.898046            621.562592           3271.732732         
model.layers.9.mlp.experts.16.down_proj       torch.Size([1, 2048])          78.141632            80.188274            621.401212           3353.317333         
model.layers.9.mlp.experts.17.gate_proj       torch.Size([0, 1408])          90.566559            92.211008            621.305173           3782.545067         
model.layers.9.mlp.experts.17.act_fn          torch.Size([0, 1408])          0.005760             1.210690             621.397333           3572.544000         
model.layers.9.mlp.experts.17.up_proj         torch.Size([0, 1408])          87.130592            88.481665            585.549987           3280.522596         
model.layers.9.mlp.experts.17.down_proj       torch.Size([0, 2048])          82.908417            84.252596            545.043942           3137.460406         
model.layers.9.mlp.experts.18.gate_proj       torch.Size([0, 1408])          98.746559            100.524902           557.996242           3198.719570         
model.layers.9.mlp.experts.18.act_fn          torch.Size([0, 1408])          0.005728             1.243114             621.568000           3261.888000         
model.layers.9.mlp.experts.18.up_proj         torch.Size([0, 1408])          87.135971            88.509083            527.193924           3136.486481         
model.layers.9.mlp.experts.18.down_proj       torch.Size([0, 2048])          92.175423            93.542814            527.878038           2946.256503         
model.layers.9.mlp.experts.19.gate_proj       torch.Size([1, 1408])          110.398430           112.145424           575.357033           2929.174887         
model.layers.9.mlp.experts.19.act_fn          torch.Size([1, 1408])          0.051008             1.525164             621.568000           3106.560000         
model.layers.9.mlp.experts.19.up_proj         torch.Size([1, 1408])          96.243874            97.879648            621.663086           3052.791314         
model.layers.9.mlp.experts.19.down_proj       torch.Size([1, 2048])          102.477760           103.049040           621.544107           3153.515093         
model.layers.9.mlp.experts.20.gate_proj       torch.Size([0, 1408])          93.664894            94.336987            621.568000           3157.775158         
model.layers.9.mlp.experts.20.act_fn          torch.Size([0, 1408])          0.348224             0.728607             621.568000           3261.888000         
model.layers.9.mlp.experts.20.up_proj         torch.Size([0, 1408])          81.767426            82.159042            550.932745           3082.580745         
model.layers.9.mlp.experts.20.down_proj       torch.Size([0, 2048])          88.463394            88.869572            563.717297           3144.744607         
model.layers.9.mlp.experts.21.gate_proj       torch.Size([0, 1408])          92.785187            93.348265            500.960582           3589.418667         
model.layers.9.mlp.experts.21.act_fn          torch.Size([0, 1408])          0.446432             0.900745             569.536000           3727.872000         
model.layers.9.mlp.experts.21.up_proj         torch.Size([0, 1408])          85.517281            85.915089            528.415147           3272.876373         
model.layers.9.mlp.experts.21.down_proj       torch.Size([0, 2048])          86.852737            87.710142            551.696106           3134.001166         
model.layers.9.mlp.experts.22.gate_proj       torch.Size([1, 1408])          93.304733            94.188929            573.667789           2952.179789         
model.layers.9.mlp.experts.22.act_fn          torch.Size([1, 1408])          0.758624             1.559019             621.568000           3106.560000         
model.layers.9.mlp.experts.22.up_proj         torch.Size([1, 1408])          87.944290            88.579893            621.628852           3047.429246         
model.layers.9.mlp.experts.22.down_proj       torch.Size([1, 2048])          83.613441            84.355116            621.568000           3043.393477         
model.layers.9.mlp.experts.23.gate_proj       torch.Size([1, 1408])          96.962944            97.637415            621.568000           3266.858496         
model.layers.9.mlp.experts.23.act_fn          torch.Size([1, 1408])          0.664832             1.157999             621.568000           3261.888000         
model.layers.9.mlp.experts.23.up_proj         torch.Size([1, 1408])          84.998657            85.578680            621.507528           3340.163528         
model.layers.9.mlp.experts.23.down_proj       torch.Size([1, 2048])          114.759071           115.332603           621.568000           3158.750090         
model.layers.9.mlp.experts.24.gate_proj       torch.Size([0, 1408])          147.575775           148.061514           621.585860           3058.634915         
model.layers.9.mlp.experts.24.act_fn          torch.Size([0, 1408])          0.331360             0.710726             621.568000           3106.560000         
model.layers.9.mlp.experts.24.up_proj         torch.Size([0, 1408])          139.127838           139.552116           621.603176           3102.238290         
model.layers.9.mlp.experts.24.down_proj       torch.Size([0, 2048])          160.428711           160.989046           556.573957           3108.295716         
model.layers.9.mlp.experts.25.gate_proj       torch.Size([1, 1408])          153.461151           154.198408           560.174400           3707.480800         
model.layers.9.mlp.experts.25.act_fn          torch.Size([1, 1408])          1.012544             1.750469             621.056000           4114.496000         
model.layers.9.mlp.experts.25.up_proj         torch.Size([1, 1408])          143.641113           144.326448           608.005565           3479.703056         
model.layers.9.mlp.experts.25.down_proj       torch.Size([1, 2048])          118.349052           118.988514           621.568000           3127.278013         
model.layers.9.mlp.experts.26.gate_proj       torch.Size([0, 1408])          165.949127           166.549683           621.568000           3098.391226         
model.layers.9.mlp.experts.26.act_fn          torch.Size([0, 1408])          0.408448             0.854015             621.568000           3261.888000         
model.layers.9.mlp.experts.26.up_proj         torch.Size([0, 1408])          154.235748           154.650927           621.698763           3111.835626         
model.layers.9.mlp.experts.26.down_proj       torch.Size([0, 2048])          152.126556           152.719736           559.961882           3158.683294         
model.layers.9.mlp.experts.27.gate_proj       torch.Size([0, 1408])          148.671173           149.182796           552.953351           3199.081974         
model.layers.9.mlp.experts.27.act_fn          torch.Size([0, 1408])          0.507456             1.108885             621.568000           3262.896000         
model.layers.9.mlp.experts.27.up_proj         torch.Size([0, 1408])          150.477341           150.945425           538.575342           3090.603397         
model.layers.9.mlp.experts.27.down_proj       torch.Size([0, 2048])          121.440704           121.879101           570.958507           3022.659840         
model.layers.9.mlp.experts.28.gate_proj       torch.Size([0, 1408])          135.569412           136.443615           564.661551           3008.265143         
model.layers.9.mlp.experts.28.act_fn          torch.Size([0, 1408])          0.411456             0.937700             621.568000           3261.888000         
model.layers.9.mlp.experts.28.up_proj         torch.Size([0, 1408])          145.769379           146.218061           558.541874           3240.289119         
model.layers.9.mlp.experts.28.down_proj       torch.Size([0, 2048])          156.123169           156.718969           568.691556           3300.977778         
model.layers.9.mlp.experts.29.gate_proj       torch.Size([0, 1408])          140.350525           141.075373           510.057459           3554.440453         
model.layers.9.mlp.experts.29.act_fn          torch.Size([0, 1408])          0.531936             1.063347             569.536000           4192.128000         
model.layers.9.mlp.experts.29.up_proj         torch.Size([0, 1408])          124.937469           125.356197           545.933333           3547.438222         
model.layers.9.mlp.experts.29.down_proj       torch.Size([0, 2048])          129.808578           130.362511           563.854703           3019.431784         
model.layers.9.mlp.experts.30.gate_proj       torch.Size([0, 1408])          137.332520           137.694359           561.359238           3144.030912         
model.layers.9.mlp.experts.30.act_fn          torch.Size([0, 1408])          0.363168             0.814199             621.568000           3106.560000         
model.layers.9.mlp.experts.30.up_proj         torch.Size([0, 1408])          86.491615            86.939573            549.151568           3209.875459         
model.layers.9.mlp.experts.30.down_proj       torch.Size([0, 2048])          75.668480            77.058554            568.028973           3150.035459         
model.layers.9.mlp.experts.31.gate_proj       torch.Size([0, 1408])          91.190399            91.726780            565.897710           3109.237848         
model.layers.9.mlp.experts.31.act_fn          torch.Size([0, 1408])          0.546336             1.185417             621.568000           3106.560000         
model.layers.9.mlp.experts.31.up_proj         torch.Size([0, 1408])          91.164604            91.656446            524.669881           3813.443391         
model.layers.9.mlp.experts.31.down_proj       torch.Size([0, 2048])          84.116928            84.599018            557.455217           3237.416727         
model.layers.9.mlp.experts.32.gate_proj       torch.Size([0, 1408])          86.805885            87.306499            572.612384           3185.918247         
model.layers.9.mlp.experts.32.act_fn          torch.Size([0, 1408])          0.388544             0.832081             621.568000           3572.544000         
model.layers.9.mlp.experts.32.up_proj         torch.Size([0, 1408])          85.358498            85.767746            509.329778           3454.947111         
model.layers.9.mlp.experts.32.down_proj       torch.Size([0, 2048])          87.909149            88.541031            558.728767           3372.965699         
model.layers.9.mlp.experts.33.gate_proj       torch.Size([0, 1408])          89.668350            90.241671            497.028241           3466.764723         
model.layers.9.mlp.experts.33.act_fn          torch.Size([0, 1408])          0.684320             1.449108             517.760000           4036.864000         
model.layers.9.mlp.experts.33.up_proj         torch.Size([0, 1408])          83.629089            84.224701            532.268482           3564.692426         
model.layers.9.mlp.experts.33.down_proj       torch.Size([0, 2048])          86.565918            87.157726            551.897252           3203.544816         
model.layers.9.mlp.experts.34.gate_proj       torch.Size([0, 1408])          82.919998            83.527327            572.271228           3231.457103         
model.layers.9.mlp.experts.34.act_fn          torch.Size([0, 1408])          0.503840             1.067877             621.568000           3261.888000         
model.layers.9.mlp.experts.34.up_proj         torch.Size([0, 1408])          80.024445            80.577135            552.626479           3123.818817         
model.layers.9.mlp.experts.34.down_proj       torch.Size([0, 2048])          76.389473            76.878548            574.014694           3028.322830         
model.layers.9.mlp.experts.35.gate_proj       torch.Size([0, 1408])          87.114243            87.659121            570.496448           3007.671944         
model.layers.9.mlp.experts.35.act_fn          torch.Size([0, 1408])          0.005696             1.259327             621.568000           3261.888000         
model.layers.9.mlp.experts.35.up_proj         torch.Size([0, 1408])          81.888802            82.354307            555.579616           3258.889205         
model.layers.9.mlp.experts.35.down_proj       torch.Size([0, 2048])          82.619713            84.025145            570.151529           3269.882824         
model.layers.9.mlp.experts.36.gate_proj       torch.Size([1, 1408])          87.713699            88.651419            588.436907           3152.479573         
model.layers.9.mlp.experts.36.act_fn          torch.Size([1, 1408])          0.442752             0.848770             621.568000           3106.560000         
model.layers.9.mlp.experts.36.up_proj         torch.Size([1, 1408])          84.089439            84.720373            621.584516           3097.838245         
model.layers.9.mlp.experts.36.down_proj       torch.Size([1, 2048])          84.499580            85.204124            621.595783           3099.728372         
model.layers.9.mlp.experts.37.gate_proj       torch.Size([0, 1408])          90.502876            91.229200            621.438247           3468.969205         
model.layers.9.mlp.experts.37.act_fn          torch.Size([0, 1408])          0.425152             0.930309             621.056000           4036.864000         
model.layers.9.mlp.experts.37.up_proj         torch.Size([0, 1408])          89.508636            90.137482            571.300940           3910.138846         
model.layers.9.mlp.experts.37.down_proj       torch.Size([0, 2048])          87.838814            88.596582            545.844400           3168.172400         
model.layers.9.mlp.experts.38.gate_proj       torch.Size([0, 1408])          87.661469            88.126659            558.189714           3070.089578         
model.layers.9.mlp.experts.38.act_fn          torch.Size([0, 1408])          0.357664             0.759363             621.568000           3106.560000         
model.layers.9.mlp.experts.38.up_proj         torch.Size([0, 1408])          77.133347            77.710390            535.824716           3020.333373         
model.layers.9.mlp.experts.38.down_proj       torch.Size([0, 2048])          96.286781            96.782446            580.286619           3148.583597         
model.layers.9.mlp.experts.39.gate_proj       torch.Size([0, 1408])          91.809822            92.506409            570.166486           3144.973405         
model.layers.9.mlp.experts.39.act_fn          torch.Size([0, 1408])          0.481856             1.026154             621.568000           3417.216000         
model.layers.9.mlp.experts.39.up_proj         torch.Size([0, 1408])          82.156479            82.639694            564.553669           3244.666475         
model.layers.9.mlp.experts.39.down_proj       torch.Size([0, 2048])          86.978462            87.698698            555.253407           2960.816552         
model.layers.9.mlp.experts.40.gate_proj       torch.Size([0, 1408])          92.289436            92.747927            585.081143           3030.951771         
model.layers.9.mlp.experts.40.act_fn          torch.Size([0, 1408])          0.582496             1.406431             621.568000           3261.888000         
model.layers.9.mlp.experts.40.up_proj         torch.Size([0, 1408])          89.499809            90.113640            557.799489           3062.370950         
model.layers.9.mlp.experts.40.down_proj       torch.Size([0, 2048])          88.440414            89.113712            567.287233           3231.749699         
model.layers.9.mlp.experts.41.gate_proj       torch.Size([0, 1408])          98.476799            100.616693           477.737931           3527.546115         
model.layers.9.mlp.experts.41.act_fn          torch.Size([0, 1408])          0.423840             0.975132             465.984000           3883.200000         
model.layers.9.mlp.experts.41.up_proj         torch.Size([0, 1408])          88.236259            88.676214            487.629241           3431.980874         
model.layers.9.mlp.experts.41.down_proj       torch.Size([0, 2048])          82.452126            82.895279            562.561280           3072.182187         
model.layers.9.mlp.experts.42.gate_proj       torch.Size([0, 1408])          94.506332            94.999313            605.461807           3095.990519         
model.layers.9.mlp.experts.42.act_fn          torch.Size([0, 1408])          0.483456             1.168489             621.568000           3572.544000         
model.layers.9.mlp.experts.42.up_proj         torch.Size([0, 1408])          86.005409            86.461782            533.584640           3160.251733         
model.layers.9.mlp.experts.42.down_proj       torch.Size([0, 2048])          87.458435            89.004040            565.841214           3254.601269         
model.layers.9.mlp.experts.43.gate_proj       torch.Size([0, 1408])          85.838753            87.191105            550.957714           3087.410701         
model.layers.9.mlp.experts.43.act_fn          torch.Size([0, 1408])          0.005664             1.230717             621.568000           3261.888000         
model.layers.9.mlp.experts.43.up_proj         torch.Size([0, 1408])          78.660477            80.062151            560.256871           3156.907537         
model.layers.9.mlp.experts.43.down_proj       torch.Size([0, 2048])          85.204094            86.472273            565.721935           3032.612810         
model.layers.9.mlp.experts.44.gate_proj       torch.Size([0, 1408])          83.947647            85.252047            558.085606           3153.403796         
model.layers.9.mlp.experts.44.act_fn          torch.Size([0, 1408])          0.005696             1.350164             621.568000           3107.200000         
model.layers.9.mlp.experts.44.up_proj         torch.Size([0, 1408])          83.242813            84.708452            543.363972           3296.686345         
model.layers.9.mlp.experts.44.down_proj       torch.Size([0, 2048])          88.829948            90.376616            579.390171           3221.093486         
model.layers.9.mlp.experts.45.gate_proj       torch.Size([0, 1408])          86.555489            88.028431            528.142528           3216.480196         
model.layers.9.mlp.experts.45.act_fn          torch.Size([0, 1408])          0.005600             1.293659             621.312000           3726.336000         
model.layers.9.mlp.experts.45.up_proj         torch.Size([0, 1408])          81.255966            82.532883            515.255329           3521.457961         
model.layers.9.mlp.experts.45.down_proj       torch.Size([0, 2048])          85.110336            86.487293            566.597908           3331.429415         
model.layers.9.mlp.experts.46.gate_proj       torch.Size([2, 1408])          87.836029            89.299202            581.949352           3230.163421         
model.layers.9.mlp.experts.46.act_fn          torch.Size([2, 1408])          0.052224             1.667500             621.568000           3261.888000         
model.layers.9.mlp.experts.46.up_proj         torch.Size([2, 1408])          83.763199            85.541964            621.596845           3164.857239         
model.layers.9.mlp.experts.46.down_proj       torch.Size([2, 2048])          87.633347            88.399172            621.568000           3109.105194         
model.layers.9.mlp.experts.47.gate_proj       torch.Size([1, 1408])          90.925667            91.698408            621.568000           3038.542118         
model.layers.9.mlp.experts.47.act_fn          torch.Size([1, 1408])          0.891296             1.631975             621.568000           3106.560000         
model.layers.9.mlp.experts.47.up_proj         torch.Size([1, 1408])          86.221725            86.950064            621.515107           3186.137388         
model.layers.9.mlp.experts.47.down_proj       torch.Size([1, 2048])          88.752289            89.479208            621.548639           3238.393008         
model.layers.9.mlp.experts.48.gate_proj       torch.Size([1, 1408])          93.311966            94.252110            621.559808           3263.130624         
model.layers.9.mlp.experts.48.act_fn          torch.Size([1, 1408])          0.585728             1.235962             621.465600           3417.216000         
model.layers.9.mlp.experts.48.up_proj         torch.Size([1, 1408])          91.384674            92.118979            621.568000           3189.178000         
model.layers.9.mlp.experts.48.down_proj       torch.Size([1, 2048])          84.210754            84.947109            621.568000           3168.691200         
model.layers.9.mlp.experts.49.gate_proj       torch.Size([3, 1408])          86.383842            87.154150            621.456787           3265.837639         
model.layers.9.mlp.experts.49.act_fn          torch.Size([3, 1408])          0.552960             1.127481             621.312000           3417.216000         
model.layers.9.mlp.experts.49.up_proj         torch.Size([3, 1408])          77.267487            77.770948            621.377829           3733.624686         
model.layers.9.mlp.experts.49.down_proj       torch.Size([3, 2048])          76.991325            77.420712            621.335273           3640.468140         
model.layers.9.mlp.experts.50.gate_proj       torch.Size([0, 1408])          94.635902            95.080137            621.568000           3189.138097         
model.layers.9.mlp.experts.50.act_fn          torch.Size([0, 1408])          0.511104             1.106977             621.568000           3106.560000         
model.layers.9.mlp.experts.50.up_proj         torch.Size([0, 1408])          88.135231            88.629961            586.057143           3124.792686         
model.layers.9.mlp.experts.50.down_proj       torch.Size([0, 2048])          85.037407            85.740566            585.170979           3160.565407         
model.layers.9.mlp.experts.51.gate_proj       torch.Size([0, 1408])          103.003517           103.443861           621.568000           3193.911172         
model.layers.9.mlp.experts.51.act_fn          torch.Size([0, 1408])          0.671520             1.454353             621.568000           3417.216000         
model.layers.9.mlp.experts.51.up_proj         torch.Size([0, 1408])          82.233665            82.931519            616.431074           3255.638744         
model.layers.9.mlp.experts.51.down_proj       torch.Size([0, 2048])          95.736641            96.537828            621.561806           3308.235871         
model.layers.9.mlp.experts.52.gate_proj       torch.Size([0, 1408])          93.183517            93.834400            614.504727           3227.927273         
model.layers.9.mlp.experts.52.act_fn          torch.Size([0, 1408])          0.581760             1.301289             621.568000           3107.840000         
model.layers.9.mlp.experts.52.up_proj         torch.Size([0, 1408])          88.269890            88.877916            621.568000           3239.159607         
model.layers.9.mlp.experts.52.down_proj       torch.Size([0, 2048])          75.887100            77.270031            621.568000           3193.470426         
model.layers.9.mlp.experts.53.gate_proj       torch.Size([0, 1408])          81.107040            81.712246            621.568000           3207.231434         
model.layers.9.mlp.experts.53.act_fn          torch.Size([0, 1408])          0.349344             0.776052             621.568000           3261.888000         
model.layers.9.mlp.experts.53.up_proj         torch.Size([0, 1408])          91.505089            91.933966            618.824205           3431.496205         
model.layers.9.mlp.experts.53.down_proj       torch.Size([0, 2048])          82.648956            83.201408            574.240970           3914.927030         
model.layers.9.mlp.experts.54.gate_proj       torch.Size([0, 1408])          94.785408            95.428705            604.644119           3306.765941         
model.layers.9.mlp.experts.54.act_fn          torch.Size([0, 1408])          0.599424             1.476526             621.568000           3417.216000         
model.layers.9.mlp.experts.54.up_proj         torch.Size([0, 1408])          94.405632            95.044851            621.570048           3191.356928         
model.layers.9.mlp.experts.54.down_proj       torch.Size([0, 2048])          88.605186            89.005470            621.568000           3111.738000         
model.layers.9.mlp.experts.55.gate_proj       torch.Size([0, 1408])          94.769310            95.249414            621.568000           3276.649660         
model.layers.9.mlp.experts.55.act_fn          torch.Size([0, 1408])          0.638144             1.355171             621.568000           3106.560000         
model.layers.9.mlp.experts.55.up_proj         torch.Size([0, 1408])          89.871902            90.425730            621.559607           3362.542689         
model.layers.9.mlp.experts.55.down_proj       torch.Size([0, 2048])          84.641342            85.541725            621.568000           3222.009806         
model.layers.9.mlp.experts.56.gate_proj       torch.Size([0, 1408])          91.128098            91.736078            621.568000           3204.647742         
model.layers.9.mlp.experts.56.act_fn          torch.Size([0, 1408])          0.499264             1.182795             621.568000           3261.888000         
model.layers.9.mlp.experts.56.up_proj         torch.Size([0, 1408])          90.717918            91.224909            621.568000           3149.492528         
model.layers.9.mlp.experts.56.down_proj       torch.Size([0, 2048])          88.323395            88.806391            621.576063           3077.660220         
model.layers.9.mlp.experts.57.gate_proj       torch.Size([0, 1408])          92.800514            93.307972            621.568000           3241.091048         
model.layers.9.mlp.experts.57.act_fn          torch.Size([0, 1408])          0.486144             0.967264             621.568000           3106.560000         
model.layers.9.mlp.experts.57.up_proj         torch.Size([0, 1408])          106.708771           107.131958           601.790836           3345.200291         
model.layers.9.mlp.experts.57.down_proj       torch.Size([0, 2048])          80.192253            80.794096            621.460211           3565.286175         
model.layers.9.mlp.experts.58.gate_proj       torch.Size([1, 1408])          97.095490            98.899603            621.568000           3316.129524         
model.layers.9.mlp.experts.58.act_fn          torch.Size([1, 1408])          0.220512             1.980543             621.568000           3106.560000         
model.layers.9.mlp.experts.58.up_proj         torch.Size([1, 1408])          88.988220            90.514660            621.568000           3194.814545         
model.layers.9.mlp.experts.58.down_proj       torch.Size([1, 2048])          104.353889           106.058836           621.521638           3221.527181         
model.layers.9.mlp.experts.59.gate_proj       torch.Size([1, 1408])          111.003616           112.479687           621.556093           3240.214326         
model.layers.9.mlp.experts.59.act_fn          torch.Size([1, 1408])          0.050912             1.569510             621.312000           3696.192000         
model.layers.9.mlp.experts.59.up_proj         torch.Size([1, 1408])          92.173820            93.569279            621.551074           3318.370909         
model.layers.9.mlp.experts.59.down_proj       torch.Size([1, 2048])          89.027969            90.735912            621.560822           3206.724785         
model.layers.9.mlp.shared_expert.gate_proj    torch.Size([5, 5632])          377.833496           379.480600           758.361716           3229.515988         
model.layers.9.mlp.shared_expert.act_fn       torch.Size([5, 5632])          0.525664             1.024485             776.640000           3322.649600         
model.layers.9.mlp.shared_expert.up_proj      torch.Size([5, 5632])          351.066925           351.444960           758.638200           3474.442600         
model.layers.9.mlp.shared_expert.down_proj    torch.Size([5, 2048])          330.554260           330.919981           742.489637           3550.120795         
model.layers.9.mlp.shared_expert_gate         torch.Size([5, 1])             8.898592             9.430885             642.729697           3182.245818         
model.layers.10.input_layernorm               torch.Size([1, 5, 2048])       6.771392             8.737087             512.350815           3372.500148         
model.layers.10.self_attn.q_proj              torch.Size([1, 5, 2048])       130.061081           130.645990           607.336575           3323.316288         
model.layers.10.self_attn.k_proj              torch.Size([1, 5, 2048])       132.406586           133.379936           621.568000           3235.492392         
model.layers.10.self_attn.v_proj              torch.Size([1, 5, 2048])       114.578239           115.239620           621.568000           3186.400179         
model.layers.10.self_attn.o_proj              torch.Size([1, 5, 2048])       133.431870           134.177446           627.654737           3172.886316         
model.layers.10.post_attention_layernorm      torch.Size([1, 5, 2048])       13.556160            14.284372            621.672136           3139.019932         
model.layers.10.mlp.gate                      torch.Size([5, 60])            14.754560            15.223980            466.276174           3377.613913         
model.layers.10.mlp.experts.0.gate_proj       torch.Size([0, 1408])          94.020676            94.610214            589.962563           3276.007146         
model.layers.10.mlp.experts.0.act_fn          torch.Size([0, 1408])          0.543488             1.209021             621.568000           3261.888000         
model.layers.10.mlp.experts.0.up_proj         torch.Size([0, 1408])          99.346115            100.069523           621.422345           3632.187586         
model.layers.10.mlp.experts.0.down_proj       torch.Size([0, 2048])          91.676643            92.316151            621.568000           3256.774400         
model.layers.10.mlp.experts.1.gate_proj       torch.Size([1, 1408])          122.339073           122.819662           621.568000           3133.421233         
model.layers.10.mlp.experts.1.act_fn          torch.Size([1, 1408])          0.389888             0.816822             621.312000           3572.544000         
model.layers.10.mlp.experts.1.up_proj         torch.Size([1, 1408])          163.629639           164.235830           621.537764           3275.341606         
model.layers.10.mlp.experts.1.down_proj       torch.Size([1, 2048])          175.018845           175.498009           621.568000           3328.255418         
model.layers.10.mlp.experts.2.gate_proj       torch.Size([0, 1408])          161.535904           162.055969           621.561263           3290.501053         
model.layers.10.mlp.experts.2.act_fn          torch.Size([0, 1408])          0.324928             0.697374             621.568000           3106.560000         
model.layers.10.mlp.experts.2.up_proj         torch.Size([0, 1408])          146.507172           146.971226           621.568000           3175.828317         
model.layers.10.mlp.experts.2.down_proj       torch.Size([0, 2048])          147.843262           148.642778           621.568000           3172.739446         
model.layers.10.mlp.experts.3.gate_proj       torch.Size([0, 1408])          160.277405           160.984039           621.568000           3164.847074         
model.layers.10.mlp.experts.3.act_fn          torch.Size([0, 1408])          0.416608             0.826120             621.568000           3572.544000         
model.layers.10.mlp.experts.3.up_proj         torch.Size([0, 1408])          146.502914           146.897316           621.568000           3253.248525         
model.layers.10.mlp.experts.3.down_proj       torch.Size([0, 2048])          157.314850           157.920599           621.547355           3342.129548         
model.layers.10.mlp.experts.4.gate_proj       torch.Size([0, 1408])          152.204666           152.634621           621.568000           3239.891302         
model.layers.10.mlp.experts.4.act_fn          torch.Size([0, 1408])          0.421312             0.914574             621.568000           3107.840000         
model.layers.10.mlp.experts.4.up_proj         torch.Size([0, 1408])          121.755043           122.180700           608.022069           3714.039724         
model.layers.10.mlp.experts.4.down_proj       torch.Size([0, 2048])          176.462311           176.957369           621.568000           3287.144585         
model.layers.10.mlp.experts.5.gate_proj       torch.Size([0, 1408])          158.704514           159.084082           621.568000           3219.254349         
model.layers.10.mlp.experts.5.act_fn          torch.Size([0, 1408])          0.444224             0.907898             621.568000           3313.664000         
model.layers.10.mlp.experts.5.up_proj         torch.Size([0, 1408])          116.455391           117.008448           621.545106           3292.519024         
model.layers.10.mlp.experts.5.down_proj       torch.Size([0, 2048])          139.263931           139.843941           621.561546           3312.858353         
model.layers.10.mlp.experts.6.gate_proj       torch.Size([0, 1408])          161.035873           161.586523           621.568000           3157.060760         
model.layers.10.mlp.experts.6.act_fn          torch.Size([0, 1408])          0.005600             1.352549             621.568000           3261.888000         
model.layers.10.mlp.experts.6.up_proj         torch.Size([0, 1408])          158.289276           158.781528           612.078412           3182.794748         
model.layers.10.mlp.experts.6.down_proj       torch.Size([0, 2048])          141.008804           142.553806           621.624672           3088.040550         
model.layers.10.mlp.experts.7.gate_proj       torch.Size([0, 1408])          146.701187           147.231579           621.646414           3177.059748         
model.layers.10.mlp.experts.7.act_fn          torch.Size([0, 1408])          0.683328             1.604557             621.568000           3261.888000         
model.layers.10.mlp.experts.7.up_proj         torch.Size([0, 1408])          133.751526           134.380817           621.557421           3314.964099         
model.layers.10.mlp.experts.7.down_proj       torch.Size([0, 2048])          83.333122            83.824396            621.568000           3249.374179         
model.layers.10.mlp.experts.8.gate_proj       torch.Size([1, 1408])          87.234398            87.900639            621.692121           3022.601697         
model.layers.10.mlp.experts.8.act_fn          torch.Size([1, 1408])          0.876064             1.720428             621.568000           3533.712000         
model.layers.10.mlp.experts.8.up_proj         torch.Size([1, 1408])          92.238205            92.872858            621.448000           3604.779500         
model.layers.10.mlp.experts.8.down_proj       torch.Size([1, 2048])          94.169823            94.796896            621.568000           3199.071529         
model.layers.10.mlp.experts.9.gate_proj       torch.Size([0, 1408])          99.929565            100.639582           621.528990           3340.291657         
model.layers.10.mlp.experts.9.act_fn          torch.Size([0, 1408])          0.594016             1.352072             621.568000           3106.560000         
model.layers.10.mlp.experts.9.up_proj         torch.Size([0, 1408])          84.162270            84.765196            621.532033           3367.183339         
model.layers.10.mlp.experts.9.down_proj       torch.Size([0, 2048])          74.144989            74.810743            621.568000           3233.869576         
model.layers.10.mlp.experts.10.gate_proj      torch.Size([0, 1408])          84.391457            84.914923            621.568000           3188.160000         
model.layers.10.mlp.experts.10.act_fn         torch.Size([0, 1408])          0.498976             1.338959             621.568000           3106.560000         
model.layers.10.mlp.experts.10.up_proj        torch.Size([0, 1408])          88.285187            88.798761            621.568000           3183.455484         
model.layers.10.mlp.experts.10.down_proj      torch.Size([0, 2048])          83.944542            84.559917            621.568000           3161.734820         
model.layers.10.mlp.experts.11.gate_proj      torch.Size([0, 1408])          90.487076            91.218233            621.568000           3116.177270         
model.layers.10.mlp.experts.11.act_fn         torch.Size([0, 1408])          0.344480             0.824928             621.568000           3417.216000         
model.layers.10.mlp.experts.11.up_proj        torch.Size([0, 1408])          82.034882            82.489491            620.129185           3308.207407         
model.layers.10.mlp.experts.11.down_proj      torch.Size([0, 2048])          80.480835            80.899954            621.568000           3209.856000         
model.layers.10.mlp.experts.12.gate_proj      torch.Size([0, 1408])          90.952255            91.450930            621.529917           3295.453620         
model.layers.10.mlp.experts.12.act_fn         torch.Size([0, 1408])          0.413280             0.842571             621.312000           3727.872000         
model.layers.10.mlp.experts.12.up_proj        torch.Size([0, 1408])          60.370274            60.708523            609.323339           3436.784882         
model.layers.10.mlp.experts.12.down_proj      torch.Size([0, 2048])          64.011330            64.416647            612.221113           3233.268932         
model.layers.10.mlp.experts.13.gate_proj      torch.Size([2, 1408])          91.615196            92.137098            621.547187           3255.573854         
model.layers.10.mlp.experts.13.act_fn         torch.Size([2, 1408])          0.412640             0.823259             621.312000           3572.544000         
model.layers.10.mlp.experts.13.up_proj        torch.Size([2, 1408])          76.348320            76.916933            621.546667           3327.784727         
model.layers.10.mlp.experts.13.down_proj      torch.Size([2, 2048])          83.308258            84.006310            621.568000           3213.724279         
model.layers.10.mlp.experts.14.gate_proj      torch.Size([0, 1408])          86.374596            86.954594            621.568000           3067.498182         
model.layers.10.mlp.experts.14.act_fn         torch.Size([0, 1408])          0.575360             1.434565             621.568000           3004.245333         
model.layers.10.mlp.experts.14.up_proj        torch.Size([0, 1408])          93.621597            94.265699            621.568000           3159.323648         
model.layers.10.mlp.experts.14.down_proj      torch.Size([0, 2048])          84.774590            85.184097            621.568000           3271.722667         
model.layers.10.mlp.experts.15.gate_proj      torch.Size([1, 1408])          95.661827            96.372843            621.560062           3241.456124         
model.layers.10.mlp.experts.15.act_fn         torch.Size([1, 1408])          0.589280             1.194000             621.568000           3261.888000         
model.layers.10.mlp.experts.15.up_proj        torch.Size([1, 1408])          77.626785            78.091383            621.568000           3255.820500         
model.layers.10.mlp.experts.15.down_proj      torch.Size([1, 2048])          134.348633           134.961367           621.568000           3188.460218         
model.layers.10.mlp.experts.16.gate_proj      torch.Size([0, 1408])          96.903267            97.596169            621.479287           3415.308673         
model.layers.10.mlp.experts.16.act_fn         torch.Size([0, 1408])          0.339744             0.745535             621.312000           3881.600000         
model.layers.10.mlp.experts.16.up_proj        torch.Size([0, 1408])          85.117348            85.538626            621.459010           3498.502337         
model.layers.10.mlp.experts.16.down_proj      torch.Size([0, 2048])          86.900993            87.272167            621.512828           3390.435310         
model.layers.10.mlp.experts.17.gate_proj      torch.Size([0, 1408])          93.025597            93.660593            621.568000           3311.762361         
model.layers.10.mlp.experts.17.act_fn         torch.Size([0, 1408])          0.558592             1.039505             621.568000           3261.888000         
model.layers.10.mlp.experts.17.up_proj        torch.Size([0, 1408])          78.443939            78.894615            613.135876           3254.941271         
model.layers.10.mlp.experts.17.down_proj      torch.Size([0, 2048])          78.684959            79.289436            602.462426           3159.111344         
model.layers.10.mlp.experts.18.gate_proj      torch.Size([0, 1408])          102.489059           103.171110           621.568000           3097.956339         
model.layers.10.mlp.experts.18.act_fn         torch.Size([0, 1408])          0.577056             1.470327             621.568000           3263.232000         
model.layers.10.mlp.experts.18.up_proj        torch.Size([0, 1408])          89.792259            90.418577            605.837102           3012.349480         
model.layers.10.mlp.experts.18.down_proj      torch.Size([0, 2048])          98.821983            99.473238            621.568000           3264.645039         
model.layers.10.mlp.experts.19.gate_proj      torch.Size([0, 1408])          81.325790            81.958532            621.568000           3334.128882         
model.layers.10.mlp.experts.19.act_fn         torch.Size([0, 1408])          0.350816             0.762463             621.568000           3261.888000         
model.layers.10.mlp.experts.19.up_proj        torch.Size([0, 1408])          89.531487            89.863062            621.568000           3247.237079         
model.layers.10.mlp.experts.19.down_proj      torch.Size([0, 2048])          101.511261           101.952076           621.568000           3148.424533         
model.layers.10.mlp.experts.20.gate_proj      torch.Size([0, 1408])          50.519135            51.034689            621.476848           3396.313697         
model.layers.10.mlp.experts.20.act_fn         torch.Size([0, 1408])          0.401472             0.833273             621.568000           3572.544000         
model.layers.10.mlp.experts.20.up_proj        torch.Size([0, 1408])          96.465378            96.893311            621.568000           3381.856780         
model.layers.10.mlp.experts.20.down_proj      torch.Size([0, 2048])          87.302788            87.858438            621.568000           3220.326400         
model.layers.10.mlp.experts.21.gate_proj      torch.Size([1, 1408])          95.794113            96.569300            621.561905           3323.526095         
model.layers.10.mlp.experts.21.act_fn         torch.Size([1, 1408])          0.871840             1.747847             621.568000           3261.888000         
model.layers.10.mlp.experts.21.up_proj        torch.Size([1, 1408])          94.904991            95.897198            621.582110           3152.596661         
model.layers.10.mlp.experts.21.down_proj      torch.Size([1, 2048])          74.999428            75.713873            621.568000           3131.692387         
model.layers.10.mlp.experts.22.gate_proj      torch.Size([0, 1408])          99.902466            100.414753           621.568000           3126.834472         
model.layers.10.mlp.experts.22.act_fn         torch.Size([0, 1408])          0.597120             1.335144             621.568000           3106.560000         
model.layers.10.mlp.experts.22.up_proj        torch.Size([0, 1408])          96.193535            96.778393            621.568000           3273.282246         
model.layers.10.mlp.experts.22.down_proj      torch.Size([0, 2048])          83.105698            83.627224            621.568000           3254.841856         
model.layers.10.mlp.experts.23.gate_proj      torch.Size([1, 1408])          93.447746            94.121933            621.636414           3088.526345         
model.layers.10.mlp.experts.23.act_fn         torch.Size([1, 1408])          0.567072             1.100302             621.568000           3261.888000         
model.layers.10.mlp.experts.23.up_proj        torch.Size([1, 1408])          67.305603            67.793846            621.725538           2956.633510         
model.layers.10.mlp.experts.23.down_proj      torch.Size([1, 2048])          82.232964            82.695723            621.568000           3068.311226         
model.layers.10.mlp.experts.24.gate_proj      torch.Size([0, 1408])          92.737534            93.242884            621.480635           3485.989079         
model.layers.10.mlp.experts.24.act_fn         torch.Size([0, 1408])          0.397312             0.832081             621.568000           3572.544000         
model.layers.10.mlp.experts.24.up_proj        torch.Size([0, 1408])          80.497566            80.879211            621.541287           3347.125426         
model.layers.10.mlp.experts.24.down_proj      torch.Size([0, 2048])          83.015778            83.683014            621.563387           3347.329153         
model.layers.10.mlp.experts.25.gate_proj      torch.Size([0, 1408])          103.205475           103.900433           621.568000           3257.001290         
model.layers.10.mlp.experts.25.act_fn         torch.Size([0, 1408])          0.574432             1.417160             621.568000           3261.888000         
model.layers.10.mlp.experts.25.up_proj        torch.Size([0, 1408])          97.168991            98.022461            621.568000           3207.518951         
model.layers.10.mlp.experts.25.down_proj      torch.Size([0, 2048])          93.836418            94.532251            621.710000           2969.155000         
model.layers.10.mlp.experts.26.gate_proj      torch.Size([1, 1408])          100.996384           101.736784           621.551213           3139.307541         
model.layers.10.mlp.experts.26.act_fn         torch.Size([1, 1408])          0.745216             1.419067             621.465600           3572.544000         
model.layers.10.mlp.experts.26.up_proj        torch.Size([1, 1408])          99.358017            100.029945           621.568000           3234.823273         
model.layers.10.mlp.experts.26.down_proj      torch.Size([1, 2048])          82.095139            82.675219            621.520372           3325.704930         
model.layers.10.mlp.experts.27.gate_proj      torch.Size([0, 1408])          72.656929            73.289871            621.568000           3204.097016         
model.layers.10.mlp.experts.27.act_fn         torch.Size([0, 1408])          0.374560             0.858784             621.568000           3107.840000         
model.layers.10.mlp.experts.27.up_proj        torch.Size([0, 1408])          83.586365            84.043980            621.568000           3199.637677         
model.layers.10.mlp.experts.27.down_proj      torch.Size([0, 2048])          96.547684            97.023249            621.568000           3185.396870         
model.layers.10.mlp.experts.28.gate_proj      torch.Size([0, 1408])          76.514435            77.015162            621.503443           3538.777043         
model.layers.10.mlp.experts.28.act_fn         torch.Size([0, 1408])          0.637536             1.417637             621.568000           3300.720000         
model.layers.10.mlp.experts.28.up_proj        torch.Size([0, 1408])          84.565025            85.126877            597.724062           3240.037415         
model.layers.10.mlp.experts.28.down_proj      torch.Size([0, 2048])          37.326591            37.826538            621.568000           3239.081143         
model.layers.10.mlp.experts.29.gate_proj      torch.Size([1, 1408])          15.136320            15.694618            621.568000           3131.893493         
model.layers.10.mlp.experts.29.act_fn         torch.Size([1, 1408])          0.388832             0.767231             621.568000           3417.216000         
model.layers.10.mlp.experts.29.up_proj        torch.Size([1, 1408])          11.532640            11.976242            621.568000           3138.266466         
model.layers.10.mlp.experts.29.down_proj      torch.Size([1, 2048])          14.250560            14.667988            621.568000           3158.431179         
model.layers.10.mlp.experts.30.gate_proj      torch.Size([1, 1408])          17.045856            17.477512            621.495193           3261.888000         
model.layers.10.mlp.experts.30.act_fn         torch.Size([1, 1408])          0.390048             0.759840             621.568000           3261.888000         
model.layers.10.mlp.experts.30.up_proj        torch.Size([1, 1408])          16.253729            16.641140            621.484218           3353.519127         
model.layers.10.mlp.experts.30.down_proj      torch.Size([1, 2048])          24.602400            24.998426            621.494539           3336.175304         
model.layers.10.mlp.experts.31.gate_proj      torch.Size([0, 1408])          17.103392            17.559528            621.560000           3152.991000         
model.layers.10.mlp.experts.31.act_fn         torch.Size([0, 1408])          0.348000             0.729799             621.568000           3261.888000         
model.layers.10.mlp.experts.31.up_proj        torch.Size([0, 1408])          19.535681            19.929171            616.823206           3115.729099         
model.layers.10.mlp.experts.31.down_proj      torch.Size([0, 2048])          13.710048            14.124870            621.528000           3317.666500         
model.layers.10.mlp.experts.32.gate_proj      torch.Size([2, 1408])          15.118720            15.615225            621.440000           3580.235940         
model.layers.10.mlp.experts.32.act_fn         torch.Size([2, 1408])          0.440832             0.812054             621.568000           3261.888000         
model.layers.10.mlp.experts.32.up_proj        torch.Size([2, 1408])          16.473633            16.891956            621.513443           3362.469246         
model.layers.10.mlp.experts.32.down_proj      torch.Size([2, 2048])          12.902304            13.405085            621.568000           3234.705600         
model.layers.10.mlp.experts.33.gate_proj      torch.Size([0, 1408])          13.060896            13.617039            621.568000           3264.963802         
model.layers.10.mlp.experts.33.act_fn         torch.Size([0, 1408])          0.413344             0.807524             621.568000           3261.888000         
model.layers.10.mlp.experts.33.up_proj        torch.Size([0, 1408])          13.985184            14.407873            621.568000           3238.876444         
model.layers.10.mlp.experts.33.down_proj      torch.Size([0, 2048])          10.724416            11.157751            621.575699           3097.779008         
model.layers.10.mlp.experts.34.gate_proj      torch.Size([0, 1408])          10.554272            10.976315            621.568000           3240.801821         
model.layers.10.mlp.experts.34.act_fn         torch.Size([0, 1408])          0.323296             0.757694             621.568000           3107.840000         
model.layers.10.mlp.experts.34.up_proj        torch.Size([0, 1408])          13.336192            13.755798            621.568000           3322.911232         
model.layers.10.mlp.experts.34.down_proj      torch.Size([0, 2048])          10.688064            11.101007            621.568000           3194.796155         
model.layers.10.mlp.experts.35.gate_proj      torch.Size([0, 1408])          16.819296            17.393351            621.568000           3167.389968         
model.layers.10.mlp.experts.35.act_fn         torch.Size([0, 1408])          0.376736             0.821114             621.568000           3106.560000         
model.layers.10.mlp.experts.35.up_proj        torch.Size([0, 1408])          12.698816            13.090372            616.856427           3109.826931         
model.layers.10.mlp.experts.35.down_proj      torch.Size([0, 2048])          10.482400            10.914803            621.526033           3364.184656         
model.layers.10.mlp.experts.36.gate_proj      torch.Size([0, 1408])          10.245184            10.687828            621.538862           3402.046959         
model.layers.10.mlp.experts.36.act_fn         torch.Size([0, 1408])          0.321344             0.745773             621.312000           4192.128000         
model.layers.10.mlp.experts.36.up_proj        torch.Size([0, 1408])          10.120992            10.495186            597.618708           3448.311631         
model.layers.10.mlp.experts.36.down_proj      torch.Size([0, 2048])          11.366720            11.805773            610.299765           3057.248471         
model.layers.10.mlp.experts.37.gate_proj      torch.Size([0, 1408])          10.276256            10.691166            621.568000           3124.952060         
model.layers.10.mlp.experts.37.act_fn         torch.Size([0, 1408])          0.294080             0.658035             621.568000           3107.840000         
model.layers.10.mlp.experts.37.up_proj        torch.Size([0, 1408])          10.166368            10.550261            602.442831           3157.565046         
model.layers.10.mlp.experts.37.down_proj      torch.Size([0, 2048])          11.467776            11.883974            621.568000           3219.006915         
model.layers.10.mlp.experts.38.gate_proj      torch.Size([0, 1408])          12.170304            12.627840            621.578079           3243.943811         
model.layers.10.mlp.experts.38.act_fn         torch.Size([0, 1408])          0.298240             0.678539             621.568000           3261.888000         
model.layers.10.mlp.experts.38.up_proj        torch.Size([0, 1408])          11.465344            11.851311            591.417313           3229.852657         
model.layers.10.mlp.experts.38.down_proj      torch.Size([0, 2048])          11.250272            11.732578            618.064842           3138.891549         
model.layers.10.mlp.experts.39.gate_proj      torch.Size([1, 1408])          10.291552            10.699272            617.040000           3086.825412         
model.layers.10.mlp.experts.39.act_fn         torch.Size([1, 1408])          0.355840             0.730276             621.568000           3106.560000         
model.layers.10.mlp.experts.39.up_proj        torch.Size([1, 1408])          10.684288            11.062145            621.540431           3185.710277         
model.layers.10.mlp.experts.39.down_proj      torch.Size([1, 2048])          10.226912            10.630369            621.485419           3451.975742         
model.layers.10.mlp.experts.40.gate_proj      torch.Size([2, 1408])          12.430208            12.834787            621.535763           3328.564622         
model.layers.10.mlp.experts.40.act_fn         torch.Size([2, 1408])          0.332480             0.697613             621.568000           3417.216000         
model.layers.10.mlp.experts.40.up_proj        torch.Size([2, 1408])          11.038272            11.496067            621.568000           3206.735304         
model.layers.10.mlp.experts.40.down_proj      torch.Size([2, 2048])          13.605728            13.998985            661.412103           3183.560205         
model.layers.10.mlp.experts.41.gate_proj      torch.Size([0, 1408])          10.901472            11.314631            630.557620           3196.419174         
model.layers.10.mlp.experts.41.act_fn         torch.Size([0, 1408])          0.317536             0.690460             621.568000           3106.560000         
model.layers.10.mlp.experts.41.up_proj        torch.Size([0, 1408])          9.909248             10.310173            621.568000           3325.064463         
model.layers.10.mlp.experts.41.down_proj      torch.Size([0, 2048])          10.527424            10.916948            614.557835           3293.851910         
model.layers.10.mlp.experts.42.gate_proj      torch.Size([0, 1408])          10.377248            10.787249            621.568000           3209.358545         
model.layers.10.mlp.experts.42.act_fn         torch.Size([0, 1408])          0.315008             0.676870             621.568000           3261.888000         
model.layers.10.mlp.experts.42.up_proj        torch.Size([0, 1408])          10.669600            11.045218            598.680806           3169.874357         
model.layers.10.mlp.experts.42.down_proj      torch.Size([0, 2048])          10.172000            10.568857            621.683101           3130.408682         
model.layers.10.mlp.experts.43.gate_proj      torch.Size([0, 1408])          10.071200            10.472536            621.568000           3114.747569         
model.layers.10.mlp.experts.43.act_fn         torch.Size([0, 1408])          0.322304             0.686407             621.568000           3494.880000         
model.layers.10.mlp.experts.43.up_proj        torch.Size([0, 1408])          11.958848            12.344360            591.218000           3462.115500         
model.layers.10.mlp.experts.43.down_proj      torch.Size([0, 2048])          10.432320            10.877609            559.416839           3956.887273         
model.layers.10.mlp.experts.44.gate_proj      torch.Size([0, 1408])          10.768160            11.201382            621.461695           3536.818441         
model.layers.10.mlp.experts.44.act_fn         torch.Size([0, 1408])          0.360352             0.734568             621.568000           3261.888000         
model.layers.10.mlp.experts.44.up_proj        torch.Size([0, 1408])          14.797600            15.224218            606.885291           3246.244787         
model.layers.10.mlp.experts.44.down_proj      torch.Size([0, 2048])          13.567840            13.963223            621.568000           3187.173161         
model.layers.10.mlp.experts.45.gate_proj      torch.Size([0, 1408])          12.633344            13.103724            621.568000           3224.127471         
model.layers.10.mlp.experts.45.act_fn         torch.Size([0, 1408])          0.331808             0.742197             621.568000           3261.888000         
model.layers.10.mlp.experts.45.up_proj        torch.Size([0, 1408])          10.945056            11.345148            598.259200           3268.763733         
model.layers.10.mlp.experts.45.down_proj      torch.Size([0, 2048])          15.371168            15.797138            613.450507           3246.140179         
model.layers.10.mlp.experts.46.gate_proj      torch.Size([0, 1408])          14.065088            14.533997            621.568000           3172.462195         
model.layers.10.mlp.experts.46.act_fn         torch.Size([0, 1408])          0.298944             0.665188             621.568000           3417.216000         
model.layers.10.mlp.experts.46.up_proj        torch.Size([0, 1408])          13.148544            13.537169            567.133431           3149.443737         
model.layers.10.mlp.experts.46.down_proj      torch.Size([0, 2048])          10.000416            10.456085            614.378171           3069.084775         
model.layers.10.mlp.experts.47.gate_proj      torch.Size([0, 1408])          11.799808            12.239218            621.591664           3245.124840         
model.layers.10.mlp.experts.47.act_fn         torch.Size([0, 1408])          0.395104             0.856400             621.568000           3106.560000         
model.layers.10.mlp.experts.47.up_proj        torch.Size([0, 1408])          13.947680            14.354944            609.511724           3294.433655         
model.layers.10.mlp.experts.47.down_proj      torch.Size([0, 2048])          17.224064            17.663717            609.747053           3303.910107         
model.layers.10.mlp.experts.48.gate_proj      torch.Size([0, 1408])          17.582945            18.011332            541.697662           3798.699221         
model.layers.10.mlp.experts.48.act_fn         torch.Size([0, 1408])          0.317888             0.787020             621.312000           3727.360000         
model.layers.10.mlp.experts.48.up_proj        torch.Size([0, 1408])          14.435712            14.841557            592.114909           3434.866909         
model.layers.10.mlp.experts.48.down_proj      torch.Size([0, 2048])          22.576864            22.966862            615.645767           3163.888620         
model.layers.10.mlp.experts.49.gate_proj      torch.Size([0, 1408])          27.467264            27.948141            616.035453           3187.848748         
model.layers.10.mlp.experts.49.act_fn         torch.Size([0, 1408])          0.329600             0.727177             621.568000           3727.872000         
model.layers.10.mlp.experts.49.up_proj        torch.Size([0, 1408])          16.883841            17.287254            587.168244           3334.529954         
model.layers.10.mlp.experts.49.down_proj      torch.Size([0, 2048])          16.468128            16.915560            621.568000           3175.652713         
model.layers.10.mlp.experts.50.gate_proj      torch.Size([0, 1408])          23.559937            24.010897            621.568000           3156.906015         
model.layers.10.mlp.experts.50.act_fn         torch.Size([0, 1408])          0.312192             0.672102             621.568000           3107.840000         
model.layers.10.mlp.experts.50.up_proj        torch.Size([0, 1408])          16.351360            16.816854            617.966636           3194.939039         
model.layers.10.mlp.experts.50.down_proj      torch.Size([0, 2048])          19.119713            19.523621            621.568000           3283.120882         
model.layers.10.mlp.experts.51.gate_proj      torch.Size([1, 1408])          16.217279            16.628504            621.542185           3305.048202         
model.layers.10.mlp.experts.51.act_fn         torch.Size([1, 1408])          0.352768             0.712872             621.568000           3378.384000         
model.layers.10.mlp.experts.51.up_proj        torch.Size([1, 1408])          14.802560            15.202045            621.568000           3269.226331         
model.layers.10.mlp.experts.51.down_proj      torch.Size([1, 2048])          10.838464            11.268139            621.568000           3203.948190         
model.layers.10.mlp.experts.52.gate_proj      torch.Size([1, 1408])          10.788160            11.257172            621.343103           3763.121047         
model.layers.10.mlp.experts.52.act_fn         torch.Size([1, 1408])          0.344736             0.731468             621.312000           3881.600000         
model.layers.10.mlp.experts.52.up_proj        torch.Size([1, 1408])          11.226016            11.608601            621.485292           3401.686646         
model.layers.10.mlp.experts.52.down_proj      torch.Size([1, 2048])          11.016064            11.410475            621.554109           3317.276279         
model.layers.10.mlp.experts.53.gate_proj      torch.Size([0, 1408])          12.829024            13.333559            621.549115           3343.403016         
model.layers.10.mlp.experts.53.act_fn         torch.Size([0, 1408])          0.363232             0.731945             621.568000           3106.986667         
model.layers.10.mlp.experts.53.up_proj        torch.Size([0, 1408])          10.988032            11.378765            621.568000           3242.168258         
model.layers.10.mlp.experts.53.down_proj      torch.Size([0, 2048])          9.958624             10.350466            605.853898           3037.349372         
model.layers.10.mlp.experts.54.gate_proj      torch.Size([0, 1408])          9.919424             10.324001            621.674000           3086.877500         
model.layers.10.mlp.experts.54.act_fn         torch.Size([0, 1408])          0.296960             0.737429             621.568000           3107.413333         
model.layers.10.mlp.experts.54.up_proj        torch.Size([0, 1408])          8.654688             9.059429             607.571934           3192.594361         
model.layers.10.mlp.experts.54.down_proj      torch.Size([0, 2048])          8.932192             9.340763             621.568000           3202.277333         
model.layers.10.mlp.experts.55.gate_proj      torch.Size([0, 1408])          9.047168             9.459019             621.568000           3270.586585         
model.layers.10.mlp.experts.55.act_fn         torch.Size([0, 1408])          0.303040             0.681877             621.568000           3417.216000         
model.layers.10.mlp.experts.55.up_proj        torch.Size([0, 1408])          9.696256             10.085344            620.304650           3266.316488         
model.layers.10.mlp.experts.55.down_proj      torch.Size([0, 2048])          10.911872            11.301756            621.518222           3385.322667         
model.layers.10.mlp.experts.56.gate_proj      torch.Size([0, 1408])          12.909728            13.338327            621.486545           3501.925818         
model.layers.10.mlp.experts.56.act_fn         torch.Size([0, 1408])          0.330784             0.709534             621.568000           3106.560000         
model.layers.10.mlp.experts.56.up_proj        torch.Size([0, 1408])          13.047392            13.451099            621.568000           3295.186211         
model.layers.10.mlp.experts.56.down_proj      torch.Size([0, 2048])          10.137760            10.548830            616.849723           3206.281354         
model.layers.10.mlp.experts.57.gate_proj      torch.Size([1, 1408])          11.000608            11.456251            621.568000           3191.140030         
model.layers.10.mlp.experts.57.act_fn         torch.Size([1, 1408])          0.368224             0.780582             621.568000           3106.560000         
model.layers.10.mlp.experts.57.up_proj        torch.Size([1, 1408])          9.434880             9.866238             621.568000           3124.479556         
model.layers.10.mlp.experts.57.down_proj      torch.Size([1, 2048])          10.777184            11.268616            621.569882           3078.069647         
model.layers.10.mlp.experts.58.gate_proj      torch.Size([1, 1408])          10.433600            10.893583            621.708511           3079.391278         
model.layers.10.mlp.experts.58.act_fn         torch.Size([1, 1408])          0.378592             0.782728             621.568000           3417.216000         
model.layers.10.mlp.experts.58.up_proj        torch.Size([1, 1408])          12.455904            12.883902            621.560358           3166.492657         
model.layers.10.mlp.experts.58.down_proj      torch.Size([1, 2048])          10.466624            11.003256            621.529791           3305.936239         
model.layers.10.mlp.experts.59.gate_proj      torch.Size([1, 1408])          12.459968            13.027191            621.568000           3272.895496         
model.layers.10.mlp.experts.59.act_fn         torch.Size([1, 1408])          0.339296             0.707150             621.568000           3145.392000         
model.layers.10.mlp.experts.59.up_proj        torch.Size([1, 1408])          12.958656            13.337135            621.568000           3197.779200         
model.layers.10.mlp.experts.59.down_proj      torch.Size([1, 2048])          11.154112            11.548042            621.452986           3536.276870         
model.layers.10.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          29.730177            30.097485            721.742867           3295.377224         
model.layers.10.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.366848             0.829458             776.640000           3415.808000         
model.layers.10.mlp.shared_expert.up_proj     torch.Size([5, 5632])          36.514912            36.870480            744.776694           3297.165318         
model.layers.10.mlp.shared_expert.down_proj   torch.Size([5, 2048])          37.751904            38.188696            749.821905           3351.141524         
model.layers.10.mlp.shared_expert_gate        torch.Size([5, 1])             6.751264             7.184982             647.399111           3362.597926         
model.layers.11.input_layernorm               torch.Size([1, 5, 2048])       6.166144             6.607771             518.186667           3278.466510         
model.layers.11.self_attn.q_proj              torch.Size([1, 5, 2048])       21.399391            21.795511            599.705739           3160.428522         
model.layers.11.self_attn.k_proj              torch.Size([1, 5, 2048])       19.599680            20.013094            621.522975           3413.457045         
model.layers.11.self_attn.v_proj              torch.Size([1, 5, 2048])       17.102688            17.520189            621.557277           3301.850471         
model.layers.11.self_attn.o_proj              torch.Size([1, 5, 2048])       16.105791            16.481400            621.657302           3036.868837         
model.layers.11.post_attention_layernorm      torch.Size([1, 5, 2048])       6.467968             6.881475             621.737290           3067.738839         
model.layers.11.mlp.gate                      torch.Size([5, 60])            5.734976             6.139994             485.403429           2965.133061         
model.layers.11.mlp.experts.0.gate_proj       torch.Size([1, 1408])          12.626176            13.038874            593.894857           3167.008000         
model.layers.11.mlp.experts.0.act_fn          torch.Size([1, 1408])          0.337152             0.705957             621.568000           3106.560000         
model.layers.11.mlp.experts.0.up_proj         torch.Size([1, 1408])          13.303296            13.689756            621.532070           3334.214175         
model.layers.11.mlp.experts.0.down_proj       torch.Size([1, 2048])          9.027424             9.435892             621.516000           3322.563000         
model.layers.11.mlp.experts.1.gate_proj       torch.Size([1, 1408])          11.992544            12.462616            621.568000           3247.873444         
model.layers.11.mlp.experts.1.act_fn          torch.Size([1, 1408])          0.341760             0.705957             621.568000           3261.888000         
model.layers.11.mlp.experts.1.up_proj         torch.Size([1, 1408])          9.420640             9.803534             621.568000           3203.124060         
model.layers.11.mlp.experts.1.down_proj       torch.Size([1, 2048])          10.027104            10.540247            621.568000           3068.308364         
model.layers.11.mlp.experts.2.gate_proj       torch.Size([1, 1408])          12.610624            13.020039            621.442098           3520.013639         
model.layers.11.mlp.experts.2.act_fn          torch.Size([1, 1408])          0.345536             0.733852             621.312000           3572.544000         
model.layers.11.mlp.experts.2.up_proj         torch.Size([1, 1408])          11.961888            12.341976            621.555906           3354.840189         
model.layers.11.mlp.experts.2.down_proj       torch.Size([1, 2048])          18.894176            19.285440            621.523478           3337.278609         
model.layers.11.mlp.experts.3.gate_proj       torch.Size([0, 1408])          10.779904            11.236429            621.659287           3178.110016         
model.layers.11.mlp.experts.3.act_fn          torch.Size([0, 1408])          0.378624             0.744820             621.824000           2952.448000         
model.layers.11.mlp.experts.3.up_proj         torch.Size([0, 1408])          10.207776            10.607719            621.576393           3169.342951         
model.layers.11.mlp.experts.3.down_proj       torch.Size([0, 2048])          9.975968             10.415316            621.586286           3156.217905         
model.layers.11.mlp.experts.4.gate_proj       torch.Size([0, 1408])          11.344000            11.775970            621.565984           3230.701354         
model.layers.11.mlp.experts.4.act_fn          torch.Size([0, 1408])          0.312320             0.745058             621.568000           3261.888000         
model.layers.11.mlp.experts.4.up_proj         torch.Size([0, 1408])          17.306816            17.735243            590.780952           3283.496635         
model.layers.11.mlp.experts.4.down_proj       torch.Size([0, 2048])          15.146208            15.599012            621.568000           3229.593500         
model.layers.11.mlp.experts.5.gate_proj       torch.Size([0, 1408])          14.603392            15.119076            621.708511           3166.906226         
model.layers.11.mlp.experts.5.act_fn          torch.Size([0, 1408])          0.431232             0.874758             621.568000           3339.552000         
model.layers.11.mlp.experts.5.up_proj         torch.Size([0, 1408])          13.357760            13.825178            574.076587           3060.977920         
model.layers.11.mlp.experts.5.down_proj       torch.Size([0, 2048])          8.705568             9.115696             583.807543           3316.948571         
model.layers.11.mlp.experts.6.gate_proj       torch.Size([1, 1408])          11.282496            11.717796            621.497600           3462.470933         
model.layers.11.mlp.experts.6.act_fn          torch.Size([1, 1408])          0.346656             0.735044             621.568000           3107.584000         
model.layers.11.mlp.experts.6.up_proj         torch.Size([1, 1408])          16.701696            17.138958            621.674985           3116.421731         
model.layers.11.mlp.experts.6.down_proj       torch.Size([1, 2048])          14.870944            15.327930            621.588706           3128.432941         
model.layers.11.mlp.experts.7.gate_proj       torch.Size([0, 1408])          11.879520            12.333632            621.573731           3101.190687         
model.layers.11.mlp.experts.7.act_fn          torch.Size([0, 1408])          0.352800             0.841856             621.568000           3107.840000         
model.layers.11.mlp.experts.7.up_proj         torch.Size([0, 1408])          15.282016            15.768766            621.571765           3188.368000         
model.layers.11.mlp.experts.7.down_proj       torch.Size([0, 2048])          11.495200            11.923075            621.568000           3269.989376         
model.layers.11.mlp.experts.8.gate_proj       torch.Size([1, 1408])          32.997025            33.424377            621.514105           3276.383759         
model.layers.11.mlp.experts.8.act_fn          torch.Size([1, 1408])          0.363488             0.762224             621.568000           3417.216000         
model.layers.11.mlp.experts.8.up_proj         torch.Size([1, 1408])          10.193280            10.690212            621.218133           3907.242133         
model.layers.11.mlp.experts.8.down_proj       torch.Size([1, 2048])          10.362368            10.761023            621.395349           3322.882481         
model.layers.11.mlp.experts.9.gate_proj       torch.Size([0, 1408])          11.462944            11.877775            621.560000           3124.848000         
model.layers.11.mlp.experts.9.act_fn          torch.Size([0, 1408])          0.320480             0.696182             621.568000           3261.888000         
model.layers.11.mlp.experts.9.up_proj         torch.Size([0, 1408])          10.441792            10.845184            621.568000           3206.206000         
model.layers.11.mlp.experts.9.down_proj       torch.Size([0, 2048])          9.334752             9.725332             621.456361           3624.631338         
model.layers.11.mlp.experts.10.gate_proj      torch.Size([0, 1408])          12.927136            13.358116            621.550000           3283.086000         
model.layers.11.mlp.experts.10.act_fn         torch.Size([0, 1408])          0.316928             0.693321             621.568000           3107.840000         
model.layers.11.mlp.experts.10.up_proj        torch.Size([0, 1408])          10.387936            10.805607            601.835683           3175.988317         
model.layers.11.mlp.experts.10.down_proj      torch.Size([0, 2048])          9.497376             9.898901             621.568000           3145.248000         
model.layers.11.mlp.experts.11.gate_proj      torch.Size([1, 1408])          10.516896            10.956526            621.568000           3070.246820         
model.layers.11.mlp.experts.11.act_fn         torch.Size([1, 1408])          0.346880             0.710964             621.568000           3106.560000         
model.layers.11.mlp.experts.11.up_proj        torch.Size([1, 1408])          12.263744            12.663126            621.518933           3186.812800         
model.layers.11.mlp.experts.11.down_proj      torch.Size([1, 2048])          11.082336            11.676550            621.539343           3208.499582         
model.layers.11.mlp.experts.12.gate_proj      torch.Size([1, 1408])          14.848320            15.261173            621.506866           3289.673552         
model.layers.11.mlp.experts.12.act_fn         torch.Size([1, 1408])          0.350432             0.735760             621.568000           3417.216000         
model.layers.11.mlp.experts.12.up_proj        torch.Size([1, 1408])          9.817824             10.280848            621.568000           3082.737727         
model.layers.11.mlp.experts.12.down_proj      torch.Size([1, 2048])          11.011680            11.396646            621.568000           3117.259237         
model.layers.11.mlp.experts.13.gate_proj      torch.Size([0, 1408])          10.139040            10.622263            621.679304           3028.335304         
model.layers.11.mlp.experts.13.act_fn         torch.Size([0, 1408])          0.300000             0.673532             621.824000           2952.448000         
model.layers.11.mlp.experts.13.up_proj        torch.Size([0, 1408])          12.562560            12.967348            595.995000           3529.839000         
model.layers.11.mlp.experts.13.down_proj      torch.Size([0, 2048])          11.626336            12.008429            621.535748           3365.918236         
model.layers.11.mlp.experts.14.gate_proj      torch.Size([0, 1408])          12.716352            13.116360            609.027765           3162.976941         
model.layers.11.mlp.experts.14.act_fn         torch.Size([0, 1408])          0.294208             0.663757             621.568000           3106.560000         
model.layers.11.mlp.experts.14.up_proj        torch.Size([0, 1408])          10.418656            10.800600            621.568000           3188.977939         
model.layers.11.mlp.experts.14.down_proj      torch.Size([0, 2048])          12.273344            12.668371            602.560464           3005.962203         
model.layers.11.mlp.experts.15.gate_proj      torch.Size([0, 1408])          15.855104            16.319990            621.553311           3162.829115         
model.layers.11.mlp.experts.15.act_fn         torch.Size([0, 1408])          0.314592             0.716448             621.568000           3572.544000         
model.layers.11.mlp.experts.15.up_proj        torch.Size([0, 1408])          12.719360            13.152838            613.070000           3232.961000         
model.layers.11.mlp.experts.15.down_proj      torch.Size([0, 2048])          11.504864            12.023687            621.555306           3356.956033         
model.layers.11.mlp.experts.16.gate_proj      torch.Size([0, 1408])          11.113760            11.548519            621.568000           3224.449655         
model.layers.11.mlp.experts.16.act_fn         torch.Size([0, 1408])          0.305984             0.685453             621.568000           3107.413333         
model.layers.11.mlp.experts.16.up_proj        torch.Size([0, 1408])          9.608736             10.026217            603.151170           3174.698667         
model.layers.11.mlp.experts.16.down_proj      torch.Size([0, 2048])          12.851232            13.287067            621.615407           3049.683437         
model.layers.11.mlp.experts.17.gate_proj      torch.Size([0, 1408])          11.207584            11.770487            614.444651           3217.991938         
model.layers.11.mlp.experts.17.act_fn         torch.Size([0, 1408])          0.348640             0.788212             621.568000           3572.544000         
model.layers.11.mlp.experts.17.up_proj        torch.Size([0, 1408])          12.114080            12.535334            591.260203           3469.869559         
model.layers.11.mlp.experts.17.down_proj      torch.Size([0, 2048])          15.179552            15.624762            621.568000           3246.370102         
model.layers.11.mlp.experts.18.gate_proj      torch.Size([0, 1408])          9.468832             9.906054             621.577922           3138.600682         
model.layers.11.mlp.experts.18.act_fn         torch.Size([0, 1408])          0.307264             0.683308             621.568000           3261.888000         
model.layers.11.mlp.experts.18.up_proj        torch.Size([0, 1408])          10.831904            11.217833            621.584254           3117.294730         
model.layers.11.mlp.experts.18.down_proj      torch.Size([0, 2048])          10.027968            10.421038            621.603176           3132.098931         
model.layers.11.mlp.experts.19.gate_proj      torch.Size([0, 1408])          11.213920            11.641502            621.586732           3271.140423         
model.layers.11.mlp.experts.19.act_fn         torch.Size([0, 1408])          0.298048             0.659227             621.568000           3107.840000         
model.layers.11.mlp.experts.19.up_proj        torch.Size([0, 1408])          13.387200            13.774872            621.569969           3342.237538         
model.layers.11.mlp.experts.19.down_proj      torch.Size([0, 2048])          13.769184            14.153481            621.568000           3206.560733         
model.layers.11.mlp.experts.20.gate_proj      torch.Size([0, 1408])          11.951008            12.379169            621.568000           3154.202791         
model.layers.11.mlp.experts.20.act_fn         torch.Size([0, 1408])          0.299232             0.673056             621.568000           3210.112000         
model.layers.11.mlp.experts.20.up_proj        torch.Size([0, 1408])          13.212544            13.665438            621.590456           3143.986526         
model.layers.11.mlp.experts.20.down_proj      torch.Size([0, 2048])          15.266368            15.727520            621.574000           3135.344500         
model.layers.11.mlp.experts.21.gate_proj      torch.Size([0, 1408])          13.225952            13.709784            621.570133           3379.825067         
model.layers.11.mlp.experts.21.act_fn         torch.Size([0, 1408])          0.328640             0.725746             621.568000           3572.544000         
model.layers.11.mlp.experts.21.up_proj        torch.Size([0, 1408])          13.043744            13.489962            583.046459           3473.086826         
model.layers.11.mlp.experts.21.down_proj      torch.Size([0, 2048])          17.590176            18.046379            621.568000           3190.104123         
model.layers.11.mlp.experts.22.gate_proj      torch.Size([0, 1408])          13.591136            14.108658            604.716155           3145.798946         
model.layers.11.mlp.experts.22.act_fn         torch.Size([0, 1408])          0.343904             0.725031             621.824000           2952.448000         
model.layers.11.mlp.experts.22.up_proj        torch.Size([0, 1408])          12.604224            13.021708            598.940964           3113.352876         
model.layers.11.mlp.experts.22.down_proj      torch.Size([0, 2048])          11.650624            12.052298            621.651145           3174.825573         
model.layers.11.mlp.experts.23.gate_proj      torch.Size([0, 1408])          10.629088            11.069775            621.594413           3258.812444         
model.layers.11.mlp.experts.23.act_fn         torch.Size([0, 1408])          0.304864             0.683784             582.720000           3184.864000         
model.layers.11.mlp.experts.23.up_proj        torch.Size([0, 1408])          9.199136             9.598017             552.869029           3116.231771         
model.layers.11.mlp.experts.23.down_proj      torch.Size([0, 2048])          9.036384             9.454966             621.570151           3125.600269         
model.layers.11.mlp.experts.24.gate_proj      torch.Size([0, 1408])          10.572224            11.061668            617.005176           3083.657412         
model.layers.11.mlp.experts.24.act_fn         torch.Size([0, 1408])          0.303904             0.726938             621.568000           3417.216000         
model.layers.11.mlp.experts.24.up_proj        torch.Size([0, 1408])          10.782848            11.164665            596.503631           3121.900800         
model.layers.11.mlp.experts.24.down_proj      torch.Size([0, 2048])          14.533152            14.995098            588.564389           3254.099823         
model.layers.11.mlp.experts.25.gate_proj      torch.Size([0, 1408])          12.382496            12.792826            621.438781           3712.485181         
model.layers.11.mlp.experts.25.act_fn         torch.Size([0, 1408])          0.315968             0.694513             621.568000           3261.888000         
model.layers.11.mlp.experts.25.up_proj        torch.Size([0, 1408])          11.986528            12.376547            589.783273           3216.583758         
model.layers.11.mlp.experts.25.down_proj      torch.Size([0, 2048])          11.572288            11.964321            600.078949           3098.322686         
model.layers.11.mlp.experts.26.gate_proj      torch.Size([0, 1408])          11.943328            12.360573            614.743230           3088.859022         
model.layers.11.mlp.experts.26.act_fn         torch.Size([0, 1408])          0.303904             0.666618             621.568000           3106.986667         
model.layers.11.mlp.experts.26.up_proj        torch.Size([0, 1408])          9.452800             9.867191             584.762785           3217.762133         
model.layers.11.mlp.experts.26.down_proj      torch.Size([0, 2048])          9.330368             9.747505             621.576192           3230.158336         
model.layers.11.mlp.experts.27.gate_proj      torch.Size([2, 1408])          14.010944            14.447927            621.568000           3258.490226         
model.layers.11.mlp.experts.27.act_fn         torch.Size([2, 1408])          0.388064             0.762224             621.568000           3417.216000         
model.layers.11.mlp.experts.27.up_proj        torch.Size([2, 1408])          12.529440            12.908459            621.568000           3209.726046         
model.layers.11.mlp.experts.27.down_proj      torch.Size([2, 2048])          10.860672            11.248112            621.568000           3182.991238         
model.layers.11.mlp.experts.28.gate_proj      torch.Size([1, 1408])          11.070400            11.509418            621.568000           3172.501132         
model.layers.11.mlp.experts.28.act_fn         torch.Size([1, 1408])          0.336928             0.699997             621.568000           3106.560000         
model.layers.11.mlp.experts.28.up_proj        torch.Size([1, 1408])          9.527136             9.900808             621.508350           3337.260117         
model.layers.11.mlp.experts.28.down_proj      torch.Size([1, 2048])          11.405312            11.803865            621.448258           3506.680258         
model.layers.11.mlp.experts.29.gate_proj      torch.Size([0, 1408])          16.360001            16.838312            621.535278           3392.609684         
model.layers.11.mlp.experts.29.act_fn         torch.Size([0, 1408])          0.305088             0.676632             621.568000           3261.888000         
model.layers.11.mlp.experts.29.up_proj        torch.Size([0, 1408])          11.062048            11.448622            621.568000           3211.465443         
model.layers.11.mlp.experts.29.down_proj      torch.Size([0, 2048])          11.235616            11.622667            621.577922           3082.154667         
model.layers.11.mlp.experts.30.gate_proj      torch.Size([0, 1408])          9.458528             9.891510             621.622114           3087.376130         
model.layers.11.mlp.experts.30.act_fn         torch.Size([0, 1408])          0.294432             0.665665             621.568000           3107.840000         
model.layers.11.mlp.experts.30.up_proj        torch.Size([0, 1408])          10.692928            11.107445            599.369143           3312.492271         
model.layers.11.mlp.experts.30.down_proj      torch.Size([0, 2048])          10.347616            10.740519            621.579815           3357.722092         
model.layers.11.mlp.experts.31.gate_proj      torch.Size([0, 1408])          10.900704            11.307001            621.568000           3243.651072         
model.layers.11.mlp.experts.31.act_fn         torch.Size([0, 1408])          0.292896             0.658512             621.568000           3223.392000         
model.layers.11.mlp.experts.31.up_proj        torch.Size([0, 1408])          9.894656             10.280132            611.864000           3188.497500         
model.layers.11.mlp.experts.31.down_proj      torch.Size([0, 2048])          8.830080             9.246826             621.613643           3106.092651         
model.layers.11.mlp.experts.32.gate_proj      torch.Size([0, 1408])          11.251168            11.702776            621.716837           3120.722853         
model.layers.11.mlp.experts.32.act_fn         torch.Size([0, 1408])          0.310752             0.679970             621.568000           3417.216000         
model.layers.11.mlp.experts.32.up_proj        torch.Size([0, 1408])          11.461632            11.878490            600.862341           3210.676148         
model.layers.11.mlp.experts.32.down_proj      torch.Size([0, 2048])          9.187488             9.608746             621.505085           3609.182915         
model.layers.11.mlp.experts.33.gate_proj      torch.Size([0, 1408])          14.428000            14.849663            621.660000           3274.661000         
model.layers.11.mlp.experts.33.act_fn         torch.Size([0, 1408])          0.300192             0.753164             621.824000           3107.840000         
model.layers.11.mlp.experts.33.up_proj        torch.Size([0, 1408])          12.383552            12.796402            595.220837           3088.458915         
model.layers.11.mlp.experts.33.down_proj      torch.Size([0, 2048])          12.121024            12.538671            621.624242           3132.561455         
model.layers.11.mlp.experts.34.gate_proj      torch.Size([0, 1408])          11.230912            11.647940            621.621895           3274.651509         
model.layers.11.mlp.experts.34.act_fn         torch.Size([0, 1408])          0.312256             0.705719             621.568000           3261.888000         
model.layers.11.mlp.experts.34.up_proj        torch.Size([0, 1408])          14.891520            15.287161            617.777951           3324.261463         
model.layers.11.mlp.experts.34.down_proj      torch.Size([0, 2048])          10.999968            11.402845            621.568000           3242.252606         
model.layers.11.mlp.experts.35.gate_proj      torch.Size([1, 1408])          11.680512            12.088299            621.568000           3170.202947         
model.layers.11.mlp.experts.35.act_fn         torch.Size([1, 1408])          0.334400             0.723124             621.568000           3417.216000         
model.layers.11.mlp.experts.35.up_proj        torch.Size([1, 1408])          12.510080            12.894869            621.568000           3187.437314         
model.layers.11.mlp.experts.35.down_proj      torch.Size([1, 2048])          11.526720            11.919260            621.568000           3120.469970         
model.layers.11.mlp.experts.36.gate_proj      torch.Size([0, 1408])          10.299904            10.730982            621.525333           3374.576941         
model.layers.11.mlp.experts.36.act_fn         torch.Size([0, 1408])          0.306816             0.663757             621.568000           3106.560000         
model.layers.11.mlp.experts.36.up_proj        torch.Size([0, 1408])          12.318624            12.696266            621.522824           3412.760471         
model.layers.11.mlp.experts.36.down_proj      torch.Size([0, 2048])          10.665152            11.066437            621.509818           3557.125333         
model.layers.11.mlp.experts.37.gate_proj      torch.Size([1, 1408])          11.103808            11.573792            621.568000           3191.010607         
model.layers.11.mlp.experts.37.act_fn         torch.Size([1, 1408])          0.352640             0.772476             621.568000           3106.560000         
model.layers.11.mlp.experts.37.up_proj        torch.Size([1, 1408])          12.060864            12.469769            621.568000           3124.055652         
model.layers.11.mlp.experts.37.down_proj      torch.Size([1, 2048])          13.011840            13.440609            621.568000           3175.368305         
model.layers.11.mlp.experts.38.gate_proj      torch.Size([0, 1408])          19.440928            19.911051            621.568000           3211.805767         
model.layers.11.mlp.experts.38.act_fn         torch.Size([0, 1408])          0.296192             0.658989             621.568000           3572.544000         
model.layers.11.mlp.experts.38.up_proj        torch.Size([0, 1408])          12.649056            13.056755            561.509859           3188.574197         
model.layers.11.mlp.experts.38.down_proj      torch.Size([0, 2048])          10.396064            10.806561            598.659606           3107.732732         
model.layers.11.mlp.experts.39.gate_proj      torch.Size([1, 1408])          12.403232            12.900829            607.509634           2997.201577         
model.layers.11.mlp.experts.39.act_fn         torch.Size([1, 1408])          0.369312             0.787735             621.568000           3184.224000         
model.layers.11.mlp.experts.39.up_proj        torch.Size([1, 1408])          19.216673            19.613981            621.568000           3127.039066         
model.layers.11.mlp.experts.39.down_proj      torch.Size([1, 2048])          13.220320            13.622046            621.568000           3287.658331         
model.layers.11.mlp.experts.40.gate_proj      torch.Size([0, 1408])          15.295520            15.771627            621.519842           3329.802139         
model.layers.11.mlp.experts.40.act_fn         torch.Size([0, 1408])          0.398272             0.851393             621.568000           3261.888000         
model.layers.11.mlp.experts.40.up_proj        torch.Size([0, 1408])          26.068544            26.608706            621.495138           3544.859077         
model.layers.11.mlp.experts.40.down_proj      torch.Size([0, 2048])          16.522593            17.019510            621.568000           3259.671000         
model.layers.11.mlp.experts.41.gate_proj      torch.Size([0, 1408])          13.268096            13.885260            621.568000           3152.354198         
model.layers.11.mlp.experts.41.act_fn         torch.Size([0, 1408])          0.388576             0.852108             621.568000           3261.888000         
model.layers.11.mlp.experts.41.up_proj        torch.Size([0, 1408])          11.829536            12.282848            621.586885           3146.928262         
model.layers.11.mlp.experts.41.down_proj      torch.Size([0, 2048])          10.208192            10.674477            621.606280           3126.169720         
model.layers.11.mlp.experts.42.gate_proj      torch.Size([1, 1408])          9.812960             10.274649            621.568000           3340.889067         
model.layers.11.mlp.experts.42.act_fn         torch.Size([1, 1408])          0.411712             0.800371             621.568000           3106.560000         
model.layers.11.mlp.experts.42.up_proj        torch.Size([1, 1408])          11.333184            11.738300            621.568000           3241.773583         
model.layers.11.mlp.experts.42.down_proj      torch.Size([1, 2048])          13.433248            13.845682            621.568000           3185.900201         
model.layers.11.mlp.experts.43.gate_proj      torch.Size([0, 1408])          10.628128            11.038303            621.568000           3154.568421         
model.layers.11.mlp.experts.43.act_fn         torch.Size([0, 1408])          0.306464             0.698805             621.568000           3261.888000         
model.layers.11.mlp.experts.43.up_proj        torch.Size([0, 1408])          10.886944            11.283636            621.568000           3290.567111         
model.layers.11.mlp.experts.43.down_proj      torch.Size([0, 2048])          12.465824            12.875319            621.701120           3152.157696         
model.layers.11.mlp.experts.44.gate_proj      torch.Size([1, 1408])          12.201632            12.619257            619.349333           3244.746894         
model.layers.11.mlp.experts.44.act_fn         torch.Size([1, 1408])          0.391712             0.775099             621.312000           4036.864000         
model.layers.11.mlp.experts.44.up_proj        torch.Size([1, 1408])          9.984288             10.401011            621.528615           3444.643804         
model.layers.11.mlp.experts.44.down_proj      torch.Size([1, 2048])          12.689920            13.087273            621.568000           3088.131531         
model.layers.11.mlp.experts.45.gate_proj      torch.Size([0, 1408])          11.093216            11.562824            621.580444           3084.588889         
model.layers.11.mlp.experts.45.act_fn         torch.Size([0, 1408])          0.315104             0.683784             621.696000           3030.144000         
model.layers.11.mlp.experts.45.up_proj        torch.Size([0, 1408])          9.704096             10.095596            602.462426           3273.884328         
model.layers.11.mlp.experts.45.down_proj      torch.Size([0, 2048])          11.311616            11.934996            593.241693           3234.396496         
model.layers.11.mlp.experts.46.gate_proj      torch.Size([0, 1408])          11.028160            11.447668            621.612271           3198.358617         
model.layers.11.mlp.experts.46.act_fn         torch.Size([0, 1408])          0.313216             0.670910             621.568000           3107.840000         
model.layers.11.mlp.experts.46.up_proj        torch.Size([0, 1408])          12.336352            12.724161            578.528234           3174.276204         
model.layers.11.mlp.experts.46.down_proj      torch.Size([0, 2048])          10.086496            10.474682            621.595279           3141.777836         
model.layers.11.mlp.experts.47.gate_proj      torch.Size([0, 1408])          9.862400             10.270357            616.917333           3186.216242         
model.layers.11.mlp.experts.47.act_fn         torch.Size([0, 1408])          0.308544             0.684500             621.568000           3417.216000         
model.layers.11.mlp.experts.47.up_proj        torch.Size([0, 1408])          10.022432            10.415554            602.732606           3267.186909         
model.layers.11.mlp.experts.47.down_proj      torch.Size([0, 2048])          10.961248            11.348724            611.052752           3278.759459         
model.layers.11.mlp.experts.48.gate_proj      torch.Size([1, 1408])          14.135360            14.548302            611.921214           3285.455007         
model.layers.11.mlp.experts.48.act_fn         torch.Size([1, 1408])          0.372928             0.745773             621.312000           3603.609600         
model.layers.11.mlp.experts.48.up_proj        torch.Size([1, 1408])          17.392736            17.815590            621.312000           3838.067789         
model.layers.11.mlp.experts.48.down_proj      torch.Size([1, 2048])          13.809728            14.279842            621.513532           3379.761021         
model.layers.11.mlp.experts.49.gate_proj      torch.Size([1, 1408])          18.637920            19.298315            621.514590           3374.638504         
model.layers.11.mlp.experts.49.act_fn         torch.Size([1, 1408])          0.693696             1.551867             621.568000           3106.560000         
model.layers.11.mlp.experts.49.up_proj        torch.Size([1, 1408])          21.012896            21.698236            621.539971           3362.907562         
model.layers.11.mlp.experts.49.down_proj      torch.Size([1, 2048])          20.483200            20.928860            621.568000           3252.685679         
model.layers.11.mlp.experts.50.gate_proj      torch.Size([0, 1408])          14.507680            14.983892            621.631072           3157.731246         
model.layers.11.mlp.experts.50.act_fn         torch.Size([0, 1408])          0.326016             0.771046             621.824000           2952.448000         
model.layers.11.mlp.experts.50.up_proj        torch.Size([0, 1408])          13.617024            14.029503            605.065771           3082.786198         
model.layers.11.mlp.experts.50.down_proj      torch.Size([0, 2048])          17.083263            17.487288            621.572339           3211.330169         
model.layers.11.mlp.experts.51.gate_proj      torch.Size([0, 1408])          12.573440            12.982607            613.211000           3182.669000         
model.layers.11.mlp.experts.51.act_fn         torch.Size([0, 1408])          0.307968             0.766277             621.568000           3572.544000         
model.layers.11.mlp.experts.51.up_proj        torch.Size([0, 1408])          9.794496             10.180235            579.782892           3207.677538         
model.layers.11.mlp.experts.51.down_proj      torch.Size([0, 2048])          14.915328            15.504122            621.568000           3151.599262         
model.layers.11.mlp.experts.52.gate_proj      torch.Size([0, 1408])          14.467456            14.949322            621.606603           3069.423746         
model.layers.11.mlp.experts.52.act_fn         torch.Size([0, 1408])          0.344736             0.788689             621.568000           3107.840000         
model.layers.11.mlp.experts.52.up_proj        torch.Size([0, 1408])          16.283104            16.776085            542.279948           3398.220967         
model.layers.11.mlp.experts.52.down_proj      torch.Size([0, 2048])          11.780896            12.247562            601.945500           3855.741500         
model.layers.11.mlp.experts.53.gate_proj      torch.Size([1, 1408])          10.523936            10.936022            621.511593           3479.002576         
model.layers.11.mlp.experts.53.act_fn         torch.Size([1, 1408])          0.369632             0.813246             621.568000           3261.888000         
model.layers.11.mlp.experts.53.up_proj        torch.Size([1, 1408])          10.815008            11.234522            621.635473           3128.654388         
model.layers.11.mlp.experts.53.down_proj      torch.Size([1, 2048])          13.384608            13.785124            621.659429           3039.350857         
model.layers.11.mlp.experts.54.gate_proj      torch.Size([1, 1408])          9.928704             10.373592            621.568000           3214.248471         
model.layers.11.mlp.experts.54.act_fn         torch.Size([1, 1408])          0.324992             0.702381             621.568000           3261.888000         
model.layers.11.mlp.experts.54.up_proj        torch.Size([1, 1408])          10.528896            10.991573            621.546827           3315.851068         
model.layers.11.mlp.experts.54.down_proj      torch.Size([1, 2048])          14.978432            15.372753            621.508776           3410.072836         
model.layers.11.mlp.experts.55.gate_proj      torch.Size([1, 1408])          20.816448            21.231413            621.568000           3249.137832         
model.layers.11.mlp.experts.55.act_fn         torch.Size([1, 1408])          0.364128             0.727892             621.568000           3300.720000         
model.layers.11.mlp.experts.55.up_proj        torch.Size([1, 1408])          25.446592            25.824070            621.696000           3115.139200         
model.layers.11.mlp.experts.55.down_proj      torch.Size([1, 2048])          13.860224            14.247656            621.568000           3072.905412         
model.layers.11.mlp.experts.56.gate_proj      torch.Size([0, 1408])          15.829888            16.262054            621.573908           3102.572308         
model.layers.11.mlp.experts.56.act_fn         torch.Size([0, 1408])          0.298656             0.656605             621.568000           3417.216000         
model.layers.11.mlp.experts.56.up_proj        torch.Size([0, 1408])          12.216640            12.623072            604.590636           3743.049426         
model.layers.11.mlp.experts.56.down_proj      torch.Size([0, 2048])          13.863648            14.268637            598.340299           3478.806925         
model.layers.11.mlp.experts.57.gate_proj      torch.Size([0, 1408])          17.414272            17.852783            609.334425           3241.615118         
model.layers.11.mlp.experts.57.act_fn         torch.Size([0, 1408])          0.293024             0.678062             621.568000           3107.840000         
model.layers.11.mlp.experts.57.up_proj        torch.Size([0, 1408])          10.715296            11.093140            612.284632           3194.907910         
model.layers.11.mlp.experts.57.down_proj      torch.Size([0, 2048])          9.718944             10.103464            621.719935           3064.549984         
model.layers.11.mlp.experts.58.gate_proj      torch.Size([0, 1408])          13.020832            13.445139            621.714853           3137.401054         
model.layers.11.mlp.experts.58.act_fn         torch.Size([0, 1408])          0.316192             0.778913             621.568000           3261.888000         
model.layers.11.mlp.experts.58.up_proj        torch.Size([0, 1408])          10.419488            10.809422            599.885395           3270.016000         
model.layers.11.mlp.experts.58.down_proj      torch.Size([0, 2048])          9.323872             9.725809             613.466466           3224.187188         
model.layers.11.mlp.experts.59.gate_proj      torch.Size([0, 1408])          10.627840            11.038542            600.879407           3141.027081         
model.layers.11.mlp.experts.59.act_fn         torch.Size([0, 1408])          0.339712             0.713348             621.568000           3417.216000         
model.layers.11.mlp.experts.59.up_proj        torch.Size([0, 1408])          11.659104            12.041569            589.600000           3119.104000         
model.layers.11.mlp.experts.59.down_proj      torch.Size([0, 2048])          12.564576            12.964487            621.568000           3133.744246         
model.layers.11.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          34.839424            35.202742            715.213971           3555.464684         
model.layers.11.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.371584             0.786304             776.640000           3532.256000         
model.layers.11.mlp.shared_expert.up_proj     torch.Size([5, 5632])          35.425858            35.749197            749.810618           3270.640291         
model.layers.11.mlp.shared_expert.down_proj   torch.Size([5, 2048])          37.599262            37.951469            756.325878           3301.814297         
model.layers.11.mlp.shared_expert_gate        torch.Size([5, 1])             7.509568             8.050680             643.328000           3387.356070         
model.layers.12.input_layernorm               torch.Size([1, 5, 2048])       6.392032             6.917477             523.474286           3288.602122         
model.layers.12.self_attn.q_proj              torch.Size([1, 5, 2048])       31.979296            32.417059            602.131545           3180.774323         
model.layers.12.self_attn.k_proj              torch.Size([1, 5, 2048])       36.807327            37.264347            621.574919           3175.102616         
model.layers.12.self_attn.v_proj              torch.Size([1, 5, 2048])       27.731552            28.143406            621.568000           3465.501702         
model.layers.12.self_attn.o_proj              torch.Size([1, 5, 2048])       18.955135            19.397974            705.561023           3334.296541         
model.layers.12.post_attention_layernorm      torch.Size([1, 5, 2048])       7.098048             7.541180             638.869333           3248.370963         
model.layers.12.mlp.gate                      torch.Size([5, 60])            6.032224             6.448984             480.346746           2990.419104         
model.layers.12.mlp.experts.0.gate_proj       torch.Size([0, 1408])          15.545280            15.987635            592.928593           3126.724148         
model.layers.12.mlp.experts.0.act_fn          torch.Size([0, 1408])          0.310304             0.695944             621.568000           3107.840000         
model.layers.12.mlp.experts.0.up_proj         torch.Size([0, 1408])          18.322624            18.702745            621.586963           3292.477630         
model.layers.12.mlp.experts.0.down_proj       torch.Size([0, 2048])          20.638208            21.219254            621.563697           3285.770756         
model.layers.12.mlp.experts.1.gate_proj       torch.Size([1, 1408])          27.076960            27.735949            621.568000           3166.922338         
model.layers.12.mlp.experts.1.act_fn          torch.Size([1, 1408])          0.434560             0.866175             621.568000           3261.888000         
model.layers.12.mlp.experts.1.up_proj         torch.Size([1, 1408])          49.901249            50.358295            621.568000           3194.790588         
model.layers.12.mlp.experts.1.down_proj       torch.Size([1, 2048])          21.079008            21.565914            621.568000           3149.430519         
model.layers.12.mlp.experts.2.gate_proj       torch.Size([0, 1408])          28.980097            29.474497            621.584254           3167.505270         
model.layers.12.mlp.experts.2.act_fn          torch.Size([0, 1408])          0.499744             0.931978             621.568000           3572.544000         
model.layers.12.mlp.experts.2.up_proj         torch.Size([0, 1408])          21.334335            21.745443            609.453635           3221.923617         
model.layers.12.mlp.experts.2.down_proj       torch.Size([0, 2048])          58.131519            58.732510            594.606677           3662.142556         
model.layers.12.mlp.experts.3.gate_proj       torch.Size([0, 1408])          47.938240            48.607826            609.091270           3283.787679         
model.layers.12.mlp.experts.3.act_fn          torch.Size([0, 1408])          0.381184             0.817299             621.568000           3107.840000         
model.layers.12.mlp.experts.3.up_proj         torch.Size([0, 1408])          15.268352            15.744925            600.289548           3196.236387         
model.layers.12.mlp.experts.3.down_proj       torch.Size([0, 2048])          17.033855            17.521620            621.649541           3108.801896         
model.layers.12.mlp.experts.4.gate_proj       torch.Size([1, 1408])          25.232992            25.792360            621.568000           3227.103059         
model.layers.12.mlp.experts.4.act_fn          torch.Size([1, 1408])          0.535776             1.260996             621.568000           3261.888000         
model.layers.12.mlp.experts.4.up_proj         torch.Size([1, 1408])          18.434528            18.948317            621.548458           3282.491115         
model.layers.12.mlp.experts.4.down_proj       torch.Size([1, 2048])          22.972160            23.484707            621.568000           3228.905143         
model.layers.12.mlp.experts.5.gate_proj       torch.Size([0, 1408])          30.393791            31.107903            621.644800           3119.195733         
model.layers.12.mlp.experts.5.act_fn          torch.Size([0, 1408])          0.406080             0.827789             621.568000           3417.216000         
model.layers.12.mlp.experts.5.up_proj         torch.Size([0, 1408])          19.882145            20.318985            621.593405           3150.447878         
model.layers.12.mlp.experts.5.down_proj       torch.Size([0, 2048])          15.713408            16.168356            621.579378           3142.929067         
model.layers.12.mlp.experts.6.gate_proj       torch.Size([1, 1408])          14.560160            14.982224            621.592471           3271.161412         
model.layers.12.mlp.experts.6.act_fn          torch.Size([1, 1408])          0.347744             0.723362             621.568000           3106.560000         
model.layers.12.mlp.experts.6.up_proj         torch.Size([1, 1408])          21.896929            22.313833            621.436878           3572.322341         
model.layers.12.mlp.experts.6.down_proj       torch.Size([1, 2048])          18.847168            19.236803            621.586000           3333.602500         
model.layers.12.mlp.experts.7.gate_proj       torch.Size([0, 1408])          15.587072            16.007185            621.674835           3043.891402         
model.layers.12.mlp.experts.7.act_fn          torch.Size([0, 1408])          0.349472             0.727415             621.568000           3107.840000         
model.layers.12.mlp.experts.7.up_proj         torch.Size([0, 1408])          36.019169            36.444426            621.586432           3169.680384         
model.layers.12.mlp.experts.7.down_proj       torch.Size([0, 2048])          18.676289            19.126892            621.606857           3197.504571         
model.layers.12.mlp.experts.8.gate_proj       torch.Size([0, 1408])          23.359520            23.785114            606.202137           3180.932397         
model.layers.12.mlp.experts.8.act_fn          torch.Size([0, 1408])          0.309216             0.704050             621.568000           3572.544000         
model.layers.12.mlp.experts.8.up_proj         torch.Size([0, 1408])          31.440063            31.858683            588.190678           3277.813950         
model.layers.12.mlp.experts.8.down_proj       torch.Size([0, 2048])          23.639551            24.280071            615.852563           3164.885333         
model.layers.12.mlp.experts.9.gate_proj       torch.Size([0, 1408])          40.540703            41.231871            605.583059           3130.366118         
model.layers.12.mlp.experts.9.act_fn          torch.Size([0, 1408])          0.424256             0.885725             621.568000           3107.840000         
model.layers.12.mlp.experts.9.up_proj         torch.Size([0, 1408])          33.306721            33.876657            586.273455           3159.359030         
model.layers.12.mlp.experts.9.down_proj       torch.Size([0, 2048])          21.717665            22.281170            621.618000           3252.510000         
model.layers.12.mlp.experts.10.gate_proj      torch.Size([0, 1408])          68.690109            69.184542            587.233371           3231.381943         
model.layers.12.mlp.experts.10.act_fn         torch.Size([0, 1408])          0.396800             0.936031             621.568000           3520.768000         
model.layers.12.mlp.experts.10.up_proj        torch.Size([0, 1408])          91.983101            92.490435            555.610245           3535.667568         
model.layers.12.mlp.experts.10.down_proj      torch.Size([0, 2048])          72.022079            72.507620            584.174752           3171.166865         
model.layers.12.mlp.experts.11.gate_proj      torch.Size([0, 1408])          107.029022           107.660770           578.520889           3089.127111         
model.layers.12.mlp.experts.11.act_fn         torch.Size([0, 1408])          0.388512             0.808239             621.568000           3262.784000         
model.layers.12.mlp.experts.11.up_proj        torch.Size([0, 1408])          100.106941           100.558758           558.381037           3162.669985         
model.layers.12.mlp.experts.11.down_proj      torch.Size([0, 2048])          167.424576           167.918205           573.293115           3166.052721         
model.layers.12.mlp.experts.12.gate_proj      torch.Size([0, 1408])          138.718399           139.540911           573.099973           3106.573932         
model.layers.12.mlp.experts.12.act_fn         torch.Size([0, 1408])          0.610400             1.396418             621.568000           3417.216000         
model.layers.12.mlp.experts.12.up_proj        torch.Size([0, 1408])          110.561951           111.449480           554.227641           3041.302510         
model.layers.12.mlp.experts.12.down_proj      torch.Size([0, 2048])          94.732162            95.395565            577.363592           3026.398476         
model.layers.12.mlp.experts.13.gate_proj      torch.Size([0, 1408])          39.375458            40.744305            580.052617           3029.622550         
model.layers.12.mlp.experts.13.act_fn         torch.Size([0, 1408])          0.005856             1.456499             621.568000           3262.784000         
model.layers.12.mlp.experts.13.up_proj        torch.Size([0, 1408])          30.120735            31.480074            569.437431           3212.609401         
model.layers.12.mlp.experts.13.down_proj      torch.Size([0, 2048])          25.548864            26.782513            577.800812           3128.731362         
model.layers.12.mlp.experts.14.gate_proj      torch.Size([0, 1408])          43.407200            44.735193            539.422166           3341.435924         
model.layers.12.mlp.experts.14.act_fn         torch.Size([0, 1408])          0.005664             1.266241             517.760000           3881.600000         
model.layers.12.mlp.experts.14.up_proj        torch.Size([0, 1408])          54.832031            56.099892            515.248608           3742.066228         
model.layers.12.mlp.experts.14.down_proj      torch.Size([0, 2048])          49.966270            51.251411            581.969214           3221.628469         
model.layers.12.mlp.experts.15.gate_proj      torch.Size([1, 1408])          34.977631            36.337614            596.946538           3226.900745         
model.layers.12.mlp.experts.15.act_fn         torch.Size([1, 1408])          0.056096             1.301527             621.568000           3107.840000         
model.layers.12.mlp.experts.15.up_proj        torch.Size([1, 1408])          40.526463            41.807175            621.592889           3257.959556         
model.layers.12.mlp.experts.15.down_proj      torch.Size([1, 2048])          34.145824            35.986185            621.599347           3132.422966         
model.layers.12.mlp.experts.16.gate_proj      torch.Size([0, 1408])          29.550207            30.906200            621.642583           3027.085102         
model.layers.12.mlp.experts.16.act_fn         torch.Size([0, 1408])          0.005728             1.325369             621.696000           3107.840000         
model.layers.12.mlp.experts.16.up_proj        torch.Size([0, 1408])          22.142784            23.437262            575.744485           3087.827394         
model.layers.12.mlp.experts.16.down_proj      torch.Size([0, 2048])          39.164448            40.438890            590.099729           3211.033985         
model.layers.12.mlp.experts.17.gate_proj      torch.Size([1, 1408])          41.515041            42.866945            595.712464           3350.191768         
model.layers.12.mlp.experts.17.act_fn         torch.Size([1, 1408])          0.055936             1.324177             621.312000           3727.872000         
model.layers.12.mlp.experts.17.up_proj        torch.Size([1, 1408])          38.789185            40.001154            621.560686           3421.701943         
model.layers.12.mlp.experts.17.down_proj      torch.Size([1, 2048])          39.082817            40.743351            621.571391           3168.704424         
model.layers.12.mlp.experts.18.gate_proj      torch.Size([0, 1408])          38.810944            40.330887            612.695089           3362.357873         
model.layers.12.mlp.experts.18.act_fn         torch.Size([0, 1408])          0.005664             1.351595             621.312000           4036.864000         
model.layers.12.mlp.experts.18.up_proj        torch.Size([0, 1408])          35.030113            36.372423            539.644580           3676.645618         
model.layers.12.mlp.experts.18.down_proj      torch.Size([0, 2048])          74.559166            75.977802            581.427021           3276.520727         
model.layers.12.mlp.experts.19.gate_proj      torch.Size([0, 1408])          49.439617            51.027775            580.064000           3196.902761         
model.layers.12.mlp.experts.19.act_fn         torch.Size([0, 1408])          0.005600             1.330376             621.696000           3107.840000         
model.layers.12.mlp.experts.19.up_proj        torch.Size([0, 1408])          59.979458            61.422348            549.872000           3155.577697         
model.layers.12.mlp.experts.19.down_proj      torch.Size([0, 2048])          47.822784            49.237251            587.770141           3087.000789         
model.layers.12.mlp.experts.20.gate_proj      torch.Size([0, 1408])          72.491234            73.189497            561.497239           3131.469070         
model.layers.12.mlp.experts.20.act_fn         torch.Size([0, 1408])          0.597952             1.323700             621.568000           3261.888000         
model.layers.12.mlp.experts.20.up_proj        torch.Size([0, 1408])          84.403938            85.031271            561.390806           3239.542448         
model.layers.12.mlp.experts.20.down_proj      torch.Size([0, 2048])          75.128510            75.826406            579.767376           3220.941163         
model.layers.12.mlp.experts.21.gate_proj      torch.Size([0, 1408])          37.591167            38.283587            579.718919           3065.660108         
model.layers.12.mlp.experts.21.act_fn         torch.Size([0, 1408])          0.371104             0.822306             621.568000           3263.232000         
model.layers.12.mlp.experts.21.up_proj        torch.Size([0, 1408])          94.176483            94.831467            565.071568           3032.547027         
model.layers.12.mlp.experts.21.down_proj      torch.Size([0, 2048])          70.938591            71.360588            576.518809           3151.594213         
model.layers.12.mlp.experts.22.gate_proj      torch.Size([0, 1408])          62.775490            63.434124            514.228026           3728.609858         
model.layers.12.mlp.experts.22.act_fn         torch.Size([0, 1408])          0.355072             0.755548             517.546667           4502.656000         
model.layers.12.mlp.experts.22.up_proj        torch.Size([0, 1408])          62.848831            63.209057            536.675858           3568.697191         
model.layers.12.mlp.experts.22.down_proj      torch.Size([0, 2048])          96.734818            97.310305            580.182281           3196.201719         
model.layers.12.mlp.experts.23.gate_proj      torch.Size([1, 1408])          118.281891           119.112730           599.656216           3063.595676         
model.layers.12.mlp.experts.23.act_fn         torch.Size([1, 1408])          0.732800             1.467705             621.568000           3261.888000         
model.layers.12.mlp.experts.23.up_proj        torch.Size([1, 1408])          67.732765            68.575621            621.728865           3079.190486         
model.layers.12.mlp.experts.23.down_proj      torch.Size([1, 2048])          55.699711            56.526184            621.573731           3184.028179         
model.layers.12.mlp.experts.24.gate_proj      torch.Size([1, 1408])          48.193665            49.030781            621.543946           3266.377450         
model.layers.12.mlp.experts.24.act_fn         torch.Size([1, 1408])          0.583936             1.218081             621.568000           3184.224000         
model.layers.12.mlp.experts.24.up_proj        torch.Size([1, 1408])          82.342751            83.080292            621.568000           3159.323717         
model.layers.12.mlp.experts.24.down_proj      torch.Size([1, 2048])          84.006401            84.690094            621.566259           3094.066939         
model.layers.12.mlp.experts.25.gate_proj      torch.Size([1, 1408])          99.220963            99.718094            621.562703           3082.992993         
model.layers.12.mlp.experts.25.act_fn         torch.Size([1, 1408])          0.424800             0.811815             621.568000           3106.560000         
model.layers.12.mlp.experts.25.up_proj        torch.Size([1, 1408])          93.959549            94.538212            621.562182           3239.698909         
model.layers.12.mlp.experts.25.down_proj      torch.Size([1, 2048])          72.305794            73.061943            621.474909           3332.630378         
model.layers.12.mlp.experts.26.gate_proj      torch.Size([0, 1408])          57.498337            58.140278            605.683038           3700.595443         
model.layers.12.mlp.experts.26.act_fn         torch.Size([0, 1408])          1.036416             1.697779             621.312000           3844.368000         
model.layers.12.mlp.experts.26.up_proj        torch.Size([0, 1408])          63.683712            64.178705            549.756910           3409.796855         
model.layers.12.mlp.experts.26.down_proj      torch.Size([0, 2048])          64.908195            65.592527            574.112444           3124.758222         
model.layers.12.mlp.experts.27.gate_proj      torch.Size([1, 1408])          107.965538           108.793020           593.333818           3265.815758         
model.layers.12.mlp.experts.27.act_fn         torch.Size([1, 1408])          0.628096             1.383066             621.568000           3261.888000         
model.layers.12.mlp.experts.27.up_proj        torch.Size([1, 1408])          61.692322            62.438488            621.542761           3285.193915         
model.layers.12.mlp.experts.27.down_proj      torch.Size([1, 2048])          66.124031            66.827536            621.568000           3157.310703         
model.layers.12.mlp.experts.28.gate_proj      torch.Size([0, 1408])          107.102371           107.733488           621.620603           3070.880438         
model.layers.12.mlp.experts.28.act_fn         torch.Size([0, 1408])          1.120832             1.895428             621.568000           3106.560000         
model.layers.12.mlp.experts.28.up_proj        torch.Size([0, 1408])          106.795555           107.494831           564.457333           3072.799556         
model.layers.12.mlp.experts.28.down_proj      torch.Size([0, 2048])          90.719261            91.452360            582.531133           3159.379245         
model.layers.12.mlp.experts.29.gate_proj      torch.Size([0, 1408])          97.095039            97.665071            564.247188           3155.733333         
model.layers.12.mlp.experts.29.act_fn         torch.Size([0, 1408])          0.364896             0.743628             621.568000           3261.888000         
model.layers.12.mlp.experts.29.up_proj        torch.Size([0, 1408])          81.960289            82.316160            531.355783           3011.181147         
model.layers.12.mlp.experts.29.down_proj      torch.Size([0, 2048])          64.507072            65.033913            590.993127           3176.237972         
model.layers.12.mlp.experts.30.gate_proj      torch.Size([0, 1408])          69.233406            69.641590            511.173302           3666.039669         
model.layers.12.mlp.experts.30.act_fn         torch.Size([0, 1408])          0.559008             1.248360             621.312000           3881.600000         
model.layers.12.mlp.experts.30.up_proj        torch.Size([0, 1408])          87.257088            87.847471            544.875368           3479.620632         
model.layers.12.mlp.experts.30.down_proj      torch.Size([0, 2048])          112.905571           113.512039           558.624464           3171.445333         
model.layers.12.mlp.experts.31.gate_proj      torch.Size([0, 1408])          80.923904            81.456661            573.798575           3182.905863         
model.layers.12.mlp.experts.31.act_fn         torch.Size([0, 1408])          0.397504             0.851393             621.568000           3313.664000         
model.layers.12.mlp.experts.31.up_proj        torch.Size([0, 1408])          79.794563            80.267668            558.930225           3068.386331         
model.layers.12.mlp.experts.31.down_proj      torch.Size([0, 2048])          89.345505            89.881420            572.047238           2994.548680         
model.layers.12.mlp.experts.32.gate_proj      torch.Size([0, 1408])          83.030273            83.467007            584.743385           3101.102098         
model.layers.12.mlp.experts.32.act_fn         torch.Size([0, 1408])          0.579040             1.344919             621.568000           3572.544000         
model.layers.12.mlp.experts.32.up_proj        torch.Size([0, 1408])          84.386307            85.003138            566.852507           3192.799099         
model.layers.12.mlp.experts.32.down_proj      torch.Size([0, 2048])          79.034943            79.508066            578.101706           3286.156084         
model.layers.12.mlp.experts.33.gate_proj      torch.Size([1, 1408])          78.835548            79.370499            604.302222           3129.799585         
model.layers.12.mlp.experts.33.act_fn         torch.Size([1, 1408])          0.454880             0.882864             621.568000           2951.536000         
model.layers.12.mlp.experts.33.up_proj        torch.Size([1, 1408])          80.900833            81.461668            621.596845           3089.345352         
model.layers.12.mlp.experts.33.down_proj      torch.Size([1, 2048])          83.307106            83.886623            621.584954           3129.492768         
model.layers.12.mlp.experts.34.gate_proj      torch.Size([0, 1408])          83.658691            84.121466            611.371077           3854.188718         
model.layers.12.mlp.experts.34.act_fn         torch.Size([0, 1408])          0.626976             1.386166             621.312000           3726.848000         
model.layers.12.mlp.experts.34.up_proj        torch.Size([0, 1408])          86.346367            87.043047            555.219692           3548.628587         
model.layers.12.mlp.experts.34.down_proj      torch.Size([0, 2048])          87.210014            87.805986            571.646629           3151.527314         
model.layers.12.mlp.experts.35.gate_proj      torch.Size([1, 1408])          89.707840            90.627909            596.082743           3082.586971         
model.layers.12.mlp.experts.35.act_fn         torch.Size([1, 1408])          0.639680             1.278877             621.568000           3106.560000         
model.layers.12.mlp.experts.35.up_proj        torch.Size([1, 1408])          84.690018            85.438251            621.609796           3103.731810         
model.layers.12.mlp.experts.35.down_proj      torch.Size([1, 2048])          83.550140            84.275723            621.586156           3184.090326         
model.layers.12.mlp.experts.36.gate_proj      torch.Size([0, 1408])          88.838722            89.529276            621.633778           3217.004444         
model.layers.12.mlp.experts.36.act_fn         torch.Size([0, 1408])          0.895616             1.492023             621.568000           3261.888000         
model.layers.12.mlp.experts.36.up_proj        torch.Size([0, 1408])          84.634018            84.985018            556.108800           3154.915657         
model.layers.12.mlp.experts.36.down_proj      torch.Size([0, 2048])          78.533890            79.082489            583.111699           3057.146226         
model.layers.12.mlp.experts.37.gate_proj      torch.Size([1, 1408])          80.740639            81.316948            600.076291           3015.879205         
model.layers.12.mlp.experts.37.act_fn         torch.Size([1, 1408])          0.465664             0.889778             621.568000           3106.560000         
model.layers.12.mlp.experts.37.up_proj        torch.Size([1, 1408])          79.128609            79.596996            621.630171           3116.261029         
model.layers.12.mlp.experts.37.down_proj      torch.Size([1, 2048])          80.079041            80.530643            621.524114           3288.815086         
model.layers.12.mlp.experts.38.gate_proj      torch.Size([0, 1408])          83.615074            84.281921            564.260335           3785.441445         
model.layers.12.mlp.experts.38.act_fn         torch.Size([0, 1408])          1.526336             2.378702             569.536000           3881.600000         
model.layers.12.mlp.experts.38.up_proj        torch.Size([0, 1408])          82.993149            83.552837            539.088980           3373.372082         
model.layers.12.mlp.experts.38.down_proj      torch.Size([0, 2048])          85.107582            85.747242            568.093746           3048.528676         
model.layers.12.mlp.experts.39.gate_proj      torch.Size([1, 1408])          87.187714            88.032007            598.374313           3069.536218         
model.layers.12.mlp.experts.39.act_fn         torch.Size([1, 1408])          0.652288             1.376390             621.568000           3572.544000         
model.layers.12.mlp.experts.39.up_proj        torch.Size([1, 1408])          83.106300            83.729982            621.610082           3168.113534         
model.layers.12.mlp.experts.39.down_proj      torch.Size([1, 2048])          80.578720            81.226826            621.547789           3241.674105         
model.layers.12.mlp.experts.40.gate_proj      torch.Size([1, 1408])          84.671234            85.513115            621.568000           3129.848320         
model.layers.12.mlp.experts.40.act_fn         torch.Size([1, 1408])          0.557984             1.212835             621.568000           3261.888000         
model.layers.12.mlp.experts.40.up_proj        torch.Size([1, 1408])          82.559395            83.116293            621.568000           3117.780000         
model.layers.12.mlp.experts.40.down_proj      torch.Size([1, 2048])          78.498428            78.978300            621.619200           3100.908308         
model.layers.12.mlp.experts.41.gate_proj      torch.Size([0, 1408])          80.005539            80.437422            621.568000           3211.330500         
model.layers.12.mlp.experts.41.act_fn         torch.Size([0, 1408])          0.511776             1.137018             621.568000           3107.840000         
model.layers.12.mlp.experts.41.up_proj        torch.Size([0, 1408])          81.764931            82.262516            565.870901           3235.231267         
model.layers.12.mlp.experts.41.down_proj      torch.Size([0, 2048])          80.140770            80.598354            559.919660           3161.140199         
model.layers.12.mlp.experts.42.gate_proj      torch.Size([1, 1408])          83.684799            84.429502            565.295897           3604.003923         
model.layers.12.mlp.experts.42.act_fn         torch.Size([1, 1408])          0.658784             1.459360             621.312000           4130.022400         
model.layers.12.mlp.experts.42.up_proj        torch.Size([1, 1408])          89.954048            90.740681            614.324132           3507.542464         
model.layers.12.mlp.experts.42.down_proj      torch.Size([1, 2048])          87.683395            88.508606            621.620321           3185.213664         
model.layers.12.mlp.experts.43.gate_proj      torch.Size([1, 1408])          86.089981            86.826324            621.564493           3248.544000         
model.layers.12.mlp.experts.43.act_fn         torch.Size([1, 1408])          0.637120             1.435280             621.568000           3261.888000         
model.layers.12.mlp.experts.43.up_proj        torch.Size([1, 1408])          84.825470            85.563183            621.646367           3146.225197         
model.layers.12.mlp.experts.43.down_proj      torch.Size([1, 2048])          84.725761            85.336685            621.688371           3056.963391         
model.layers.12.mlp.experts.44.gate_proj      torch.Size([0, 1408])          85.002724            85.546970            621.723366           2959.870234         
model.layers.12.mlp.experts.44.act_fn         torch.Size([0, 1408])          0.613056             1.454830             621.568000           3107.840000         
model.layers.12.mlp.experts.44.up_proj        torch.Size([0, 1408])          81.862946            82.560539            541.870904           3128.760986         
model.layers.12.mlp.experts.44.down_proj      torch.Size([0, 2048])          77.932579            78.572273            567.000789           3131.616451         
model.layers.12.mlp.experts.45.gate_proj      torch.Size([0, 1408])          80.575935            80.958128            562.797021           3081.989297         
model.layers.12.mlp.experts.45.act_fn         torch.Size([0, 1408])          0.500448             1.073122             621.568000           3417.216000         
model.layers.12.mlp.experts.45.up_proj        torch.Size([0, 1408])          83.738045            84.159374            543.539544           3051.495087         
model.layers.12.mlp.experts.45.down_proj      torch.Size([0, 2048])          81.973793            82.561255            567.461260           3037.518027         
model.layers.12.mlp.experts.46.gate_proj      torch.Size([0, 1408])          85.155167            85.624695            471.078318           3589.104917         
model.layers.12.mlp.experts.46.act_fn         torch.Size([0, 1408])          0.537344             1.174450             465.792000           4606.165333         
model.layers.12.mlp.experts.46.up_proj        torch.Size([0, 1408])          85.441917            85.980415            485.768901           3573.017854         
model.layers.12.mlp.experts.46.down_proj      torch.Size([0, 2048])          80.725601            81.128359            517.391543           3167.628800         
model.layers.12.mlp.experts.47.gate_proj      torch.Size([0, 1408])          84.406914            85.255146            553.757000           3083.527000         
model.layers.12.mlp.experts.47.act_fn         torch.Size([0, 1408])          0.581632             1.301527             621.568000           3365.440000         
model.layers.12.mlp.experts.47.up_proj        torch.Size([0, 1408])          82.881348            83.445311            545.100800           3031.179947         
model.layers.12.mlp.experts.47.down_proj      torch.Size([0, 2048])          86.712158            87.344885            549.948028           3040.324855         
model.layers.12.mlp.experts.48.gate_proj      torch.Size([0, 1408])          82.676033            83.181620            573.038222           3178.914667         
model.layers.12.mlp.experts.48.act_fn         torch.Size([0, 1408])          0.444480             1.250029             621.824000           3004.245333         
model.layers.12.mlp.experts.48.up_proj        torch.Size([0, 1408])          79.532829            80.056429            560.742490           3246.365986         
model.layers.12.mlp.experts.48.down_proj      torch.Size([0, 2048])          77.900291            78.317881            571.645315           3081.713231         
model.layers.12.mlp.experts.49.gate_proj      torch.Size([0, 1408])          85.877441            86.491108            570.925778           3035.539556         
model.layers.12.mlp.experts.49.act_fn         torch.Size([0, 1408])          0.758784             1.549482             621.632000           2952.448000         
model.layers.12.mlp.experts.49.up_proj        torch.Size([0, 1408])          83.508385            84.050417            552.586667           3034.460444         
model.layers.12.mlp.experts.49.down_proj      torch.Size([0, 2048])          87.038849            87.683916            565.253215           3191.183170         
model.layers.12.mlp.experts.50.gate_proj      torch.Size([0, 1408])          83.172798            83.858967            508.149333           3651.031111         
model.layers.12.mlp.experts.50.act_fn         torch.Size([0, 1408])          0.308128             0.688791             517.760000           4347.392000         
model.layers.12.mlp.experts.50.up_proj        torch.Size([0, 1408])          79.228416            79.685926            496.997722           3716.134993         
model.layers.12.mlp.experts.50.down_proj      torch.Size([0, 2048])          80.116196            80.610514            559.484910           3100.273434         
model.layers.12.mlp.experts.51.gate_proj      torch.Size([1, 1408])          86.433441            87.018013            590.611627           3046.640640         
model.layers.12.mlp.experts.51.act_fn         torch.Size([1, 1408])          0.615488             1.342535             621.568000           3106.880000         
model.layers.12.mlp.experts.51.up_proj        torch.Size([1, 1408])          85.600960            86.267471            621.661091           3166.967049         
model.layers.12.mlp.experts.51.down_proj      torch.Size([1, 2048])          84.331940            85.281849            621.652757           3163.954595         
model.layers.12.mlp.experts.52.gate_proj      torch.Size([0, 1408])          83.008926            83.476067            621.692343           3104.112000         
model.layers.12.mlp.experts.52.act_fn         torch.Size([0, 1408])          0.619552             1.292467             621.568000           3263.232000         
model.layers.12.mlp.experts.52.up_proj        torch.Size([0, 1408])          82.247421            82.844973            552.162462           3095.820979         
model.layers.12.mlp.experts.52.down_proj      torch.Size([0, 2048])          77.256798            77.819824            574.585379           3034.818207         
model.layers.12.mlp.experts.53.gate_proj      torch.Size([1, 1408])          84.186623            84.927797            587.444083           3072.278069         
model.layers.12.mlp.experts.53.act_fn         torch.Size([1, 1408])          0.716832             1.488686             621.568000           3533.712000         
model.layers.12.mlp.experts.53.up_proj        torch.Size([1, 1408])          83.655266            84.489346            621.708108           3118.042378         
model.layers.12.mlp.experts.53.down_proj      torch.Size([1, 2048])          85.231331            85.999727            621.568000           3250.104497         
model.layers.12.mlp.experts.54.gate_proj      torch.Size([1, 1408])          85.746239            86.440086            619.479748           3617.925635         
model.layers.12.mlp.experts.54.act_fn         torch.Size([1, 1408])          0.397984             0.776052             621.056000           4386.208000         
model.layers.12.mlp.experts.54.up_proj        torch.Size([1, 1408])          84.072159            84.525585            598.601816           3619.003681         
model.layers.12.mlp.experts.54.down_proj      torch.Size([1, 2048])          81.262016            82.510233            621.619532           3113.523117         
model.layers.12.mlp.experts.55.gate_proj      torch.Size([0, 1408])          85.159843            85.767984            621.739243           3028.809514         
model.layers.12.mlp.experts.55.act_fn         torch.Size([0, 1408])          0.589024             1.381159             621.568000           3727.872000         
model.layers.12.mlp.experts.55.up_proj        torch.Size([0, 1408])          82.704063            83.223820            542.272448           3223.852755         
model.layers.12.mlp.experts.55.down_proj      torch.Size([0, 2048])          80.979485            81.588745            572.014752           3137.526014         
model.layers.12.mlp.experts.56.gate_proj      torch.Size([0, 1408])          83.463295            83.895206            573.850853           3061.113734         
model.layers.12.mlp.experts.56.act_fn         torch.Size([0, 1408])          0.592000             1.311064             544.096000           2797.056000         
model.layers.12.mlp.experts.56.up_proj        torch.Size([0, 1408])          103.956131           104.666233           536.642630           2967.380164         
model.layers.12.mlp.experts.56.down_proj      torch.Size([0, 2048])          143.874023           144.259930           565.085714           3162.774400         
model.layers.12.mlp.experts.57.gate_proj      torch.Size([0, 1408])          138.813126           139.233351           552.448877           3143.805808         
model.layers.12.mlp.experts.57.act_fn         torch.Size([0, 1408])          0.352480             0.825644             621.568000           3107.840000         
model.layers.12.mlp.experts.57.up_proj        torch.Size([0, 1408])          155.919586           156.291723           539.303642           3117.085612         
model.layers.12.mlp.experts.57.down_proj      torch.Size([0, 2048])          136.952667           137.410641           546.743049           3016.560783         
model.layers.12.mlp.experts.58.gate_proj      torch.Size([1, 1408])          144.561157           145.306587           548.581783           3251.939084         
model.layers.12.mlp.experts.58.act_fn         torch.Size([1, 1408])          0.669280             1.269817             621.312000           3998.048000         
model.layers.12.mlp.experts.58.up_proj        torch.Size([1, 1408])          129.818726           130.339146           591.870822           3715.940908         
model.layers.12.mlp.experts.58.down_proj      torch.Size([1, 2048])          133.407715           133.974552           621.597808           3286.730521         
model.layers.12.mlp.experts.59.gate_proj      torch.Size([0, 1408])          139.842239           140.326023           621.635368           3113.267970         
model.layers.12.mlp.experts.59.act_fn         torch.Size([0, 1408])          0.383616             0.841856             621.568000           3107.840000         
model.layers.12.mlp.experts.59.up_proj        torch.Size([0, 1408])          141.884506           142.250061           542.855556           3128.116000         
model.layers.12.mlp.experts.59.down_proj      torch.Size([0, 2048])          133.778946           134.308577           576.642207           3118.397793         
model.layers.12.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          511.029633           511.441708           662.843658           3207.389749         
model.layers.12.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.522368             1.091719             776.640000           3261.888000         
model.layers.12.mlp.shared_expert.up_proj     torch.Size([5, 5632])          507.200043           507.597923           709.802122           3179.953306         
model.layers.12.mlp.shared_expert.down_proj   torch.Size([5, 2048])          509.624481           510.041952           692.276622           3492.671052         
model.layers.12.mlp.shared_expert_gate        torch.Size([5, 1])             8.950432             9.488344             635.778954           3533.883077         
model.layers.13.input_layernorm               torch.Size([1, 5, 2048])       6.540608             8.275747             483.250036           3232.101236         
model.layers.13.self_attn.q_proj              torch.Size([1, 5, 2048])       125.583107           127.394915           577.171373           3062.500670         
model.layers.13.self_attn.k_proj              torch.Size([1, 5, 2048])       131.556061           133.129597           621.668991           3058.226789         
model.layers.13.self_attn.v_proj              torch.Size([1, 5, 2048])       122.255005           122.815609           621.624344           3139.405780         
model.layers.13.self_attn.o_proj              torch.Size([1, 5, 2048])       115.943199           116.422892           621.667868           3031.416615         
model.layers.13.post_attention_layernorm      torch.Size([1, 5, 2048])       14.402528            16.309261            576.250483           3006.157241         
model.layers.13.mlp.gate                      torch.Size([5, 60])            14.326336            15.765429            466.368000           3064.326000         
model.layers.13.mlp.experts.0.gate_proj       torch.Size([0, 1408])          84.220512            85.749149            551.019860           3152.670881         
model.layers.13.mlp.experts.0.act_fn          torch.Size([0, 1408])          0.005472             1.456261             621.568000           3107.840000         
model.layers.13.mlp.experts.0.up_proj         torch.Size([0, 1408])          81.055939            82.499504            599.932706           3223.560471         
model.layers.13.mlp.experts.0.down_proj       torch.Size([0, 2048])          84.073982            85.598230            513.262158           3318.815030         
model.layers.13.mlp.experts.1.gate_proj       torch.Size([0, 1408])          84.578690            86.097479            520.247089           3567.699848         
model.layers.13.mlp.experts.1.act_fn          torch.Size([0, 1408])          0.005504             1.502752             621.568000           3261.888000         
model.layers.13.mlp.experts.1.up_proj         torch.Size([0, 1408])          81.714432            83.190918            554.723111           3143.242222         
model.layers.13.mlp.experts.1.down_proj       torch.Size([0, 2048])          78.327202            80.045223            568.709689           3153.408000         
model.layers.13.mlp.experts.2.gate_proj       torch.Size([0, 1408])          83.428963            84.926605            565.174601           3146.329510         
model.layers.13.mlp.experts.2.act_fn          torch.Size([0, 1408])          0.005632             1.686096             621.568000           3261.888000         
model.layers.13.mlp.experts.2.up_proj         torch.Size([0, 1408])          83.633438            84.030151            560.158667           3183.881333         
model.layers.13.mlp.experts.2.down_proj       torch.Size([0, 2048])          83.289055            84.826708            573.817425           3060.964384         
model.layers.13.mlp.experts.3.gate_proj       torch.Size([0, 1408])          85.736191            87.237597            576.700028           3081.768166         
model.layers.13.mlp.experts.3.act_fn          torch.Size([0, 1408])          0.005568             1.297951             621.568000           3261.888000         
model.layers.13.mlp.experts.3.up_proj         torch.Size([0, 1408])          83.098114            83.442926            546.701427           3175.887217         
model.layers.13.mlp.experts.3.down_proj       torch.Size([0, 2048])          83.143875            84.859848            567.530947           3152.455158         
model.layers.13.mlp.experts.4.gate_proj       torch.Size([0, 1408])          86.834656            87.687016            568.778440           3169.272284         
model.layers.13.mlp.experts.4.act_fn          torch.Size([0, 1408])          0.575264             1.335621             621.568000           3417.216000         
model.layers.13.mlp.experts.4.up_proj         torch.Size([0, 1408])          85.760963            86.453438            559.788522           3129.062493         
model.layers.13.mlp.experts.4.down_proj       torch.Size([0, 2048])          84.811165            85.468769            534.746597           3432.509922         
model.layers.13.mlp.experts.5.gate_proj       torch.Size([0, 1408])          85.045380            85.672617            506.396354           3865.915544         
model.layers.13.mlp.experts.5.act_fn          torch.Size([0, 1408])          0.617216             1.285791             465.984000           3883.200000         
model.layers.13.mlp.experts.5.up_proj         torch.Size([0, 1408])          81.438141            82.022905            531.565449           3294.387942         
model.layers.13.mlp.experts.5.down_proj       torch.Size([0, 2048])          80.051231            80.471277            575.946294           3297.189147         
model.layers.13.mlp.experts.6.gate_proj       torch.Size([2, 1408])          87.192223            87.864876            598.504649           3150.198486         
model.layers.13.mlp.experts.6.act_fn          torch.Size([2, 1408])          0.398464             0.784159             621.568000           3107.840000         
model.layers.13.mlp.experts.6.up_proj         torch.Size([2, 1408])          80.297729            80.765486            621.714526           2948.296842         
model.layers.13.mlp.experts.6.down_proj       torch.Size([2, 2048])          80.944801            81.412077            621.640113           2991.671887         
model.layers.13.mlp.experts.7.gate_proj       torch.Size([1, 1408])          83.152451            83.744287            621.568000           3188.004848         
model.layers.13.mlp.experts.7.act_fn          torch.Size([1, 1408])          0.452480             0.890732             621.568000           3107.328000         
model.layers.13.mlp.experts.7.up_proj         torch.Size([1, 1408])          79.242561            79.853773            621.615787           3216.739413         
model.layers.13.mlp.experts.7.down_proj       torch.Size([1, 2048])          87.300865            88.136196            621.627362           3116.086261         
model.layers.13.mlp.experts.8.gate_proj       torch.Size([0, 1408])          84.951042            85.595608            621.710604           2992.996081         
model.layers.13.mlp.experts.8.act_fn          torch.Size([0, 1408])          0.539424             1.242638             621.824000           2952.448000         
model.layers.13.mlp.experts.8.up_proj         torch.Size([0, 1408])          91.724319            92.354536            547.895497           2965.487888         
model.layers.13.mlp.experts.8.down_proj       torch.Size([0, 2048])          82.975487            83.374500            521.644025           3275.347567         
model.layers.13.mlp.experts.9.gate_proj       torch.Size([0, 1408])          81.183105            81.764936            515.259871           3628.653419         
model.layers.13.mlp.experts.9.act_fn          torch.Size([0, 1408])          0.457600             0.902414             621.568000           3262.784000         
model.layers.13.mlp.experts.9.up_proj         torch.Size([0, 1408])          81.983490            82.422018            548.143132           3153.410977         
model.layers.13.mlp.experts.9.down_proj       torch.Size([0, 2048])          83.865181            84.480762            584.925838           3063.742270         
model.layers.13.mlp.experts.10.gate_proj      torch.Size([0, 1408])          86.495934            87.167025            569.883234           2988.816340         
model.layers.13.mlp.experts.10.act_fn         torch.Size([0, 1408])          1.266240             1.992226             621.568000           3107.840000         
model.layers.13.mlp.experts.10.up_proj        torch.Size([0, 1408])          86.143906            86.759329            545.067429           3157.237943         
model.layers.13.mlp.experts.10.down_proj      torch.Size([0, 2048])          89.270050            89.900970            560.676978           3144.202904         
model.layers.13.mlp.experts.11.gate_proj      torch.Size([0, 1408])          91.442978            92.099190            573.412757           3103.360000         
model.layers.13.mlp.experts.11.act_fn         torch.Size([0, 1408])          0.772064             1.559973             621.568000           3262.336000         
model.layers.13.mlp.experts.11.up_proj        torch.Size([0, 1408])          86.713120            87.290764            556.055887           3165.800113         
model.layers.13.mlp.experts.11.down_proj      torch.Size([0, 2048])          82.893410            84.341526            577.512444           3028.000889         
model.layers.13.mlp.experts.12.gate_proj      torch.Size([0, 1408])          88.335518            89.814425            570.299586           3047.721490         
model.layers.13.mlp.experts.12.act_fn         torch.Size([0, 1408])          0.005792             1.372337             621.568000           3572.544000         
model.layers.13.mlp.experts.12.up_proj        torch.Size([0, 1408])          80.581665            81.949472            554.655508           3193.546338         
model.layers.13.mlp.experts.12.down_proj      torch.Size([0, 2048])          78.121216            79.449415            539.902619           3632.675914         
model.layers.13.mlp.experts.13.gate_proj      torch.Size([0, 1408])          82.081985            83.533764            522.183432           3825.052490         
model.layers.13.mlp.experts.13.act_fn         torch.Size([0, 1408])          0.005664             1.303673             621.568000           3417.216000         
model.layers.13.mlp.experts.13.up_proj        torch.Size([0, 1408])          80.688995            82.145929            550.407111           3187.353333         
model.layers.13.mlp.experts.13.down_proj      torch.Size([0, 2048])          79.007553            80.348253            582.589762           3045.900531         
model.layers.13.mlp.experts.14.gate_proj      torch.Size([0, 1408])          84.158211            85.664511            569.783154           3239.826211         
model.layers.13.mlp.experts.14.act_fn         torch.Size([0, 1408])          0.005664             1.241207             621.824000           2952.448000         
model.layers.13.mlp.experts.14.up_proj        torch.Size([0, 1408])          82.367996            83.716869            529.901778           3183.164889         
model.layers.13.mlp.experts.14.down_proj      torch.Size([0, 2048])          79.202972            80.456018            557.591450           3103.073710         
model.layers.13.mlp.experts.15.gate_proj      torch.Size([0, 1408])          83.616768            84.995985            547.637404           3029.629457         
model.layers.13.mlp.experts.15.act_fn         torch.Size([0, 1408])          0.005504             1.449347             621.568000           3107.840000         
model.layers.13.mlp.experts.15.up_proj        torch.Size([0, 1408])          85.111298            86.618423            553.866738           3076.553020         
model.layers.13.mlp.experts.15.down_proj      torch.Size([0, 2048])          80.783485            81.214190            576.767549           3165.381859         
model.layers.13.mlp.experts.16.gate_proj      torch.Size([1, 1408])          85.233086            85.861444            594.728533           3207.671893         
model.layers.13.mlp.experts.16.act_fn         torch.Size([1, 1408])          0.732256             1.436710             621.568000           3261.888000         
model.layers.13.mlp.experts.16.up_proj        torch.Size([1, 1408])          81.874397            82.604408            621.576889           3150.411556         
model.layers.13.mlp.experts.16.down_proj      torch.Size([1, 2048])          80.617889            81.262112            621.598014           3182.269793         
model.layers.13.mlp.experts.17.gate_proj      torch.Size([1, 1408])          79.425186            80.000877            621.449481           3707.325235         
model.layers.13.mlp.experts.17.act_fn         torch.Size([1, 1408])          0.365568             0.733852             621.568000           3417.216000         
model.layers.13.mlp.experts.17.up_proj        torch.Size([1, 1408])          78.373444            78.821421            621.635090           3309.468248         
model.layers.13.mlp.experts.17.down_proj      torch.Size([1, 2048])          82.127586            82.591057            621.568000           3242.179710         
model.layers.13.mlp.experts.18.gate_proj      torch.Size([0, 1408])          86.397408            86.823702            621.679304           3127.756986         
model.layers.13.mlp.experts.18.act_fn         torch.Size([0, 1408])          0.397152             0.841141             621.568000           3262.784000         
model.layers.13.mlp.experts.18.up_proj        torch.Size([0, 1408])          83.105118            83.534002            549.985566           3089.348028         
model.layers.13.mlp.experts.18.down_proj      torch.Size([0, 2048])          82.666306            83.076239            562.944865           3033.293838         
model.layers.13.mlp.experts.19.gate_proj      torch.Size([0, 1408])          85.191582            85.925102            559.806145           3067.360464         
model.layers.13.mlp.experts.19.act_fn         torch.Size([0, 1408])          0.611616             1.500845             621.568000           3417.216000         
model.layers.13.mlp.experts.19.up_proj        torch.Size([0, 1408])          85.565315            86.191416            555.609418           3115.357957         
model.layers.13.mlp.experts.19.down_proj      torch.Size([0, 2048])          80.856483            81.306219            569.818667           3198.279111         
model.layers.13.mlp.experts.20.gate_proj      torch.Size([0, 1408])          88.413216            89.061499            586.303546           3191.389957         
model.layers.13.mlp.experts.20.act_fn         torch.Size([0, 1408])          0.426208             0.863075             621.653333           3107.840000         
model.layers.13.mlp.experts.20.up_proj        torch.Size([0, 1408])          80.415039            80.830812            561.077560           3079.186156         
model.layers.13.mlp.experts.20.down_proj      torch.Size([0, 2048])          79.679550            80.259800            572.843912           3250.122277         
model.layers.13.mlp.experts.21.gate_proj      torch.Size([1, 1408])          79.696541            80.247641            565.486829           3912.423805         
model.layers.13.mlp.experts.21.act_fn         torch.Size([1, 1408])          0.524544             1.099586             621.312000           3727.872000         
model.layers.13.mlp.experts.21.up_proj        torch.Size([1, 1408])          80.728287            81.289768            621.510892           3521.076677         
model.layers.13.mlp.experts.21.down_proj      torch.Size([1, 2048])          80.653313            81.238508            621.602909           3134.013091         
model.layers.13.mlp.experts.22.gate_proj      torch.Size([0, 1408])          85.009277            85.498095            621.623497           3093.452531         
model.layers.13.mlp.experts.22.act_fn         torch.Size([0, 1408])          0.636640             1.372814             621.568000           3107.840000         
model.layers.13.mlp.experts.22.up_proj        torch.Size([0, 1408])          86.407936            87.029457            576.141653           3095.408640         
model.layers.13.mlp.experts.22.down_proj      torch.Size([0, 2048])          84.799934            85.357904            581.144789           3171.007099         
model.layers.13.mlp.experts.23.gate_proj      torch.Size([3, 1408])          82.309952            82.882643            595.044384           3241.230466         
model.layers.13.mlp.experts.23.act_fn         torch.Size([3, 1408])          0.671488             1.365900             621.568000           3300.720000         
model.layers.13.mlp.experts.23.up_proj        torch.Size([3, 1408])          84.887169            85.668087            621.609465           3191.351437         
model.layers.13.mlp.experts.23.down_proj      torch.Size([3, 2048])          83.476257            84.244251            621.719893           3018.450773         
model.layers.13.mlp.experts.24.gate_proj      torch.Size([0, 1408])          84.556450            85.277319            621.733959           2953.519669         
model.layers.13.mlp.experts.24.act_fn         torch.Size([0, 1408])          0.325344             0.698805             621.568000           3107.840000         
model.layers.13.mlp.experts.24.up_proj        torch.Size([0, 1408])          79.297409            79.695702            569.519441           3142.246042         
model.layers.13.mlp.experts.24.down_proj      torch.Size([0, 2048])          75.194687            76.514244            572.431655           3306.252432         
model.layers.13.mlp.experts.25.gate_proj      torch.Size([0, 1408])          81.831039            82.319021            515.869281           3734.891922         
model.layers.13.mlp.experts.25.act_fn         torch.Size([0, 1408])          0.461760             0.913620             621.312000           3883.200000         
model.layers.13.mlp.experts.25.up_proj        torch.Size([0, 1408])          80.175774            80.564260            527.328914           3353.971200         
model.layers.13.mlp.experts.25.down_proj      torch.Size([0, 2048])          81.494080            81.936836            566.373699           3062.073863         
model.layers.13.mlp.experts.26.gate_proj      torch.Size([0, 1408])          81.205154            81.869364            570.296000           3095.044235         
model.layers.13.mlp.experts.26.act_fn         torch.Size([0, 1408])          0.333248             0.718594             582.720000           3262.896000         
model.layers.13.mlp.experts.26.up_proj        torch.Size([0, 1408])          83.016930            83.409786            519.243801           3099.904454         
model.layers.13.mlp.experts.26.down_proj      torch.Size([0, 2048])          84.620514            85.205317            563.737690           3148.090141         
model.layers.13.mlp.experts.27.gate_proj      torch.Size([0, 1408])          83.456413            84.100962            572.513803           3088.023437         
model.layers.13.mlp.experts.27.act_fn         torch.Size([0, 1408])          0.623456             1.382351             621.568000           3263.232000         
model.layers.13.mlp.experts.27.up_proj        torch.Size([0, 1408])          82.756256            83.377123            547.257863           3089.659616         
model.layers.13.mlp.experts.27.down_proj      torch.Size([0, 2048])          81.982048            82.558155            567.521185           3099.772681         
model.layers.13.mlp.experts.28.gate_proj      torch.Size([0, 1408])          81.512993            82.183123            575.578112           3203.089408         
model.layers.13.mlp.experts.28.act_fn         torch.Size([0, 1408])          0.336160             0.766277             621.824000           3107.840000         
model.layers.13.mlp.experts.28.up_proj        torch.Size([0, 1408])          76.960480            77.385664            560.753231           3307.924587         
model.layers.13.mlp.experts.28.down_proj      torch.Size([0, 2048])          78.329346            78.793049            576.760789           3204.405634         
model.layers.13.mlp.experts.29.gate_proj      torch.Size([0, 1408])          82.285088            82.787514            514.023087           3783.577342         
model.layers.13.mlp.experts.29.act_fn         torch.Size([0, 1408])          0.482624             1.036406             543.648000           4036.864000         
model.layers.13.mlp.experts.29.up_proj        torch.Size([0, 1408])          81.735229            82.166910            536.294222           3527.266222         
model.layers.13.mlp.experts.29.down_proj      torch.Size([0, 2048])          83.224770            83.649397            575.898353           3234.137882         
model.layers.13.mlp.experts.30.gate_proj      torch.Size([0, 1408])          84.422882            84.821939            576.965525           3137.577439         
model.layers.13.mlp.experts.30.act_fn         torch.Size([0, 1408])          0.569664             1.404762             466.368000           2797.056000         
model.layers.13.mlp.experts.30.up_proj        torch.Size([0, 1408])          87.398460            88.064909            529.829859           2925.476056         
model.layers.13.mlp.experts.30.down_proj      torch.Size([0, 2048])          85.209564            85.968018            585.751510           3058.156844         
model.layers.13.mlp.experts.31.gate_proj      torch.Size([0, 1408])          85.403488            86.222410            578.228811           3030.329734         
model.layers.13.mlp.experts.31.act_fn         torch.Size([0, 1408])          0.557632             1.264572             621.568000           3263.232000         
model.layers.13.mlp.experts.31.up_proj        torch.Size([0, 1408])          84.096893            84.664822            559.944170           3212.086014         
model.layers.13.mlp.experts.31.down_proj      torch.Size([0, 2048])          85.550369            85.939407            580.567059           3200.027294         
model.layers.13.mlp.experts.32.gate_proj      torch.Size([0, 1408])          88.078079            88.687897            556.519832           3144.594350         
model.layers.13.mlp.experts.32.act_fn         torch.Size([0, 1408])          0.379040             0.940561             621.568000           3417.216000         
model.layers.13.mlp.experts.32.up_proj        torch.Size([0, 1408])          81.431488            81.866026            541.956267           3172.992000         
model.layers.13.mlp.experts.32.down_proj      torch.Size([0, 2048])          83.290977            83.978653            575.397674           3173.792681         
model.layers.13.mlp.experts.33.gate_proj      torch.Size([0, 1408])          81.977661            82.396507            525.065316           3737.206684         
model.layers.13.mlp.experts.33.act_fn         torch.Size([0, 1408])          0.466944             0.942707             504.608000           4580.288000         
model.layers.13.mlp.experts.33.up_proj        torch.Size([0, 1408])          81.579262            82.005262            544.361490           3618.567945         
model.layers.13.mlp.experts.33.down_proj      torch.Size([0, 2048])          80.811996            81.297398            570.872738           3350.426326         
model.layers.13.mlp.experts.34.gate_proj      torch.Size([0, 1408])          85.641182            86.158752            573.886488           3160.085669         
model.layers.13.mlp.experts.34.act_fn         torch.Size([0, 1408])          0.426240             0.843525             621.653333           3107.840000         
model.layers.13.mlp.experts.34.up_proj        torch.Size([0, 1408])          81.353859            81.768036            559.122222           3060.359111         
model.layers.13.mlp.experts.34.down_proj      torch.Size([0, 2048])          80.479454            81.149817            566.550756           2999.641126         
model.layers.13.mlp.experts.35.gate_proj      torch.Size([0, 1408])          82.582497            83.027601            577.070545           3175.810238         
model.layers.13.mlp.experts.35.act_fn         torch.Size([0, 1408])          0.529440             1.062870             621.568000           3107.840000         
model.layers.13.mlp.experts.35.up_proj        torch.Size([0, 1408])          83.918526            84.532976            542.347755           3221.376435         
model.layers.13.mlp.experts.35.down_proj      torch.Size([0, 2048])          83.586945            84.459782            578.248471           3101.906353         
model.layers.13.mlp.experts.36.gate_proj      torch.Size([0, 1408])          84.390404            85.073233            569.157297           3071.403255         
model.layers.13.mlp.experts.36.act_fn         torch.Size([0, 1408])          0.357440             0.795126             621.568000           3107.840000         
model.layers.13.mlp.experts.36.up_proj        torch.Size([0, 1408])          81.861214            82.260609            567.062952           3048.824055         
model.layers.13.mlp.experts.36.down_proj      torch.Size([0, 2048])          118.097984           118.755817           569.529927           3151.855650         
model.layers.13.mlp.experts.37.gate_proj      torch.Size([1, 1408])          138.628891           139.137506           558.016390           3635.846244         
model.layers.13.mlp.experts.37.act_fn         torch.Size([1, 1408])          0.508992             0.931501             621.184000           4230.944000         
model.layers.13.mlp.experts.37.up_proj        torch.Size([1, 1408])          143.394211           143.877506           600.172758           3685.875451         
model.layers.13.mlp.experts.37.down_proj      torch.Size([1, 2048])          147.163330           147.777319           621.619892           3117.671784         
model.layers.13.mlp.experts.38.gate_proj      torch.Size([1, 1408])          140.229568           140.969038           621.693352           2994.145545         
model.layers.13.mlp.experts.38.act_fn         torch.Size([1, 1408])          0.449120             0.898600             621.568000           3106.560000         
model.layers.13.mlp.experts.38.up_proj        torch.Size([1, 1408])          140.773346           141.309500           621.656965           3142.628312         
model.layers.13.mlp.experts.38.down_proj      torch.Size([1, 2048])          123.706268           124.305964           621.730072           3100.889784         
model.layers.13.mlp.experts.39.gate_proj      torch.Size([0, 1408])          138.112549           138.558865           621.714028           3111.755718         
model.layers.13.mlp.experts.39.act_fn         torch.Size([0, 1408])          0.636064             1.394033             621.568000           3261.888000         
model.layers.13.mlp.experts.39.up_proj        torch.Size([0, 1408])          138.208359           138.843536           573.443459           3050.065730         
model.layers.13.mlp.experts.39.down_proj      torch.Size([0, 2048])          139.932190           140.326262           580.471497           3023.080727         
model.layers.13.mlp.experts.40.gate_proj      torch.Size([0, 1408])          138.279205           138.859272           556.187429           3039.934259         
model.layers.13.mlp.experts.40.act_fn         torch.Size([0, 1408])          0.460096             1.001596             621.568000           3689.040000         
model.layers.13.mlp.experts.40.up_proj        torch.Size([0, 1408])          152.632996           153.034687           549.542957           3239.288116         
model.layers.13.mlp.experts.40.down_proj      torch.Size([0, 2048])          132.329727           132.965803           581.344691           3264.850417         
model.layers.13.mlp.experts.41.gate_proj      torch.Size([0, 1408])          129.731491           130.364418           533.071111           3404.593333         
model.layers.13.mlp.experts.41.act_fn         torch.Size([0, 1408])          0.382016             0.833750             621.312000           3985.109333         
model.layers.13.mlp.experts.41.up_proj        torch.Size([0, 1408])          130.988159           131.408691           517.174278           3831.519190         
model.layers.13.mlp.experts.41.down_proj      torch.Size([0, 2048])          137.957031           138.727188           576.565848           3233.736386         
model.layers.13.mlp.experts.42.gate_proj      torch.Size([1, 1408])          142.022461           142.955303           601.064889           3253.718222         
model.layers.13.mlp.experts.42.act_fn         torch.Size([1, 1408])          0.456704             0.937700             621.568000           3107.840000         
model.layers.13.mlp.experts.42.up_proj        torch.Size([1, 1408])          137.519043           138.219595           621.601315           3275.061479         
model.layers.13.mlp.experts.42.down_proj      torch.Size([1, 2048])          140.018265           141.036510           621.668958           3086.612732         
model.layers.13.mlp.experts.43.gate_proj      torch.Size([0, 1408])          130.453568           131.088018           621.676973           3002.845405         
model.layers.13.mlp.experts.43.act_fn         torch.Size([0, 1408])          0.594880             1.333952             621.568000           3107.840000         
model.layers.13.mlp.experts.43.up_proj        torch.Size([0, 1408])          141.509155           142.139196           568.140800           3040.324855         
model.layers.13.mlp.experts.43.down_proj      torch.Size([0, 2048])          103.957245           104.402065           571.746569           3143.812672         
model.layers.13.mlp.experts.44.gate_proj      torch.Size([1, 1408])          89.667839            90.709925            598.075586           3210.030345         
model.layers.13.mlp.experts.44.act_fn         torch.Size([1, 1408])          0.694688             1.475811             621.568000           3261.888000         
model.layers.13.mlp.experts.44.up_proj        torch.Size([1, 1408])          84.892738            85.627317            621.666462           3159.402965         
model.layers.13.mlp.experts.44.down_proj      torch.Size([1, 2048])          82.899422            83.351135            621.608960           3105.163093         
model.layers.13.mlp.experts.45.gate_proj      torch.Size([0, 1408])          84.636543            85.077047            621.560686           3313.393371         
model.layers.13.mlp.experts.45.act_fn         torch.Size([0, 1408])          0.624352             1.596928             621.312000           4192.128000         
model.layers.13.mlp.experts.45.up_proj        torch.Size([0, 1408])          84.731682            85.308075            512.364079           3909.526887         
model.layers.13.mlp.experts.45.down_proj      torch.Size([0, 2048])          83.346306            83.974838            564.069594           3365.757762         
model.layers.13.mlp.experts.46.gate_proj      torch.Size([1, 1408])          85.952095            86.871386            594.198639           3200.370503         
model.layers.13.mlp.experts.46.act_fn         torch.Size([1, 1408])          0.718368             1.552582             621.568000           3261.888000         
model.layers.13.mlp.experts.46.up_proj        torch.Size([1, 1408])          85.392799            85.983753            621.712772           3091.400386         
model.layers.13.mlp.experts.46.down_proj      torch.Size([1, 2048])          88.015137            88.796616            621.644800           3047.450453         
model.layers.13.mlp.experts.47.gate_proj      torch.Size([0, 1408])          83.762688            84.458113            621.696921           3115.363914         
model.layers.13.mlp.experts.47.act_fn         torch.Size([0, 1408])          0.435360             0.986576             621.568000           3572.544000         
model.layers.13.mlp.experts.47.up_proj        torch.Size([0, 1408])          78.609344            79.081059            561.875459           3219.841730         
model.layers.13.mlp.experts.47.down_proj      torch.Size([0, 2048])          77.762306            78.180075            565.037838           3182.160000         
model.layers.13.mlp.experts.48.gate_proj      torch.Size([0, 1408])          86.019394            86.648941            577.104213           3125.451093         
model.layers.13.mlp.experts.48.act_fn         torch.Size([0, 1408])          0.603616             1.391172             621.824000           2952.448000         
model.layers.13.mlp.experts.48.up_proj        torch.Size([0, 1408])          82.921661            83.416224            552.908886           3103.668403         
model.layers.13.mlp.experts.48.down_proj      torch.Size([0, 2048])          81.913376            82.711935            588.419657           3050.122971         
model.layers.13.mlp.experts.49.gate_proj      torch.Size([0, 1408])          84.391708            85.026741            533.665545           3429.193710         
model.layers.13.mlp.experts.49.act_fn         torch.Size([0, 1408])          0.588512             1.448393             517.760000           4036.864000         
model.layers.13.mlp.experts.49.up_proj        torch.Size([0, 1408])          85.287041            85.869789            511.088723           4064.473600         
model.layers.13.mlp.experts.49.down_proj      torch.Size([0, 2048])          82.107262            82.544804            559.497269           3217.954869         
model.layers.13.mlp.experts.50.gate_proj      torch.Size([0, 1408])          87.813087            88.471889            580.594286           3055.672686         
model.layers.13.mlp.experts.50.act_fn         torch.Size([0, 1408])          0.573280             1.484156             621.568000           3107.840000         
model.layers.13.mlp.experts.50.up_proj        torch.Size([0, 1408])          84.430466            85.001707            556.504941           3151.046588         
model.layers.13.mlp.experts.50.down_proj      torch.Size([0, 2048])          84.072319            84.714174            572.800457           3158.325943         
model.layers.13.mlp.experts.51.gate_proj      torch.Size([0, 1408])          86.729309            87.225676            568.428274           3207.170630         
model.layers.13.mlp.experts.51.act_fn         torch.Size([0, 1408])          0.360672             0.827312             621.568000           3263.232000         
model.layers.13.mlp.experts.51.up_proj        torch.Size([0, 1408])          82.641602            83.252668            558.536000           3156.128500         
model.layers.13.mlp.experts.51.down_proj      torch.Size([0, 2048])          77.259521            77.761412            584.025697           3074.867879         
model.layers.13.mlp.experts.52.gate_proj      torch.Size([1, 1408])          84.102211            84.861755            601.904107           2985.990872         
model.layers.13.mlp.experts.52.act_fn         torch.Size([1, 1408])          0.668032             1.486540             621.568000           3107.840000         
model.layers.13.mlp.experts.52.up_proj        torch.Size([1, 1408])          84.148125            84.787369            621.691646           3133.949823         
model.layers.13.mlp.experts.52.down_proj      torch.Size([1, 2048])          81.775841            82.420349            621.691524           3140.030210         
model.layers.13.mlp.experts.53.gate_proj      torch.Size([1, 1408])          82.624893            83.464622            621.539556           3374.251111         
model.layers.13.mlp.experts.53.act_fn         torch.Size([1, 1408])          0.477536             0.930548             621.312000           4192.128000         
model.layers.13.mlp.experts.53.up_proj        torch.Size([1, 1408])          81.444191            82.075119            620.436915           3776.243869         
model.layers.13.mlp.experts.53.down_proj      torch.Size([1, 2048])          82.942657            83.691120            621.691705           3133.412510         
model.layers.13.mlp.experts.54.gate_proj      torch.Size([0, 1408])          88.268929            88.865995            621.679881           3129.411793         
model.layers.13.mlp.experts.54.act_fn         torch.Size([0, 1408])          0.663968             1.165152             621.568000           3417.216000         
model.layers.13.mlp.experts.54.up_proj        torch.Size([0, 1408])          82.161987            82.624912            559.774434           3142.297958         
model.layers.13.mlp.experts.54.down_proj      torch.Size([0, 2048])          80.441315            81.025600            575.887781           3291.640986         
model.layers.13.mlp.experts.55.gate_proj      torch.Size([2, 1408])          82.043457            82.811356            595.708160           3148.081493         
model.layers.13.mlp.experts.55.act_fn         torch.Size([2, 1408])          0.832384             1.360893             621.568000           3386.150400         
model.layers.13.mlp.experts.55.up_proj        torch.Size([2, 1408])          81.057663            81.604481            621.708715           3073.740291         
model.layers.13.mlp.experts.55.down_proj      torch.Size([2, 2048])          79.430847            79.971790            621.568000           3113.938097         
model.layers.13.mlp.experts.56.gate_proj      torch.Size([1, 1408])          87.924095            88.648796            621.568000           3241.003563         
model.layers.13.mlp.experts.56.act_fn         torch.Size([1, 1408])          0.793312             1.518488             621.568000           3106.560000         
model.layers.13.mlp.experts.56.up_proj        torch.Size([1, 1408])          83.207458            83.858013            621.568000           3387.044374         
model.layers.13.mlp.experts.56.down_proj      torch.Size([1, 2048])          83.414719            83.991766            621.568000           3259.906207         
model.layers.13.mlp.experts.57.gate_proj      torch.Size([0, 1408])          85.277954            87.876320            621.623252           3193.131281         
model.layers.13.mlp.experts.57.act_fn         torch.Size([0, 1408])          0.392832             0.798225             621.568000           3572.544000         
model.layers.13.mlp.experts.57.up_proj        torch.Size([0, 1408])          83.297440            83.671331            518.880000           3747.468308         
model.layers.13.mlp.experts.57.down_proj      torch.Size([0, 2048])          83.039680            83.653927            583.283014           3389.228058         
model.layers.13.mlp.experts.58.gate_proj      torch.Size([0, 1408])          83.907967            84.621668            579.241622           3254.982713         
model.layers.13.mlp.experts.58.act_fn         torch.Size([0, 1408])          0.363488             0.815630             621.568000           3263.232000         
model.layers.13.mlp.experts.58.up_proj        torch.Size([0, 1408])          83.863136            84.234476            553.994449           3160.431020         
model.layers.13.mlp.experts.58.down_proj      torch.Size([0, 2048])          83.525726            84.134340            587.440000           3078.008000         
model.layers.13.mlp.experts.59.gate_proj      torch.Size([1, 1408])          89.052483            89.690685            579.247787           2918.575787         
model.layers.13.mlp.experts.59.act_fn         torch.Size([1, 1408])          0.394880             0.874043             621.568000           3107.840000         
model.layers.13.mlp.experts.59.up_proj        torch.Size([1, 1408])          76.281120            76.713562            621.651592           3210.706286         
model.layers.13.mlp.experts.59.down_proj      torch.Size([1, 2048])          84.492737            85.211754            621.628343           3187.050971         
model.layers.13.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          358.257782           358.862877           675.051943           3048.931215         
model.layers.13.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.879840             1.470566             776.640000           3261.888000         
model.layers.13.mlp.shared_expert.up_proj     torch.Size([5, 5632])          348.193909           348.783731           697.386286           3561.865633         
model.layers.13.mlp.shared_expert.down_proj   torch.Size([5, 2048])          356.701202           357.128382           687.477784           3270.749146         
model.layers.13.mlp.shared_expert_gate        torch.Size([5, 1])             10.963648            11.575699            641.846519           3118.990222         
model.layers.14.input_layernorm               torch.Size([1, 5, 2048])       11.692960            12.497902            506.786560           3154.739200         
model.layers.14.self_attn.q_proj              torch.Size([1, 5, 2048])       142.297440           143.109322           580.472043           3222.060973         
model.layers.14.self_attn.k_proj              torch.Size([1, 5, 2048])       134.389374           135.057926           621.695363           3077.567045         
model.layers.14.self_attn.v_proj              torch.Size([1, 5, 2048])       126.393280           127.058029           621.778242           3001.981217         
model.layers.14.self_attn.o_proj              torch.Size([1, 5, 2048])       126.681534           127.550840           625.044065           3074.498076         
model.layers.14.post_attention_layernorm      torch.Size([1, 5, 2048])       17.798624            18.576145            597.033651           3161.660952         
model.layers.14.mlp.gate                      torch.Size([5, 60])            10.495648            12.167454            466.176000           3602.690462         
model.layers.14.mlp.experts.0.gate_proj       torch.Size([0, 1408])          96.260002            96.810579            537.104914           3765.587200         
model.layers.14.mlp.experts.0.act_fn          torch.Size([0, 1408])          0.426688             0.893116             621.312000           3727.872000         
model.layers.14.mlp.experts.0.up_proj         torch.Size([0, 1408])          97.484001            98.000526            621.568000           3353.658435         
model.layers.14.mlp.experts.0.down_proj       torch.Size([0, 2048])          90.508736            91.081381            613.268027           3063.405714         
model.layers.14.mlp.experts.1.gate_proj       torch.Size([0, 1408])          90.882271            91.374636            577.487883           3113.481810         
model.layers.14.mlp.experts.1.act_fn          torch.Size([0, 1408])          0.381184             0.848293             621.568000           3263.232000         
model.layers.14.mlp.experts.1.up_proj         torch.Size([0, 1408])          85.675171            86.237669            567.587556           3178.730667         
model.layers.14.mlp.experts.1.down_proj       torch.Size([0, 2048])          96.701027            97.277164            586.201143           3122.090971         
model.layers.14.mlp.experts.2.gate_proj       torch.Size([0, 1408])          93.660957            94.472408            572.061605           3034.956190         
model.layers.14.mlp.experts.2.act_fn          torch.Size([0, 1408])          0.732224             1.467228             621.568000           3263.232000         
model.layers.14.mlp.experts.2.up_proj         torch.Size([0, 1408])          91.338943            91.907501            555.005746           3034.521239         
model.layers.14.mlp.experts.2.down_proj       torch.Size([0, 2048])          90.790627            91.658592            570.698971           3081.227886         
model.layers.14.mlp.experts.3.gate_proj       torch.Size([0, 1408])          88.501762            89.285851            581.809333           3162.660000         
model.layers.14.mlp.experts.3.act_fn          torch.Size([0, 1408])          0.589504             1.326799             621.568000           3572.544000         
model.layers.14.mlp.experts.3.up_proj         torch.Size([0, 1408])          86.236099            86.856604            556.992444           3207.908444         
model.layers.14.mlp.experts.3.down_proj       torch.Size([0, 2048])          85.989311            86.485624            580.204662           3304.058935         
model.layers.14.mlp.experts.4.gate_proj       torch.Size([1, 1408])          88.925667            89.755774            565.271123           3725.167071         
model.layers.14.mlp.experts.4.act_fn          torch.Size([1, 1408])          0.492864             0.989676             621.312000           3727.872000         
model.layers.14.mlp.experts.4.up_proj         torch.Size([1, 1408])          94.599075            95.169544            621.548844           3417.250830         
model.layers.14.mlp.experts.4.down_proj       torch.Size([1, 2048])          89.526947            89.985847            621.568000           3284.008216         
model.layers.14.mlp.experts.5.gate_proj       torch.Size([1, 1408])          84.316032            84.836483            621.568000           3239.790389         
model.layers.14.mlp.experts.5.act_fn          torch.Size([1, 1408])          0.520864             0.973940             621.568000           3107.840000         
model.layers.14.mlp.experts.5.up_proj         torch.Size([1, 1408])          86.313148            86.775780            621.688163           3107.691973         
model.layers.14.mlp.experts.5.down_proj       torch.Size([1, 2048])          83.589951            84.082603            621.663030           3011.253333         
model.layers.14.mlp.experts.6.gate_proj       torch.Size([0, 1408])          91.629662            92.053652            621.699459           2983.946378         
model.layers.14.mlp.experts.6.act_fn          torch.Size([0, 1408])          0.643840             1.345396             621.568000           3107.840000         
model.layers.14.mlp.experts.6.up_proj         torch.Size([0, 1408])          92.715645            93.285799            554.392511           3196.753702         
model.layers.14.mlp.experts.6.down_proj       torch.Size([0, 2048])          88.424065            90.163708            564.835310           3196.434979         
model.layers.14.mlp.experts.7.gate_proj       torch.Size([0, 1408])          80.949341            81.659555            579.081956           3129.351585         
model.layers.14.mlp.experts.7.act_fn          torch.Size([0, 1408])          0.643168             1.332998             621.568000           3210.112000         
model.layers.14.mlp.experts.7.up_proj         torch.Size([0, 1408])          83.390083            83.947182            565.360107           3106.688430         
model.layers.14.mlp.experts.7.down_proj       torch.Size([0, 2048])          80.346817            81.082582            582.871529           3108.615529         
model.layers.14.mlp.experts.8.gate_proj       torch.Size([1, 1408])          86.431137            87.117672            556.539139           3759.866734         
model.layers.14.mlp.experts.8.act_fn          torch.Size([1, 1408])          0.663296             1.369715             621.312000           4036.864000         
model.layers.14.mlp.experts.8.up_proj         torch.Size([1, 1408])          84.739586            85.700512            621.517176           3580.407059         
model.layers.14.mlp.experts.8.down_proj       torch.Size([1, 2048])          84.587776            85.223198            621.652768           3221.387868         
model.layers.14.mlp.experts.9.gate_proj       torch.Size([0, 1408])          92.811996            93.465090            621.655075           3193.176381         
model.layers.14.mlp.experts.9.act_fn          torch.Size([0, 1408])          0.616544             1.490593             621.568000           3262.336000         
model.layers.14.mlp.experts.9.up_proj         torch.Size([0, 1408])          78.859901            79.489231            565.274853           3018.740811         
model.layers.14.mlp.experts.9.down_proj       torch.Size([0, 2048])          80.496605            80.950975            557.862575           3092.794740         
model.layers.14.mlp.experts.10.gate_proj      torch.Size([1, 1408])          99.933212            100.591660           586.331366           3159.996469         
model.layers.14.mlp.experts.10.act_fn         torch.Size([1, 1408])          0.675200             1.400471             621.568000           3417.216000         
model.layers.14.mlp.experts.10.up_proj        torch.Size([1, 1408])          90.255203            90.846777            621.713194           3105.193075         
model.layers.14.mlp.experts.10.down_proj      torch.Size([1, 2048])          53.856224            54.685116            621.632000           3087.563152         
model.layers.14.mlp.experts.11.gate_proj      torch.Size([0, 1408])          91.649696            92.337370            621.763459           3010.059676         
model.layers.14.mlp.experts.11.act_fn         torch.Size([0, 1408])          0.431456             0.952005             621.568000           3365.440000         
model.layers.14.mlp.experts.11.up_proj        torch.Size([0, 1408])          83.128769            83.640099            558.513434           3087.439448         
model.layers.14.mlp.experts.11.down_proj      torch.Size([0, 2048])          89.699135            90.095997            573.539453           3282.737727         
model.layers.14.mlp.experts.12.gate_proj      torch.Size([0, 1408])          91.667618            92.231750            527.956810           3952.837104         
model.layers.14.mlp.experts.12.act_fn         torch.Size([0, 1408])          0.733568             1.479149             543.648000           4036.864000         
model.layers.14.mlp.experts.12.up_proj        torch.Size([0, 1408])          94.331902            94.862700            546.457007           3450.649854         
model.layers.14.mlp.experts.12.down_proj      torch.Size([0, 2048])          101.272514           102.449417           569.174510           3101.409986         
model.layers.14.mlp.experts.13.gate_proj      torch.Size([0, 1408])          96.565186            97.123146            580.389147           3069.750601         
model.layers.14.mlp.experts.13.act_fn         torch.Size([0, 1408])          0.669152             1.431942             621.568000           3263.232000         
model.layers.14.mlp.experts.13.up_proj        torch.Size([0, 1408])          96.284546            96.926689            544.580031           3191.030929         
model.layers.14.mlp.experts.13.down_proj      torch.Size([0, 2048])          96.935295            97.351313            574.723765           3279.830118         
model.layers.14.mlp.experts.14.gate_proj      torch.Size([0, 1408])          96.099998            96.808434            590.804825           3139.905016         
model.layers.14.mlp.experts.14.act_fn         torch.Size([0, 1408])          0.602272             1.457214             621.568000           3107.840000         
model.layers.14.mlp.experts.14.up_proj        torch.Size([0, 1408])          97.022209            97.633600            544.500966           3091.764966         
model.layers.14.mlp.experts.14.down_proj      torch.Size([0, 2048])          93.719582            94.151020            578.656432           3078.441514         
model.layers.14.mlp.experts.15.gate_proj      torch.Size([0, 1408])          104.721855           105.309963           580.923461           3128.629560         
model.layers.14.mlp.experts.15.act_fn         torch.Size([0, 1408])          0.439616             0.970602             621.824000           3107.840000         
model.layers.14.mlp.experts.15.up_proj        torch.Size([0, 1408])          168.520248           169.020414           553.333106           3222.137191         
model.layers.14.mlp.experts.15.down_proj      torch.Size([0, 2048])          163.530304           164.115191           576.660745           3233.761103         
model.layers.14.mlp.experts.16.gate_proj      torch.Size([0, 1408])          179.357849           179.885387           495.915689           3625.518754         
model.layers.14.mlp.experts.16.act_fn         torch.Size([0, 1408])          0.735200             1.251698             582.720000           3572.544000         
model.layers.14.mlp.experts.16.up_proj        torch.Size([0, 1408])          150.152740           150.615215           538.464000           3247.620958         
model.layers.14.mlp.experts.16.down_proj      torch.Size([0, 2048])          148.327454           149.182558           575.912471           3263.874824         
model.layers.14.mlp.experts.17.gate_proj      torch.Size([0, 1408])          144.664932           145.146608           589.288000           3273.423111         
model.layers.14.mlp.experts.17.act_fn         torch.Size([0, 1408])          0.339520             0.721455             621.568000           3417.216000         
model.layers.14.mlp.experts.17.up_proj        torch.Size([0, 1408])          138.274689           138.696432           562.999944           3209.500196         
model.layers.14.mlp.experts.17.down_proj      torch.Size([0, 2048])          140.373276           140.910387           575.538595           3060.590703         
model.layers.14.mlp.experts.18.gate_proj      torch.Size([0, 1408])          143.670212           144.300461           579.666667           3033.381333         
model.layers.14.mlp.experts.18.act_fn         torch.Size([0, 1408])          0.365536             0.765085             621.568000           3263.232000         
model.layers.14.mlp.experts.18.up_proj        torch.Size([0, 1408])          150.994431           151.473999           559.968438           3119.451178         
model.layers.14.mlp.experts.18.down_proj      torch.Size([0, 2048])          145.370911           146.060467           585.174588           3139.571294         
model.layers.14.mlp.experts.19.gate_proj      torch.Size([1, 1408])          124.949341           125.492096           602.277959           3268.624331         
model.layers.14.mlp.experts.19.act_fn         torch.Size([1, 1408])          0.419040             0.878334             621.568000           3107.840000         
model.layers.14.mlp.experts.19.up_proj        torch.Size([1, 1408])          111.022179           111.522198           621.568000           3212.963155         
model.layers.14.mlp.experts.19.down_proj      torch.Size([1, 2048])          157.035172           157.607555           621.625469           3154.546939         
model.layers.14.mlp.experts.20.gate_proj      torch.Size([1, 1408])          94.750946            95.290661            621.399579           3687.160000         
model.layers.14.mlp.experts.20.act_fn         torch.Size([1, 1408])          0.543008             0.957727             621.312000           4036.864000         
model.layers.14.mlp.experts.20.up_proj        torch.Size([1, 1408])          141.540253           141.994715           621.532932           3457.687671         
model.layers.14.mlp.experts.20.down_proj      torch.Size([1, 2048])          141.530655           142.184973           621.568000           3314.766968         
model.layers.14.mlp.experts.21.gate_proj      torch.Size([0, 1408])          141.703491           142.339468           621.603765           3120.260706         
model.layers.14.mlp.experts.21.act_fn         torch.Size([0, 1408])          0.649440             1.539707             621.824000           3107.840000         
model.layers.14.mlp.experts.21.up_proj        torch.Size([0, 1408])          138.566528           139.213324           569.145690           3082.670873         
model.layers.14.mlp.experts.21.down_proj      torch.Size([0, 2048])          97.697472            98.330498            574.511669           3048.898207         
model.layers.14.mlp.experts.22.gate_proj      torch.Size([0, 1408])          78.895523            79.365253            583.645867           3187.074844         
model.layers.14.mlp.experts.22.act_fn         torch.Size([0, 1408])          0.391264             0.855446             621.568000           3107.840000         
model.layers.14.mlp.experts.22.up_proj        torch.Size([0, 1408])          81.295296            81.661940            568.385401           3197.192409         
model.layers.14.mlp.experts.22.down_proj      torch.Size([0, 2048])          79.637154            80.213547            586.923860           3086.106853         
model.layers.14.mlp.experts.23.gate_proj      torch.Size([0, 1408])          86.042366            86.634636            588.986707           3062.273925         
model.layers.14.mlp.experts.23.act_fn         torch.Size([0, 1408])          0.397792             0.949860             621.568000           3211.434667         
model.layers.14.mlp.experts.23.up_proj        torch.Size([0, 1408])          86.857277            87.284088            562.774510           3061.775007         
model.layers.14.mlp.experts.23.down_proj      torch.Size([0, 2048])          83.455170            84.127188            583.424000           3204.326400         
model.layers.14.mlp.experts.24.gate_proj      torch.Size([1, 1408])          79.506592            79.954147            562.892247           3806.807704         
model.layers.14.mlp.experts.24.act_fn         torch.Size([1, 1408])          0.536768             0.931978             621.056000           4502.656000         
model.layers.14.mlp.experts.24.up_proj        torch.Size([1, 1408])          84.808228            85.284472            621.505730           3670.964757         
model.layers.14.mlp.experts.24.down_proj      torch.Size([1, 2048])          72.012253            72.655201            621.719195           3057.456107         
model.layers.14.mlp.experts.25.gate_proj      torch.Size([1, 1408])          92.246941            93.077421            621.730595           3042.437622         
model.layers.14.mlp.experts.25.act_fn         torch.Size([1, 1408])          0.635744             1.488447             621.568000           3261.888000         
model.layers.14.mlp.experts.25.up_proj        torch.Size([1, 1408])          86.133629            86.781025            621.704533           3096.200107         
model.layers.14.mlp.experts.25.down_proj      torch.Size([1, 2048])          67.998306            68.456173            621.687351           3164.121081         
model.layers.14.mlp.experts.26.gate_proj      torch.Size([0, 1408])          70.920319            71.705818            621.733220           3093.257986         
model.layers.14.mlp.experts.26.act_fn         torch.Size([0, 1408])          0.363328             0.831127             621.568000           3417.216000         
model.layers.14.mlp.experts.26.up_proj        torch.Size([0, 1408])          67.089088            67.561150            556.554741           3030.888727         
model.layers.14.mlp.experts.26.down_proj      torch.Size([0, 2048])          83.998947            84.593773            582.266740           3025.464548         
model.layers.14.mlp.experts.27.gate_proj      torch.Size([1, 1408])          92.851616            93.462467            594.269405           3134.172973         
model.layers.14.mlp.experts.27.act_fn         torch.Size([1, 1408])          0.596544             1.338005             621.568000           3417.216000         
model.layers.14.mlp.experts.27.up_proj        torch.Size([1, 1408])          90.037918            90.625286            621.583568           3208.008649         
model.layers.14.mlp.experts.27.down_proj      torch.Size([1, 2048])          83.087006            83.609104            621.568000           3329.421913         
model.layers.14.mlp.experts.28.gate_proj      torch.Size([0, 1408])          84.085793            84.537029            621.381368           3779.972955         
model.layers.14.mlp.experts.28.act_fn         torch.Size([0, 1408])          0.759456             1.535654             621.312000           3727.872000         
model.layers.14.mlp.experts.28.up_proj        torch.Size([0, 1408])          85.234016            85.828066            564.928914           3428.512000         
model.layers.14.mlp.experts.28.down_proj      torch.Size([0, 2048])          89.581375            90.264082            573.523338           3144.596259         
model.layers.14.mlp.experts.29.gate_proj      torch.Size([0, 1408])          95.926208            96.523762            577.829452           3216.666074         
model.layers.14.mlp.experts.29.act_fn         torch.Size([0, 1408])          0.671232             1.710892             621.568000           3107.840000         
model.layers.14.mlp.experts.29.up_proj        torch.Size([0, 1408])          91.809891            92.415571            553.509295           3202.496921         
model.layers.14.mlp.experts.29.down_proj      torch.Size([0, 2048])          83.531326            84.062576            576.496865           3132.842378         
model.layers.14.mlp.experts.30.gate_proj      torch.Size([1, 1408])          81.614754            82.185984            596.430703           3112.389189         
model.layers.14.mlp.experts.30.act_fn         torch.Size([1, 1408])          0.514112             1.091719             621.568000           3106.560000         
model.layers.14.mlp.experts.30.up_proj        torch.Size([1, 1408])          86.672989            87.418318            621.568000           3132.984320         
model.layers.14.mlp.experts.30.down_proj      torch.Size([1, 2048])          91.502434            92.284441            621.568000           3218.288232         
model.layers.14.mlp.experts.31.gate_proj      torch.Size([0, 1408])          80.858879            81.734896            621.568000           3193.838126         
model.layers.14.mlp.experts.31.act_fn         torch.Size([0, 1408])          0.384640             0.794411             621.568000           3417.216000         
model.layers.14.mlp.experts.31.up_proj        torch.Size([0, 1408])          92.348351            92.892885            621.638687           3218.659343         
model.layers.14.mlp.experts.31.down_proj      torch.Size([0, 2048])          94.615005            95.151186            598.894545           3096.673119         
model.layers.14.mlp.experts.32.gate_proj      torch.Size([0, 1408])          86.245155            86.726665            513.096000           3635.829053         
model.layers.14.mlp.experts.32.act_fn         torch.Size([0, 1408])          0.625888             1.254559             517.760000           4347.392000         
model.layers.14.mlp.experts.32.up_proj        torch.Size([0, 1408])          93.604477            94.449043            548.654786           3654.742952         
model.layers.14.mlp.experts.32.down_proj      torch.Size([0, 2048])          91.282051            91.853619            572.739068           3230.746740         
model.layers.14.mlp.experts.33.gate_proj      torch.Size([1, 1408])          83.074142            83.719254            590.764927           3199.076026         
model.layers.14.mlp.experts.33.act_fn         torch.Size([1, 1408])          0.602080             1.162767             621.568000           3417.216000         
model.layers.14.mlp.experts.33.up_proj        torch.Size([1, 1408])          88.104607            88.639498            621.568000           3111.719087         
model.layers.14.mlp.experts.33.down_proj      torch.Size([1, 2048])          82.425728            82.960844            621.568000           3073.029224         
model.layers.14.mlp.experts.34.gate_proj      torch.Size([1, 1408])          86.943741            87.519407            621.568000           3142.749808         
model.layers.14.mlp.experts.34.act_fn         torch.Size([1, 1408])          0.403520             0.863552             621.568000           3261.888000         
model.layers.14.mlp.experts.34.up_proj        torch.Size([1, 1408])          86.320259            86.766481            621.568000           3232.256000         
model.layers.14.mlp.experts.34.down_proj      torch.Size([1, 2048])          89.419136            90.813875            621.568000           3252.312986         
model.layers.14.mlp.experts.35.gate_proj      torch.Size([0, 1408])          85.048126            85.672379            621.591111           3133.998667         
model.layers.14.mlp.experts.35.act_fn         torch.Size([0, 1408])          0.342240             0.723362             621.568000           3107.413333         
model.layers.14.mlp.experts.35.up_proj        torch.Size([0, 1408])          84.226433            84.629536            581.697333           3102.267556         
model.layers.14.mlp.experts.35.down_proj      torch.Size([0, 2048])          86.427299            87.018728            591.682743           3063.346743         
model.layers.14.mlp.experts.36.gate_proj      torch.Size([0, 1408])          88.265091            88.877439            508.383782           3543.905524         
model.layers.14.mlp.experts.36.act_fn         torch.Size([0, 1408])          0.577472             1.281261             621.312000           4192.128000         
model.layers.14.mlp.experts.36.up_proj        torch.Size([0, 1408])          91.182877            91.899157            518.893128           3717.699282         
model.layers.14.mlp.experts.36.down_proj      torch.Size([0, 2048])          87.724319            88.334560            567.017514           3160.976432         
model.layers.14.mlp.experts.37.gate_proj      torch.Size([0, 1408])          84.265533            84.786177            569.858177           3081.321796         
model.layers.14.mlp.experts.37.act_fn         torch.Size([0, 1408])          0.386368             0.862598             621.568000           3107.840000         
model.layers.14.mlp.experts.37.up_proj        torch.Size([0, 1408])          84.021919            84.551096            545.026667           3075.457333         
model.layers.14.mlp.experts.37.down_proj      torch.Size([0, 2048])          79.369987            79.798698            568.690551           3157.787826         
model.layers.14.mlp.experts.38.gate_proj      torch.Size([0, 1408])          85.849052            86.257935            569.100892           3175.329151         
model.layers.14.mlp.experts.38.act_fn         torch.Size([0, 1408])          0.554688             1.307487             621.568000           3261.888000         
model.layers.14.mlp.experts.38.up_proj        torch.Size([0, 1408])          82.295105            83.076239            549.701584           3162.649772         
model.layers.14.mlp.experts.38.down_proj      torch.Size([0, 2048])          86.411522            87.564945            555.083429           3096.529371         
model.layers.14.mlp.experts.39.gate_proj      torch.Size([0, 1408])          87.833023            88.381529            565.036541           3031.193946         
model.layers.14.mlp.experts.39.act_fn         torch.Size([0, 1408])          0.005632             3.329277             621.568000           3263.232000         
model.layers.14.mlp.experts.39.up_proj        torch.Size([0, 1408])          82.300163            82.703590            539.726667           3100.557333         
model.layers.14.mlp.experts.39.down_proj      torch.Size([0, 2048])          82.012032            82.652330            575.367716           3226.478752         
model.layers.14.mlp.experts.40.gate_proj      torch.Size([0, 1408])          89.332001            89.902639            493.843975           3596.426191         
model.layers.14.mlp.experts.40.act_fn         torch.Size([0, 1408])          0.634112             1.305580             465.792000           4502.656000         
model.layers.14.mlp.experts.40.up_proj        torch.Size([0, 1408])          84.336349            84.947348            524.645403           3622.035948         
model.layers.14.mlp.experts.40.down_proj      torch.Size([0, 2048])          79.275040            79.837322            559.989828           3107.710305         
model.layers.14.mlp.experts.41.gate_proj      torch.Size([0, 1408])          79.923424            80.377817            572.758825           3226.140196         
model.layers.14.mlp.experts.41.act_fn         torch.Size([0, 1408])          0.341664             0.752926             621.568000           3494.880000         
model.layers.14.mlp.experts.41.up_proj        torch.Size([0, 1408])          75.325569            75.935364            546.206118           3218.354353         
model.layers.14.mlp.experts.41.down_proj      torch.Size([0, 2048])          73.764351            74.508429            568.330971           3209.550629         
model.layers.14.mlp.experts.42.gate_proj      torch.Size([0, 1408])          85.890015            86.350918            566.296168           3087.193510         
model.layers.14.mlp.experts.42.act_fn         torch.Size([0, 1408])          0.397120             0.805378             621.824000           3030.144000         
model.layers.14.mlp.experts.42.up_proj        torch.Size([0, 1408])          80.225121            80.656528            552.813419           3063.979355         
model.layers.14.mlp.experts.42.down_proj      torch.Size([0, 2048])          84.141022            84.651470            565.683556           3022.590222         
model.layers.14.mlp.experts.43.gate_proj      torch.Size([0, 1408])          83.547264            84.068775            564.091972           3181.538462         
model.layers.14.mlp.experts.43.act_fn         torch.Size([0, 1408])          0.458272             1.010180             621.824000           3107.840000         
model.layers.14.mlp.experts.43.up_proj        torch.Size([0, 1408])          83.620354            84.373474            537.868255           3224.295943         
model.layers.14.mlp.experts.43.down_proj      torch.Size([0, 2048])          84.320450            84.977865            570.590685           3085.480329         
model.layers.14.mlp.experts.44.gate_proj      torch.Size([0, 1408])          88.824318            89.586973            494.059897           3421.294359         
model.layers.14.mlp.experts.44.act_fn         torch.Size([0, 1408])          0.654656             1.539230             465.984000           4036.864000         
model.layers.14.mlp.experts.44.up_proj        torch.Size([0, 1408])          84.444771            85.055590            504.258415           3533.703245         
model.layers.14.mlp.experts.44.down_proj      torch.Size([0, 2048])          85.986557            86.565733            554.539281           3219.440806         
model.layers.14.mlp.experts.45.gate_proj      torch.Size([0, 1408])          80.990623            81.521511            570.961159           3200.931246         
model.layers.14.mlp.experts.45.act_fn         torch.Size([0, 1408])          0.422016             0.958920             621.568000           3159.637333         
model.layers.14.mlp.experts.45.up_proj        torch.Size([0, 1408])          80.111588            80.530882            526.521469           3121.562993         
model.layers.14.mlp.experts.45.down_proj      torch.Size([0, 2048])          85.912354            86.481333            577.147077           3062.200392         
model.layers.14.mlp.experts.46.gate_proj      torch.Size([1, 1408])          92.509346            93.127728            589.425039           3024.089766         
model.layers.14.mlp.experts.46.act_fn         torch.Size([1, 1408])          0.560832             1.140356             621.568000           3263.232000         
model.layers.14.mlp.experts.46.up_proj        torch.Size([1, 1408])          90.557762            91.183186            621.657946           3160.137514         
model.layers.14.mlp.experts.46.down_proj      torch.Size([1, 2048])          77.804832            78.351736            621.705710           3123.782621         
model.layers.14.mlp.experts.47.gate_proj      torch.Size([0, 1408])          80.900574            81.442356            621.726118           3137.215529         
model.layers.14.mlp.experts.47.act_fn         torch.Size([0, 1408])          0.414912             0.869989             621.568000           3261.888000         
model.layers.14.mlp.experts.47.up_proj        torch.Size([0, 1408])          85.784798            86.178780            551.000276           3076.705103         
model.layers.14.mlp.experts.47.down_proj      torch.Size([0, 2048])          83.689949            84.141493            564.320000           3057.062493         
model.layers.14.mlp.experts.48.gate_proj      torch.Size([0, 1408])          91.596451            92.225313            509.496935           3640.012883         
model.layers.14.mlp.experts.48.act_fn         torch.Size([0, 1408])          0.570752             1.268864             517.546667           4606.165333         
model.layers.14.mlp.experts.48.up_proj        torch.Size([0, 1408])          81.864388            82.489014            516.521514           3749.714162         
model.layers.14.mlp.experts.48.down_proj      torch.Size([0, 2048])          79.660706            80.076933            544.604029           3157.492321         
model.layers.14.mlp.experts.49.gate_proj      torch.Size([0, 1408])          82.066017            82.564116            573.442595           3080.436757         
model.layers.14.mlp.experts.49.act_fn         torch.Size([0, 1408])          0.333952             0.783682             621.568000           3263.232000         
model.layers.14.mlp.experts.49.up_proj        torch.Size([0, 1408])          88.388252            88.857412            555.188083           3202.912662         
model.layers.14.mlp.experts.49.down_proj      torch.Size([0, 2048])          90.035011            90.720415            568.455302           3151.614711         
model.layers.14.mlp.experts.50.gate_proj      torch.Size([1, 1408])          80.512062            81.187010            586.376533           3145.134080         
model.layers.14.mlp.experts.50.act_fn         torch.Size([1, 1408])          0.643488             1.416683             621.568000           3232.153600         
model.layers.14.mlp.experts.50.up_proj        torch.Size([1, 1408])          89.919197            90.679646            621.568000           3260.503393         
model.layers.14.mlp.experts.50.down_proj      torch.Size([1, 2048])          84.131485            84.587574            621.611243           3147.897514         
model.layers.14.mlp.experts.51.gate_proj      torch.Size([1, 1408])          118.706078           119.359970           621.654486           3059.002378         
model.layers.14.mlp.experts.51.act_fn         torch.Size([1, 1408])          0.764128             1.640558             621.824000           2952.448000         
model.layers.14.mlp.experts.51.up_proj        torch.Size([1, 1408])          91.127518            91.818094            621.671784           3030.124973         
model.layers.14.mlp.experts.51.down_proj      torch.Size([1, 2048])          86.563904            87.163210            621.590101           3258.959194         
model.layers.14.mlp.experts.52.gate_proj      torch.Size([0, 1408])          93.494560            94.063520            603.648000           3637.489325         
model.layers.14.mlp.experts.52.act_fn         torch.Size([0, 1408])          0.473216             0.966787             517.760000           4036.864000         
model.layers.14.mlp.experts.52.up_proj        torch.Size([0, 1408])          73.663261            74.022770            505.248619           3585.612800         
model.layers.14.mlp.experts.52.down_proj      torch.Size([0, 2048])          75.912994            76.487303            554.898028           3108.934310         
model.layers.14.mlp.experts.53.gate_proj      torch.Size([1, 1408])          95.859489            96.471548            587.628712           3048.182356         
model.layers.14.mlp.experts.53.act_fn         torch.Size([1, 1408])          0.451136             0.919104             621.568000           3107.840000         
model.layers.14.mlp.experts.53.up_proj        torch.Size([1, 1408])          85.336159            85.919380            621.612755           3209.311329         
model.layers.14.mlp.experts.53.down_proj      torch.Size([1, 2048])          81.524864            82.303524            621.582423           3253.564394         
model.layers.14.mlp.experts.54.gate_proj      torch.Size([0, 1408])          91.202110            91.856241            621.695117           3141.705269         
model.layers.14.mlp.experts.54.act_fn         torch.Size([0, 1408])          0.630272             1.534939             621.568000           3263.232000         
model.layers.14.mlp.experts.54.up_proj        torch.Size([0, 1408])          90.141953            90.749502            556.792548           3063.138192         
model.layers.14.mlp.experts.54.down_proj      torch.Size([0, 2048])          86.358307            86.982489            539.458388           2894.784000         
model.layers.14.mlp.experts.55.gate_proj      torch.Size([0, 1408])          80.974754            81.647635            559.817624           3086.714226         
model.layers.14.mlp.experts.55.act_fn         torch.Size([0, 1408])          0.571680             1.653194             621.568000           3263.232000         
model.layers.14.mlp.experts.55.up_proj        torch.Size([0, 1408])          87.463646            88.033676            544.530538           3166.542566         
model.layers.14.mlp.experts.55.down_proj      torch.Size([0, 2048])          80.928894            81.607819            559.164993           3101.373423         
model.layers.14.mlp.experts.56.gate_proj      torch.Size([1, 1408])          84.045410            84.692717            556.771603           3344.925669         
model.layers.14.mlp.experts.56.act_fn         torch.Size([1, 1408])          0.575200             1.341820             621.312000           4036.864000         
model.layers.14.mlp.experts.56.up_proj        torch.Size([1, 1408])          83.193604            83.760738            592.129730           3508.912000         
model.layers.14.mlp.experts.56.down_proj      torch.Size([1, 2048])          79.819229            80.473661            621.656816           3158.233687         
model.layers.14.mlp.experts.57.gate_proj      torch.Size([2, 1408])          83.435265            84.038019            621.670042           3269.206825         
model.layers.14.mlp.experts.57.act_fn         torch.Size([2, 1408])          0.458208             0.867844             621.568000           3572.544000         
model.layers.14.mlp.experts.57.up_proj        torch.Size([2, 1408])          85.378273            85.797787            621.601545           3188.824717         
model.layers.14.mlp.experts.57.down_proj      torch.Size([2, 2048])          83.226112            83.676577            621.622731           3066.920607         
model.layers.14.mlp.experts.58.gate_proj      torch.Size([1, 1408])          88.909508            89.587927            621.656816           3046.362558         
model.layers.14.mlp.experts.58.act_fn         torch.Size([1, 1408])          0.695456             1.558542             621.568000           3261.888000         
model.layers.14.mlp.experts.58.up_proj        torch.Size([1, 1408])          83.806435            84.618568            621.568000           3198.990071         
model.layers.14.mlp.experts.58.down_proj      torch.Size([1, 2048])          88.487297            89.079380            621.568000           3204.274068         
model.layers.14.mlp.experts.59.gate_proj      torch.Size([0, 1408])          84.397629            85.008621            621.596248           3244.235476         
model.layers.14.mlp.experts.59.act_fn         torch.Size([0, 1408])          0.562784             1.251698             621.824000           3107.840000         
model.layers.14.mlp.experts.59.up_proj        torch.Size([0, 1408])          101.292221           101.858377           557.129465           3100.179831         
model.layers.14.mlp.experts.59.down_proj      torch.Size([0, 2048])          90.631584            91.263056            583.086715           3052.261839         
model.layers.14.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          537.694580           538.251638           622.099270           3468.724888         
model.layers.14.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.698784             1.245022             776.640000           3726.336000         
model.layers.14.mlp.shared_expert.up_proj     torch.Size([5, 5632])          585.745117           586.147070           698.175028           3207.290329         
model.layers.14.mlp.shared_expert.down_proj   torch.Size([5, 2048])          593.217712           593.786716           702.939499           3084.251171         
model.layers.14.mlp.shared_expert_gate        torch.Size([5, 1])             15.047040            15.526533            633.450667           3480.960000         
model.layers.15.input_layernorm               torch.Size([1, 5, 2048])       10.786240            12.336731            475.695360           3188.669440         
model.layers.15.self_attn.q_proj              torch.Size([1, 5, 2048])       197.101410           198.742151           575.181348           3160.949048         
model.layers.15.self_attn.k_proj              torch.Size([1, 5, 2048])       178.773788           179.237366           621.648176           3090.661275         
model.layers.15.self_attn.v_proj              torch.Size([1, 5, 2048])       211.132004           211.773872           621.422298           3702.411574         
model.layers.15.self_attn.o_proj              torch.Size([1, 5, 2048])       190.585663           191.222429           658.501781           3636.356129         
model.layers.15.post_attention_layernorm      torch.Size([1, 5, 2048])       10.072128            10.687590            633.911216           3214.195451         
model.layers.15.mlp.gate                      torch.Size([5, 60])            19.638784            20.156145            479.058286           3146.104163         
model.layers.15.mlp.experts.0.gate_proj       torch.Size([0, 1408])          129.009888           129.837513           561.077593           3077.920780         
model.layers.15.mlp.experts.0.act_fn          torch.Size([0, 1408])          0.607968             1.387358             621.568000           3107.840000         
model.layers.15.mlp.experts.0.up_proj         torch.Size([0, 1408])          143.823013           144.541264           621.579327           3313.310018         
model.layers.15.mlp.experts.0.down_proj       torch.Size([0, 2048])          120.868095           121.741295           621.633488           3212.202171         
model.layers.15.mlp.experts.1.gate_proj       torch.Size([0, 1408])          83.796829            84.392548            573.195801           3116.616624         
model.layers.15.mlp.experts.1.act_fn          torch.Size([0, 1408])          0.476512             0.967503             621.568000           3263.232000         
model.layers.15.mlp.experts.1.up_proj         torch.Size([0, 1408])          84.233154            84.602118            549.909628           3075.689931         
model.layers.15.mlp.experts.1.down_proj       torch.Size([0, 2048])          77.997154            78.557253            560.250222           2907.501333         
model.layers.15.mlp.experts.2.gate_proj       torch.Size([1, 1408])          83.803070            84.796667            591.498738           3043.256698         
model.layers.15.mlp.experts.2.act_fn          torch.Size([1, 1408])          0.659776             1.439095             621.568000           3263.232000         
model.layers.15.mlp.experts.2.up_proj         torch.Size([1, 1408])          78.927521            79.564095            621.677203           3170.517930         
model.layers.15.mlp.experts.2.down_proj       torch.Size([1, 2048])          85.768227            86.313725            621.702179           3163.111724         
model.layers.15.mlp.experts.3.gate_proj       torch.Size([0, 1408])          86.561859            87.022066            610.145707           3533.211307         
model.layers.15.mlp.experts.3.act_fn          torch.Size([0, 1408])          0.456064             0.882864             621.312000           4192.128000         
model.layers.15.mlp.experts.3.up_proj         torch.Size([0, 1408])          87.637985            88.119507            533.670295           3495.033180         
model.layers.15.mlp.experts.3.down_proj       torch.Size([0, 2048])          90.322754            91.907740            539.242372           3101.696000         
model.layers.15.mlp.experts.4.gate_proj       torch.Size([0, 1408])          87.447868            88.109255            556.165660           3125.665959         
model.layers.15.mlp.experts.4.act_fn          torch.Size([0, 1408])          0.616704             1.409292             466.368000           3263.232000         
model.layers.15.mlp.experts.4.up_proj         torch.Size([0, 1408])          84.641090            85.370779            534.967172           3048.898207         
model.layers.15.mlp.experts.4.down_proj       torch.Size([0, 2048])          82.937439            84.261179            551.042207           3019.963145         
model.layers.15.mlp.experts.5.gate_proj       torch.Size([0, 1408])          82.298752            82.798481            564.034595           2965.047351         
model.layers.15.mlp.experts.5.act_fn          torch.Size([0, 1408])          0.381824             0.766277             621.568000           3263.232000         
model.layers.15.mlp.experts.5.up_proj         torch.Size([0, 1408])          84.927872            85.296392            549.562057           3080.091429         
model.layers.15.mlp.experts.5.down_proj       torch.Size([0, 2048])          88.616638            89.228868            569.487781           3189.679342         
model.layers.15.mlp.experts.6.gate_proj       torch.Size([0, 1408])          91.886208            92.398643            576.557903           3278.924800         
model.layers.15.mlp.experts.6.act_fn          torch.Size([0, 1408])          0.740800             1.617432             621.568000           3107.840000         
model.layers.15.mlp.experts.6.up_proj         torch.Size([0, 1408])          90.305374            90.884447            567.984676           3216.039662         
model.layers.15.mlp.experts.6.down_proj       torch.Size([0, 2048])          81.566147            82.057953            563.499973           3161.422367         
model.layers.15.mlp.experts.7.gate_proj       torch.Size([1, 1408])          97.192001            97.882748            552.136453           3532.597937         
model.layers.15.mlp.experts.7.act_fn          torch.Size([1, 1408])          0.695232             1.301527             621.312000           3881.600000         
model.layers.15.mlp.experts.7.up_proj         torch.Size([1, 1408])          96.517441            97.254753            621.547741           3449.853237         
model.layers.15.mlp.experts.7.down_proj       torch.Size([1, 2048])          96.570145            97.381353            621.568000           3324.047007         
model.layers.15.mlp.experts.8.gate_proj       torch.Size([0, 1408])          101.389343           102.338314           621.634866           3095.036179         
model.layers.15.mlp.experts.8.act_fn          torch.Size([0, 1408])          0.403904             0.844002             621.824000           3107.840000         
model.layers.15.mlp.experts.8.up_proj         torch.Size([0, 1408])          84.818527            85.236549            543.364961           3090.975752         
model.layers.15.mlp.experts.8.down_proj       torch.Size([0, 2048])          80.446815            80.990314            569.870222           3064.675556         
model.layers.15.mlp.experts.9.gate_proj       torch.Size([0, 1408])          86.910690            87.418556            563.533813           3156.837755         
model.layers.15.mlp.experts.9.act_fn          torch.Size([0, 1408])          0.354272             0.845909             621.653333           3107.840000         
model.layers.15.mlp.experts.9.up_proj         torch.Size([0, 1408])          88.980385            89.365721            533.633343           3232.280615         
model.layers.15.mlp.experts.9.down_proj       torch.Size([0, 2048])          90.476318            91.167927            534.499938           2999.466831         
model.layers.15.mlp.experts.10.gate_proj      torch.Size([0, 1408])          91.205666            91.990232            582.339945           3057.816548         
model.layers.15.mlp.experts.10.act_fn         torch.Size([0, 1408])          0.369408             0.833035             621.568000           3107.840000         
model.layers.15.mlp.experts.10.up_proj        torch.Size([0, 1408])          87.951523            88.368893            557.086365           3051.127591         
model.layers.15.mlp.experts.10.down_proj      torch.Size([0, 2048])          87.833565            88.376999            580.098704           3214.678535         
model.layers.15.mlp.experts.11.gate_proj      torch.Size([0, 1408])          89.548256            89.965343            497.028923           3740.760615         
model.layers.15.mlp.experts.11.act_fn         torch.Size([0, 1408])          0.596192             1.341343             504.816000           3960.864000         
model.layers.15.mlp.experts.11.up_proj        torch.Size([0, 1408])          101.739906           102.278471           526.413972           3470.610930         
model.layers.15.mlp.experts.11.down_proj      torch.Size([0, 2048])          85.382370            86.024284            561.481915           3159.272563         
model.layers.15.mlp.experts.12.gate_proj      torch.Size([1, 1408])          85.865982            86.830139            584.165647           3039.580026         
model.layers.15.mlp.experts.12.act_fn         torch.Size([1, 1408])          0.610656             1.153946             621.568000           3261.888000         
model.layers.15.mlp.experts.12.up_proj        torch.Size([1, 1408])          84.557411            85.132599            621.668634           3152.506703         
model.layers.15.mlp.experts.12.down_proj      torch.Size([1, 2048])          95.715103            96.162319            621.578449           3209.846857         
model.layers.15.mlp.experts.13.gate_proj      torch.Size([0, 1408])          86.032188            86.654902            621.605547           3163.554560         
model.layers.15.mlp.experts.13.act_fn         torch.Size([0, 1408])          0.400384             0.905037             621.568000           3365.888000         
model.layers.15.mlp.experts.13.up_proj        torch.Size([0, 1408])          105.547997           105.988741           570.919111           3144.412444         
model.layers.15.mlp.experts.13.down_proj      torch.Size([0, 2048])          82.743874            83.265305            583.614158           3127.962705         
model.layers.15.mlp.experts.14.gate_proj      torch.Size([0, 1408])          85.249855            85.761547            573.602532           3105.604144         
model.layers.15.mlp.experts.14.act_fn         torch.Size([0, 1408])          0.700352             1.495123             621.568000           3263.232000         
model.layers.15.mlp.experts.14.up_proj        torch.Size([0, 1408])          87.947716            88.575840            556.963971           3213.191474         
model.layers.15.mlp.experts.14.down_proj      torch.Size([0, 2048])          84.485886            85.157394            567.986479           3288.845521         
model.layers.15.mlp.experts.15.gate_proj      torch.Size([0, 1408])          106.174622           106.857061           501.525063           3601.120000         
model.layers.15.mlp.experts.15.act_fn         torch.Size([0, 1408])          0.432576             0.930786             517.760000           4036.864000         
model.layers.15.mlp.experts.15.up_proj        torch.Size([0, 1408])          83.179108            83.630562            538.453778           3535.028000         
model.layers.15.mlp.experts.15.down_proj      torch.Size([0, 2048])          84.498466            84.967375            577.736812           3098.831768         
model.layers.15.mlp.experts.16.gate_proj      torch.Size([1, 1408])          78.603485            79.142809            594.249915           3195.967099         
model.layers.15.mlp.experts.16.act_fn         torch.Size([1, 1408])          0.446016             0.857830             621.568000           3107.328000         
model.layers.15.mlp.experts.16.up_proj        torch.Size([1, 1408])          87.761826            88.333845            621.608054           3253.848381         
model.layers.15.mlp.experts.16.down_proj      torch.Size([1, 2048])          85.690147            86.436272            621.569855           3138.787246         
model.layers.15.mlp.experts.17.gate_proj      torch.Size([0, 1408])          98.657181            99.495649            621.688358           3067.242985         
model.layers.15.mlp.experts.17.act_fn         torch.Size([0, 1408])          0.644448             1.367331             621.653333           3056.042667         
model.layers.15.mlp.experts.17.up_proj        torch.Size([0, 1408])          100.305054           100.931883           558.136889           2864.451556         
model.layers.15.mlp.experts.17.down_proj      torch.Size([0, 2048])          86.114365            86.539507            563.063049           3108.916811         
model.layers.15.mlp.experts.18.gate_proj      torch.Size([0, 1408])          88.556480            89.348316            573.965714           3148.818286         
model.layers.15.mlp.experts.18.act_fn         torch.Size([0, 1408])          0.005440             1.473665             621.568000           3417.216000         
model.layers.15.mlp.experts.18.up_proj        torch.Size([0, 1408])          81.993980            82.828999            549.866667           3096.202449         
model.layers.15.mlp.experts.18.down_proj      torch.Size([0, 2048])          93.082748            93.687773            572.906514           3093.309257         
model.layers.15.mlp.experts.19.gate_proj      torch.Size([0, 1408])          97.933662            98.479509            483.238400           3492.652181         
model.layers.15.mlp.experts.19.act_fn         torch.Size([0, 1408])          0.456896             0.938416             465.984000           4192.128000         
model.layers.15.mlp.experts.19.up_proj        torch.Size([0, 1408])          104.636734           105.051517           517.499240           3638.059901         
model.layers.15.mlp.experts.19.down_proj      torch.Size([0, 2048])          105.452515           105.991364           552.384000           3180.229525         
model.layers.15.mlp.experts.20.gate_proj      torch.Size([1, 1408])          95.381630            96.050501            590.252340           3157.429124         
model.layers.15.mlp.experts.20.act_fn         torch.Size([1, 1408])          0.878912             1.671553             621.568000           3417.216000         
model.layers.15.mlp.experts.20.up_proj        torch.Size([1, 1408])          92.192734            92.943192            621.651592           3132.018939         
model.layers.15.mlp.experts.20.down_proj      torch.Size([1, 2048])          89.191360            89.930773            621.568000           3113.125442         
model.layers.15.mlp.experts.21.gate_proj      torch.Size([0, 1408])          94.830940            95.479965            621.580800           3139.893943         
model.layers.15.mlp.experts.21.act_fn         torch.Size([0, 1408])          0.606304             1.381636             621.568000           3262.560000         
model.layers.15.mlp.experts.21.up_proj        torch.Size([0, 1408])          114.504448           115.104914           563.080918           3195.645377         
model.layers.15.mlp.experts.21.down_proj      torch.Size([0, 2048])          85.455330            86.127758            574.615022           3281.809957         
model.layers.15.mlp.experts.22.gate_proj      torch.Size([0, 1408])          87.455681            88.043690            557.970222           3135.896889         
model.layers.15.mlp.experts.22.act_fn         torch.Size([0, 1408])          0.574752             1.423597             621.568000           3107.840000         
model.layers.15.mlp.experts.22.up_proj        torch.Size([0, 1408])          88.266014            88.804722            562.046145           3053.790609         
model.layers.15.mlp.experts.22.down_proj      torch.Size([0, 2048])          93.210754            93.842268            581.202479           3060.614310         
model.layers.15.mlp.experts.23.gate_proj      torch.Size([0, 1408])          88.102654            88.742256            520.358137           3639.166685         
model.layers.15.mlp.experts.23.act_fn         torch.Size([0, 1408])          0.300768             0.667572             569.536000           4295.637333         
model.layers.15.mlp.experts.23.up_proj        torch.Size([0, 1408])          98.848480            99.194050            520.679417           3768.753589         
model.layers.15.mlp.experts.23.down_proj      torch.Size([0, 2048])          88.696960            89.257956            576.604290           3185.238725         
model.layers.15.mlp.experts.24.gate_proj      torch.Size([0, 1408])          106.320641           106.774092           572.097816           3087.992738         
model.layers.15.mlp.experts.24.act_fn         torch.Size([0, 1408])          0.444864             0.900507             582.896000           3030.144000         
model.layers.15.mlp.experts.24.up_proj        torch.Size([0, 1408])          84.616867            84.986687            525.314648           2963.465269         
model.layers.15.mlp.experts.24.down_proj      torch.Size([0, 2048])          89.200447            89.722872            564.797296           3168.992451         
model.layers.15.mlp.experts.25.gate_proj      torch.Size([0, 1408])          91.313026            92.024088            569.524321           3101.155036         
model.layers.15.mlp.experts.25.act_fn         torch.Size([0, 1408])          0.530432             1.185894             621.568000           3263.232000         
model.layers.15.mlp.experts.25.up_proj        torch.Size([0, 1408])          81.752930            82.332373            554.652055           3114.105425         
model.layers.15.mlp.experts.25.down_proj      torch.Size([0, 2048])          97.495811            98.075390            551.198865           2994.326695         
model.layers.15.mlp.experts.26.gate_proj      torch.Size([2, 1408])          93.214371            93.929529            590.065263           2937.338105         
model.layers.15.mlp.experts.26.act_fn         torch.Size([2, 1408])          0.365152             0.746965             621.568000           3146.688000         
model.layers.15.mlp.experts.26.up_proj        torch.Size([2, 1408])          81.209793            81.634998            621.733959           3099.122759         
model.layers.15.mlp.experts.26.down_proj      torch.Size([2, 2048])          92.264381            92.709064            621.671164           3232.343881         
model.layers.15.mlp.experts.27.gate_proj      torch.Size([1, 1408])          87.604706            88.424921            621.376435           3795.777306         
model.layers.15.mlp.experts.27.act_fn         torch.Size([1, 1408])          0.614368             1.308441             621.312000           4316.339200         
model.layers.15.mlp.experts.27.up_proj        torch.Size([1, 1408])          112.419556           112.999916           621.494356           3675.532274         
model.layers.15.mlp.experts.27.down_proj      torch.Size([1, 2048])          91.139427            91.667891            621.740927           3037.657430         
model.layers.15.mlp.experts.28.gate_proj      torch.Size([1, 1408])          85.802589            86.493731            621.659807           3125.654510         
model.layers.15.mlp.experts.28.act_fn         torch.Size([1, 1408])          0.879264             1.822233             621.568000           3417.216000         
model.layers.15.mlp.experts.28.up_proj        torch.Size([1, 1408])          79.108482            80.196142            621.697730           3168.185946         
model.layers.15.mlp.experts.28.down_proj      torch.Size([1, 2048])          98.544098            99.163771            621.622980           3097.116349         
model.layers.15.mlp.experts.29.gate_proj      torch.Size([1, 1408])          95.521217            96.231937            621.685760           3045.500160         
model.layers.15.mlp.experts.29.act_fn         torch.Size([1, 1408])          0.512384             0.899553             621.568000           3262.694400         
model.layers.15.mlp.experts.29.up_proj        torch.Size([1, 1408])          79.084030            79.718828            621.776213           3053.895680         
model.layers.15.mlp.experts.29.down_proj      torch.Size([1, 2048])          77.879967            78.461409            621.568000           3161.570133         
model.layers.15.mlp.experts.30.gate_proj      torch.Size([0, 1408])          83.651939            84.092379            621.590795           3147.156603         
model.layers.15.mlp.experts.30.act_fn         torch.Size([0, 1408])          0.385120             0.848055             621.568000           3417.216000         
model.layers.15.mlp.experts.30.up_proj        torch.Size([0, 1408])          82.211617            82.661390            568.199500           3248.343000         
model.layers.15.mlp.experts.30.down_proj      torch.Size([0, 2048])          91.887360            92.287540            570.541257           3301.120457         
model.layers.15.mlp.experts.31.gate_proj      torch.Size([1, 1408])          102.393761           103.049994           560.262000           3733.278000         
model.layers.15.mlp.experts.31.act_fn         torch.Size([1, 1408])          0.667520             1.414537             621.312000           3883.200000         
model.layers.15.mlp.experts.31.up_proj        torch.Size([1, 1408])          107.117821           107.885838           621.554726           3445.980444         
model.layers.15.mlp.experts.31.down_proj      torch.Size([1, 2048])          104.441856           105.084181           621.580274           3222.951890         
model.layers.15.mlp.experts.32.gate_proj      torch.Size([0, 1408])          106.624962           107.074976           621.568000           3336.690286         
model.layers.15.mlp.experts.32.act_fn         torch.Size([0, 1408])          0.936064             2.001286             621.568000           3107.840000         
model.layers.15.mlp.experts.32.up_proj        torch.Size([0, 1408])          85.430687            86.045742            560.169333           3124.026667         
model.layers.15.mlp.experts.32.down_proj      torch.Size([0, 2048])          102.843712           103.613853           571.013778           3034.460444         
model.layers.15.mlp.experts.33.gate_proj      torch.Size([1, 1408])          87.782845            88.523626            591.051718           3058.370254         
model.layers.15.mlp.experts.33.act_fn         torch.Size([1, 1408])          0.589824             1.241207             621.568000           3107.840000         
model.layers.15.mlp.experts.33.up_proj        torch.Size([1, 1408])          84.898148            85.414171            621.593239           3206.829070         
model.layers.15.mlp.experts.33.down_proj      torch.Size([1, 2048])          80.902237            81.433058            621.630061           3195.400727         
model.layers.15.mlp.experts.34.gate_proj      torch.Size([0, 1408])          106.589699           107.116222           621.728260           3061.075252         
model.layers.15.mlp.experts.34.act_fn         torch.Size([0, 1408])          0.650016             1.415968             621.568000           3263.232000         
model.layers.15.mlp.experts.34.up_proj        torch.Size([0, 1408])          86.248253            86.876392            564.821183           3068.444845         
model.layers.15.mlp.experts.34.down_proj      torch.Size([0, 2048])          95.158592            95.676899            580.918014           3204.533106         
model.layers.15.mlp.experts.35.gate_proj      torch.Size([0, 1408])          76.089790            76.565266            505.463233           3815.824219         
model.layers.15.mlp.experts.35.act_fn         torch.Size([0, 1408])          0.548736             1.171827             569.536000           4295.637333         
model.layers.15.mlp.experts.35.up_proj        torch.Size([0, 1408])          87.287491            87.839365            528.361931           3589.055559         
model.layers.15.mlp.experts.35.down_proj      torch.Size([0, 2048])          78.129120            78.803062            563.045594           3188.144336         
model.layers.15.mlp.experts.36.gate_proj      torch.Size([0, 1408])          97.961121            98.566294            581.319452           3041.822685         
model.layers.15.mlp.experts.36.act_fn         torch.Size([0, 1408])          0.568192             1.104593             621.568000           3417.216000         
model.layers.15.mlp.experts.36.up_proj        torch.Size([0, 1408])          83.533859            84.128380            556.831562           3129.068712         
model.layers.15.mlp.experts.36.down_proj      torch.Size([0, 2048])          84.442688            84.960938            572.669808           3173.754740         
model.layers.15.mlp.experts.37.gate_proj      torch.Size([1, 1408])          114.711197           115.257740           596.748444           3204.501333         
model.layers.15.mlp.experts.37.act_fn         torch.Size([1, 1408])          0.425376             0.898838             621.568000           3417.216000         
model.layers.15.mlp.experts.37.up_proj        torch.Size([1, 1408])          170.998627           171.577930           621.703314           3149.418514         
model.layers.15.mlp.experts.37.down_proj      torch.Size([1, 2048])          184.915619           185.564041           621.616432           3081.223784         
model.layers.15.mlp.experts.38.gate_proj      torch.Size([0, 1408])          165.438019           166.077137           621.698648           3048.898207         
model.layers.15.mlp.experts.38.act_fn         torch.Size([0, 1408])          0.584768             1.594305             621.824000           3107.840000         
model.layers.15.mlp.experts.38.up_proj        torch.Size([0, 1408])          178.812057           179.483175           564.654504           3096.631712         
model.layers.15.mlp.experts.38.down_proj      torch.Size([0, 2048])          138.243515           138.816357           586.594704           3264.719324         
model.layers.15.mlp.experts.39.gate_proj      torch.Size([0, 1408])          160.359390           160.891056           493.558422           3709.322449         
model.layers.15.mlp.experts.39.act_fn         torch.Size([0, 1408])          0.313344             0.692606             517.760000           4036.864000         
model.layers.15.mlp.experts.39.up_proj        torch.Size([0, 1408])          169.501144           169.877052           518.667917           3520.173021         
model.layers.15.mlp.experts.39.down_proj      torch.Size([0, 2048])          161.871170           162.324667           576.952986           3105.711342         
model.layers.15.mlp.experts.40.gate_proj      torch.Size([0, 1408])          153.223297           153.783798           569.512280           3117.619916         
model.layers.15.mlp.experts.40.act_fn         torch.Size([0, 1408])          0.393024             0.881195             621.824000           2952.448000         
model.layers.15.mlp.experts.40.up_proj        torch.Size([0, 1408])          143.757568           144.134045           534.221333           3212.406222         
model.layers.15.mlp.experts.40.down_proj      torch.Size([0, 2048])          173.054657           173.855782           575.329135           3240.733504         
model.layers.15.mlp.experts.41.gate_proj      torch.Size([1, 1408])          168.335999           169.108868           591.408623           3096.300883         
model.layers.15.mlp.experts.41.act_fn         torch.Size([1, 1408])          0.487328             0.871658             621.568000           3106.560000         
model.layers.15.mlp.experts.41.up_proj        torch.Size([1, 1408])          159.325699           160.037756           621.697730           3084.687568         
model.layers.15.mlp.experts.41.down_proj      torch.Size([1, 2048])          162.544357           163.128376           621.715620           3057.655591         
model.layers.15.mlp.experts.42.gate_proj      torch.Size([0, 1408])          153.581085           154.067039           621.639442           3215.766326         
model.layers.15.mlp.experts.42.act_fn         torch.Size([0, 1408])          0.842816             1.752615             621.568000           3417.216000         
model.layers.15.mlp.experts.42.up_proj        torch.Size([0, 1408])          151.689667           152.298450           612.684058           3222.488580         
model.layers.15.mlp.experts.42.down_proj      torch.Size([0, 2048])          136.280548           137.340784           575.663407           3219.159230         
model.layers.15.mlp.experts.43.gate_proj      torch.Size([0, 1408])          91.956573            92.679262            492.712911           3570.701367         
model.layers.15.mlp.experts.43.act_fn         torch.Size([0, 1408])          0.713760             1.473904             465.984000           4347.392000         
model.layers.15.mlp.experts.43.up_proj        torch.Size([0, 1408])          104.215683           104.932070           524.986811           3601.071135         
model.layers.15.mlp.experts.43.down_proj      torch.Size([0, 2048])          90.330238            90.964794            577.795606           3241.099718         
model.layers.15.mlp.experts.44.gate_proj      torch.Size([1, 1408])          102.200706           102.883339           597.419243           3265.030919         
model.layers.15.mlp.experts.44.act_fn         torch.Size([1, 1408])          0.655904             1.428604             621.568000           3417.216000         
model.layers.15.mlp.experts.44.up_proj        torch.Size([1, 1408])          88.435043            89.137316            621.581745           3238.337718         
model.layers.15.mlp.experts.44.down_proj      torch.Size([1, 2048])          87.687134            88.191032            621.607385           3154.787357         
model.layers.15.mlp.experts.45.gate_proj      torch.Size([0, 1408])          89.591454            90.077400            621.658667           3079.773778         
model.layers.15.mlp.experts.45.act_fn         torch.Size([0, 1408])          0.609184             1.451254             621.824000           2952.448000         
model.layers.15.mlp.experts.45.up_proj        torch.Size([0, 1408])          68.685280            69.298983            568.748028           3117.739574         
model.layers.15.mlp.experts.45.down_proj      torch.Size([0, 2048])          56.236286            56.689978            568.759728           3233.273034         
model.layers.15.mlp.experts.46.gate_proj      torch.Size([1, 1408])          79.231842            80.122948            596.443676           3207.994378         
model.layers.15.mlp.experts.46.act_fn         torch.Size([1, 1408])          0.656480             1.505136             621.568000           3107.840000         
model.layers.15.mlp.experts.46.up_proj        torch.Size([1, 1408])          112.844322           113.715887           621.666743           3108.700343         
model.layers.15.mlp.experts.46.down_proj      torch.Size([1, 2048])          89.401855            90.211630            621.661867           3110.316373         
model.layers.15.mlp.experts.47.gate_proj      torch.Size([0, 1408])          101.318115           101.850748           621.537483           3452.148556         
model.layers.15.mlp.experts.47.act_fn         torch.Size([0, 1408])          0.475040             0.939131             621.312000           4192.128000         
model.layers.15.mlp.experts.47.up_proj        torch.Size([0, 1408])          96.311646            96.680164            518.578286           3801.235532         
model.layers.15.mlp.experts.47.down_proj      torch.Size([0, 2048])          83.390686            83.899021            569.419212           3304.722686         
model.layers.15.mlp.experts.48.gate_proj      torch.Size([0, 1408])          86.626305            87.229729            574.849753           3150.186082         
model.layers.15.mlp.experts.48.act_fn         torch.Size([0, 1408])          0.457088             0.967741             621.568000           3263.232000         
model.layers.15.mlp.experts.48.up_proj        torch.Size([0, 1408])          86.405571            86.791039            561.664441           3097.123310         
model.layers.15.mlp.experts.48.down_proj      torch.Size([0, 2048])          115.322365           115.752220           582.887111           3050.647111         
model.layers.15.mlp.experts.49.gate_proj      torch.Size([1, 1408])          123.925789           124.876738           598.060503           3108.546543         
model.layers.15.mlp.experts.49.act_fn         torch.Size([1, 1408])          0.753536             1.520872             621.568000           3262.224000         
model.layers.15.mlp.experts.49.up_proj        torch.Size([1, 1408])          100.175774           100.888252           621.664227           3225.176511         
model.layers.15.mlp.experts.49.down_proj      torch.Size([1, 2048])          111.826401           112.679482           621.604081           3182.494067         
model.layers.15.mlp.experts.50.gate_proj      torch.Size([0, 1408])          110.085602           110.774517           621.749116           3065.381007         
model.layers.15.mlp.experts.50.act_fn         torch.Size([0, 1408])          0.328096             0.711918             621.568000           3417.216000         
model.layers.15.mlp.experts.50.up_proj        torch.Size([0, 1408])          114.916382           115.316868           582.921778           3084.099556         
model.layers.15.mlp.experts.50.down_proj      torch.Size([0, 2048])          116.927170           117.558241           575.072457           3187.381943         
model.layers.15.mlp.experts.51.gate_proj      torch.Size([1, 1408])          141.630844           142.402172           565.221301           3718.688196         
model.layers.15.mlp.experts.51.act_fn         torch.Size([1, 1408])          0.454720             0.907421             621.056000           4502.656000         
model.layers.15.mlp.experts.51.up_proj        torch.Size([1, 1408])          100.780769           101.273298           588.569026           3779.019487         
model.layers.15.mlp.experts.51.down_proj      torch.Size([1, 2048])          83.162209            84.011555            621.608889           3189.236444         
model.layers.15.mlp.experts.52.gate_proj      torch.Size([0, 1408])          86.522369            87.146282            621.646071           3093.504000         
model.layers.15.mlp.experts.52.act_fn         torch.Size([0, 1408])          0.658816             1.603842             621.824000           2952.448000         
model.layers.15.mlp.experts.52.up_proj        torch.Size([0, 1408])          129.775650           130.389452           582.820800           3155.730133         
model.layers.15.mlp.experts.52.down_proj      torch.Size([0, 2048])          104.096703           104.877472           567.280390           3191.033756         
model.layers.15.mlp.experts.53.gate_proj      torch.Size([1, 1408])          108.513474           109.408140           587.036444           3292.269037         
model.layers.15.mlp.experts.53.act_fn         torch.Size([1, 1408])          0.711776             1.567841             621.568000           3107.840000         
model.layers.15.mlp.experts.53.up_proj        torch.Size([1, 1408])          94.780739            95.394611            621.621895           3144.348632         
model.layers.15.mlp.experts.53.down_proj      torch.Size([1, 2048])          84.071236            84.603786            621.639680           3092.112640         
model.layers.15.mlp.experts.54.gate_proj      torch.Size([0, 1408])          91.710304            92.264414            621.656965           3084.696511         
model.layers.15.mlp.experts.54.act_fn         torch.Size([0, 1408])          0.399808             0.948668             621.568000           3107.840000         
model.layers.15.mlp.experts.54.up_proj        torch.Size([0, 1408])          91.966240            92.367411            586.155294           3241.205647         
model.layers.15.mlp.experts.54.down_proj      torch.Size([0, 2048])          90.500542            91.113091            584.509134           3256.821970         
model.layers.15.mlp.experts.55.gate_proj      torch.Size([1, 1408])          84.250816            84.748030            570.749128           3510.736821         
model.layers.15.mlp.experts.55.act_fn         torch.Size([1, 1408])          0.468928             0.901222             621.312000           3920.416000         
model.layers.15.mlp.experts.55.up_proj        torch.Size([1, 1408])          81.517921            82.069635            596.664889           3394.019160         
model.layers.15.mlp.experts.55.down_proj      torch.Size([1, 2048])          93.540482            94.316721            621.735320           3006.206327         
model.layers.15.mlp.experts.56.gate_proj      torch.Size([0, 1408])          90.381729            91.077805            621.708620           3129.503549         
model.layers.15.mlp.experts.56.act_fn         torch.Size([0, 1408])          0.447200             0.851154             621.568000           3262.784000         
model.layers.15.mlp.experts.56.up_proj        torch.Size([0, 1408])          81.859299            82.275152            557.056901           3238.799775         
model.layers.15.mlp.experts.56.down_proj      torch.Size([0, 2048])          83.627678            85.127115            583.666126           3085.020196         
model.layers.15.mlp.experts.57.gate_proj      torch.Size([0, 1408])          84.970749            85.509300            590.041684           3047.523368         
model.layers.15.mlp.experts.57.act_fn         torch.Size([0, 1408])          0.416288             0.848293             621.568000           3211.434667         
model.layers.15.mlp.experts.57.up_proj        torch.Size([0, 1408])          80.270271            80.651999            560.892420           3053.634685         
model.layers.15.mlp.experts.57.down_proj      torch.Size([0, 2048])          84.464546            85.004091            577.503556           3088.536000         
model.layers.15.mlp.experts.58.gate_proj      torch.Size([0, 1408])          88.577187            89.182615            578.730213           3136.344057         
model.layers.15.mlp.experts.58.act_fn         torch.Size([0, 1408])          0.560576             1.313448             621.568000           3417.216000         
model.layers.15.mlp.experts.58.up_proj        torch.Size([0, 1408])          94.652832            95.139503            558.137557           3071.280537         
model.layers.15.mlp.experts.58.down_proj      torch.Size([0, 2048])          87.825310            88.191032            587.359475           3106.522230         
model.layers.15.mlp.experts.59.gate_proj      torch.Size([0, 1408])          89.659454            90.162754            533.710545           3532.482078         
model.layers.15.mlp.experts.59.act_fn         torch.Size([0, 1408])          0.808512             1.644850             621.312000           4347.392000         
model.layers.15.mlp.experts.59.up_proj        torch.Size([0, 1408])          109.679970           110.274792           535.741091           3743.636779         
model.layers.15.mlp.experts.59.down_proj      torch.Size([0, 2048])          93.566238            94.156981            579.200895           3302.841287         
model.layers.15.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          334.833038           336.508274           662.609267           3245.627248         
model.layers.15.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.056416             1.629591             776.640000           3415.808000         
model.layers.15.mlp.shared_expert.up_proj     torch.Size([5, 5632])          325.218872           326.753855           703.664122           3142.200547         
model.layers.15.mlp.shared_expert.down_proj   torch.Size([5, 2048])          375.745544           377.553940           718.359111           3230.247111         
model.layers.15.mlp.shared_expert_gate        torch.Size([5, 1])             13.842336            15.410185            652.117714           3312.382857         
model.layers.16.input_layernorm               torch.Size([1, 5, 2048])       11.631456            13.209343            527.331137           3096.247216         
model.layers.16.self_attn.q_proj              torch.Size([1, 5, 2048])       130.760635           132.256031           579.884866           3650.179299         
model.layers.16.self_attn.k_proj              torch.Size([1, 5, 2048])       144.349594           145.649195           621.502638           3547.694298         
model.layers.16.self_attn.v_proj              torch.Size([1, 5, 2048])       135.285721           136.704206           621.681778           3124.958609         
model.layers.16.self_attn.o_proj              torch.Size([1, 5, 2048])       121.945984           123.362303           690.299535           3086.264930         
model.layers.16.post_attention_layernorm      torch.Size([1, 5, 2048])       15.709952            17.470121            624.443429           3268.589714         
model.layers.16.mlp.gate                      torch.Size([5, 60])            15.348064            16.848564            483.265391           3212.560696         
model.layers.16.mlp.experts.0.gate_proj       torch.Size([2, 1408])          84.937057            86.369753            580.536066           3316.760331         
model.layers.16.mlp.experts.0.act_fn          torch.Size([2, 1408])          0.050784             1.492739             621.568000           3261.888000         
model.layers.16.mlp.experts.0.up_proj         torch.Size([2, 1408])          81.830147            83.433151            621.586286           3196.926171         
model.layers.16.mlp.experts.0.down_proj       torch.Size([2, 2048])          116.192192           117.956400           621.635090           3095.899807         
model.layers.16.mlp.experts.1.gate_proj       torch.Size([0, 1408])          76.664223            78.292847            621.635090           3094.979972         
model.layers.16.mlp.experts.1.act_fn          torch.Size([0, 1408])          0.767040             1.476288             621.568000           3262.560000         
model.layers.16.mlp.experts.1.up_proj         torch.Size([0, 1408])          97.140930            97.632885            585.985333           3273.710222         
model.layers.16.mlp.experts.1.down_proj       torch.Size([0, 2048])          100.254845           100.742340           551.336444           3573.795556         
model.layers.16.mlp.experts.2.gate_proj       torch.Size([1, 1408])          93.750786            94.402313            568.382807           3738.250335         
model.layers.16.mlp.experts.2.act_fn          torch.Size([1, 1408])          0.412192             0.883818             621.568000           3417.216000         
model.layers.16.mlp.experts.2.up_proj         torch.Size([1, 1408])          99.462402            99.967718            621.628541           3219.502703         
model.layers.16.mlp.experts.2.down_proj       torch.Size([1, 2048])          103.199364           103.815317           621.670042           3099.583105         
model.layers.16.mlp.experts.3.gate_proj       torch.Size([1, 1408])          90.802078            91.438770            621.568000           3227.474721         
model.layers.16.mlp.experts.3.act_fn          torch.Size([1, 1408])          0.745952             1.564980             621.568000           3262.425600         
model.layers.16.mlp.experts.3.up_proj         torch.Size([1, 1408])          96.668381            97.438574            621.593239           3304.014873         
model.layers.16.mlp.experts.3.down_proj       torch.Size([1, 2048])          92.749855            93.519926            621.600451           3181.679775         
model.layers.16.mlp.experts.4.gate_proj       torch.Size([0, 1408])          87.926498            88.518620            621.639890           3170.542027         
model.layers.16.mlp.experts.4.act_fn          torch.Size([0, 1408])          0.639008             1.388788             621.568000           3263.232000         
model.layers.16.mlp.experts.4.up_proj         torch.Size([0, 1408])          87.200356            87.816954            569.631123           2996.196822         
model.layers.16.mlp.experts.4.down_proj       torch.Size([0, 2048])          97.843613            98.391294            576.553305           3158.535262         
model.layers.16.mlp.experts.5.gate_proj       torch.Size([0, 1408])          98.705475            99.090099            565.582917           3171.845774         
model.layers.16.mlp.experts.5.act_fn          torch.Size([0, 1408])          0.447488             1.025438             621.568000           3417.216000         
model.layers.16.mlp.experts.5.up_proj         torch.Size([0, 1408])          78.584320            79.071522            555.583568           3132.943568         
model.layers.16.mlp.experts.5.down_proj       torch.Size([0, 2048])          95.812386            96.377611            532.685686           3300.766591         
model.layers.16.mlp.experts.6.gate_proj       torch.Size([0, 1408])          79.661537            80.172539            526.692987           3689.528519         
model.layers.16.mlp.experts.6.act_fn          torch.Size([0, 1408])          0.547552             1.314402             621.568000           3572.544000         
model.layers.16.mlp.experts.6.up_proj         torch.Size([0, 1408])          91.216415            91.885328            551.566436           3274.648541         
model.layers.16.mlp.experts.6.down_proj       torch.Size([0, 2048])          99.733856            100.249529           540.221762           3116.662601         
model.layers.16.mlp.experts.7.gate_proj       torch.Size([0, 1408])          85.298241            86.008072            573.517683           3151.710455         
model.layers.16.mlp.experts.7.act_fn          torch.Size([0, 1408])          0.355648             0.784636             621.568000           3417.216000         
model.layers.16.mlp.experts.7.up_proj         torch.Size([0, 1408])          74.126717            74.496984            562.823503           3042.429352         
model.layers.16.mlp.experts.7.down_proj       torch.Size([0, 2048])          83.547646            84.148407            593.133844           3054.940596         
model.layers.16.mlp.experts.8.gate_proj       torch.Size([1, 1408])          77.011742            77.721596            590.532414           3183.714869         
model.layers.16.mlp.experts.8.act_fn          torch.Size([1, 1408])          0.661920             1.337767             621.568000           3263.232000         
model.layers.16.mlp.experts.8.up_proj         torch.Size([1, 1408])          99.001923            99.641323            621.568000           3260.122537         
model.layers.16.mlp.experts.8.down_proj       torch.Size([1, 2048])          85.677216            86.210251            621.568000           3224.410667         
model.layers.16.mlp.experts.9.gate_proj       torch.Size([0, 1408])          85.149055            85.857630            621.634443           3086.488427         
model.layers.16.mlp.experts.9.act_fn          torch.Size([0, 1408])          0.386752             0.916243             621.824000           3056.042667         
model.layers.16.mlp.experts.9.up_proj         torch.Size([0, 1408])          80.873505            81.418514            579.786440           3082.492369         
model.layers.16.mlp.experts.9.down_proj       torch.Size([0, 2048])          84.376289            84.911823            574.513577           3281.748732         
model.layers.16.mlp.experts.10.gate_proj      torch.Size([0, 1408])          86.095200            86.513042            527.309061           3879.956898         
model.layers.16.mlp.experts.10.act_fn         torch.Size([0, 1408])          0.545856             1.260757             621.312000           3883.200000         
model.layers.16.mlp.experts.10.up_proj        torch.Size([0, 1408])          92.741890            93.340635            551.897600           3464.447117         
model.layers.16.mlp.experts.10.down_proj      torch.Size([0, 2048])          92.919968            94.291925            583.807568           3164.405189         
model.layers.16.mlp.experts.11.gate_proj      torch.Size([0, 1408])          85.541054            86.055040            589.106595           3083.691243         
model.layers.16.mlp.experts.11.act_fn         torch.Size([0, 1408])          0.356768             0.762939             621.568000           3107.840000         
model.layers.16.mlp.experts.11.up_proj        torch.Size([0, 1408])          84.657341            85.076571            564.570993           3085.568000         
model.layers.16.mlp.experts.11.down_proj      torch.Size([0, 2048])          91.583389            92.013597            576.294667           3182.944000         
model.layers.16.mlp.experts.12.gate_proj      torch.Size([0, 1408])          96.236542            96.861839            562.871937           3216.077102         
model.layers.16.mlp.experts.12.act_fn         torch.Size([0, 1408])          0.539584             1.263857             621.568000           3261.888000         
model.layers.16.mlp.experts.12.up_proj        torch.Size([0, 1408])          71.956413            72.572231            564.083916           3186.981147         
model.layers.16.mlp.experts.12.down_proj      torch.Size([0, 2048])          116.058723           116.582632           589.727059           3046.090824         
model.layers.16.mlp.experts.13.gate_proj      torch.Size([1, 1408])          156.193954           156.793833           591.263373           2959.580444         
model.layers.16.mlp.experts.13.act_fn         torch.Size([1, 1408])          0.499232             0.975132             621.568000           3107.840000         
model.layers.16.mlp.experts.13.up_proj        torch.Size([1, 1408])          144.186661           144.642353           621.744941           3102.917647         
model.layers.16.mlp.experts.13.down_proj      torch.Size([1, 2048])          168.515167           169.086218           621.490647           3420.466647         
model.layers.16.mlp.experts.14.gate_proj      torch.Size([1, 1408])          117.742882           118.409634           621.346595           3921.890595         
model.layers.16.mlp.experts.14.act_fn         torch.Size([1, 1408])          0.695616             1.435757             621.376000           3572.544000         
model.layers.16.mlp.experts.14.up_proj        torch.Size([1, 1408])          147.608871           148.508072           621.706378           3193.427892         
model.layers.16.mlp.experts.14.down_proj      torch.Size([1, 2048])          128.805466           129.628420           621.707320           3044.096871         
model.layers.16.mlp.experts.15.gate_proj      torch.Size([0, 1408])          139.887329           140.466690           621.639111           3143.211111         
model.layers.16.mlp.experts.15.act_fn         torch.Size([0, 1408])          0.830656             1.643896             621.568000           3417.216000         
model.layers.16.mlp.experts.15.up_proj        torch.Size([0, 1408])          143.134918           143.774271           551.953882           3235.427294         
model.layers.16.mlp.experts.15.down_proj      torch.Size([0, 2048])          135.429382           136.034250           580.963752           3145.049159         
model.layers.16.mlp.experts.16.gate_proj      torch.Size([0, 1408])          154.000381           154.454231           564.594503           3078.089143         
model.layers.16.mlp.experts.16.act_fn         torch.Size([0, 1408])          0.639328             1.501322             621.568000           3417.216000         
model.layers.16.mlp.experts.16.up_proj        torch.Size([0, 1408])          147.124252           147.784233           560.042213           3057.015830         
model.layers.16.mlp.experts.16.down_proj      torch.Size([0, 2048])          150.598526           151.371241           579.689305           3176.954553         
model.layers.16.mlp.experts.17.gate_proj      torch.Size([0, 1408])          127.867714           128.239155           567.946817           3224.667042         
model.layers.16.mlp.experts.17.act_fn         torch.Size([0, 1408])          0.334496             0.769615             621.568000           3417.216000         
model.layers.16.mlp.experts.17.up_proj        torch.Size([0, 1408])          131.400574           132.042646           552.036699           3236.955301         
model.layers.16.mlp.experts.17.down_proj      torch.Size([0, 2048])          141.664703           142.126799           537.814695           3444.990638         
model.layers.16.mlp.experts.18.gate_proj      torch.Size([0, 1408])          148.648346           149.341106           511.758222           3822.715399         
model.layers.16.mlp.experts.18.act_fn         torch.Size([0, 1408])          0.754656             1.668453             621.568000           3417.216000         
model.layers.16.mlp.experts.18.up_proj        torch.Size([0, 1408])          147.229797           147.869349           544.936329           3290.969863         
model.layers.16.mlp.experts.18.down_proj      torch.Size([0, 2048])          142.786469           143.301964           563.625651           3198.677333         
model.layers.16.mlp.experts.19.gate_proj      torch.Size([0, 1408])          136.854401           138.160706           562.082000           3277.063500         
model.layers.16.mlp.experts.19.act_fn         torch.Size([0, 1408])          0.558112             1.125813             621.568000           3107.840000         
model.layers.16.mlp.experts.19.up_proj        torch.Size([0, 1408])          128.837402           129.267931           553.100094           3160.441953         
model.layers.16.mlp.experts.19.down_proj      torch.Size([0, 2048])          80.320030            80.846071            574.163556           3067.912889         
model.layers.16.mlp.experts.20.gate_proj      torch.Size([0, 1408])          78.779587            79.226255            568.131027           2998.645622         
model.layers.16.mlp.experts.20.act_fn         torch.Size([0, 1408])          0.380160             0.882626             582.896000           2952.448000         
model.layers.16.mlp.experts.20.up_proj        torch.Size([0, 1408])          85.313538            85.736513            539.153214           3136.736221         
model.layers.16.mlp.experts.20.down_proj      torch.Size([0, 2048])          92.208893            92.658997            566.989000           3198.405000         
model.layers.16.mlp.experts.21.gate_proj      torch.Size([1, 1408])          85.718620            86.359024            595.571973           3134.491490         
model.layers.16.mlp.experts.21.act_fn         torch.Size([1, 1408])          0.536544             0.976086             621.568000           3261.888000         
model.layers.16.mlp.experts.21.up_proj        torch.Size([1, 1408])          94.067230            94.553947            621.703111           3068.575111         
model.layers.16.mlp.experts.21.down_proj      torch.Size([1, 2048])          92.330017            92.894554            621.519324           3351.565521         
model.layers.16.mlp.experts.22.gate_proj      torch.Size([0, 1408])          94.036995            94.493151            592.852253           3960.845772         
model.layers.16.mlp.experts.22.act_fn         torch.Size([0, 1408])          0.830336             1.584291             621.568000           3572.544000         
model.layers.16.mlp.experts.22.up_proj        torch.Size([0, 1408])          87.575203            88.217258            543.916418           3393.356896         
model.layers.16.mlp.experts.22.down_proj      torch.Size([0, 2048])          88.633789            89.218378            577.005589           3126.696767         
model.layers.16.mlp.experts.23.gate_proj      torch.Size([0, 1408])          91.074081            91.726542            548.211200           2909.329920         
model.layers.16.mlp.experts.23.act_fn         torch.Size([0, 1408])          0.457728             1.000881             621.568000           3263.232000         
model.layers.16.mlp.experts.23.up_proj        torch.Size([0, 1408])          81.660995            82.230568            552.699111           3020.432000         
model.layers.16.mlp.experts.23.down_proj      torch.Size([0, 2048])          86.747360            87.251186            525.243586           3123.848386         
model.layers.16.mlp.experts.24.gate_proj      torch.Size([0, 1408])          90.806114            91.356277            533.473730           3163.353946         
model.layers.16.mlp.experts.24.act_fn         torch.Size([0, 1408])          0.424224             0.816584             621.568000           3572.544000         
model.layers.16.mlp.experts.24.up_proj        torch.Size([0, 1408])          82.695137            83.058834            545.113863           3185.396603         
model.layers.16.mlp.experts.24.down_proj      torch.Size([0, 2048])          86.328323            86.987972            579.369796           3153.294803         
model.layers.16.mlp.experts.25.gate_proj      torch.Size([0, 1408])          92.444572            93.204498            569.609771           3063.950656         
model.layers.16.mlp.experts.25.act_fn         torch.Size([0, 1408])          0.401728             0.871420             621.824000           2952.448000         
model.layers.16.mlp.experts.25.up_proj        torch.Size([0, 1408])          85.260033            85.677385            552.184839           3120.823497         
model.layers.16.mlp.experts.25.down_proj      torch.Size([0, 2048])          119.726463           120.221615           539.120246           3448.602585         
model.layers.16.mlp.experts.26.gate_proj      torch.Size([0, 1408])          94.612961            95.402479            502.449823           3920.702380         
model.layers.16.mlp.experts.26.act_fn         torch.Size([0, 1408])          0.667584             1.372576             569.770667           3417.216000         
model.layers.16.mlp.experts.26.up_proj        torch.Size([0, 1408])          84.698975            85.224867            527.469091           3251.318303         
model.layers.16.mlp.experts.26.down_proj      torch.Size([0, 2048])          90.873375            91.428995            538.092308           3050.247161         
model.layers.16.mlp.experts.27.gate_proj      torch.Size([0, 1408])          90.854179            91.549635            563.574331           3085.442763         
model.layers.16.mlp.experts.27.act_fn         torch.Size([0, 1408])          0.372352             0.790596             621.568000           3417.216000         
model.layers.16.mlp.experts.27.up_proj        torch.Size([0, 1408])          80.775040            81.113815            534.943782           3211.358041         
model.layers.16.mlp.experts.27.down_proj      torch.Size([0, 2048])          88.234627            88.810444            541.797699           3233.430795         
model.layers.16.mlp.experts.28.gate_proj      torch.Size([0, 1408])          100.114433           100.608110           559.144518           3096.660719         
model.layers.16.mlp.experts.28.act_fn         torch.Size([0, 1408])          0.855584             1.680374             621.824000           3107.840000         
model.layers.16.mlp.experts.28.up_proj        torch.Size([0, 1408])          97.250206            98.089457            554.228083           3058.543228         
model.layers.16.mlp.experts.28.down_proj      torch.Size([0, 2048])          98.144447            98.583937            570.333647           3017.600941         
model.layers.16.mlp.experts.29.gate_proj      torch.Size([2, 1408])          89.808418            90.442657            590.433074           3143.986685         
model.layers.16.mlp.experts.29.act_fn         torch.Size([2, 1408])          0.404896             0.783205             621.568000           3261.888000         
model.layers.16.mlp.experts.29.up_proj        torch.Size([2, 1408])          94.594498            95.183849            621.649623           3236.689623         
model.layers.16.mlp.experts.29.down_proj      torch.Size([2, 2048])          103.631683           104.325533           621.585534           3375.071123         
model.layers.16.mlp.experts.30.gate_proj      torch.Size([0, 1408])          94.428093            94.980001            586.130228           3613.867747         
model.layers.16.mlp.experts.30.act_fn         torch.Size([0, 1408])          0.370720             0.867367             621.568000           3417.216000         
model.layers.16.mlp.experts.30.up_proj        torch.Size([0, 1408])          83.529922            84.095478            547.183342           3167.365699         
model.layers.16.mlp.experts.30.down_proj      torch.Size([0, 2048])          81.500671            82.424402            542.462282           3099.606336         
model.layers.16.mlp.experts.31.gate_proj      torch.Size([0, 1408])          91.726814            92.135429            545.626122           3105.890830         
model.layers.16.mlp.experts.31.act_fn         torch.Size([0, 1408])          0.395296             0.877857             621.568000           3211.434667         
model.layers.16.mlp.experts.31.up_proj        torch.Size([0, 1408])          85.753120            86.321354            532.172889           3069.194667         
model.layers.16.mlp.experts.31.down_proj      torch.Size([0, 2048])          85.677795            86.200237            553.061007           3037.270204         
model.layers.16.mlp.experts.32.gate_proj      torch.Size([0, 1408])          93.610397            94.021082            555.471217           3030.687329         
model.layers.16.mlp.experts.32.act_fn         torch.Size([0, 1408])          0.596512             1.310349             621.568000           3263.232000         
model.layers.16.mlp.experts.32.up_proj        torch.Size([0, 1408])          89.988960            90.554476            509.787301           3142.613035         
model.layers.16.mlp.experts.32.down_proj      torch.Size([0, 2048])          93.017532            93.382120            548.128244           3171.830229         
model.layers.16.mlp.experts.33.gate_proj      torch.Size([0, 1408])          88.371330            89.010239            572.459697           3138.840276         
model.layers.16.mlp.experts.33.act_fn         torch.Size([0, 1408])          0.416896             0.919819             621.568000           3315.029333         
model.layers.16.mlp.experts.33.up_proj        torch.Size([0, 1408])          89.327171            89.719057            546.225127           3137.386366         
model.layers.16.mlp.experts.33.down_proj      torch.Size([0, 2048])          94.116989            94.821930            538.614486           3331.860757         
model.layers.16.mlp.experts.34.gate_proj      torch.Size([0, 1408])          75.205856            75.823784            503.825297           3803.134270         
model.layers.16.mlp.experts.34.act_fn         torch.Size([0, 1408])          0.397280             0.838518             505.024000           3533.712000         
model.layers.16.mlp.experts.34.up_proj        torch.Size([0, 1408])          83.346046            83.745241            537.125101           3345.712696         
model.layers.16.mlp.experts.34.down_proj      torch.Size([0, 2048])          89.015587            89.599609            560.889219           3216.829457         
model.layers.16.mlp.experts.35.gate_proj      torch.Size([2, 1408])          93.538750            94.353914            587.188524           3737.533352         
model.layers.16.mlp.experts.35.act_fn         torch.Size([2, 1408])          0.742176             1.542091             621.824000           3107.840000         
model.layers.16.mlp.experts.35.up_proj        torch.Size([2, 1408])          82.882751            83.762169            621.731556           3080.862222         
model.layers.16.mlp.experts.35.down_proj      torch.Size([2, 2048])          89.398590            90.160131            621.628867           3147.656951         
model.layers.16.mlp.experts.36.gate_proj      torch.Size([1, 1408])          90.344223            91.125727            621.649778           3132.594222         
model.layers.16.mlp.experts.36.act_fn         torch.Size([1, 1408])          0.683136             1.457691             621.568000           3261.888000         
model.layers.16.mlp.experts.36.up_proj        torch.Size([1, 1408])          87.406754            88.356733            621.587421           3195.525297         
model.layers.16.mlp.experts.36.down_proj      torch.Size([1, 2048])          90.029091            90.851068            621.624889           3058.141867         
model.layers.16.mlp.experts.37.gate_proj      torch.Size([1, 1408])          90.805183            91.630220            621.643917           3073.491862         
model.layers.16.mlp.experts.37.act_fn         torch.Size([1, 1408])          0.661312             1.477718             621.568000           3107.840000         
model.layers.16.mlp.experts.37.up_proj        torch.Size([1, 1408])          84.436546            85.143805            621.614545           3261.256056         
model.layers.16.mlp.experts.37.down_proj      torch.Size([1, 2048])          82.458656            82.993507            621.401187           3737.361342         
model.layers.16.mlp.experts.38.gate_proj      torch.Size([0, 1408])          80.813789            81.340551            571.380439           3628.410632         
model.layers.16.mlp.experts.38.act_fn         torch.Size([0, 1408])          0.562880             1.363754             570.005333           3107.840000         
model.layers.16.mlp.experts.38.up_proj        torch.Size([0, 1408])          81.765091            82.431078            523.811081           3160.788385         
model.layers.16.mlp.experts.38.down_proj      torch.Size([0, 2048])          86.891266            87.260008            563.560518           3107.840000         
model.layers.16.mlp.experts.39.gate_proj      torch.Size([0, 1408])          90.274109            90.710878            566.174629           3073.431771         
model.layers.16.mlp.experts.39.act_fn         torch.Size([0, 1408])          0.356864             0.853300             621.568000           3224.384000         
model.layers.16.mlp.experts.39.up_proj        torch.Size([0, 1408])          80.978333            81.426144            531.674971           3290.424229         
model.layers.16.mlp.experts.39.down_proj      torch.Size([0, 2048])          96.516960            97.101212            576.032671           3177.386070         
model.layers.16.mlp.experts.40.gate_proj      torch.Size([1, 1408])          90.912094            91.385841            591.044354           3068.480871         
model.layers.16.mlp.experts.40.act_fn         torch.Size([1, 1408])          0.414080             0.839472             621.619200           2983.526400         
model.layers.16.mlp.experts.40.up_proj        torch.Size([1, 1408])          97.182335            97.700357            621.743891           2964.248381         
model.layers.16.mlp.experts.40.down_proj      torch.Size([1, 2048])          103.373665           104.165077           621.740408           2950.333823         
model.layers.16.mlp.experts.41.gate_proj      torch.Size([0, 1408])          93.139900            93.697309            621.818475           3012.973122         
model.layers.16.mlp.experts.41.act_fn         torch.Size([0, 1408])          0.361664             0.787973             621.568000           3107.840000         
model.layers.16.mlp.experts.41.up_proj        torch.Size([0, 1408])          89.042015            89.569807            530.477913           3223.467130         
model.layers.16.mlp.experts.41.down_proj      torch.Size([0, 2048])          90.527939            90.886116            469.136306           3658.627261         
model.layers.16.mlp.experts.42.gate_proj      torch.Size([0, 1408])          95.029312            95.751762            535.814621           3466.906483         
model.layers.16.mlp.experts.42.act_fn         torch.Size([0, 1408])          0.631840             1.363754             621.568000           3262.896000         
model.layers.16.mlp.experts.42.up_proj        torch.Size([0, 1408])          86.959747            87.498426            532.017396           3113.054497         
model.layers.16.mlp.experts.42.down_proj      torch.Size([0, 2048])          84.192352            84.630251            537.961305           3162.943546         
model.layers.16.mlp.experts.43.gate_proj      torch.Size([1, 1408])          103.479744           103.945017           581.455217           3199.923469         
model.layers.16.mlp.experts.43.act_fn         torch.Size([1, 1408])          0.391136             0.847816             621.568000           3417.216000         
model.layers.16.mlp.experts.43.up_proj        torch.Size([1, 1408])          88.409569            89.312553            621.731914           3100.912345         
model.layers.16.mlp.experts.43.down_proj      torch.Size([1, 2048])          75.774590            76.490164            621.752795           3030.525033         
model.layers.16.mlp.experts.44.gate_proj      torch.Size([0, 1408])          88.549438            89.164734            621.763556           3016.040889         
model.layers.16.mlp.experts.44.act_fn         torch.Size([0, 1408])          0.430464             0.855446             621.568000           3418.154667         
model.layers.16.mlp.experts.44.up_proj        torch.Size([0, 1408])          96.062370            96.627712            551.524444           3122.947556         
model.layers.16.mlp.experts.44.down_proj      torch.Size([0, 2048])          82.576576            83.095551            563.548086           3216.187856         
model.layers.16.mlp.experts.45.gate_proj      torch.Size([0, 1408])          89.574173            90.117455            571.273014           3215.082366         
model.layers.16.mlp.experts.45.act_fn         torch.Size([0, 1408])          0.357408             0.793695             621.824000           3107.840000         
model.layers.16.mlp.experts.45.up_proj        torch.Size([0, 1408])          90.802048            91.193676            548.362514           3229.417143         
model.layers.16.mlp.experts.45.down_proj      torch.Size([0, 2048])          85.855743            86.395502            493.984821           3664.123077         
model.layers.16.mlp.experts.46.gate_proj      torch.Size([0, 1408])          89.967773            90.442657            548.188444           3517.644000         
model.layers.16.mlp.experts.46.act_fn         torch.Size([0, 1408])          0.341984             0.730038             621.568000           3263.232000         
model.layers.16.mlp.experts.46.up_proj        torch.Size([0, 1408])          90.195999            90.616703            535.700848           3226.663758         
model.layers.16.mlp.experts.46.down_proj      torch.Size([0, 2048])          70.763168            71.193218            529.894788           3111.371636         
model.layers.16.mlp.experts.47.gate_proj      torch.Size([0, 1408])          92.215263            92.654228            558.130222           3022.622222         
model.layers.16.mlp.experts.47.act_fn         torch.Size([0, 1408])          0.635328             1.488447             621.824000           2952.448000         
model.layers.16.mlp.experts.47.up_proj        torch.Size([0, 1408])          90.720642            91.459513            547.900867           3051.333818         
model.layers.16.mlp.experts.47.down_proj      torch.Size([0, 2048])          97.271713            97.950697            574.548745           3077.786041         
model.layers.16.mlp.experts.48.gate_proj      torch.Size([2, 1408])          105.313889           106.114149           590.775523           3115.025801         
model.layers.16.mlp.experts.48.act_fn         torch.Size([2, 1408])          0.736992             1.379967             621.568000           3230.822400         
model.layers.16.mlp.experts.48.up_proj        torch.Size([2, 1408])          86.724640            87.419748            621.568000           3277.367049         
model.layers.16.mlp.experts.48.down_proj      torch.Size([2, 2048])          91.196129            91.828585            621.659178           3089.216000         
model.layers.16.mlp.experts.49.gate_proj      torch.Size([0, 1408])          87.825188            88.213921            621.675016           3078.118295         
model.layers.16.mlp.experts.49.act_fn         torch.Size([0, 1408])          0.637472             1.421452             621.568000           3159.210667         
model.layers.16.mlp.experts.49.up_proj        torch.Size([0, 1408])          97.529503            98.089695            621.708899           3155.572093         
model.layers.16.mlp.experts.49.down_proj      torch.Size([0, 2048])          90.245377            90.956450            491.989760           3781.327360         
model.layers.16.mlp.experts.50.gate_proj      torch.Size([1, 1408])          62.593216            63.235760            567.926535           3613.994366         
model.layers.16.mlp.experts.50.act_fn         torch.Size([1, 1408])          0.402144             0.806332             621.568000           3324.019200         
model.layers.16.mlp.experts.50.up_proj        torch.Size([1, 1408])          87.792511            88.239193            621.676503           3196.847470         
model.layers.16.mlp.experts.50.down_proj      torch.Size([1, 2048])          82.075455            82.548618            621.721958           3057.554350         
model.layers.16.mlp.experts.51.gate_proj      torch.Size([0, 1408])          119.624252           120.136499           621.738667           3128.899483         
model.layers.16.mlp.experts.51.act_fn         torch.Size([0, 1408])          0.626784             1.403809             621.568000           3418.624000         
model.layers.16.mlp.experts.51.up_proj        torch.Size([0, 1408])          97.365181            97.912073            532.773517           3200.222897         
model.layers.16.mlp.experts.51.down_proj      torch.Size([0, 2048])          105.015839           105.796814           568.036507           3259.709746         
model.layers.16.mlp.experts.52.gate_proj      torch.Size([0, 1408])          93.144989            93.885422            542.473578           3005.302422         
model.layers.16.mlp.experts.52.act_fn         torch.Size([0, 1408])          0.560384             1.494408             621.568000           3263.232000         
model.layers.16.mlp.experts.52.up_proj        torch.Size([0, 1408])          86.439102            86.851835            558.050532           3019.523683         
model.layers.16.mlp.experts.52.down_proj      torch.Size([0, 2048])          90.064285            90.776205            564.415570           3007.844081         
model.layers.16.mlp.experts.53.gate_proj      torch.Size([0, 1408])          94.205406            94.668627            561.904000           3089.990919         
model.layers.16.mlp.experts.53.act_fn         torch.Size([0, 1408])          0.483136             1.042128             621.568000           3263.232000         
model.layers.16.mlp.experts.53.up_proj        torch.Size([0, 1408])          92.633087            93.199730            548.697159           3338.858372         
model.layers.16.mlp.experts.53.down_proj      torch.Size([0, 2048])          94.054497            94.558477            499.974310           3836.550761         
model.layers.16.mlp.experts.54.gate_proj      torch.Size([0, 1408])          98.372925            98.968267            542.840986           3391.239014         
model.layers.16.mlp.experts.54.act_fn         torch.Size([0, 1408])          0.373952             0.784636             621.824000           3107.840000         
model.layers.16.mlp.experts.54.up_proj        torch.Size([0, 1408])          88.432861            88.806629            553.361194           3103.201433         
model.layers.16.mlp.experts.54.down_proj      torch.Size([0, 2048])          93.100029            93.662739            562.629408           3137.269634         
model.layers.16.mlp.experts.55.gate_proj      torch.Size([0, 1408])          94.753441            95.251560            562.588394           3164.664789         
model.layers.16.mlp.experts.55.act_fn         torch.Size([0, 1408])          0.428544             0.929594             621.568000           3417.216000         
model.layers.16.mlp.experts.55.up_proj        torch.Size([0, 1408])          83.449501            83.785057            543.928338           3263.122479         
model.layers.16.mlp.experts.55.down_proj      torch.Size([0, 2048])          101.047585           101.542473           567.400635           3120.172698         
model.layers.16.mlp.experts.56.gate_proj      torch.Size([0, 1408])          149.195587           149.614334           577.225846           3010.040839         
model.layers.16.mlp.experts.56.act_fn         torch.Size([0, 1408])          0.438336             0.941277             621.824000           3107.840000         
model.layers.16.mlp.experts.56.up_proj        torch.Size([0, 1408])          141.211197           141.646147           556.110873           3071.727775         
model.layers.16.mlp.experts.56.down_proj      torch.Size([0, 2048])          146.885147           147.269487           575.700364           3251.062303         
model.layers.16.mlp.experts.57.gate_proj      torch.Size([1, 1408])          146.931366           147.614002           584.772741           3283.462163         
model.layers.16.mlp.experts.57.act_fn         torch.Size([1, 1408])          0.551488             1.145363             621.568000           3261.888000         
model.layers.16.mlp.experts.57.up_proj        torch.Size([1, 1408])          141.418396           142.049789           621.625344           3302.411264         
model.layers.16.mlp.experts.57.down_proj      torch.Size([1, 2048])          127.594589           128.092766           617.741796           3715.308072         
model.layers.16.mlp.experts.58.gate_proj      torch.Size([0, 1408])          148.594879           149.077654           621.555973           3390.624215         
model.layers.16.mlp.experts.58.act_fn         torch.Size([0, 1408])          0.360384             0.829220             621.568000           3263.232000         
model.layers.16.mlp.experts.58.up_proj        torch.Size([0, 1408])          143.652512           144.104958           556.696358           3213.272836         
model.layers.16.mlp.experts.58.down_proj      torch.Size([0, 2048])          158.385696           159.038305           561.439347           3228.336762         
model.layers.16.mlp.experts.59.gate_proj      torch.Size([0, 1408])          156.105988           156.729460           566.070919           3118.339459         
model.layers.16.mlp.experts.59.act_fn         torch.Size([0, 1408])          0.782688             1.765490             621.568000           3263.232000         
model.layers.16.mlp.experts.59.up_proj        torch.Size([0, 1408])          152.711014           155.374289           545.090133           3061.222400         
model.layers.16.mlp.experts.59.down_proj      torch.Size([0, 2048])          135.389786           136.729479           560.703117           3034.045793         
model.layers.16.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          565.662781           566.375017           639.738501           3131.207026         
model.layers.16.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.060256             1.553297             776.704000           3261.888000         
model.layers.16.mlp.shared_expert.up_proj     torch.Size([5, 5632])          563.230225           564.603806           690.574472           3214.375397         
model.layers.16.mlp.shared_expert.down_proj   torch.Size([5, 2048])          366.704071           368.607521           647.507899           3555.179429         
model.layers.16.mlp.shared_expert_gate        torch.Size([5, 1])             14.832544            16.455889            643.395368           3254.529123         
model.layers.17.input_layernorm               torch.Size([1, 5, 2048])       13.153632            14.746904            466.386824           3077.955765         
model.layers.17.self_attn.q_proj              torch.Size([1, 5, 2048])       139.078140           140.675068           573.473492           3066.051316         
model.layers.17.self_attn.k_proj              torch.Size([1, 5, 2048])       152.205444           153.638601           621.654732           3190.670339         
model.layers.17.self_attn.v_proj              torch.Size([1, 5, 2048])       137.830078           139.274597           621.597397           3210.279809         
model.layers.17.self_attn.o_proj              torch.Size([1, 5, 2048])       125.461121           126.945972           663.939241           3093.506835         
model.layers.17.post_attention_layernorm      torch.Size([1, 5, 2048])       8.358688             10.093689            637.265920           3113.824000         
model.layers.17.mlp.gate                      torch.Size([5, 60])            12.512064            13.853788            477.742829           3274.602146         
model.layers.17.mlp.experts.0.gate_proj       torch.Size([0, 1408])          86.431358            87.686539            565.642492           3281.764721         
model.layers.17.mlp.experts.0.act_fn          torch.Size([0, 1408])          0.005504             1.379251             621.568000           3417.216000         
model.layers.17.mlp.experts.0.up_proj         torch.Size([0, 1408])          86.130493            87.471485            618.356211           3925.283789         
model.layers.17.mlp.experts.0.down_proj       torch.Size([0, 2048])          95.058273            96.506119            568.287086           3518.409600         
model.layers.17.mlp.experts.1.gate_proj       torch.Size([1, 1408])          86.066628            87.414503            593.306811           3137.082378         
model.layers.17.mlp.experts.1.act_fn          torch.Size([1, 1408])          0.052480             1.302481             621.781333           2952.448000         
model.layers.17.mlp.experts.1.up_proj         torch.Size([1, 1408])          80.481987            82.076311            621.709617           2989.918411         
model.layers.17.mlp.experts.1.down_proj       torch.Size([1, 2048])          100.952316           101.833582           621.568000           3209.098811         
model.layers.17.mlp.experts.2.gate_proj       torch.Size([0, 1408])          104.431808           105.191231           621.641915           3185.178592         
model.layers.17.mlp.experts.2.act_fn          torch.Size([0, 1408])          0.669088             1.446724             621.568000           3211.434667         
model.layers.17.mlp.experts.2.up_proj         torch.Size([0, 1408])          113.600098           114.262819           549.810068           3122.639238         
model.layers.17.mlp.experts.2.down_proj       torch.Size([0, 2048])          97.556381            98.234415            568.163752           3044.611531         
model.layers.17.mlp.experts.3.gate_proj       torch.Size([1, 1408])          97.519997            98.156691            584.285504           3028.462298         
model.layers.17.mlp.experts.3.act_fn          torch.Size([1, 1408])          0.415840             0.888586             621.568000           3107.840000         
model.layers.17.mlp.experts.3.up_proj         torch.Size([1, 1408])          105.525406           105.974674           621.745778           3121.977333         
model.layers.17.mlp.experts.3.down_proj       torch.Size([1, 2048])          104.871651           105.329514           621.649541           3181.074015         
model.layers.17.mlp.experts.4.gate_proj       torch.Size([1, 1408])          106.044800           106.537819           621.580190           3195.001469         
model.layers.17.mlp.experts.4.act_fn          torch.Size([1, 1408])          0.429120             0.864267             621.312000           3696.806400         
model.layers.17.mlp.experts.4.up_proj         torch.Size([1, 1408])          97.969795            98.669767            605.902000           3841.952000         
model.layers.17.mlp.experts.4.down_proj       torch.Size([1, 2048])          97.310333            98.019361            621.552537           3320.164940         
model.layers.17.mlp.experts.5.gate_proj       torch.Size([1, 1408])          94.792732            95.441103            621.748706           3125.928000         
model.layers.17.mlp.experts.5.act_fn          torch.Size([1, 1408])          0.671840             1.415253             621.568000           3417.216000         
model.layers.17.mlp.experts.5.up_proj         torch.Size([1, 1408])          98.832352            99.649429            621.641669           3258.220662         
model.layers.17.mlp.experts.5.down_proj       torch.Size([1, 2048])          93.610947            94.497204            621.731556           3069.189333         
model.layers.17.mlp.experts.6.gate_proj       torch.Size([0, 1408])          95.758430            96.431971            621.772456           3030.714416         
model.layers.17.mlp.experts.6.act_fn          torch.Size([0, 1408])          0.699392             1.551390             621.568000           3263.232000         
model.layers.17.mlp.experts.6.up_proj         torch.Size([0, 1408])          68.875618            69.490194            563.630150           3030.837986         
model.layers.17.mlp.experts.6.down_proj       torch.Size([0, 2048])          85.275810            85.721970            580.769297           3128.801297         
model.layers.17.mlp.experts.7.gate_proj       torch.Size([0, 1408])          85.513763            86.161375            565.699918           3185.949605         
model.layers.17.mlp.experts.7.act_fn          torch.Size([0, 1408])          0.005600             1.303673             621.568000           3417.685333         
model.layers.17.mlp.experts.7.up_proj         torch.Size([0, 1408])          106.864418           107.250214           549.386959           3144.936767         
model.layers.17.mlp.experts.7.down_proj       torch.Size([0, 2048])          102.215263           102.704048           582.947556           3108.919111         
model.layers.17.mlp.experts.8.gate_proj       torch.Size([0, 1408])          73.949760            74.360371            553.900800           3340.051200         
model.layers.17.mlp.experts.8.act_fn          torch.Size([0, 1408])          0.577408             1.298189             621.312000           3881.600000         
model.layers.17.mlp.experts.8.up_proj         torch.Size([0, 1408])          100.137405           100.783348           499.266013           3900.207497         
model.layers.17.mlp.experts.8.down_proj       torch.Size([0, 2048])          93.052063            93.602180            561.071878           3335.923786         
model.layers.17.mlp.experts.9.gate_proj       torch.Size([0, 1408])          111.374718           112.049818           569.264110           3188.215172         
model.layers.17.mlp.experts.9.act_fn          torch.Size([0, 1408])          0.541792             1.255751             621.568000           3211.434667         
model.layers.17.mlp.experts.9.up_proj         torch.Size([0, 1408])          96.825920            97.396851            538.032113           3108.942071         
model.layers.17.mlp.experts.9.down_proj       torch.Size([0, 2048])          77.838013            78.394890            578.308476           3039.380587         
model.layers.17.mlp.experts.10.gate_proj      torch.Size([1, 1408])          95.952515            96.828938            585.895597           3045.133813         
model.layers.17.mlp.experts.10.act_fn         torch.Size([1, 1408])          0.491808             1.065969             621.568000           3261.888000         
model.layers.17.mlp.experts.10.up_proj        torch.Size([1, 1408])          95.048836            95.568180            621.622993           3168.574578         
model.layers.17.mlp.experts.10.down_proj      torch.Size([1, 2048])          91.836639            92.446089            621.568000           3282.438575         
model.layers.17.mlp.experts.11.gate_proj      torch.Size([1, 1408])          102.558723           103.317261           621.662940           3094.453404         
model.layers.17.mlp.experts.11.act_fn         torch.Size([1, 1408])          0.625280             1.441002             621.568000           3107.840000         
model.layers.17.mlp.experts.11.up_proj        torch.Size([1, 1408])          98.346115            99.364758            621.682939           3081.020517         
model.layers.17.mlp.experts.11.down_proj      torch.Size([1, 2048])          95.628899            96.366405            621.682526           3060.681263         
model.layers.17.mlp.experts.12.gate_proj      torch.Size([0, 1408])          107.544899           108.013391           621.558657           3369.848526         
model.layers.17.mlp.experts.12.act_fn         torch.Size([0, 1408])          0.692000             1.351357             621.312000           3779.648000         
model.layers.17.mlp.experts.12.up_proj        torch.Size([0, 1408])          94.334686            94.930172            499.904398           3765.463851         
model.layers.17.mlp.experts.12.down_proj      torch.Size([0, 2048])          91.507683            92.216969            565.932138           3219.177048         
model.layers.17.mlp.experts.13.gate_proj      torch.Size([0, 1408])          93.947678            94.532490            566.878118           3062.136471         
model.layers.17.mlp.experts.13.act_fn         torch.Size([0, 1408])          0.757920             1.516342             621.568000           3263.232000         
model.layers.17.mlp.experts.13.up_proj        torch.Size([0, 1408])          83.880226            84.505558            561.508571           3069.784816         
model.layers.17.mlp.experts.13.down_proj      torch.Size([0, 2048])          92.470116            92.912674            583.658965           3172.845203         
model.layers.17.mlp.experts.14.gate_proj      torch.Size([1, 1408])          93.977470            94.592333            588.311195           3166.073557         
model.layers.17.mlp.experts.14.act_fn         torch.Size([1, 1408])          0.605440             1.378536             621.568000           3263.232000         
model.layers.17.mlp.experts.14.up_proj        torch.Size([1, 1408])          76.694305            77.451468            621.729391           3078.524290         
model.layers.17.mlp.experts.14.down_proj      torch.Size([1, 2048])          90.377922            91.032267            621.737558           3044.043636         
model.layers.17.mlp.experts.15.gate_proj      torch.Size([0, 1408])          96.408195            96.793175            621.774222           3031.176444         
model.layers.17.mlp.experts.15.act_fn         torch.Size([0, 1408])          0.380352             0.791073             621.568000           3263.232000         
model.layers.17.mlp.experts.15.up_proj        torch.Size([0, 1408])          87.704926            88.093996            556.509091           3197.924252         
model.layers.17.mlp.experts.15.down_proj      torch.Size([0, 2048])          104.896317           105.532408           575.700732           3187.634930         
model.layers.17.mlp.experts.16.gate_proj      torch.Size([0, 1408])          97.423363            98.063231            508.858562           3331.504105         
model.layers.17.mlp.experts.16.act_fn         torch.Size([0, 1408])          0.563008             1.293421             517.760000           4036.864000         
model.layers.17.mlp.experts.16.up_proj        torch.Size([0, 1408])          95.069794            95.636368            507.462076           3638.428759         
model.layers.17.mlp.experts.16.down_proj      torch.Size([0, 2048])          96.395203            96.917868            548.867531           3082.090814         
model.layers.17.mlp.experts.17.gate_proj      torch.Size([0, 1408])          92.342751            92.879295            559.490286           3192.195657         
model.layers.17.mlp.experts.17.act_fn         torch.Size([0, 1408])          0.433024             1.024961             621.568000           3418.624000         
model.layers.17.mlp.experts.17.up_proj        torch.Size([0, 1408])          85.124001            85.596323            550.588527           3243.849426         
model.layers.17.mlp.experts.17.down_proj      torch.Size([0, 2048])          94.131073            94.517469            579.343217           3168.573315         
model.layers.17.mlp.experts.18.gate_proj      torch.Size([0, 1408])          101.722946           102.315903           577.988958           3091.425352         
model.layers.17.mlp.experts.18.act_fn         torch.Size([0, 1408])          0.755840             1.489401             621.824000           2952.448000         
model.layers.17.mlp.experts.18.up_proj        torch.Size([0, 1408])          82.475586            83.190680            545.160767           3085.489096         
model.layers.17.mlp.experts.18.down_proj      torch.Size([0, 2048])          93.684509            94.153881            569.916444           3165.920444         
model.layers.17.mlp.experts.19.gate_proj      torch.Size([1, 1408])          88.928223            89.676142            595.719111           3197.193333         
model.layers.17.mlp.experts.19.act_fn         torch.Size([1, 1408])          0.935648             1.766205             621.568000           3417.216000         
model.layers.17.mlp.experts.19.up_proj        torch.Size([1, 1408])          87.649857            90.966225            621.568000           3237.776225         
model.layers.17.mlp.experts.19.down_proj      torch.Size([1, 2048])          93.198524            93.808413            621.605298           3140.416000         
model.layers.17.mlp.experts.20.gate_proj      torch.Size([0, 1408])          89.377411            89.993238            621.618503           3304.628680         
model.layers.17.mlp.experts.20.act_fn         torch.Size([0, 1408])          0.627328             1.326799             621.312000           3881.600000         
model.layers.17.mlp.experts.20.up_proj        torch.Size([0, 1408])          93.019905            93.703747            513.125895           3812.364211         
model.layers.17.mlp.experts.20.down_proj      torch.Size([0, 2048])          81.829315            82.340717            555.184993           3315.447172         
model.layers.17.mlp.experts.21.gate_proj      torch.Size([1, 1408])          87.506912            88.217258            590.329128           3289.469423         
model.layers.17.mlp.experts.21.act_fn         torch.Size([1, 1408])          0.401504             0.884533             621.568000           3107.840000         
model.layers.17.mlp.experts.21.up_proj        torch.Size([1, 1408])          84.203171            84.783792            621.647568           3189.523459         
model.layers.17.mlp.experts.21.down_proj      torch.Size([1, 2048])          89.185661            89.850664            621.648658           3099.928548         
model.layers.17.mlp.experts.22.gate_proj      torch.Size([0, 1408])          85.488510            85.939407            621.751376           3036.196312         
model.layers.17.mlp.experts.22.act_fn         torch.Size([0, 1408])          0.838464             1.984596             621.568000           3301.728000         
model.layers.17.mlp.experts.22.up_proj        torch.Size([0, 1408])          76.381119            77.018738            539.310199           3223.004397         
model.layers.17.mlp.experts.22.down_proj      torch.Size([0, 2048])          82.962303            84.336042            568.211000           3235.134000         
model.layers.17.mlp.experts.23.gate_proj      torch.Size([1, 1408])          91.343491            91.980219            590.392173           3056.376633         
model.layers.17.mlp.experts.23.act_fn         torch.Size([1, 1408])          0.688704             1.422882             621.568000           3107.840000         
model.layers.17.mlp.experts.23.up_proj        torch.Size([1, 1408])          85.825409            86.427927            621.721263           3043.434105         
model.layers.17.mlp.experts.23.down_proj      torch.Size([1, 2048])          96.390526            97.264528            621.726720           2961.065813         
model.layers.17.mlp.experts.24.gate_proj      torch.Size([0, 1408])          87.989532            88.888407            595.748923           3274.542359         
model.layers.17.mlp.experts.24.act_fn         torch.Size([0, 1408])          0.362528             0.881433             621.312000           4036.864000         
model.layers.17.mlp.experts.24.up_proj        torch.Size([0, 1408])          86.869118            87.312698            510.609936           3908.307975         
model.layers.17.mlp.experts.24.down_proj      torch.Size([0, 2048])          89.356003            89.852333            543.466965           3184.992671         
model.layers.17.mlp.experts.25.gate_proj      torch.Size([0, 1408])          90.008163            90.509892            574.803758           3054.652134         
model.layers.17.mlp.experts.25.act_fn         torch.Size([0, 1408])          0.644448             1.386881             621.568000           3107.840000         
model.layers.17.mlp.experts.25.up_proj        torch.Size([0, 1408])          99.548355            100.114822           544.542476           3146.952272         
model.layers.17.mlp.experts.25.down_proj      torch.Size([0, 2048])          98.558975            99.340916            569.143820           3152.393143         
model.layers.17.mlp.experts.26.gate_proj      torch.Size([1, 1408])          85.256638            85.802555            595.122411           3175.854904         
model.layers.17.mlp.experts.26.act_fn         torch.Size([1, 1408])          0.393472             0.795603             621.568000           3262.896000         
model.layers.17.mlp.experts.26.up_proj        torch.Size([1, 1408])          88.089539            88.620186            621.728427           3110.964053         
model.layers.17.mlp.experts.26.down_proj      torch.Size([1, 2048])          88.667648            89.212656            621.747200           3046.469120         
model.layers.17.mlp.experts.27.gate_proj      torch.Size([0, 1408])          94.951714            95.608950            621.770203           3034.648116         
model.layers.17.mlp.experts.27.act_fn         torch.Size([0, 1408])          0.562336             1.463175             621.568000           3263.232000         
model.layers.17.mlp.experts.27.up_proj        torch.Size([0, 1408])          98.921181            99.468470            548.333151           3112.290630         
model.layers.17.mlp.experts.27.down_proj      torch.Size([0, 2048])          94.217155            94.704390            566.587007           3184.851518         
model.layers.17.mlp.experts.28.gate_proj      torch.Size([0, 1408])          97.675743            98.395109            504.133200           3353.056800         
model.layers.17.mlp.experts.28.act_fn         torch.Size([0, 1408])          0.339296             0.779390             465.984000           4140.373333         
model.layers.17.mlp.experts.28.up_proj        torch.Size([0, 1408])          82.014175            82.574368            504.510380           3682.790076         
model.layers.17.mlp.experts.28.down_proj      torch.Size([0, 2048])          89.433731            90.058088            569.577175           3118.627804         
model.layers.17.mlp.experts.29.gate_proj      torch.Size([0, 1408])          71.713699            72.164536            563.724620           3206.258479         
model.layers.17.mlp.experts.29.act_fn         torch.Size([0, 1408])          0.005632             1.276255             621.568000           3418.624000         
model.layers.17.mlp.experts.29.up_proj        torch.Size([0, 1408])          90.577538            90.927839            533.089659           3232.070163         
model.layers.17.mlp.experts.29.down_proj      torch.Size([0, 2048])          108.760284           109.369278           565.252028           3115.407217         
model.layers.17.mlp.experts.30.gate_proj      torch.Size([0, 1408])          92.943619            93.404770            572.709053           3071.036632         
model.layers.17.mlp.experts.30.act_fn         torch.Size([0, 1408])          0.499616             1.158237             621.568000           3263.232000         
model.layers.17.mlp.experts.30.up_proj        torch.Size([0, 1408])          82.874657            83.526850            556.669405           3094.190703         
model.layers.17.mlp.experts.30.down_proj      torch.Size([0, 2048])          99.815773            100.557089           585.863608           3153.460364         
model.layers.17.mlp.experts.31.gate_proj      torch.Size([0, 1408])          90.645630            91.325521            576.744166           3144.161986         
model.layers.17.mlp.experts.31.act_fn         torch.Size([0, 1408])          0.374144             0.827551             621.568000           3263.232000         
model.layers.17.mlp.experts.31.up_proj        torch.Size([0, 1408])          103.697632           104.190350           548.449371           3217.724343         
model.layers.17.mlp.experts.31.down_proj      torch.Size([0, 2048])          143.888382           144.867897           570.327393           3133.560055         
model.layers.17.mlp.experts.32.gate_proj      torch.Size([0, 1408])          154.860153           155.621052           544.478881           3306.921175         
model.layers.17.mlp.experts.32.act_fn         torch.Size([0, 1408])          0.604064             1.323223             621.312000           3881.600000         
model.layers.17.mlp.experts.32.up_proj        torch.Size([0, 1408])          186.075043           186.685562           511.833935           3798.937935         
model.layers.17.mlp.experts.32.down_proj      torch.Size([0, 2048])          149.110214           149.562359           548.234222           3287.794222         
model.layers.17.mlp.experts.33.gate_proj      torch.Size([0, 1408])          162.968185           163.485050           569.443357           3320.238098         
model.layers.17.mlp.experts.33.act_fn         torch.Size([0, 1408])          0.723968             1.633406             621.568000           3263.232000         
model.layers.17.mlp.experts.33.up_proj        torch.Size([0, 1408])          170.208099           170.823097           551.416986           3195.114959         
model.layers.17.mlp.experts.33.down_proj      torch.Size([0, 2048])          154.457306           154.912949           566.520698           3058.823732         
model.layers.17.mlp.experts.34.gate_proj      torch.Size([0, 1408])          148.315033           148.732901           557.795765           2994.723765         
model.layers.17.mlp.experts.34.act_fn         torch.Size([0, 1408])          0.584768             1.345634             621.568000           3262.784000         
model.layers.17.mlp.experts.34.up_proj        torch.Size([0, 1408])          161.900131           162.469149           535.340000           3196.288000         
model.layers.17.mlp.experts.34.down_proj      torch.Size([0, 2048])          159.251450           159.796476           569.144497           3233.225269         
model.layers.17.mlp.experts.35.gate_proj      torch.Size([0, 1408])          155.221893           155.930996           572.052889           3122.947556         
model.layers.17.mlp.experts.35.act_fn         torch.Size([0, 1408])          0.355904             0.790596             621.568000           3107.840000         
model.layers.17.mlp.experts.35.up_proj        torch.Size([0, 1408])          136.270813           136.648893           552.556712           3063.138192         
model.layers.17.mlp.experts.35.down_proj      torch.Size([0, 2048])          145.668732           146.069288           575.035524           3039.481287         
model.layers.17.mlp.experts.36.gate_proj      torch.Size([1, 1408])          144.970947           145.548105           561.834137           3269.415752         
model.layers.17.mlp.experts.36.act_fn         torch.Size([1, 1408])          0.516032             1.085758             621.312000           3881.600000         
model.layers.17.mlp.experts.36.up_proj        torch.Size([1, 1408])          168.990082           169.526815           595.439888           3725.763133         
model.layers.17.mlp.experts.36.down_proj      torch.Size([1, 2048])          172.250214           173.073053           621.568000           3211.153655         
model.layers.17.mlp.experts.37.gate_proj      torch.Size([1, 1408])          157.646301           158.495903           621.689821           3107.625931         
model.layers.17.mlp.experts.37.act_fn         torch.Size([1, 1408])          0.838112             1.925945             621.568000           3263.232000         
model.layers.17.mlp.experts.37.up_proj        torch.Size([1, 1408])          139.444412           140.498161           621.711895           3049.948863         
model.layers.17.mlp.experts.37.down_proj      torch.Size([1, 2048])          128.813660           129.502773           621.662316           3168.773474         
model.layers.17.mlp.experts.38.gate_proj      torch.Size([1, 1408])          91.344322            91.967583            621.698685           3175.083860         
model.layers.17.mlp.experts.38.act_fn         torch.Size([1, 1408])          0.412384             0.891209             621.568000           3263.232000         
model.layers.17.mlp.experts.38.up_proj        torch.Size([1, 1408])          108.971741           109.617472           621.713297           3156.805622         
model.layers.17.mlp.experts.38.down_proj      torch.Size([1, 2048])          97.735298            98.539352            621.726316           3032.320421         
model.layers.17.mlp.experts.39.gate_proj      torch.Size([0, 1408])          91.855293            92.407703            621.802814           3021.134124         
model.layers.17.mlp.experts.39.act_fn         torch.Size([0, 1408])          0.659840             1.500607             621.824000           3107.840000         
model.layers.17.mlp.experts.39.up_proj        torch.Size([0, 1408])          91.790817            92.625141            559.148889           3187.694222         
model.layers.17.mlp.experts.39.down_proj      torch.Size([0, 2048])          73.526749            74.034691            572.874971           3218.617600         
model.layers.17.mlp.experts.40.gate_proj      torch.Size([0, 1408])          115.499901           116.019726           477.802137           3408.070758         
model.layers.17.mlp.experts.40.act_fn         torch.Size([0, 1408])          0.661312             1.507998             465.984000           4192.128000         
model.layers.17.mlp.experts.40.up_proj        torch.Size([0, 1408])          113.560669           114.441156           508.877600           3640.757200         
model.layers.17.mlp.experts.40.down_proj      torch.Size([0, 2048])          104.710785           105.399609           557.498262           2994.728607         
model.layers.17.mlp.experts.41.gate_proj      torch.Size([0, 1408])          71.846687            72.331667            561.397871           3072.143194         
model.layers.17.mlp.experts.41.act_fn         torch.Size([0, 1408])          0.417792             0.863791             621.568000           3263.232000         
model.layers.17.mlp.experts.41.up_proj        torch.Size([0, 1408])          86.187202            86.576462            547.260444           3182.420889         
model.layers.17.mlp.experts.41.down_proj      torch.Size([0, 2048])          103.514236           103.957176           574.576993           3118.556690         
model.layers.17.mlp.experts.42.gate_proj      torch.Size([1, 1408])          99.639870            100.330830           596.024938           3132.291531         
model.layers.17.mlp.experts.42.act_fn         torch.Size([1, 1408])          0.439392             0.879049             621.568000           3261.888000         
model.layers.17.mlp.experts.42.up_proj        torch.Size([1, 1408])          84.842018            85.337162            621.752795           3055.312106         
model.layers.17.mlp.experts.42.down_proj      torch.Size([1, 2048])          84.624481            85.107565            621.675520           3127.430827         
model.layers.17.mlp.experts.43.gate_proj      torch.Size([0, 1408])          94.836479            95.252514            621.659301           3148.872056         
model.layers.17.mlp.experts.43.act_fn         torch.Size([0, 1408])          0.808704             1.580954             621.568000           3572.544000         
model.layers.17.mlp.experts.43.up_proj        torch.Size([0, 1408])          95.006531            95.600367            565.263664           3201.150210         
model.layers.17.mlp.experts.43.down_proj      torch.Size([0, 2048])          91.907204            92.531681            576.413957           3161.841475         
model.layers.17.mlp.experts.44.gate_proj      torch.Size([0, 1408])          80.726974            81.460238            511.953231           3569.798154         
model.layers.17.mlp.experts.44.act_fn         torch.Size([0, 1408])          0.371328             0.830412             465.984000           4192.128000         
model.layers.17.mlp.experts.44.up_proj        torch.Size([0, 1408])          88.799484            89.166403            535.724418           3613.279045         
model.layers.17.mlp.experts.44.down_proj      torch.Size([0, 2048])          89.125183            89.712620            583.943758           3254.991515         
model.layers.17.mlp.experts.45.gate_proj      torch.Size([1, 1408])          84.665604            85.235834            599.120421           3189.598737         
model.layers.17.mlp.experts.45.act_fn         torch.Size([1, 1408])          0.364544             0.755787             621.568000           3107.840000         
model.layers.17.mlp.experts.45.up_proj        torch.Size([1, 1408])          85.531326            86.086750            621.705974           3047.297662         
model.layers.17.mlp.experts.45.down_proj      torch.Size([1, 2048])          86.880318            87.680817            621.637818           3027.427357         
model.layers.17.mlp.experts.46.gate_proj      torch.Size([1, 1408])          93.269600            93.873262            621.635459           3110.626595         
model.layers.17.mlp.experts.46.act_fn         torch.Size([1, 1408])          0.470976             0.888586             621.568000           3262.156800         
model.layers.17.mlp.experts.46.up_proj        torch.Size([1, 1408])          92.434143            92.931032            621.613903           3219.990069         
model.layers.17.mlp.experts.46.down_proj      torch.Size([1, 2048])          52.412128            53.053141            621.595864           3211.034122         
model.layers.17.mlp.experts.47.gate_proj      torch.Size([0, 1408])          92.753372            93.404055            621.734575           3095.068055         
model.layers.17.mlp.experts.47.act_fn         torch.Size([0, 1408])          0.648576             1.436949             621.824000           3107.840000         
model.layers.17.mlp.experts.47.up_proj        torch.Size([0, 1408])          97.314209            97.933054            525.527948           3009.592155         
model.layers.17.mlp.experts.47.down_proj      torch.Size([0, 2048])          86.167297            86.735010            535.447233           3136.073205         
model.layers.17.mlp.experts.48.gate_proj      torch.Size([0, 1408])          96.711777            97.273350            505.692863           3783.313987         
model.layers.17.mlp.experts.48.act_fn         torch.Size([0, 1408])          0.465408             1.014948             517.760000           4038.528000         
model.layers.17.mlp.experts.48.up_proj        torch.Size([0, 1408])          90.539619            90.915203            541.664914           3459.877943         
model.layers.17.mlp.experts.48.down_proj      torch.Size([0, 2048])          84.986435            85.459948            569.496548           3179.150027         
model.layers.17.mlp.experts.49.gate_proj      torch.Size([0, 1408])          108.335869           108.843327           553.207172           2954.654897         
model.layers.17.mlp.experts.49.act_fn         torch.Size([0, 1408])          0.799360             1.660109             621.824000           2952.448000         
model.layers.17.mlp.experts.49.up_proj        torch.Size([0, 1408])          100.199997           100.744963           548.506514           3015.657143         
model.layers.17.mlp.experts.49.down_proj      torch.Size([0, 2048])          90.817505            91.332912            586.609534           3133.383890         
model.layers.17.mlp.experts.50.gate_proj      torch.Size([1, 1408])          97.405411            98.116398            603.907866           3196.316349         
model.layers.17.mlp.experts.50.act_fn         torch.Size([1, 1408])          0.778912             1.482487             621.824000           3107.840000         
model.layers.17.mlp.experts.50.up_proj        torch.Size([1, 1408])          96.908195            97.716808            621.712544           3074.013170         
model.layers.17.mlp.experts.50.down_proj      torch.Size([1, 2048])          99.810242            100.585461           621.715338           3043.870388         
model.layers.17.mlp.experts.51.gate_proj      torch.Size([2, 1408])          108.967262           109.843731           621.709061           3193.117605         
model.layers.17.mlp.experts.51.act_fn         torch.Size([2, 1408])          0.685568             1.453161             621.568000           3262.224000         
model.layers.17.mlp.experts.51.up_proj        torch.Size([2, 1408])          94.527779            95.093489            621.698612           3232.269932         
model.layers.17.mlp.experts.51.down_proj      torch.Size([2, 2048])          105.523682           106.360674           621.557921           3366.226646         
model.layers.17.mlp.experts.52.gate_proj      torch.Size([0, 1408])          89.536514            90.078592            621.474909           3734.025558         
model.layers.17.mlp.experts.52.act_fn         torch.Size([0, 1408])          0.342080             0.800371             621.568000           3572.544000         
model.layers.17.mlp.experts.52.up_proj        torch.Size([0, 1408])          93.637856            93.997955            562.897730           3243.155892         
model.layers.17.mlp.experts.52.down_proj      torch.Size([0, 2048])          95.197342            95.848799            570.370763           3000.720115         
model.layers.17.mlp.experts.53.gate_proj      torch.Size([0, 1408])          88.684349            89.224815            555.802245           3077.739741         
model.layers.17.mlp.experts.53.act_fn         torch.Size([0, 1408])          0.481216             1.019955             621.568000           3263.232000         
model.layers.17.mlp.experts.53.up_proj        torch.Size([0, 1408])          84.050209            84.532738            554.286545           3276.053483         
model.layers.17.mlp.experts.53.down_proj      torch.Size([0, 2048])          96.384926            96.848726            574.902118           3076.945882         
model.layers.17.mlp.experts.54.gate_proj      torch.Size([0, 1408])          88.653793            89.328766            574.937863           3071.652822         
model.layers.17.mlp.experts.54.act_fn         torch.Size([0, 1408])          0.306912             0.698566             621.568000           3418.624000         
model.layers.17.mlp.experts.54.up_proj        torch.Size([0, 1408])          80.570084            81.014633            550.383568           3065.859027         
model.layers.17.mlp.experts.54.down_proj      torch.Size([0, 2048])          83.839996            84.243774            578.000593           3142.371556         
model.layers.17.mlp.experts.55.gate_proj      torch.Size([0, 1408])          91.404770            91.979742            578.025785           3220.725421         
model.layers.17.mlp.experts.55.act_fn         torch.Size([0, 1408])          0.520960             1.241922             621.568000           3263.232000         
model.layers.17.mlp.experts.55.up_proj        torch.Size([0, 1408])          92.274109            92.791080            566.614222           3214.662222         
model.layers.17.mlp.experts.55.down_proj      torch.Size([0, 2048])          81.390526            81.980705            572.378592           3287.669183         
model.layers.17.mlp.experts.56.gate_proj      torch.Size([0, 1408])          80.158012            80.625772            524.650805           3718.831377         
model.layers.17.mlp.experts.56.act_fn         torch.Size([0, 1408])          0.719552             1.401424             621.568000           3417.216000         
model.layers.17.mlp.experts.56.up_proj        torch.Size([0, 1408])          81.384514            82.511902            550.961678           3338.962797         
model.layers.17.mlp.experts.56.down_proj      torch.Size([0, 2048])          95.476608            96.120834            551.387095           3198.538745         
model.layers.17.mlp.experts.57.gate_proj      torch.Size([0, 1408])          90.368416            91.044188            566.912471           3148.973176         
model.layers.17.mlp.experts.57.act_fn         torch.Size([0, 1408])          0.370176             0.827312             621.824000           3107.840000         
model.layers.17.mlp.experts.57.up_proj        torch.Size([0, 1408])          83.520386            83.861828            538.423947           2988.952583         
model.layers.17.mlp.experts.57.down_proj      torch.Size([0, 2048])          88.554749            89.106560            559.162667           3073.568000         
model.layers.17.mlp.experts.58.gate_proj      torch.Size([0, 1408])          96.378784            96.949816            570.310761           3104.485408         
model.layers.17.mlp.experts.58.act_fn         torch.Size([0, 1408])          0.433216             0.959158             621.568000           3263.232000         
model.layers.17.mlp.experts.58.up_proj        torch.Size([0, 1408])          86.469246            86.881638            548.519420           3166.273855         
model.layers.17.mlp.experts.58.down_proj      torch.Size([0, 2048])          83.129181            83.684683            582.203826           3231.408232         
model.layers.17.mlp.experts.59.gate_proj      torch.Size([0, 1408])          83.418015            83.907366            581.547656           3139.741669         
model.layers.17.mlp.experts.59.act_fn         torch.Size([0, 1408])          0.519584             1.183033             621.568000           3107.840000         
model.layers.17.mlp.experts.59.up_proj        torch.Size([0, 1408])          81.692993            82.166672            569.155223           3089.953151         
model.layers.17.mlp.experts.59.down_proj      torch.Size([0, 2048])          94.036797            94.770432            590.067489           3326.878316         
model.layers.17.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          365.419098           366.279125           616.592396           3411.320521         
model.layers.17.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.875552             1.830578             776.640000           3571.072000         
model.layers.17.mlp.shared_expert.up_proj     torch.Size([5, 5632])          337.545166           338.090897           699.792605           3151.431577         
model.layers.17.mlp.shared_expert.down_proj   torch.Size([5, 2048])          333.871155           334.359646           707.697920           3190.262240         
model.layers.17.mlp.shared_expert_gate        torch.Size([5, 1])             12.278816            13.709307            629.564746           3296.872136         
model.layers.18.input_layernorm               torch.Size([1, 5, 2048])       11.175296            12.952089            496.315509           3358.648140         
model.layers.18.self_attn.q_proj              torch.Size([1, 5, 2048])       130.890366           132.323027           575.881280           3114.894080         
model.layers.18.self_attn.k_proj              torch.Size([1, 5, 2048])       137.431686           139.116526           621.523665           3425.118749         
model.layers.18.self_attn.v_proj              torch.Size([1, 5, 2048])       135.017822           136.629820           621.490462           3717.940923         
model.layers.18.self_attn.o_proj              torch.Size([1, 5, 2048])       123.242531           124.845266           649.150171           3099.156480         
model.layers.18.post_attention_layernorm      torch.Size([1, 5, 2048])       12.795520            14.530897            603.566933           3185.514667         
model.layers.18.mlp.gate                      torch.Size([5, 60])            12.739136            14.216423            466.368000           3186.954203         
model.layers.18.mlp.experts.0.gate_proj       torch.Size([0, 1408])          85.413086            86.936712            556.855403           3125.710806         
model.layers.18.mlp.experts.0.act_fn          torch.Size([0, 1408])          0.005472             1.522541             621.568000           3418.624000         
model.layers.18.mlp.experts.0.up_proj         torch.Size([0, 1408])          78.210785            79.891443            608.647211           3170.215662         
model.layers.18.mlp.experts.0.down_proj       torch.Size([0, 2048])          87.796448            89.604616            561.761103           3061.758234         
model.layers.18.mlp.experts.1.gate_proj       torch.Size([0, 1408])          94.018654            95.567942            584.569690           3129.726197         
model.layers.18.mlp.experts.1.act_fn          torch.Size([0, 1408])          0.005600             1.681566             621.824000           3146.688000         
model.layers.18.mlp.experts.1.up_proj         torch.Size([0, 1408])          89.464447            91.213226            552.728338           3236.753577         
model.layers.18.mlp.experts.1.down_proj       torch.Size([0, 2048])          92.788765            93.239784            578.344229           3244.133029         
model.layers.18.mlp.experts.2.gate_proj       torch.Size([0, 1408])          88.163971            88.663816            559.204444           3043.306667         
model.layers.18.mlp.experts.2.act_fn          torch.Size([0, 1408])          0.388704             0.825405             621.824000           3004.245333         
model.layers.18.mlp.experts.2.up_proj         torch.Size([0, 1408])          86.299011            86.834669            517.323342           3402.088911         
model.layers.18.mlp.experts.2.down_proj       torch.Size([0, 2048])          77.113693            77.839613            537.884606           3754.741818         
model.layers.18.mlp.experts.3.gate_proj       torch.Size([1, 1408])          81.040131            81.810236            590.960485           3254.680242         
model.layers.18.mlp.experts.3.act_fn          torch.Size([1, 1408])          0.630816             1.290321             621.568000           3107.840000         
model.layers.18.mlp.experts.3.up_proj         torch.Size([1, 1408])          69.149956            69.843292            621.587027           3249.108324         
model.layers.18.mlp.experts.3.down_proj       torch.Size([1, 2048])          79.286140            80.208302            621.674523           3118.193396         
model.layers.18.mlp.experts.4.gate_proj       torch.Size([0, 1408])          90.417854            91.184855            621.824000           3057.471559         
model.layers.18.mlp.experts.4.act_fn          torch.Size([0, 1408])          0.439392             0.935555             621.824000           3107.840000         
model.layers.18.mlp.experts.4.up_proj         torch.Size([0, 1408])          87.080673            87.589979            569.239437           3120.971718         
model.layers.18.mlp.experts.4.down_proj       torch.Size([0, 2048])          85.406433            86.105585            574.981818           3137.179748         
model.layers.18.mlp.experts.5.gate_proj       torch.Size([0, 1408])          85.167107            85.737705            567.055448           3150.629076         
model.layers.18.mlp.experts.5.act_fn          torch.Size([0, 1408])          0.650272             1.464128             621.568000           3417.216000         
model.layers.18.mlp.experts.5.up_proj         torch.Size([0, 1408])          95.837181            96.458435            549.329333           3244.848000         
model.layers.18.mlp.experts.5.down_proj       torch.Size([0, 2048])          89.997826            90.618372            582.857946           3127.788973         
model.layers.18.mlp.experts.6.gate_proj       torch.Size([0, 1408])          89.316223            89.781284            575.294667           3107.840000         
model.layers.18.mlp.experts.6.act_fn          torch.Size([0, 1408])          0.319776             0.689268             621.568000           3261.888000         
model.layers.18.mlp.experts.6.up_proj         torch.Size([0, 1408])          92.840637            93.409777            521.362526           3459.658947         
model.layers.18.mlp.experts.6.down_proj       torch.Size([0, 2048])          89.422211            90.056419            517.586752           3734.604637         
model.layers.18.mlp.experts.7.gate_proj       torch.Size([0, 1408])          91.090561            91.757298            572.305655           3335.785048         
model.layers.18.mlp.experts.7.act_fn          torch.Size([0, 1408])          0.552736             1.312017             621.568000           3211.434667         
model.layers.18.mlp.experts.7.up_proj         torch.Size([0, 1408])          92.207870            92.866898            569.495771           3183.316114         
model.layers.18.mlp.experts.7.down_proj       torch.Size([0, 2048])          89.548988            90.101719            604.584000           3068.981647         
model.layers.18.mlp.experts.8.gate_proj       torch.Size([0, 1408])          106.292992           106.841326           584.803357           3037.207273         
model.layers.18.mlp.experts.8.act_fn          torch.Size([0, 1408])          0.346080             0.788927             621.568000           3263.232000         
model.layers.18.mlp.experts.8.up_proj         torch.Size([0, 1408])          161.068802           161.473036           561.960727           3196.945902         
model.layers.18.mlp.experts.8.down_proj       torch.Size([0, 2048])          148.465118           148.889303           564.433702           3181.841248         
model.layers.18.mlp.experts.9.gate_proj       torch.Size([0, 1408])          171.537445           172.084093           576.429333           3076.680889         
model.layers.18.mlp.experts.9.act_fn          torch.Size([0, 1408])          0.553440             1.167297             621.568000           3263.232000         
model.layers.18.mlp.experts.9.up_proj         torch.Size([0, 1408])          139.659515           140.103817           569.286358           3038.891232         
model.layers.18.mlp.experts.9.down_proj       torch.Size([0, 2048])          148.833023           149.421692           579.033772           3004.592966         
model.layers.18.mlp.experts.10.gate_proj      torch.Size([1, 1408])          120.642174           121.322632           590.156973           3138.278919         
model.layers.18.mlp.experts.10.act_fn         torch.Size([1, 1408])          0.508096             1.091719             621.568000           3520.768000         
model.layers.18.mlp.experts.10.up_proj        torch.Size([1, 1408])          118.526047           119.067192           610.131627           3534.496427         
model.layers.18.mlp.experts.10.down_proj      torch.Size([1, 2048])          145.579239           146.103144           613.093783           3715.555855         
model.layers.18.mlp.experts.11.gate_proj      torch.Size([1, 1408])          153.630463           154.270649           621.747200           3073.718187         
model.layers.18.mlp.experts.11.act_fn         torch.Size([1, 1408])          0.503136             1.034737             621.568000           3263.232000         
model.layers.18.mlp.experts.11.up_proj        torch.Size([1, 1408])          135.816391           136.265755           621.755007           3044.936170         
model.layers.18.mlp.experts.11.down_proj      torch.Size([1, 2048])          151.028641           151.607037           621.701333           3141.159111         
model.layers.18.mlp.experts.12.gate_proj      torch.Size([1, 1408])          126.154556           126.840353           621.654486           3168.569081         
model.layers.18.mlp.experts.12.act_fn         torch.Size([1, 1408])          0.623744             1.139879             621.568000           3417.216000         
model.layers.18.mlp.experts.12.up_proj        torch.Size([1, 1408])          141.753830           142.369509           621.587027           3258.765838         
model.layers.18.mlp.experts.12.down_proj      torch.Size([1, 2048])          144.909698           145.543337           621.568000           3262.073507         
model.layers.18.mlp.experts.13.gate_proj      torch.Size([0, 1408])          140.159454           140.894175           621.585778           3229.415556         
model.layers.18.mlp.experts.13.act_fn         torch.Size([0, 1408])          0.422848             0.906467             621.824000           3107.840000         
model.layers.18.mlp.experts.13.up_proj        torch.Size([0, 1408])          141.393509           141.765833           591.225043           3232.666435         
model.layers.18.mlp.experts.13.down_proj      torch.Size([0, 2048])          153.019424           153.498411           601.512518           3203.769554         
model.layers.18.mlp.experts.14.gate_proj      torch.Size([0, 1408])          157.861145           158.520222           582.838667           3187.674667         
model.layers.18.mlp.experts.14.act_fn         torch.Size([0, 1408])          0.439360             1.013756             621.568000           3263.232000         
model.layers.18.mlp.experts.14.up_proj        torch.Size([0, 1408])          142.632736           143.077850           504.036400           3478.912000         
model.layers.18.mlp.experts.14.down_proj      torch.Size([0, 2048])          90.083488            90.857267            530.044354           3686.704203         
model.layers.18.mlp.experts.15.gate_proj      torch.Size([0, 1408])          88.826340            89.411736            581.970538           3246.878455         
model.layers.18.mlp.experts.15.act_fn         torch.Size([0, 1408])          0.353760             0.753880             621.568000           3263.232000         
model.layers.18.mlp.experts.15.up_proj        torch.Size([0, 1408])          85.298332            85.671425            567.677333           3227.504444         
model.layers.18.mlp.experts.15.down_proj      torch.Size([0, 2048])          89.471039            90.004921            589.893408           3321.829408         
model.layers.18.mlp.experts.16.gate_proj      torch.Size([0, 1408])          91.149277            91.819525            577.457431           3142.712195         
model.layers.18.mlp.experts.16.act_fn         torch.Size([0, 1408])          0.005536             1.261950             621.568000           3106.560000         
model.layers.18.mlp.experts.16.up_proj        torch.Size([0, 1408])          87.587395            87.991953            560.343075           3079.200653         
model.layers.18.mlp.experts.16.down_proj      torch.Size([0, 2048])          88.683777            89.976072            589.935030           3025.315879         
model.layers.18.mlp.experts.17.gate_proj      torch.Size([0, 1408])          100.990562           102.349281           563.025455           3187.077371         
model.layers.18.mlp.experts.17.act_fn         torch.Size([0, 1408])          0.077600             1.665354             621.568000           3263.232000         
model.layers.18.mlp.experts.17.up_proj        torch.Size([0, 1408])          91.660225            93.084574            555.398266           3197.835636         
model.layers.18.mlp.experts.17.down_proj      torch.Size([0, 2048])          75.857185            77.164888            577.302857           3135.324800         
model.layers.18.mlp.experts.18.gate_proj      torch.Size([0, 1408])          97.238464            98.801851            571.687452           3105.601315         
model.layers.18.mlp.experts.18.act_fn         torch.Size([0, 1408])          0.005440             1.379490             621.568000           3417.216000         
model.layers.18.mlp.experts.18.up_proj        torch.Size([0, 1408])          88.149757            89.463234            505.232103           3541.581213         
model.layers.18.mlp.experts.18.down_proj      torch.Size([0, 2048])          80.572227            81.817627            555.341405           3764.138811         
model.layers.18.mlp.experts.19.gate_proj      torch.Size([0, 1408])          85.567490            87.005854            569.191724           3226.791724         
model.layers.18.mlp.experts.19.act_fn         torch.Size([0, 1408])          0.005600             1.343727             621.568000           3263.232000         
model.layers.18.mlp.experts.19.up_proj        torch.Size([0, 1408])          84.931709            86.280584            569.512175           3192.687182         
model.layers.18.mlp.experts.19.down_proj      torch.Size([0, 2048])          85.485283            86.903334            583.996343           3050.065371         
model.layers.18.mlp.experts.20.gate_proj      torch.Size([1, 1408])          87.196930            88.956118            588.755726           3035.373589         
model.layers.18.mlp.experts.20.act_fn         torch.Size([1, 1408])          0.448416             0.926256             621.568000           3417.216000         
model.layers.18.mlp.experts.20.up_proj        torch.Size([1, 1408])          82.831779            83.271265            621.602830           3222.670367         
model.layers.18.mlp.experts.20.down_proj      torch.Size([1, 2048])          81.993629            82.604647            621.649297           3151.308541         
model.layers.18.mlp.experts.21.gate_proj      torch.Size([0, 1408])          90.701469            91.325998            621.599347           3185.789388         
model.layers.18.mlp.experts.21.act_fn         torch.Size([0, 1408])          0.629568             1.381397             621.568000           3417.216000         
model.layers.18.mlp.experts.21.up_proj        torch.Size([0, 1408])          86.668510            87.220669            563.620571           3069.689034         
model.layers.18.mlp.experts.21.down_proj      torch.Size([0, 2048])          82.780418            83.492517            564.912390           3023.195577         
model.layers.18.mlp.experts.22.gate_proj      torch.Size([0, 1408])          82.710205            83.366871            582.457094           3254.790906         
model.layers.18.mlp.experts.22.act_fn         torch.Size([0, 1408])          0.371136             0.863791             621.568000           3417.216000         
model.layers.18.mlp.experts.22.up_proj        torch.Size([0, 1408])          78.338814            78.797340            504.572028           3952.983393         
model.layers.18.mlp.experts.22.down_proj      torch.Size([0, 2048])          84.880577            85.334539            561.562057           3648.904686         
model.layers.18.mlp.experts.23.gate_proj      torch.Size([0, 1408])          83.993057            84.678411            553.017905           3076.127347         
model.layers.18.mlp.experts.23.act_fn         torch.Size([0, 1408])          0.406976             0.903845             621.824000           3004.245333         
model.layers.18.mlp.experts.23.up_proj        torch.Size([0, 1408])          87.001091            87.460995            557.518322           3125.226517         
model.layers.18.mlp.experts.23.down_proj      torch.Size([0, 2048])          81.481789            82.881927            581.664000           3141.976686         
model.layers.18.mlp.experts.24.gate_proj      torch.Size([1, 1408])          86.089378            86.613178            588.625096           3157.526356         
model.layers.18.mlp.experts.24.act_fn         torch.Size([1, 1408])          0.472864             0.870466             621.568000           3261.888000         
model.layers.18.mlp.experts.24.up_proj        torch.Size([1, 1408])          90.322464            90.947866            621.586000           3189.746500         
model.layers.18.mlp.experts.24.down_proj      torch.Size([1, 2048])          87.880798            88.774920            621.710027           2982.977315         
model.layers.18.mlp.experts.25.gate_proj      torch.Size([0, 1408])          81.570847            82.235098            621.672490           2958.790531         
model.layers.18.mlp.experts.25.act_fn         torch.Size([0, 1408])          0.591968             1.382351             621.653333           3056.042667         
model.layers.18.mlp.experts.25.up_proj        torch.Size([0, 1408])          86.255714            86.880684            566.307068           3106.508712         
model.layers.18.mlp.experts.25.down_proj      torch.Size([0, 2048])          86.953407            87.547779            572.337876           3162.206014         
model.layers.18.mlp.experts.26.gate_proj      torch.Size([1, 1408])          88.120926            88.656902            589.144889           3392.874222         
model.layers.18.mlp.experts.26.act_fn         torch.Size([1, 1408])          0.527328             1.073122             621.312000           3572.544000         
model.layers.18.mlp.experts.26.up_proj        torch.Size([1, 1408])          84.768578            85.360050            594.111169           3847.002597         
model.layers.18.mlp.experts.26.down_proj      torch.Size([1, 2048])          83.374657            84.103823            621.532632           3408.947368         
model.layers.18.mlp.experts.27.gate_proj      torch.Size([0, 1408])          87.382812            87.991953            621.657946           3087.495351         
model.layers.18.mlp.experts.27.act_fn         torch.Size([0, 1408])          0.566336             1.263857             621.568000           3313.664000         
model.layers.18.mlp.experts.27.up_proj        torch.Size([0, 1408])          91.694435            92.265368            556.625248           3152.918695         
model.layers.18.mlp.experts.27.down_proj      torch.Size([0, 2048])          87.007454            87.584734            565.116420           3210.773483         
model.layers.18.mlp.experts.28.gate_proj      torch.Size([0, 1408])          88.621315            89.352369            562.488163           3156.245769         
model.layers.18.mlp.experts.28.act_fn         torch.Size([0, 1408])          0.501920             1.076698             621.568000           3263.232000         
model.layers.18.mlp.experts.28.up_proj        torch.Size([0, 1408])          75.593216            75.989246            545.603972           3113.179807         
model.layers.18.mlp.experts.28.down_proj      torch.Size([0, 2048])          90.257919            90.865612            581.185391           3040.278261         
model.layers.18.mlp.experts.29.gate_proj      torch.Size([1, 1408])          88.692513            89.430809            583.729727           3071.083741         
model.layers.18.mlp.experts.29.act_fn         torch.Size([1, 1408])          0.818080             1.588821             621.568000           3263.232000         
model.layers.18.mlp.experts.29.up_proj        torch.Size([1, 1408])          88.373283            89.122534            621.726648           3143.800789         
model.layers.18.mlp.experts.29.down_proj      torch.Size([1, 2048])          75.558594            76.193810            621.624889           3183.965778         
model.layers.18.mlp.experts.30.gate_proj      torch.Size([0, 1408])          93.396637            93.952656            621.558448           3351.528597         
model.layers.18.mlp.experts.30.act_fn         torch.Size([0, 1408])          0.322048             0.704050             621.312000           4036.864000         
model.layers.18.mlp.experts.30.up_proj        torch.Size([0, 1408])          73.002274            73.370457            493.104310           3965.510194         
model.layers.18.mlp.experts.30.down_proj      torch.Size([0, 2048])          91.571007            92.272043            549.485449           3495.110957         
model.layers.18.mlp.experts.31.gate_proj      torch.Size([2, 1408])          93.858719            94.441414            582.241391           3170.656000         
model.layers.18.mlp.experts.31.act_fn         torch.Size([2, 1408])          0.418400             0.883818             621.568000           3417.216000         
model.layers.18.mlp.experts.31.up_proj        torch.Size([2, 1408])          90.893280            91.491222            621.672490           3118.179701         
model.layers.18.mlp.experts.31.down_proj      torch.Size([2, 2048])          96.965248            97.652674            621.568000           3068.449959         
model.layers.18.mlp.experts.32.gate_proj      torch.Size([0, 1408])          91.980637            92.479467            621.644979           3094.647497         
model.layers.18.mlp.experts.32.act_fn         torch.Size([0, 1408])          0.399712             1.045465             621.568000           3263.232000         
model.layers.18.mlp.experts.32.up_proj        torch.Size([0, 1408])          92.392159            92.987537            552.504889           3204.556000         
model.layers.18.mlp.experts.32.down_proj      torch.Size([0, 2048])          86.457764            86.979628            571.620571           3250.609371         
model.layers.18.mlp.experts.33.gate_proj      torch.Size([0, 1408])          90.540321            91.218233            554.343832           3073.066965         
model.layers.18.mlp.experts.33.act_fn         torch.Size([0, 1408])          0.386080             0.896931             621.824000           3107.840000         
model.layers.18.mlp.experts.33.up_proj        torch.Size([0, 1408])          84.175583            84.571838            547.385412           3078.132706         
model.layers.18.mlp.experts.33.down_proj      torch.Size([0, 2048])          88.915871            89.557171            562.301852           3008.764564         
model.layers.18.mlp.experts.34.gate_proj      torch.Size([0, 1408])          85.172035            85.597992            555.298462           3242.871049         
model.layers.18.mlp.experts.34.act_fn         torch.Size([0, 1408])          0.553152             1.262188             465.984000           3881.600000         
model.layers.18.mlp.experts.34.up_proj        torch.Size([0, 1408])          83.771805            84.345102            474.905358           3754.997937         
model.layers.18.mlp.experts.34.down_proj      torch.Size([0, 2048])          90.501884            90.911865            529.007781           3221.367671         
model.layers.18.mlp.experts.35.gate_proj      torch.Size([0, 1408])          86.819550            87.460041            548.366222           3045.251556         
model.layers.18.mlp.experts.35.act_fn         torch.Size([0, 1408])          0.661088             1.441479             621.824000           2952.448000         
model.layers.18.mlp.experts.35.up_proj        torch.Size([0, 1408])          89.000572            89.604616            538.096336           3025.254042         
model.layers.18.mlp.experts.35.down_proj      torch.Size([0, 2048])          91.880348            92.484713            562.544225           3117.490028         
model.layers.18.mlp.experts.36.gate_proj      torch.Size([1, 1408])          87.972610            88.453293            593.474577           3129.231463         
model.layers.18.mlp.experts.36.act_fn         torch.Size([1, 1408])          0.660544             1.380920             621.568000           3417.216000         
model.layers.18.mlp.experts.36.up_proj        torch.Size([1, 1408])          94.138176            95.208406            621.620321           3187.468146         
model.layers.18.mlp.experts.36.down_proj      torch.Size([1, 2048])          89.791809            90.642691            621.650411           3075.336329         
model.layers.18.mlp.experts.37.gate_proj      torch.Size([0, 1408])          92.605888            93.154669            621.682759           3012.461462         
model.layers.18.mlp.experts.37.act_fn         torch.Size([0, 1408])          0.669888             1.481295             621.568000           3107.840000         
model.layers.18.mlp.experts.37.up_proj        torch.Size([0, 1408])          82.808388            83.298683            546.094904           3084.259068         
model.layers.18.mlp.experts.37.down_proj      torch.Size([0, 2048])          83.891327            84.271908            565.250581           3136.466581         
model.layers.18.mlp.experts.38.gate_proj      torch.Size([1, 1408])          88.518112            89.236498            559.322453           3454.577920         
model.layers.18.mlp.experts.38.act_fn         torch.Size([1, 1408])          0.668256             1.408577             621.141333           4192.128000         
model.layers.18.mlp.experts.38.up_proj        torch.Size([1, 1408])          85.537918            86.177349            572.209292           3774.599155         
model.layers.18.mlp.experts.38.down_proj      torch.Size([1, 2048])          83.561378            84.073782            621.588480           3157.988267         
model.layers.18.mlp.experts.39.gate_proj      torch.Size([0, 1408])          86.547104            87.089539            621.661091           3072.915245         
model.layers.18.mlp.experts.39.act_fn         torch.Size([0, 1408])          0.379232             0.770092             621.568000           3417.216000         
model.layers.18.mlp.experts.39.up_proj        torch.Size([0, 1408])          84.386848            84.705830            522.757818           3181.587245         
model.layers.18.mlp.experts.39.down_proj      torch.Size([0, 2048])          86.848381            87.361574            562.089305           3216.564199         
model.layers.18.mlp.experts.40.gate_proj      torch.Size([1, 1408])          90.157539            90.881348            583.868632           3049.676632         
model.layers.18.mlp.experts.40.act_fn         torch.Size([1, 1408])          0.638080             1.387835             621.568000           3107.840000         
model.layers.18.mlp.experts.40.up_proj        torch.Size([1, 1408])          82.162720            83.030224            621.698510           3064.812758         
model.layers.18.mlp.experts.40.down_proj      torch.Size([1, 2048])          84.560417            85.343361            621.705450           3026.135195         
model.layers.18.mlp.experts.41.gate_proj      torch.Size([1, 1408])          82.508995            83.010674            621.568000           3162.889465         
model.layers.18.mlp.experts.41.act_fn         torch.Size([1, 1408])          0.767104             1.228094             621.568000           3261.888000         
model.layers.18.mlp.experts.41.up_proj        torch.Size([1, 1408])          85.253983            85.779667            621.592548           3262.516164         
model.layers.18.mlp.experts.41.down_proj      torch.Size([1, 2048])          85.882881            86.457491            621.617826           3125.173691         
model.layers.18.mlp.experts.42.gate_proj      torch.Size([0, 1408])          101.006721           101.421833           532.739325           3565.350234         
model.layers.18.mlp.experts.42.act_fn         torch.Size([0, 1408])          0.455168             0.971317             465.984000           4347.392000         
model.layers.18.mlp.experts.42.up_proj        torch.Size([0, 1408])          93.311325            93.813658            499.064795           3622.719576         
model.layers.18.mlp.experts.42.down_proj      torch.Size([0, 2048])          87.771805            88.158131            503.992000           3248.059111         
model.layers.18.mlp.experts.43.gate_proj      torch.Size([1, 1408])          73.826401            74.499130            572.661041           3187.310904         
model.layers.18.mlp.experts.43.act_fn         torch.Size([1, 1408])          0.675104             1.405239             621.568000           3261.888000         
model.layers.18.mlp.experts.43.up_proj        torch.Size([1, 1408])          96.772797            97.740412            621.568000           3120.188179         
model.layers.18.mlp.experts.43.down_proj      torch.Size([1, 2048])          109.515038           110.168934           621.736376           2933.607087         
model.layers.18.mlp.experts.44.gate_proj      torch.Size([0, 1408])          95.677155            96.358776            621.766137           2908.960438         
model.layers.18.mlp.experts.44.act_fn         torch.Size([0, 1408])          0.369280             0.900030             621.568000           3107.840000         
model.layers.18.mlp.experts.44.up_proj        torch.Size([0, 1408])          84.666397            85.243464            533.835016           3120.521967         
model.layers.18.mlp.experts.44.down_proj      torch.Size([0, 2048])          68.967651            69.458961            524.394015           3113.708458         
model.layers.18.mlp.experts.45.gate_proj      torch.Size([2, 1408])          43.068768            43.581724            577.960805           3010.850362         
model.layers.18.mlp.experts.45.act_fn         torch.Size([2, 1408])          0.372032             0.768661             621.568000           3263.232000         
model.layers.18.mlp.experts.45.up_proj        torch.Size([2, 1408])          69.652382            70.099592            621.648752           3049.399839         
model.layers.18.mlp.experts.45.down_proj      torch.Size([2, 2048])          30.847296            31.392336            621.568000           3181.136559         
model.layers.18.mlp.experts.46.gate_proj      torch.Size([1, 1408])          83.765121            84.422827            621.407573           3836.673280         
model.layers.18.mlp.experts.46.act_fn         torch.Size([1, 1408])          0.778656             1.338482             621.312000           4036.864000         
model.layers.18.mlp.experts.46.up_proj        torch.Size([1, 1408])          88.351807            88.983774            608.402479           3546.239549         
model.layers.18.mlp.experts.46.down_proj      torch.Size([1, 2048])          86.527039            87.171316            621.681778           3156.938222         
model.layers.18.mlp.experts.47.gate_proj      torch.Size([0, 1408])          108.294174           108.882189           621.698648           3111.055007         
model.layers.18.mlp.experts.47.act_fn         torch.Size([0, 1408])          0.337472             0.724077             621.824000           2952.448000         
model.layers.18.mlp.experts.47.up_proj        torch.Size([0, 1408])          92.005821            92.384577            541.903781           3106.775671         
model.layers.18.mlp.experts.47.down_proj      torch.Size([0, 2048])          92.697922            93.317986            511.499801           3048.352681         
model.layers.18.mlp.experts.48.gate_proj      torch.Size([0, 1408])          93.885475            94.605207            511.957930           3146.871497         
model.layers.18.mlp.experts.48.act_fn         torch.Size([0, 1408])          0.614912             1.411676             517.973333           3263.232000         
model.layers.18.mlp.experts.48.up_proj        torch.Size([0, 1408])          92.961372            93.559980            523.499556           3162.874667         
model.layers.18.mlp.experts.48.down_proj      torch.Size([0, 2048])          82.792580            83.270788            543.030054           3049.043027         
model.layers.18.mlp.experts.49.gate_proj      torch.Size([0, 1408])          89.977341            90.466261            521.359238           2964.303238         
model.layers.18.mlp.experts.49.act_fn         torch.Size([0, 1408])          0.005696             1.248837             621.824000           2952.448000         
model.layers.18.mlp.experts.49.up_proj        torch.Size([0, 1408])          82.451454            83.136797            523.385500           3055.533000         
model.layers.18.mlp.experts.49.down_proj      torch.Size([0, 2048])          85.728638            87.045908            470.788672           3201.347737         
model.layers.18.mlp.experts.50.gate_proj      torch.Size([0, 1408])          93.109856            93.540430            466.073684           3827.615579         
model.layers.18.mlp.experts.50.act_fn         torch.Size([0, 1408])          0.393824             0.832319             466.176000           3727.872000         
model.layers.18.mlp.experts.50.up_proj        torch.Size([0, 1408])          95.124031            95.600128            494.549189           3335.263135         
model.layers.18.mlp.experts.50.down_proj      torch.Size([0, 2048])          90.109085            90.579033            499.312318           3003.902305         
model.layers.18.mlp.experts.51.gate_proj      torch.Size([0, 1408])          91.005569            91.487408            497.419378           2997.319111         
model.layers.18.mlp.experts.51.act_fn         torch.Size([0, 1408])          0.562944             1.255035             517.973333           3263.232000         
model.layers.18.mlp.experts.51.up_proj        torch.Size([0, 1408])          90.045921            90.638399            494.388000           3107.840000         
model.layers.18.mlp.experts.51.down_proj      torch.Size([0, 2048])          96.109444            96.688986            511.588000           3205.875556         
model.layers.18.mlp.experts.52.gate_proj      torch.Size([1, 1408])          87.978081            88.708162            578.842483           3062.709407         
model.layers.18.mlp.experts.52.act_fn         torch.Size([1, 1408])          0.621280             1.233101             621.568000           3107.840000         
model.layers.18.mlp.experts.52.up_proj        torch.Size([1, 1408])          131.624512           132.198572           621.714286           3054.894150         
model.layers.18.mlp.experts.52.down_proj      torch.Size([1, 2048])          161.938553           162.388325           621.713067           3032.144213         
model.layers.18.mlp.experts.53.gate_proj      torch.Size([0, 1408])          171.415329           171.994686           621.713496           3115.665496         
model.layers.18.mlp.experts.53.act_fn         torch.Size([0, 1408])          0.384928             0.891209             621.568000           3263.232000         
model.layers.18.mlp.experts.53.up_proj        torch.Size([0, 1408])          160.169159           160.533667           526.496451           3200.856338         
model.layers.18.mlp.experts.53.down_proj      torch.Size([0, 2048])          154.358215           154.996872           499.789353           3226.000115         
model.layers.18.mlp.experts.54.gate_proj      torch.Size([0, 1408])          152.902817           153.500080           473.227148           3518.863277         
model.layers.18.mlp.experts.54.act_fn         torch.Size([0, 1408])          0.757056             1.497269             466.176000           3417.216000         
model.layers.18.mlp.experts.54.up_proj        torch.Size([0, 1408])          132.951065           133.442640           487.932444           3080.816444         
model.layers.18.mlp.experts.54.down_proj      torch.Size([0, 2048])          143.265213           143.756390           529.106610           3234.578156         
model.layers.18.mlp.experts.55.gate_proj      torch.Size([1, 1408])          151.018112           151.962757           570.176000           3229.389838         
model.layers.18.mlp.experts.55.act_fn         torch.Size([1, 1408])          0.703744             1.492262             621.568000           3378.384000         
model.layers.18.mlp.experts.55.up_proj        torch.Size([1, 1408])          144.363617           145.248175           609.211705           3109.770309         
model.layers.18.mlp.experts.55.down_proj      torch.Size([1, 2048])          146.211838           146.932602           621.757881           3024.386119         
model.layers.18.mlp.experts.56.gate_proj      torch.Size([0, 1408])          157.414215           158.093929           621.781333           3008.515111         
model.layers.18.mlp.experts.56.act_fn         torch.Size([0, 1408])          0.005440             1.402140             621.568000           3263.232000         
model.layers.18.mlp.experts.56.up_proj        torch.Size([0, 1408])          138.171936           138.787031           523.810192           3150.413151         
model.layers.18.mlp.experts.56.down_proj      torch.Size([0, 2048])          99.384544            99.861622            554.934519           3188.249600         
model.layers.18.mlp.experts.57.gate_proj      torch.Size([0, 1408])          145.685028           146.116018           544.582355           3129.881418         
model.layers.18.mlp.experts.57.act_fn         torch.Size([0, 1408])          0.711072             1.595497             518.186667           3056.042667         
model.layers.18.mlp.experts.57.up_proj        torch.Size([0, 1408])          139.688004           140.275240           500.305577           3033.426930         
model.layers.18.mlp.experts.57.down_proj      torch.Size([0, 2048])          139.029892           139.469147           507.805296           3276.671549         
model.layers.18.mlp.experts.58.gate_proj      torch.Size([0, 1408])          150.153305           150.834084           466.134204           3692.938884         
model.layers.18.mlp.experts.58.act_fn         torch.Size([0, 1408])          0.645376             1.500607             466.176000           3417.216000         
model.layers.18.mlp.experts.58.up_proj        torch.Size([0, 1408])          135.615585           136.183739           502.889778           3307.038667         
model.layers.18.mlp.experts.58.down_proj      torch.Size([0, 2048])          136.903900           137.542248           531.119885           3181.623252         
model.layers.18.mlp.experts.59.gate_proj      torch.Size([0, 1408])          120.254143           120.694160           521.731580           3118.706573         
model.layers.18.mlp.experts.59.act_fn         torch.Size([0, 1408])          0.005632             1.302958             621.824000           3107.840000         
model.layers.18.mlp.experts.59.up_proj        torch.Size([0, 1408])          84.378784            85.777760            516.368112           3089.366825         
model.layers.18.mlp.experts.59.down_proj      torch.Size([0, 2048])          82.688095            84.112644            506.857739           3071.777391         
model.layers.18.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          340.415894           342.284203           639.441171           3012.992780         
model.layers.18.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.059936             1.611471             776.640000           3571.366400         
model.layers.18.mlp.shared_expert.up_proj     torch.Size([5, 5632])          339.416382           340.841293           684.192637           3029.714945         
model.layers.18.mlp.shared_expert.down_proj   torch.Size([5, 2048])          315.738007           317.779303           630.794920           3468.645184         
model.layers.18.mlp.shared_expert_gate        torch.Size([5, 1])             12.837920            14.318228            590.659938           2919.345231         
model.layers.19.input_layernorm               torch.Size([1, 5, 2048])       10.398464            11.934280            466.419429           3017.512000         
model.layers.19.self_attn.q_proj              torch.Size([1, 5, 2048])       130.953415           132.249594           568.305548           3045.460301         
model.layers.19.self_attn.k_proj              torch.Size([1, 5, 2048])       138.867172           140.402079           621.568000           3280.728976         
model.layers.19.self_attn.v_proj              torch.Size([1, 5, 2048])       137.850525           139.305592           617.014673           3061.755497         
model.layers.19.self_attn.o_proj              torch.Size([1, 5, 2048])       119.372803           121.074438           667.950112           3130.280149         
model.layers.19.post_attention_layernorm      torch.Size([1, 5, 2048])       14.798560            16.532898            572.116406           3238.252522         
model.layers.19.mlp.gate                      torch.Size([5, 60])            14.719392            16.201258            466.403797           3113.929763         
model.layers.19.mlp.experts.0.gate_proj       torch.Size([0, 1408])          95.010780            96.783161            548.022780           3142.255729         
model.layers.19.mlp.experts.0.act_fn          torch.Size([0, 1408])          0.005504             1.392126             621.568000           3417.216000         
model.layers.19.mlp.experts.0.up_proj         torch.Size([0, 1408])          90.630753            92.089415            592.519367           3443.128173         
model.layers.19.mlp.experts.0.down_proj       torch.Size([0, 2048])          80.925377            82.415581            502.760764           3701.117146         
model.layers.19.mlp.experts.1.gate_proj       torch.Size([0, 1408])          80.609985            81.864357            535.563679           3058.012029         
model.layers.19.mlp.experts.1.act_fn          torch.Size([0, 1408])          0.005728             1.252174             621.568000           3263.232000         
model.layers.19.mlp.experts.1.up_proj         torch.Size([0, 1408])          83.492287            84.859848            509.645932           3204.986776         
model.layers.19.mlp.experts.1.down_proj       torch.Size([0, 2048])          80.759331            81.286669            493.299556           3166.112000         
model.layers.19.mlp.experts.2.gate_proj       torch.Size([0, 1408])          83.171295            83.620310            499.442383           2991.151660         
model.layers.19.mlp.experts.2.act_fn          torch.Size([0, 1408])          0.361120             0.768661             570.005333           3107.840000         
model.layers.19.mlp.experts.2.up_proj         torch.Size([0, 1408])          84.902557            85.415602            519.924524           3041.396524         
model.layers.19.mlp.experts.2.down_proj       torch.Size([0, 2048])          93.353058            93.921185            528.733296           3030.144000         
model.layers.19.mlp.experts.3.gate_proj       torch.Size([1, 1408])          83.448349            84.107876            576.444444           3087.359556         
model.layers.19.mlp.experts.3.act_fn          torch.Size([1, 1408])          0.675040             1.463890             621.568000           3262.560000         
model.layers.19.mlp.experts.3.up_proj         torch.Size([1, 1408])          83.282242            83.883286            621.628632           3221.859789         
model.layers.19.mlp.experts.3.down_proj       torch.Size([1, 2048])          87.480095            88.379383            617.174588           3079.105882         
model.layers.19.mlp.experts.4.gate_proj       torch.Size([1, 1408])          84.226463            85.133076            531.819636           3404.540675         
model.layers.19.mlp.experts.4.act_fn          torch.Size([1, 1408])          0.461984             0.926971             621.312000           4192.128000         
model.layers.19.mlp.experts.4.up_proj         torch.Size([1, 1408])          89.043076            89.530706            570.644528           3789.999497         
model.layers.19.mlp.experts.4.down_proj       torch.Size([1, 2048])          81.788132            82.258940            615.488000           3234.944842         
model.layers.19.mlp.experts.5.gate_proj       torch.Size([0, 1408])          95.780258            96.247435            621.629370           3186.441205         
model.layers.19.mlp.experts.5.act_fn          torch.Size([0, 1408])          0.389120             0.995874             621.568000           3263.232000         
model.layers.19.mlp.experts.5.up_proj         torch.Size([0, 1408])          82.018494            82.399607            538.501408           3149.423775         
model.layers.19.mlp.experts.5.down_proj       torch.Size([0, 2048])          101.469757           102.104664           530.672993           3015.676469         
model.layers.19.mlp.experts.6.gate_proj       torch.Size([0, 1408])          89.887009            90.347290            528.929333           3047.409778         
model.layers.19.mlp.experts.6.act_fn          torch.Size([0, 1408])          0.372128             0.844240             466.176000           3366.826667         
model.layers.19.mlp.experts.6.up_proj         torch.Size([0, 1408])          82.835747            83.314896            508.258102           3135.061956         
model.layers.19.mlp.experts.6.down_proj       torch.Size([0, 2048])          83.961761            84.322214            540.086014           3212.516766         
model.layers.19.mlp.experts.7.gate_proj       torch.Size([0, 1408])          85.837280            86.367130            545.140406           3065.050899         
model.layers.19.mlp.experts.7.act_fn          torch.Size([0, 1408])          0.610656             1.378775             621.653333           3107.840000         
model.layers.19.mlp.experts.7.up_proj         torch.Size([0, 1408])          80.072418            80.864429            521.491518           2949.421844         
model.layers.19.mlp.experts.7.down_proj       torch.Size([0, 2048])          87.285217            87.932587            557.465600           3018.891476         
model.layers.19.mlp.experts.8.gate_proj       torch.Size([0, 1408])          91.000031            91.571569            477.852735           3376.810231         
model.layers.19.mlp.experts.8.act_fn          torch.Size([0, 1408])          0.413664             0.956297             465.984000           4192.128000         
model.layers.19.mlp.experts.8.up_proj         torch.Size([0, 1408])          79.155357            79.592228            473.513946           3711.222919         
model.layers.19.mlp.experts.8.down_proj       torch.Size([0, 2048])          79.284637            79.766035            504.314014           3133.636144         
model.layers.19.mlp.experts.9.gate_proj       torch.Size([0, 1408])          86.552383            86.948633            519.963366           2961.499366         
model.layers.19.mlp.experts.9.act_fn          torch.Size([0, 1408])          0.466848             1.055241             518.186667           3107.840000         
model.layers.19.mlp.experts.9.up_proj         torch.Size([0, 1408])          84.144768            84.732533            523.088432           2935.788973         
model.layers.19.mlp.experts.9.down_proj       torch.Size([0, 2048])          94.220291            94.797611            541.376883           3117.485021         
model.layers.19.mlp.experts.10.gate_proj      torch.Size([0, 1408])          92.091232            92.583895            530.396973           3170.925838         
model.layers.19.mlp.experts.10.act_fn         torch.Size([0, 1408])          0.375424             0.864744             569.770667           3418.624000         
model.layers.19.mlp.experts.10.up_proj        torch.Size([0, 1408])          83.854622            84.458590            534.596757           3147.680865         
model.layers.19.mlp.experts.10.down_proj      torch.Size([0, 2048])          82.300797            82.958937            550.465315           3065.247562         
model.layers.19.mlp.experts.11.gate_proj      torch.Size([0, 1408])          80.986687            81.385136            544.077405           3023.844324         
model.layers.19.mlp.experts.11.act_fn         torch.Size([0, 1408])          0.751136             1.514673             621.824000           3107.840000         
model.layers.19.mlp.experts.11.up_proj        torch.Size([0, 1408])          99.059677            99.623680            539.545143           3207.674514         
model.layers.19.mlp.experts.11.down_proj      torch.Size([0, 2048])          92.968704            93.539238            560.427268           3187.557408         
model.layers.19.mlp.experts.12.gate_proj      torch.Size([0, 1408])          63.102783            63.557625            485.355836           3368.969644         
model.layers.19.mlp.experts.12.act_fn         torch.Size([0, 1408])          0.368512             0.798225             465.984000           3883.200000         
model.layers.19.mlp.experts.12.up_proj        torch.Size([0, 1408])          91.021347            91.424942            497.610811           3691.171892         
model.layers.19.mlp.experts.12.down_proj      torch.Size([0, 2048])          94.058434            94.663620            543.445483           3180.596811         
model.layers.19.mlp.experts.13.gate_proj      torch.Size([1, 1408])          92.486076            93.046188            585.474630           3120.333589         
model.layers.19.mlp.experts.13.act_fn         torch.Size([1, 1408])          0.423840             0.854731             621.568000           3263.232000         
model.layers.19.mlp.experts.13.up_proj        torch.Size([1, 1408])          93.986305            94.510794            621.598648           3257.397183         
model.layers.19.mlp.experts.13.down_proj      torch.Size([1, 2048])          97.553635            98.039865            621.599347           3151.014748         
model.layers.19.mlp.experts.14.gate_proj      torch.Size([0, 1408])          110.879135           111.468554           621.645353           3108.957928         
model.layers.19.mlp.experts.14.act_fn         torch.Size([0, 1408])          0.646816             1.546621             621.568000           3107.840000         
model.layers.19.mlp.experts.14.up_proj        torch.Size([0, 1408])          107.756355           108.392954           532.036444           3428.559556         
model.layers.19.mlp.experts.14.down_proj      torch.Size([0, 2048])          90.974243            91.593504            528.020879           3148.538553         
model.layers.19.mlp.experts.15.gate_proj      torch.Size([0, 1408])          92.538338            93.189240            530.947737           3137.228146         
model.layers.19.mlp.experts.15.act_fn         torch.Size([0, 1408])          0.427328             0.906229             621.568000           3417.216000         
model.layers.19.mlp.experts.15.up_proj        torch.Size([0, 1408])          89.939011            90.366602            508.125504           3413.423206         
model.layers.19.mlp.experts.15.down_proj      torch.Size([0, 2048])          84.612259            85.165739            530.523807           3268.432331         
model.layers.19.mlp.experts.16.gate_proj      torch.Size([0, 1408])          87.664223            88.180780            484.021809           3333.491363         
model.layers.19.mlp.experts.16.act_fn         torch.Size([0, 1408])          0.390368             0.855207             465.984000           3985.109333         
model.layers.19.mlp.experts.16.up_proj        torch.Size([0, 1408])          87.736641            88.140011            488.765975           3737.585823         
model.layers.19.mlp.experts.16.down_proj      torch.Size([0, 2048])          90.555618            91.083050            525.555298           3229.858198         
model.layers.19.mlp.experts.17.gate_proj      torch.Size([0, 1408])          93.458878            94.186306            521.111059           3194.593882         
model.layers.19.mlp.experts.17.act_fn         torch.Size([0, 1408])          0.587328             1.390696             621.824000           3107.840000         
model.layers.19.mlp.experts.17.up_proj        torch.Size([0, 1408])          92.344864            93.044519            522.717370           3098.261041         
model.layers.19.mlp.experts.17.down_proj      torch.Size([0, 2048])          95.171616            95.732689            528.932444           3061.438222         
model.layers.19.mlp.experts.18.gate_proj      torch.Size([1, 1408])          93.075134            93.677521            576.737684           3039.300632         
model.layers.19.mlp.experts.18.act_fn         torch.Size([1, 1408])          0.608352             1.406908             621.568000           3417.216000         
model.layers.19.mlp.experts.18.up_proj        torch.Size([1, 1408])          90.078270            90.739012            621.699325           3193.294130         
model.layers.19.mlp.experts.18.down_proj      torch.Size([1, 2048])          79.955933            80.431223            621.621169           3185.275077         
model.layers.19.mlp.experts.19.gate_proj      torch.Size([0, 1408])          82.172096            82.738400            621.726476           3074.004027         
model.layers.19.mlp.experts.19.act_fn         torch.Size([0, 1408])          0.326720             0.699282             621.568000           3263.232000         
model.layers.19.mlp.experts.19.up_proj        torch.Size([0, 1408])          84.502785            84.885120            547.194378           3070.041946         
model.layers.19.mlp.experts.19.down_proj      torch.Size([0, 2048])          82.675041            83.169460            537.036084           2937.881063         
model.layers.19.mlp.experts.20.gate_proj      torch.Size([0, 1408])          84.389023            84.981441            470.226947           3613.590316         
model.layers.19.mlp.experts.20.act_fn         torch.Size([0, 1408])          0.616128             1.315594             465.984000           4347.392000         
model.layers.19.mlp.experts.20.up_proj        torch.Size([0, 1408])          88.068382            88.673115            517.912000           3749.161778         
model.layers.19.mlp.experts.20.down_proj      torch.Size([0, 2048])          88.680481            89.102507            537.734054           3082.708757         
model.layers.19.mlp.experts.21.gate_proj      torch.Size([0, 1408])          90.237823            90.824127            552.706667           2939.514667         
model.layers.19.mlp.experts.21.act_fn         torch.Size([0, 1408])          0.549984             1.349926             621.568000           3263.232000         
model.layers.19.mlp.experts.21.up_proj        torch.Size([0, 1408])          90.793411            91.463804            534.499068           3023.758027         
model.layers.19.mlp.experts.21.down_proj      torch.Size([0, 2048])          95.738045            96.393108            535.792113           3118.860709         
model.layers.19.mlp.experts.22.gate_proj      torch.Size([2, 1408])          82.838562            83.600044            574.320432           3263.873730         
model.layers.19.mlp.experts.22.act_fn         torch.Size([2, 1408])          0.718240             1.537800             621.568000           3263.232000         
model.layers.19.mlp.experts.22.up_proj        torch.Size([2, 1408])          87.588928            88.167667            621.606575           3170.587178         
model.layers.19.mlp.experts.22.down_proj      torch.Size([2, 2048])          80.390335            80.807209            621.645683           3075.689931         
model.layers.19.mlp.experts.23.gate_proj      torch.Size([0, 1408])          85.577858            86.012840            621.763133           3032.860643         
model.layers.19.mlp.experts.23.act_fn         torch.Size([0, 1408])          0.616000             1.423597             621.824000           2952.448000         
model.layers.19.mlp.experts.23.up_proj        torch.Size([0, 1408])          87.681252            88.341236            541.083429           3107.798617         
model.layers.19.mlp.experts.23.down_proj      torch.Size([0, 2048])          90.423904            91.093779            538.979097           3186.401032         
model.layers.19.mlp.experts.24.gate_proj      torch.Size([0, 1408])          87.843903            88.551283            485.570667           3551.206667         
model.layers.19.mlp.experts.24.act_fn         torch.Size([0, 1408])          0.005568             1.286507             465.984000           4036.864000         
model.layers.19.mlp.experts.24.up_proj        torch.Size([0, 1408])          84.787201            85.190535            514.730667           3504.057333         
model.layers.19.mlp.experts.24.down_proj      torch.Size([0, 2048])          82.296158            82.880735            522.452000           3116.472889         
model.layers.19.mlp.experts.25.gate_proj      torch.Size([1, 1408])          85.225471            86.004019            585.464110           3119.119342         
model.layers.19.mlp.experts.25.act_fn         torch.Size([1, 1408])          0.725696             1.581192             621.568000           3262.156800         
model.layers.19.mlp.experts.25.up_proj        torch.Size([1, 1408])          88.872162            89.719057            621.644979           3180.263385         
model.layers.19.mlp.experts.25.down_proj      torch.Size([1, 2048])          82.388832            83.156347            621.628952           3169.817252         
model.layers.19.mlp.experts.26.gate_proj      torch.Size([0, 1408])          71.264450            71.939707            621.688889           3089.459556         
model.layers.19.mlp.experts.26.act_fn         torch.Size([0, 1408])          0.320192             0.740767             621.738667           3107.840000         
model.layers.19.mlp.experts.26.up_proj        torch.Size([0, 1408])          57.343582            57.786703            536.821871           3064.240806         
model.layers.19.mlp.experts.26.down_proj      torch.Size([0, 2048])          61.856449            62.289476            563.986743           3099.979886         
model.layers.19.mlp.experts.27.gate_proj      torch.Size([0, 1408])          86.055969            86.469889            526.118874           3141.210074         
model.layers.19.mlp.experts.27.act_fn         torch.Size([0, 1408])          0.590528             1.308203             621.568000           3211.434667         
model.layers.19.mlp.experts.27.up_proj        torch.Size([0, 1408])          91.454147            92.051744            530.756056           3303.513239         
model.layers.19.mlp.experts.27.down_proj      torch.Size([0, 2048])          89.042145            89.618444            555.440471           3146.387765         
model.layers.19.mlp.experts.28.gate_proj      torch.Size([0, 1408])          89.578300            90.229034            470.112405           3540.362937         
model.layers.19.mlp.experts.28.act_fn         torch.Size([0, 1408])          0.580736             1.338959             466.080000           3805.536000         
model.layers.19.mlp.experts.28.up_proj        torch.Size([0, 1408])          87.308990            88.037491            466.269333           3276.020444         
model.layers.19.mlp.experts.28.down_proj      torch.Size([0, 2048])          83.641533            84.482908            537.427380           3154.875493         
model.layers.19.mlp.experts.29.gate_proj      torch.Size([1, 1408])          84.831169            85.650682            586.364910           3212.589462         
model.layers.19.mlp.experts.29.act_fn         torch.Size([1, 1408])          0.653056             1.512527             621.568000           3261.888000         
model.layers.19.mlp.experts.29.up_proj        torch.Size([1, 1408])          88.047234            88.737011            621.728865           3097.222486         
model.layers.19.mlp.experts.29.down_proj      torch.Size([1, 2048])          83.832161            84.538460            621.730301           3035.721203         
model.layers.19.mlp.experts.30.gate_proj      torch.Size([0, 1408])          90.013565            90.554237            621.755733           3020.820480         
model.layers.19.mlp.experts.30.act_fn         torch.Size([0, 1408])          0.402240             0.857353             621.653333           3107.840000         
model.layers.19.mlp.experts.30.up_proj        torch.Size([0, 1408])          84.134369            84.595203            529.152438           3133.383890         
model.layers.19.mlp.experts.30.down_proj      torch.Size([0, 2048])          148.684860           149.120331           540.786667           3176.795556         
model.layers.19.mlp.experts.31.gate_proj      torch.Size([0, 1408])          145.487579           146.097183           551.022345           3139.960938         
model.layers.19.mlp.experts.31.act_fn         torch.Size([0, 1408])          0.350656             0.775337             569.770667           3417.216000         
model.layers.19.mlp.experts.31.up_proj        torch.Size([0, 1408])          157.220322           157.555819           521.787524           3092.587413         
model.layers.19.mlp.experts.31.down_proj      torch.Size([0, 2048])          136.486298           136.911631           542.288818           3153.159942         
model.layers.19.mlp.experts.32.gate_proj      torch.Size([2, 1408])          138.508224           139.291525           555.393255           3837.734065         
model.layers.19.mlp.experts.32.act_fn         torch.Size([2, 1408])          0.823168             1.654625             621.312000           4036.864000         
model.layers.19.mlp.experts.32.up_proj        torch.Size([2, 1408])          149.148804           149.763584           621.548844           3462.933333         
model.layers.19.mlp.experts.32.down_proj      torch.Size([2, 2048])          138.430054           138.998270           621.740973           3047.851676         
model.layers.19.mlp.experts.33.gate_proj      torch.Size([0, 1408])          110.118080           110.543966           621.787429           3004.181333         
model.layers.19.mlp.experts.33.act_fn         torch.Size([0, 1408])          0.720640             1.527071             621.824000           3263.232000         
model.layers.19.mlp.experts.33.up_proj        torch.Size([0, 1408])          175.238495           175.885677           534.513096           3059.945205         
model.layers.19.mlp.experts.33.down_proj      torch.Size([0, 2048])          115.062050           115.657806           540.453415           3125.769846         
model.layers.19.mlp.experts.34.gate_proj      torch.Size([0, 1408])          131.313248           131.857634           520.301714           3119.476245         
model.layers.19.mlp.experts.34.act_fn         torch.Size([0, 1408])          0.638976             1.565218             621.824000           3107.840000         
model.layers.19.mlp.experts.34.up_proj        torch.Size([0, 1408])          127.754463           128.354549           528.091688           3150.820766         
model.layers.19.mlp.experts.34.down_proj      torch.Size([0, 2048])          118.248672           118.743420           554.307133           3112.186629         
model.layers.19.mlp.experts.35.gate_proj      torch.Size([1, 1408])          135.310272           135.993719           590.188108           3073.191784         
model.layers.19.mlp.experts.35.act_fn         torch.Size([1, 1408])          0.536960             1.039505             621.824000           2952.448000         
model.layers.19.mlp.experts.35.up_proj        torch.Size([1, 1408])          135.146149           135.789394           621.656403           3161.012029         
model.layers.19.mlp.experts.35.down_proj      torch.Size([1, 2048])          151.758087           152.326107           621.518979           3465.690780         
model.layers.19.mlp.experts.36.gate_proj      torch.Size([0, 1408])          138.090179           138.646126           573.269063           3813.068152         
model.layers.19.mlp.experts.36.act_fn         torch.Size([0, 1408])          0.379744             0.837803             621.568000           3417.216000         
model.layers.19.mlp.experts.36.up_proj        torch.Size([0, 1408])          142.988098           143.345594           525.893260           3206.793644         
model.layers.19.mlp.experts.36.down_proj      torch.Size([0, 2048])          144.786362           145.288467           550.484603           3005.664438         
model.layers.19.mlp.experts.37.gate_proj      torch.Size([0, 1408])          134.425919           135.122776           543.473434           3091.764966         
model.layers.19.mlp.experts.37.act_fn         torch.Size([0, 1408])          0.884896             1.839638             517.973333           3263.232000         
model.layers.19.mlp.experts.37.up_proj        torch.Size([0, 1408])          105.882751           106.757641           515.169371           3163.127771         
model.layers.19.mlp.experts.37.down_proj      torch.Size([0, 2048])          78.064835            78.549623            543.949333           3215.712000         
model.layers.19.mlp.experts.38.gate_proj      torch.Size([0, 1408])          83.136002            83.532810            546.234971           3085.641143         
model.layers.19.mlp.experts.38.act_fn         torch.Size([0, 1408])          0.688288             1.508713             621.653333           3107.840000         
model.layers.19.mlp.experts.38.up_proj        torch.Size([0, 1408])          81.155838            81.813812            538.730959           3061.009534         
model.layers.19.mlp.experts.38.down_proj      torch.Size([0, 2048])          88.299522            88.876247            552.816225           3055.254085         
model.layers.19.mlp.experts.39.gate_proj      torch.Size([0, 1408])          87.882782            88.461161            555.902667           3112.088889         
model.layers.19.mlp.experts.39.act_fn         torch.Size([0, 1408])          0.556768             1.217127             570.005333           3107.840000         
model.layers.19.mlp.experts.39.up_proj        torch.Size([0, 1408])          87.614883            88.133812            532.116889           3285.678222         
model.layers.19.mlp.experts.39.down_proj      torch.Size([0, 2048])          78.586304            79.166651            494.738824           3450.595765         
model.layers.19.mlp.experts.40.gate_proj      torch.Size([0, 1408])          81.369278            82.013845            483.850937           3721.975494         
model.layers.19.mlp.experts.40.act_fn         torch.Size([0, 1408])          0.389568             0.804186             505.024000           3417.216000         
model.layers.19.mlp.experts.40.up_proj        torch.Size([0, 1408])          83.215683            83.629847            527.795111           3212.406222         
model.layers.19.mlp.experts.40.down_proj      torch.Size([0, 2048])          82.750626            83.415031            519.542121           3145.251221         
model.layers.19.mlp.experts.41.gate_proj      torch.Size([1, 1408])          86.511620            87.209463            579.273669           3126.679942         
model.layers.19.mlp.experts.41.act_fn         torch.Size([1, 1408])          0.608640             1.170397             621.568000           3262.963200         
model.layers.19.mlp.experts.41.up_proj        torch.Size([1, 1408])          79.419777            80.028772            621.749029           3096.498743         
model.layers.19.mlp.experts.41.down_proj      torch.Size([1, 2048])          80.455742            81.108570            621.742150           3035.738558         
model.layers.19.mlp.experts.42.gate_proj      torch.Size([0, 1408])          79.374748            79.920530            621.779862           3041.396524         
model.layers.19.mlp.experts.42.act_fn         torch.Size([0, 1408])          0.429952             0.874043             621.568000           3263.232000         
model.layers.19.mlp.experts.42.up_proj        torch.Size([0, 1408])          79.677246            80.078363            529.666370           3135.465244         
model.layers.19.mlp.experts.42.down_proj      torch.Size([0, 2048])          87.152672            87.850809            526.953305           3145.310411         
model.layers.19.mlp.experts.43.gate_proj      torch.Size([1, 1408])          86.134529            87.011337            576.952205           3033.132308         
model.layers.19.mlp.experts.43.act_fn         torch.Size([1, 1408])          0.814880             1.737833             621.568000           3263.232000         
model.layers.19.mlp.experts.43.up_proj        torch.Size([1, 1408])          80.885956            81.522942            621.715288           3079.029041         
model.layers.19.mlp.experts.43.down_proj      torch.Size([1, 2048])          86.662590            87.352991            601.242236           3396.355975         
model.layers.19.mlp.experts.44.gate_proj      torch.Size([0, 1408])          87.863838            88.505745            569.351432           3726.528413         
model.layers.19.mlp.experts.44.act_fn         torch.Size([0, 1408])          0.497152             1.180649             621.568000           3417.216000         
model.layers.19.mlp.experts.44.up_proj        torch.Size([0, 1408])          82.580864            83.196163            531.797943           3266.469943         
model.layers.19.mlp.experts.44.down_proj      torch.Size([0, 2048])          84.822174            85.382462            569.258814           3116.413352         
model.layers.19.mlp.experts.45.gate_proj      torch.Size([1, 1408])          83.669502            84.423065            581.066309           3077.595919         
model.layers.19.mlp.experts.45.act_fn         torch.Size([1, 1408])          0.355680             0.732660             621.568000           3262.694400         
model.layers.19.mlp.experts.45.up_proj        torch.Size([1, 1408])          78.530144            78.988552            621.689263           3091.344000         
model.layers.19.mlp.experts.45.down_proj      torch.Size([1, 2048])          81.149536            81.573009            621.638919           3190.301405         
model.layers.19.mlp.experts.46.gate_proj      torch.Size([0, 1408])          83.819199            84.258318            621.636028           3207.419524         
model.layers.19.mlp.experts.46.act_fn         torch.Size([0, 1408])          0.575424             1.121521             621.824000           3107.840000         
model.layers.19.mlp.experts.46.up_proj        torch.Size([0, 1408])          30.305729            31.028748            547.206054           3131.988757         
model.layers.19.mlp.experts.46.down_proj      torch.Size([0, 2048])          58.075615            58.672667            561.952432           3021.760000         
model.layers.19.mlp.experts.47.gate_proj      torch.Size([0, 1408])          79.985214            80.597401            557.754811           2984.070919         
model.layers.19.mlp.experts.47.act_fn         torch.Size([0, 1408])          0.381632             0.775576             621.824000           2952.448000         
model.layers.19.mlp.experts.47.up_proj        torch.Size([0, 1408])          81.641472            82.138300            533.052845           3159.926986         
model.layers.19.mlp.experts.47.down_proj      torch.Size([0, 2048])          81.942947            82.423687            478.248397           3682.516426         
model.layers.19.mlp.experts.48.gate_proj      torch.Size([0, 1408])          87.207108            87.783337            511.283459           3660.890378         
model.layers.19.mlp.experts.48.act_fn         torch.Size([0, 1408])          0.550272             1.200199             569.770667           3263.232000         
model.layers.19.mlp.experts.48.up_proj        torch.Size([0, 1408])          83.781021            84.494114            511.616955           2982.912955         
model.layers.19.mlp.experts.48.down_proj      torch.Size([0, 2048])          83.244354            83.968639            541.217185           2952.773689         
model.layers.19.mlp.experts.49.gate_proj      torch.Size([0, 1408])          87.320030            87.982893            554.752889           3161.516889         
model.layers.19.mlp.experts.49.act_fn         torch.Size([0, 1408])          1.233024             2.076149             621.568000           3263.232000         
model.layers.19.mlp.experts.49.up_proj        torch.Size([0, 1408])          88.561089            89.076757            535.198648           3209.422423         
model.layers.19.mlp.experts.49.down_proj      torch.Size([0, 2048])          81.297859            81.783056            548.729905           3178.617034         
model.layers.19.mlp.experts.50.gate_proj      torch.Size([0, 1408])          80.091843            80.578566            560.647945           3087.478290         
model.layers.19.mlp.experts.50.act_fn         torch.Size([0, 1408])          0.345664             0.751734             621.824000           3107.840000         
model.layers.19.mlp.experts.50.up_proj        torch.Size([0, 1408])          88.401566            88.815212            559.164134           3065.081128         
model.layers.19.mlp.experts.50.down_proj      torch.Size([0, 2048])          94.431870            95.014572            563.239014           3019.485808         
model.layers.19.mlp.experts.51.gate_proj      torch.Size([1, 1408])          81.199486            81.970692            585.452373           3173.010773         
model.layers.19.mlp.experts.51.act_fn         torch.Size([1, 1408])          0.603776             1.144648             621.568000           3263.232000         
model.layers.19.mlp.experts.51.up_proj        torch.Size([1, 1408])          79.766273            80.421686            621.505343           3431.922126         
model.layers.19.mlp.experts.51.down_proj      torch.Size([1, 2048])          82.312416            83.273649            603.294626           3871.063558         
model.layers.19.mlp.experts.52.gate_proj      torch.Size([1, 1408])          116.483231           117.177486           621.542570           3375.235391         
model.layers.19.mlp.experts.52.act_fn         torch.Size([1, 1408])          0.681088             1.487970             621.568000           3230.822400         
model.layers.19.mlp.experts.52.up_proj        torch.Size([1, 1408])          84.889534            85.715294            621.705014           3095.665577         
model.layers.19.mlp.experts.52.down_proj      torch.Size([1, 2048])          86.837891            87.522745            621.686675           3104.474702         
model.layers.19.mlp.experts.53.gate_proj      torch.Size([0, 1408])          85.050751            85.725307            621.692493           3195.939945         
model.layers.19.mlp.experts.53.act_fn         torch.Size([0, 1408])          0.367968             0.874758             621.568000           3263.232000         
model.layers.19.mlp.experts.53.up_proj        torch.Size([0, 1408])          83.708130            84.107876            533.763580           3101.434182         
model.layers.19.mlp.experts.53.down_proj      torch.Size([0, 2048])          81.231392            81.732273            564.034162           3038.617514         
model.layers.19.mlp.experts.54.gate_proj      torch.Size([0, 1408])          85.969025            86.533070            553.836444           2979.795111         
model.layers.19.mlp.experts.54.act_fn         torch.Size([0, 1408])          0.384512             0.845432             621.568000           3263.232000         
model.layers.19.mlp.experts.54.up_proj        torch.Size([0, 1408])          90.931839            91.342211            535.640403           3106.783309         
model.layers.19.mlp.experts.54.down_proj      torch.Size([0, 2048])          88.703552            89.354753            557.289244           3178.054163         
model.layers.19.mlp.experts.55.gate_proj      torch.Size([1, 1408])          82.115295            82.636356            592.756083           3124.958897         
model.layers.19.mlp.experts.55.act_fn         torch.Size([1, 1408])          0.428000             0.814676             621.568000           3417.216000         
model.layers.19.mlp.experts.55.up_proj        torch.Size([1, 1408])          83.347809            83.832264            621.571436           3291.635544         
model.layers.19.mlp.experts.55.down_proj      torch.Size([1, 2048])          85.845123            86.440325            602.330469           3719.045136         
model.layers.19.mlp.experts.56.gate_proj      torch.Size([1, 1408])          88.214722            88.998556            621.568000           3337.191943         
model.layers.19.mlp.experts.56.act_fn         torch.Size([1, 1408])          0.652224             1.378775             621.568000           3417.216000         
model.layers.19.mlp.experts.56.up_proj        torch.Size([1, 1408])          91.200478            92.010736            621.583568           3351.689081         
model.layers.19.mlp.experts.56.down_proj      torch.Size([1, 2048])          83.547997            84.194183            621.741474           3135.253474         
model.layers.19.mlp.experts.57.gate_proj      torch.Size([2, 1408])          85.931549            86.431742            621.771444           3039.875815         
model.layers.19.mlp.experts.57.act_fn         torch.Size([2, 1408])          0.425600             0.900984             621.568000           3262.560000         
model.layers.19.mlp.experts.57.up_proj        torch.Size([2, 1408])          76.710495            77.168226            621.761272           3030.596238         
model.layers.19.mlp.experts.57.down_proj      torch.Size([2, 2048])          85.666878            86.269140            621.641697           3133.606303         
model.layers.19.mlp.experts.58.gate_proj      torch.Size([0, 1408])          89.854431            90.431929            621.671452           3154.503452         
model.layers.19.mlp.experts.58.act_fn         torch.Size([0, 1408])          0.300896             0.683784             621.568000           3417.216000         
model.layers.19.mlp.experts.58.up_proj        torch.Size([0, 1408])          82.816353            83.318949            556.671135           3143.442162         
model.layers.19.mlp.experts.58.down_proj      torch.Size([0, 2048])          92.511101            93.291998            557.540267           3038.431573         
model.layers.19.mlp.experts.59.gate_proj      torch.Size([0, 1408])          91.436066            91.911793            575.078490           3063.287049         
model.layers.19.mlp.experts.59.act_fn         torch.Size([0, 1408])          0.596736             1.325846             621.824000           3107.840000         
model.layers.19.mlp.experts.59.up_proj        torch.Size([0, 1408])          83.915520            84.489107            498.797650           3476.380643         
model.layers.19.mlp.experts.59.down_proj      torch.Size([0, 2048])          91.344193            91.708422            506.460160           3856.825600         
model.layers.19.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          357.637024           358.326435           639.827560           3109.033467         
model.layers.19.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.746880             1.417398             776.640000           3261.888000         
model.layers.19.mlp.shared_expert.up_proj     torch.Size([5, 5632])          340.306946           341.152430           689.011167           3149.413018         
model.layers.19.mlp.shared_expert.down_proj   torch.Size([5, 2048])          336.738495           337.641478           702.343959           3140.090964         
model.layers.19.mlp.shared_expert_gate        torch.Size([5, 1])             14.039264            14.913559            637.430725           3141.107942         
model.layers.20.input_layernorm               torch.Size([1, 5, 2048])       11.101408            11.808395            488.576000           3215.811918         
model.layers.20.self_attn.q_proj              torch.Size([1, 5, 2048])       137.581314           138.133049           572.745901           3284.396552         
model.layers.20.self_attn.k_proj              torch.Size([1, 5, 2048])       139.010941           139.527321           621.447385           3702.818769         
model.layers.20.self_attn.v_proj              torch.Size([1, 5, 2048])       131.789703           132.348061           621.629388           3182.138449         
model.layers.20.self_attn.o_proj              torch.Size([1, 5, 2048])       117.792801           118.407965           621.580800           3249.185422         
model.layers.20.post_attention_layernorm      torch.Size([1, 5, 2048])       11.055264            11.614084            584.330240           3358.877440         
model.layers.20.mlp.gate                      torch.Size([5, 60])            12.528800            13.039351            466.368000           3269.574531         
model.layers.20.mlp.experts.0.gate_proj       torch.Size([1, 1408])          84.679810            85.183144            555.474853           3132.097984         
model.layers.20.mlp.experts.0.act_fn          torch.Size([1, 1408])          0.450176             0.916243             621.568000           3262.224000         
model.layers.20.mlp.experts.0.up_proj         torch.Size([1, 1408])          81.935326            82.372189            621.719111           3074.376444         
model.layers.20.mlp.experts.0.down_proj       torch.Size([1, 2048])          86.328354            86.967230            621.749622           3004.672865         
model.layers.20.mlp.experts.1.gate_proj       torch.Size([0, 1408])          94.133919            95.007896            621.617672           3253.181612         
model.layers.20.mlp.experts.1.act_fn          torch.Size([0, 1408])          0.726880             1.503229             621.568000           3417.216000         
model.layers.20.mlp.experts.1.up_proj         torch.Size([0, 1408])          78.916801            79.888582            617.043729           3250.136541         
model.layers.20.mlp.experts.1.down_proj       torch.Size([0, 2048])          87.241600            87.823629            621.707130           3170.734841         
model.layers.20.mlp.experts.2.gate_proj       torch.Size([1, 1408])          81.198364            81.866026            578.656842           3463.682947         
model.layers.20.mlp.experts.2.act_fn          torch.Size([1, 1408])          0.684800             1.251698             621.312000           4347.392000         
model.layers.20.mlp.experts.2.up_proj         torch.Size([1, 1408])          85.209343            85.823774            608.916324           3588.225730         
model.layers.20.mlp.experts.2.down_proj       torch.Size([1, 2048])          82.270111            82.760096            621.568000           3288.272865         
model.layers.20.mlp.experts.3.gate_proj       torch.Size([0, 1408])          87.647331            88.266611            621.696000           3200.831086         
model.layers.20.mlp.experts.3.act_fn          torch.Size([0, 1408])          0.425440             0.877380             621.568000           3417.216000         
model.layers.20.mlp.experts.3.up_proj         torch.Size([0, 1408])          92.570015            93.056679            618.374761           3182.152113         
model.layers.20.mlp.experts.3.down_proj       torch.Size([0, 2048])          82.350113            82.842588            609.351884           3090.929159         
model.layers.20.mlp.experts.4.gate_proj       torch.Size([0, 1408])          81.701668            82.211971            614.005183           3127.537577         
model.layers.20.mlp.experts.4.act_fn          torch.Size([0, 1408])          0.398272             0.841379             621.824000           3107.840000         
model.layers.20.mlp.experts.4.up_proj         torch.Size([0, 1408])          80.659264            81.066608            604.236531           3234.675469         
model.layers.20.mlp.experts.4.down_proj       torch.Size([0, 2048])          81.187263            81.959009            615.639814           3217.102884         
model.layers.20.mlp.experts.5.gate_proj       torch.Size([1, 1408])          85.275841            86.081266            621.628444           3150.767111         
model.layers.20.mlp.experts.5.act_fn          torch.Size([1, 1408])          0.648672             1.367569             621.568000           3107.840000         
model.layers.20.mlp.experts.5.up_proj         torch.Size([1, 1408])          83.455681            84.240198            621.624110           3143.481425         
model.layers.20.mlp.experts.5.down_proj       torch.Size([1, 2048])          84.732674            85.344315            621.637660           3146.171211         
model.layers.20.mlp.experts.6.gate_proj       torch.Size([0, 1408])          80.660416            81.117868            621.376000           3775.899886         
model.layers.20.mlp.experts.6.act_fn          torch.Size([0, 1408])          0.379232             0.950336             621.056000           4501.728000         
model.layers.20.mlp.experts.6.up_proj         torch.Size([0, 1408])          77.057373            77.525377            591.541662           3912.629169         
model.layers.20.mlp.experts.6.down_proj       torch.Size([0, 2048])          83.431297            83.998442            619.335007           3292.382365         
model.layers.20.mlp.experts.7.gate_proj       torch.Size([0, 1408])          83.181694            83.716393            617.160348           3116.848232         
model.layers.20.mlp.experts.7.act_fn          torch.Size([0, 1408])          0.369152             0.827312             621.568000           3107.840000         
model.layers.20.mlp.experts.7.up_proj         torch.Size([0, 1408])          81.824318            82.258463            598.408707           3125.810503         
model.layers.20.mlp.experts.7.down_proj       torch.Size([0, 2048])          83.463295            83.861589            621.688242           3132.214303         
model.layers.20.mlp.experts.8.gate_proj       torch.Size([0, 1408])          92.293633            92.954874            621.687712           3212.716662         
model.layers.20.mlp.experts.8.act_fn          torch.Size([0, 1408])          0.724352             1.437187             621.568000           3417.216000         
model.layers.20.mlp.experts.8.up_proj         torch.Size([0, 1408])          86.114464            86.725235            612.914126           3310.423720         
model.layers.20.mlp.experts.8.down_proj       torch.Size([0, 2048])          103.279198           103.839636           619.491246           3117.944116         
model.layers.20.mlp.experts.9.gate_proj       torch.Size([1, 1408])          105.901154           106.682777           619.641034           3021.139156         
model.layers.20.mlp.experts.9.act_fn          torch.Size([1, 1408])          0.644768             1.353502             621.568000           3261.888000         
model.layers.20.mlp.experts.9.up_proj         torch.Size([1, 1408])          103.993889           104.582071           621.752110           3038.545973         
model.layers.20.mlp.experts.9.down_proj       torch.Size([1, 2048])          106.550880           107.260942           621.580190           3197.108825         
model.layers.20.mlp.experts.10.gate_proj      torch.Size([0, 1408])          168.984833           169.478416           621.466864           3801.146074         
model.layers.20.mlp.experts.10.act_fn         torch.Size([0, 1408])          0.580832             1.354218             569.536000           4502.656000         
model.layers.20.mlp.experts.10.up_proj        torch.Size([0, 1408])          181.229156           181.813717           511.794955           3503.169631         
model.layers.20.mlp.experts.10.down_proj      torch.Size([0, 2048])          166.843903           167.269468           606.308766           3125.463149         
model.layers.20.mlp.experts.11.gate_proj      torch.Size([0, 1408])          150.157761           150.742054           621.744806           3143.563511         
model.layers.20.mlp.experts.11.act_fn         torch.Size([0, 1408])          0.619552             1.445770             621.568000           3417.685333         
model.layers.20.mlp.experts.11.up_proj        torch.Size([0, 1408])          146.730759           147.366762           592.562992           3280.487545         
model.layers.20.mlp.experts.11.down_proj      torch.Size([0, 2048])          154.163589           155.032873           615.404903           3220.546065         
model.layers.20.mlp.experts.12.gate_proj      torch.Size([0, 1408])          139.174240           139.710903           621.687591           3167.872934         
model.layers.20.mlp.experts.12.act_fn         torch.Size([0, 1408])          0.765568             1.640558             621.568000           3211.434667         
model.layers.20.mlp.experts.12.up_proj        torch.Size([0, 1408])          149.282593           149.837971           602.232471           3154.686118         
model.layers.20.mlp.experts.12.down_proj      torch.Size([0, 2048])          146.732956           148.053169           616.125237           3107.840000         
model.layers.20.mlp.experts.13.gate_proj      torch.Size([0, 1408])          159.383362           161.010742           616.129816           3203.355234         
model.layers.20.mlp.experts.13.act_fn         torch.Size([0, 1408])          0.005728             1.332283             621.568000           3107.840000         
model.layers.20.mlp.experts.13.up_proj        torch.Size([0, 1408])          140.385788           141.802549           606.984812           3270.718145         
model.layers.20.mlp.experts.13.down_proj      torch.Size([0, 2048])          135.989410           137.476683           621.618453           3291.839533         
model.layers.20.mlp.experts.14.gate_proj      torch.Size([0, 1408])          132.734970           134.325266           570.367158           3641.972211         
model.layers.20.mlp.experts.14.act_fn         torch.Size([0, 1408])          0.005664             1.299381             621.312000           4036.864000         
model.layers.20.mlp.experts.14.up_proj        torch.Size([0, 1408])          127.321213           128.729343           590.436978           3726.598637         
model.layers.20.mlp.experts.14.down_proj      torch.Size([0, 2048])          140.667068           142.209291           616.195223           3110.075856         
model.layers.20.mlp.experts.15.gate_proj      torch.Size([0, 1408])          136.360001           136.983395           617.038328           3181.756657         
model.layers.20.mlp.experts.15.act_fn         torch.Size([0, 1408])          0.540896             1.049042             621.568000           3263.232000         
model.layers.20.mlp.experts.15.up_proj        torch.Size([0, 1408])          133.179962           133.577824           586.971569           3173.582769         
model.layers.20.mlp.experts.15.down_proj      torch.Size([0, 2048])          149.850052           150.498629           619.394866           3089.285731         
model.layers.20.mlp.experts.16.gate_proj      torch.Size([0, 1408])          130.755142           131.380558           621.686986           3099.085521         
model.layers.20.mlp.experts.16.act_fn         torch.Size([0, 1408])          0.650816             1.630545             621.568000           3107.840000         
model.layers.20.mlp.experts.16.up_proj        torch.Size([0, 1408])          84.619453            85.256815            609.030163           3139.765096         
model.layers.20.mlp.experts.16.down_proj      torch.Size([0, 2048])          88.143906            88.670254            612.669217           3157.183536         
model.layers.20.mlp.experts.17.gate_proj      torch.Size([1, 1408])          91.978050            92.478514            621.575062           3227.227366         
model.layers.20.mlp.experts.17.act_fn         torch.Size([1, 1408])          0.483328             0.946999             621.568000           3168.691200         
model.layers.20.mlp.experts.17.up_proj        torch.Size([1, 1408])          104.514175           105.094671           621.685622           3117.107892         
model.layers.20.mlp.experts.17.down_proj      torch.Size([1, 2048])          90.946594            91.576815            621.646904           3156.375233         
model.layers.20.mlp.experts.18.gate_proj      torch.Size([0, 1408])          104.272324           104.748964           621.497081           3756.949189         
model.layers.20.mlp.experts.18.act_fn         torch.Size([0, 1408])          0.392192             0.820637             621.312000           4347.392000         
model.layers.20.mlp.experts.18.up_proj        torch.Size([0, 1408])          105.938461           106.370211           593.799771           3546.392686         
model.layers.20.mlp.experts.18.down_proj      torch.Size([0, 2048])          105.205956           105.782509           612.440471           3308.195294         
model.layers.20.mlp.experts.19.gate_proj      torch.Size([1, 1408])          90.167549            91.130257            621.730428           3130.074483         
model.layers.20.mlp.experts.19.act_fn         torch.Size([1, 1408])          0.694496             1.398802             621.568000           3261.888000         
model.layers.20.mlp.experts.19.up_proj        torch.Size([1, 1408])          87.268990            87.907314            621.739789           3084.034526         
model.layers.20.mlp.experts.19.down_proj      torch.Size([1, 2048])          84.422531            85.032701            621.738044           3041.827504         
model.layers.20.mlp.experts.20.gate_proj      torch.Size([2, 1408])          100.051392           100.535870           621.568000           3208.490203         
model.layers.20.mlp.experts.20.act_fn         torch.Size([2, 1408])          0.354144             0.774860             621.568000           3417.216000         
model.layers.20.mlp.experts.20.up_proj        torch.Size([2, 1408])          79.575935            80.015659            621.568000           3245.316031         
model.layers.20.mlp.experts.20.down_proj      torch.Size([2, 2048])          94.037827            94.782829            621.664241           3124.050767         
model.layers.20.mlp.experts.21.gate_proj      torch.Size([0, 1408])          94.550751            95.259666            621.780114           3028.938057         
model.layers.20.mlp.experts.21.act_fn         torch.Size([0, 1408])          0.005696             1.262426             621.824000           3107.840000         
model.layers.20.mlp.experts.21.up_proj        torch.Size([0, 1408])          101.302979           101.807117           621.677714           3121.405968         
model.layers.20.mlp.experts.21.down_proj      torch.Size([0, 2048])          99.123940            99.600792            621.641412           3337.841882         
model.layers.20.mlp.experts.22.gate_proj      torch.Size([0, 1408])          103.802017           104.253292           582.836403           3829.436134         
model.layers.20.mlp.experts.22.act_fn         torch.Size([0, 1408])          0.688384             1.403570             621.312000           4037.973333         
model.layers.20.mlp.experts.22.up_proj        torch.Size([0, 1408])          100.056419           100.658178           587.869091           3548.863552         
model.layers.20.mlp.experts.22.down_proj      torch.Size([0, 2048])          96.159134            96.817732            621.653333           3151.755130         
model.layers.20.mlp.experts.23.gate_proj      torch.Size([0, 1408])          90.419617            90.930223            621.655188           3135.990725         
model.layers.20.mlp.experts.23.act_fn         torch.Size([0, 1408])          0.458528             1.009464             621.653333           3107.840000         
model.layers.20.mlp.experts.23.up_proj        torch.Size([0, 1408])          94.324867            94.797611            609.814473           3186.842382         
model.layers.20.mlp.experts.23.down_proj      torch.Size([0, 2048])          81.149696            81.688404            621.660000           3207.071000         
model.layers.20.mlp.experts.24.gate_proj      torch.Size([1, 1408])          92.439331            92.939377            618.366648           3217.651831         
model.layers.20.mlp.experts.24.act_fn         torch.Size([1, 1408])          0.433056             0.833035             621.568000           3261.888000         
model.layers.20.mlp.experts.24.up_proj        torch.Size([1, 1408])          78.898308            79.361916            621.639890           3205.001644         
model.layers.20.mlp.experts.24.down_proj      torch.Size([1, 2048])          100.454079           100.940228           621.675789           3080.421053         
model.layers.20.mlp.experts.25.gate_proj      torch.Size([0, 1408])          84.367554            84.862471            621.717477           3090.922523         
model.layers.20.mlp.experts.25.act_fn         torch.Size([0, 1408])          0.420192             0.935078             621.568000           3417.216000         
model.layers.20.mlp.experts.25.up_proj        torch.Size([0, 1408])          52.925022            53.393364            619.426824           3201.429647         
model.layers.20.mlp.experts.25.down_proj      torch.Size([0, 2048])          80.929443            81.444740            621.576127           3379.732825         
model.layers.20.mlp.experts.26.gate_proj      torch.Size([0, 1408])          102.661377           103.137493           575.499457           3649.310025         
model.layers.20.mlp.experts.26.act_fn         torch.Size([0, 1408])          0.585536             1.366615             621.568000           3727.872000         
model.layers.20.mlp.experts.26.up_proj        torch.Size([0, 1408])          71.055901            71.654320            538.065823           3313.218025         
model.layers.20.mlp.experts.26.down_proj      torch.Size([0, 2048])          96.076477            96.884012            615.105362           3112.001816         
model.layers.20.mlp.experts.27.gate_proj      torch.Size([0, 1408])          77.681602            78.176737            619.537902           3213.012140         
model.layers.20.mlp.experts.27.act_fn         torch.Size([0, 1408])          0.370656             0.850439             621.568000           3262.784000         
model.layers.20.mlp.experts.27.up_proj        torch.Size([0, 1408])          80.421570            80.874205            605.914295           3303.517271         
model.layers.20.mlp.experts.27.down_proj      torch.Size([0, 2048])          80.087296            80.566406            621.684706           3175.047059         
model.layers.20.mlp.experts.28.gate_proj      torch.Size([0, 1408])          82.255486            82.810640            621.788196           3013.300811         
model.layers.20.mlp.experts.28.act_fn         torch.Size([0, 1408])          0.360768             0.766277             621.568000           3418.624000         
model.layers.20.mlp.experts.28.up_proj        torch.Size([0, 1408])          82.386017            82.859993            602.503942           3049.993343         
model.layers.20.mlp.experts.28.down_proj      torch.Size([0, 2048])          86.056030            86.522818            608.522894           3164.045617         
model.layers.20.mlp.experts.29.gate_proj      torch.Size([1, 1408])          91.853661            92.537403            621.568000           3287.229333         
model.layers.20.mlp.experts.29.act_fn         torch.Size([1, 1408])          0.697504             1.180410             621.568000           3261.888000         
model.layers.20.mlp.experts.29.up_proj        torch.Size([1, 1408])          84.379356            84.993124            621.568000           3228.900835         
model.layers.20.mlp.experts.29.down_proj      torch.Size([1, 2048])          89.995811            90.633869            621.573297           3233.471117         
model.layers.20.mlp.experts.30.gate_proj      torch.Size([2, 1408])          89.306274            90.144873            621.427358           3655.715556         
model.layers.20.mlp.experts.30.act_fn         torch.Size([2, 1408])          0.755776             1.540661             621.312000           3766.704000         
model.layers.20.mlp.experts.30.up_proj        torch.Size([2, 1408])          111.364418           112.246990           621.544727           3506.285203         
model.layers.20.mlp.experts.30.down_proj      torch.Size([2, 2048])          84.553246            85.551500            621.568000           3303.201566         
model.layers.20.mlp.experts.31.gate_proj      torch.Size([0, 1408])          83.401535            83.866358            621.580190           3163.627537         
model.layers.20.mlp.experts.31.act_fn         torch.Size([0, 1408])          0.319968             0.791550             621.568000           3107.840000         
model.layers.20.mlp.experts.31.up_proj        torch.Size([0, 1408])          98.315613            98.811388            612.062247           3177.021370         
model.layers.20.mlp.experts.31.down_proj      torch.Size([0, 2048])          101.993149           102.612972           621.648941           3114.695529         
model.layers.20.mlp.experts.32.gate_proj      torch.Size([0, 1408])          91.944733            92.352390            621.657600           3210.636800         
model.layers.20.mlp.experts.32.act_fn         torch.Size([0, 1408])          0.401024             0.859022             621.568000           3263.232000         
model.layers.20.mlp.experts.32.up_proj        torch.Size([0, 1408])          98.163521            98.550558            603.889371           3239.510857         
model.layers.20.mlp.experts.32.down_proj      torch.Size([0, 2048])          97.310944            97.830772            619.457803           3194.125972         
model.layers.20.mlp.experts.33.gate_proj      torch.Size([0, 1408])          93.412834            94.090462            621.691115           3090.047023         
model.layers.20.mlp.experts.33.act_fn         torch.Size([0, 1408])          0.556160             1.312256             621.568000           3107.840000         
model.layers.20.mlp.experts.33.up_proj        torch.Size([0, 1408])          93.032288            93.566895            614.938899           3081.941333         
model.layers.20.mlp.experts.33.down_proj      torch.Size([0, 2048])          89.476929            90.222359            621.697829           3203.862857         
model.layers.20.mlp.experts.34.gate_proj      torch.Size([0, 1408])          97.283966            97.917318            583.040386           3929.448867         
model.layers.20.mlp.experts.34.act_fn         torch.Size([0, 1408])          0.005728             1.433372             621.312000           4038.528000         
model.layers.20.mlp.experts.34.up_proj        torch.Size([0, 1408])          86.033730            86.569071            537.736421           3429.399158         
model.layers.20.mlp.experts.34.down_proj      torch.Size([0, 2048])          78.179108            78.700542            617.031218           3121.698647         
model.layers.20.mlp.experts.35.gate_proj      torch.Size([1, 1408])          88.229820            88.746309            621.705846           3090.020699         
model.layers.20.mlp.experts.35.act_fn         torch.Size([1, 1408])          0.505280             1.003504             621.568000           3261.888000         
model.layers.20.mlp.experts.35.up_proj        torch.Size([1, 1408])          97.352348            97.963333            621.687944           3159.498294         
model.layers.20.mlp.experts.35.down_proj      torch.Size([1, 2048])          84.313919            84.982395            621.603310           3205.837683         
model.layers.20.mlp.experts.36.gate_proj      torch.Size([0, 1408])          75.491714            75.905323            621.664914           3280.442514         
model.layers.20.mlp.experts.36.act_fn         torch.Size([0, 1408])          0.577376             1.303196             621.568000           3314.581333         
model.layers.20.mlp.experts.36.up_proj        torch.Size([0, 1408])          90.360542            90.939283            621.734957           3211.250087         
model.layers.20.mlp.experts.36.down_proj      torch.Size([0, 2048])          92.358177            93.176603            621.762704           3089.141183         
model.layers.20.mlp.experts.37.gate_proj      torch.Size([1, 1408])          85.624893            86.309195            621.779556           3020.338222         
model.layers.20.mlp.experts.37.act_fn         torch.Size([1, 1408])          0.741184             1.568794             621.568000           3417.216000         
model.layers.20.mlp.experts.37.up_proj        torch.Size([1, 1408])          83.313629            83.992720            621.568000           3227.500058         
model.layers.20.mlp.experts.37.down_proj      torch.Size([1, 2048])          81.133087            81.871271            621.456361           3473.445053         
model.layers.20.mlp.experts.38.gate_proj      torch.Size([0, 1408])          98.507843            99.143028            621.346362           3985.224591         
model.layers.20.mlp.experts.38.act_fn         torch.Size([0, 1408])          0.353568             0.761271             621.312000           3883.200000         
model.layers.20.mlp.experts.38.up_proj        torch.Size([0, 1408])          89.264420            89.642048            591.877447           3314.764709         
model.layers.20.mlp.experts.38.down_proj      torch.Size([0, 2048])          91.292801            91.739655            621.780757           3138.240865         
model.layers.20.mlp.experts.39.gate_proj      torch.Size([0, 1408])          95.881378            96.377611            621.676973           3228.147459         
model.layers.20.mlp.experts.39.act_fn         torch.Size([0, 1408])          0.516480             0.996113             621.824000           3107.840000         
model.layers.20.mlp.experts.39.up_proj        torch.Size([0, 1408])          95.541183            95.965385            604.747411           3265.271566         
model.layers.20.mlp.experts.39.down_proj      torch.Size([0, 2048])          89.237923            89.917183            621.628472           3187.371339         
model.layers.20.mlp.experts.40.gate_proj      torch.Size([0, 1408])          76.524803            76.946735            621.665933           3120.354792         
model.layers.20.mlp.experts.40.act_fn         torch.Size([0, 1408])          0.351008             0.813007             621.824000           3107.840000         
model.layers.20.mlp.experts.40.up_proj        torch.Size([0, 1408])          85.183105            85.596561            612.755338           3116.783424         
model.layers.20.mlp.experts.40.down_proj      torch.Size([0, 2048])          85.136894            85.534096            621.676850           3161.390866         
model.layers.20.mlp.experts.41.gate_proj      torch.Size([0, 1408])          89.767967            90.295792            619.462400           3167.430400         
model.layers.20.mlp.experts.41.act_fn         torch.Size([0, 1408])          0.586560             1.322746             621.568000           3261.888000         
model.layers.20.mlp.experts.41.up_proj        torch.Size([0, 1408])          102.353630           103.093863           611.875357           3216.372364         
model.layers.20.mlp.experts.41.down_proj      torch.Size([0, 2048])          102.593086           103.083849           619.474878           3146.485871         
model.layers.20.mlp.experts.42.gate_proj      torch.Size([1, 1408])          99.956161            100.674629           576.324571           3466.510066         
model.layers.20.mlp.experts.42.act_fn         torch.Size([1, 1408])          0.820928             1.567602             621.568000           3263.232000         
model.layers.20.mlp.experts.42.up_proj        torch.Size([1, 1408])          97.263390            97.934723            621.632000           3246.886919         
model.layers.20.mlp.experts.42.down_proj      torch.Size([1, 2048])          103.718781           104.172707           621.616107           3243.681933         
model.layers.20.mlp.experts.43.gate_proj      torch.Size([0, 1408])          93.072990            93.517303            621.613390           3151.806638         
model.layers.20.mlp.experts.43.act_fn         torch.Size([0, 1408])          0.392576             0.856161             621.568000           3107.840000         
model.layers.20.mlp.experts.43.up_proj        torch.Size([0, 1408])          91.492256            91.901541            621.656965           3132.085560         
model.layers.20.mlp.experts.43.down_proj      torch.Size([0, 2048])          81.413727            81.861734            621.690592           3080.482254         
model.layers.20.mlp.experts.44.gate_proj      torch.Size([0, 1408])          87.469826            87.994576            621.721600           3122.492681         
model.layers.20.mlp.experts.44.act_fn         torch.Size([0, 1408])          0.322432             0.712872             621.568000           3263.232000         
model.layers.20.mlp.experts.44.up_proj        torch.Size([0, 1408])          73.386398            73.935747            597.298286           3139.879771         
model.layers.20.mlp.experts.44.down_proj      torch.Size([0, 2048])          88.409698            89.006186            621.729391           3224.710029         
model.layers.20.mlp.experts.45.gate_proj      torch.Size([0, 1408])          88.842529            89.577436            621.760000           3048.025946         
model.layers.20.mlp.experts.45.act_fn         torch.Size([0, 1408])          0.005792             1.303911             621.568000           3263.232000         
model.layers.20.mlp.experts.45.up_proj        torch.Size([0, 1408])          79.731613            80.132961            605.980754           3070.640232         
model.layers.20.mlp.experts.45.down_proj      torch.Size([0, 2048])          83.053665            83.713770            581.046217           3339.687541         
model.layers.20.mlp.experts.46.gate_proj      torch.Size([0, 1408])          87.443550            87.944746            578.715976           3868.030467         
model.layers.20.mlp.experts.46.act_fn         torch.Size([0, 1408])          0.600544             1.380920             621.568000           3727.872000         
model.layers.20.mlp.experts.46.up_proj        torch.Size([0, 1408])          90.353821            90.983152            544.481882           3289.433516         
model.layers.20.mlp.experts.46.down_proj      torch.Size([0, 2048])          90.313759            90.957165            619.456448           3271.509035         
model.layers.20.mlp.experts.47.gate_proj      torch.Size([0, 1408])          102.421761           103.085518           621.731914           3084.396662         
model.layers.20.mlp.experts.47.act_fn         torch.Size([0, 1408])          0.598624             1.371861             621.568000           3263.232000         
model.layers.20.mlp.experts.47.up_proj        torch.Size([0, 1408])          95.624702            96.350908            610.479304           3135.949913         
model.layers.20.mlp.experts.47.down_proj      torch.Size([0, 2048])          97.347519            98.837376            621.725835           3189.338466         
model.layers.20.mlp.experts.48.gate_proj      torch.Size([0, 1408])          93.150627            94.630003            621.612271           3443.676872         
model.layers.20.mlp.experts.48.act_fn         torch.Size([0, 1408])          0.005440             1.373768             621.568000           3727.872000         
model.layers.20.mlp.experts.48.up_proj        torch.Size([0, 1408])          93.293922            94.723463            598.281143           3323.941943         
model.layers.20.mlp.experts.48.down_proj      torch.Size([0, 2048])          97.704033            99.080086            621.780732           3114.336451         
model.layers.20.mlp.experts.49.gate_proj      torch.Size([0, 1408])          100.501694           101.888895           621.781918           3096.132384         
model.layers.20.mlp.experts.49.act_fn         torch.Size([0, 1408])          0.005792             1.253366             621.824000           3107.840000         
model.layers.20.mlp.experts.49.up_proj        torch.Size([0, 1408])          93.682274            95.089197            619.276511           3269.785023         
model.layers.20.mlp.experts.49.down_proj      torch.Size([0, 2048])          81.062462            82.616329            590.432457           3553.605029         
model.layers.20.mlp.experts.50.gate_proj      torch.Size([1, 1408])          81.989761            83.726406            590.961778           3791.146248         
model.layers.20.mlp.experts.50.act_fn         torch.Size([1, 1408])          0.050848             1.709461             621.568000           3378.384000         
model.layers.20.mlp.experts.50.up_proj        torch.Size([1, 1408])          107.360832           108.843327           621.568000           3256.130462         
model.layers.20.mlp.experts.50.down_proj      torch.Size([1, 2048])          96.398819            98.170280            621.573606           3150.135591         
model.layers.20.mlp.experts.51.gate_proj      torch.Size([0, 1408])          102.775101           104.259968           621.604848           3210.828121         
model.layers.20.mlp.experts.51.act_fn         torch.Size([0, 1408])          0.655200             1.466274             621.568000           3107.840000         
model.layers.20.mlp.experts.51.up_proj        torch.Size([0, 1408])          112.267937           112.859249           621.642203           3284.053333         
model.layers.20.mlp.experts.51.down_proj      torch.Size([0, 2048])          97.546082            97.970009            621.626935           3293.975942         
model.layers.20.mlp.experts.52.gate_proj      torch.Size([2, 1408])          98.105057            98.754883            621.655771           3139.754514         
model.layers.20.mlp.experts.52.act_fn         torch.Size([2, 1408])          0.424736             0.838757             621.568000           3107.840000         
model.layers.20.mlp.experts.52.up_proj        torch.Size([2, 1408])          137.832733           138.291597           621.703837           3072.706177         
model.layers.20.mlp.experts.52.down_proj      torch.Size([2, 2048])          172.960159           173.531771           621.684980           3064.112742         
model.layers.20.mlp.experts.53.gate_proj      torch.Size([0, 1408])          173.495010           174.019098           621.650286           3195.161600         
model.layers.20.mlp.experts.53.act_fn         torch.Size([0, 1408])          0.005632             1.312256             621.568000           3417.216000         
model.layers.20.mlp.experts.53.up_proj        torch.Size([0, 1408])          174.028320           174.415112           619.488889           3243.720000         
model.layers.20.mlp.experts.53.down_proj      torch.Size([0, 2048])          154.832230           155.604124           595.548349           3361.412725         
model.layers.20.mlp.experts.54.gate_proj      torch.Size([1, 1408])          138.971420           139.749289           582.648000           3654.218400         
model.layers.20.mlp.experts.54.act_fn         torch.Size([1, 1408])          0.521440             1.065731             621.568000           3261.888000         
model.layers.20.mlp.experts.54.up_proj        torch.Size([1, 1408])          137.815353           138.545275           621.628681           3303.839289         
model.layers.20.mlp.experts.54.down_proj      torch.Size([1, 2048])          164.972198           165.445566           621.656471           3195.147294         
model.layers.20.mlp.experts.55.gate_proj      torch.Size([0, 1408])          157.547104           158.031702           621.571631           3285.494468         
model.layers.20.mlp.experts.55.act_fn         torch.Size([0, 1408])          0.561472             1.431465             621.568000           3261.888000         
model.layers.20.mlp.experts.55.up_proj        torch.Size([0, 1408])          178.931015           179.611683           616.280889           3194.043556         
model.layers.20.mlp.experts.55.down_proj      torch.Size([0, 2048])          133.814590           134.518385           621.727785           3026.493852         
model.layers.20.mlp.experts.56.gate_proj      torch.Size([0, 1408])          143.150818           143.668890           621.751111           3067.775111         
model.layers.20.mlp.experts.56.act_fn         torch.Size([0, 1408])          0.644640             1.576185             621.568000           3572.544000         
model.layers.20.mlp.experts.56.up_proj        torch.Size([0, 1408])          137.329208           137.905598           617.578384           3246.548768         
model.layers.20.mlp.experts.56.down_proj      torch.Size([0, 2048])          183.175323           183.764458           621.693315           3246.775944         
model.layers.20.mlp.experts.57.gate_proj      torch.Size([0, 1408])          198.514145           199.304104           621.756632           3110.134376         
model.layers.20.mlp.experts.57.act_fn         torch.Size([0, 1408])          0.325984             0.772715             621.568000           3418.154667         
model.layers.20.mlp.experts.57.up_proj        torch.Size([0, 1408])          154.500473           155.783176           618.365664           3066.945401         
model.layers.20.mlp.experts.57.down_proj      torch.Size([0, 2048])          136.123077           136.871099           590.892211           3419.570947         
model.layers.20.mlp.experts.58.gate_proj      torch.Size([1, 1408])          173.398529           174.048901           570.251799           3848.764067         
model.layers.20.mlp.experts.58.act_fn         torch.Size([1, 1408])          0.051168             1.752853             621.568000           3541.478400         
model.layers.20.mlp.experts.58.up_proj        torch.Size([1, 1408])          65.002495            66.644192            621.568000           3434.566137         
model.layers.20.mlp.experts.58.down_proj      torch.Size([1, 2048])          83.178108            84.838152            621.568000           3233.144599         
model.layers.20.mlp.experts.59.gate_proj      torch.Size([0, 1408])          93.896927            95.162153            621.749797           3045.791536         
model.layers.20.mlp.experts.59.act_fn         torch.Size([0, 1408])          0.005696             1.265049             621.568000           3263.232000         
model.layers.20.mlp.experts.59.up_proj        torch.Size([0, 1408])          99.407936            100.730896           621.771718           3103.462761         
model.layers.20.mlp.experts.59.down_proj      torch.Size([0, 2048])          70.065155            71.415424            621.638687           3268.602269         
model.layers.20.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          388.808228           390.574694           660.122971           3050.695010         
model.layers.20.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.057856             1.668215             776.960000           3106.560000         
model.layers.20.mlp.shared_expert.up_proj     torch.Size([5, 5632])          325.196167           326.435566           715.439689           3123.662913         
model.layers.20.mlp.shared_expert.down_proj   torch.Size([5, 2048])          354.629730           355.227709           674.385131           3328.626021         
model.layers.20.mlp.shared_expert_gate        torch.Size([5, 1])             12.189600            12.818336            641.536000           3104.068085         
model.layers.21.input_layernorm               torch.Size([1, 5, 2048])       9.941824             10.542870            472.464314           3324.220235         
model.layers.21.self_attn.q_proj              torch.Size([1, 5, 2048])       132.629639           133.162260           572.414127           3171.516566         
model.layers.21.self_attn.k_proj              torch.Size([1, 5, 2048])       156.569412           157.117844           621.714286           3163.204571         
model.layers.21.self_attn.v_proj              torch.Size([1, 5, 2048])       42.158623            42.916536            621.798902           2965.557020         
model.layers.21.self_attn.o_proj              torch.Size([1, 5, 2048])       83.621216            84.256887            621.624352           3250.838541         
model.layers.21.post_attention_layernorm      torch.Size([1, 5, 2048])       12.868064            13.545752            590.589440           3324.814080         
model.layers.21.mlp.gate                      torch.Size([5, 60])            9.976736             10.524035            466.368000           3285.893333         
model.layers.21.mlp.experts.0.gate_proj       torch.Size([0, 1408])          72.494690            72.921991            521.720255           3267.920713         
model.layers.21.mlp.experts.0.act_fn          torch.Size([0, 1408])          0.331488             0.719070             621.312000           3881.600000         
model.layers.21.mlp.experts.0.up_proj         torch.Size([0, 1408])          87.992676            88.448286            569.430634           3615.371707         
model.layers.21.mlp.experts.0.down_proj       torch.Size([0, 2048])          79.055199            79.654217            556.119075           3183.787973         
model.layers.21.mlp.experts.1.gate_proj       torch.Size([1, 1408])          93.545441            94.423771            617.345778           3213.068000         
model.layers.21.mlp.experts.1.act_fn          torch.Size([1, 1408])          0.833440             1.647472             621.568000           3417.216000         
model.layers.21.mlp.experts.1.up_proj         torch.Size([1, 1408])          88.030914            88.793516            621.568000           3303.744948         
model.layers.21.mlp.experts.1.down_proj       torch.Size([1, 2048])          98.011490            98.790407            621.615342           3123.101808         
model.layers.21.mlp.experts.2.gate_proj       torch.Size([1, 1408])          95.103935            95.905066            621.661699           3084.100601         
model.layers.21.mlp.experts.2.act_fn          torch.Size([1, 1408])          0.732480             1.494884             621.568000           3106.560000         
model.layers.21.mlp.experts.2.up_proj         torch.Size([1, 1408])          99.654404            100.399017           621.666192           3179.567342         
model.layers.21.mlp.experts.2.down_proj       torch.Size([1, 2048])          97.828545            98.556042            621.668634           3160.712828         
model.layers.21.mlp.experts.3.gate_proj       torch.Size([0, 1408])          93.632156            94.310522            621.639529           3184.912000         
model.layers.21.mlp.experts.3.act_fn          torch.Size([0, 1408])          0.303392             0.724792             621.568000           3261.888000         
model.layers.21.mlp.experts.3.up_proj         torch.Size([0, 1408])          88.211105            88.822842            621.707801           3136.436652         
model.layers.21.mlp.experts.3.down_proj       torch.Size([0, 2048])          99.811325            100.255251           621.744318           3096.207682         
model.layers.21.mlp.experts.4.gate_proj       torch.Size([0, 1408])          86.449501            86.934805            583.779892           3510.894270         
model.layers.21.mlp.experts.4.act_fn          torch.Size([0, 1408])          0.343232             0.738859             621.312000           4347.392000         
model.layers.21.mlp.experts.4.up_proj         torch.Size([0, 1408])          104.047554           104.524374           546.170635           3585.733365         
model.layers.21.mlp.experts.4.down_proj       torch.Size([0, 2048])          85.186172            85.751295            561.071899           3195.744604         
model.layers.21.mlp.experts.5.gate_proj       torch.Size([0, 1408])          89.119583            89.745760            614.185048           3116.413352         
model.layers.21.mlp.experts.5.act_fn          torch.Size([0, 1408])          0.606368             1.496077             621.568000           3263.232000         
model.layers.21.mlp.experts.5.up_proj         torch.Size([0, 1408])          96.941475            97.615719            612.751655           3138.024058         
model.layers.21.mlp.experts.5.down_proj       torch.Size([0, 2048])          99.209152            99.630356            621.735597           3110.944230         
model.layers.21.mlp.experts.6.gate_proj       torch.Size([0, 1408])          87.724960            88.484526            621.717041           3149.175671         
model.layers.21.mlp.experts.6.act_fn          torch.Size([0, 1408])          0.573440             1.361609             621.568000           3624.320000         
model.layers.21.mlp.experts.6.up_proj         torch.Size([0, 1408])          84.053246            84.627628            600.437871           3301.912863         
model.layers.21.mlp.experts.6.down_proj       torch.Size([0, 2048])          91.471390            92.060089            621.731404           3173.735489         
model.layers.21.mlp.experts.7.gate_proj       torch.Size([1, 1408])          86.664291            87.412596            621.745778           3130.348889         
model.layers.21.mlp.experts.7.act_fn          torch.Size([1, 1408])          0.444480             0.878096             621.568000           3261.888000         
model.layers.21.mlp.experts.7.up_proj         torch.Size([1, 1408])          84.298752            84.770441            621.737967           3117.795672         
model.layers.21.mlp.experts.7.down_proj       torch.Size([1, 2048])          88.246429            88.855028            621.541333           3380.420444         
model.layers.21.mlp.experts.8.gate_proj       torch.Size([0, 1408])          79.444382            80.038309            621.341479           3945.088388         
model.layers.21.mlp.experts.8.act_fn          torch.Size([0, 1408])          0.592416             1.318455             621.312000           3883.200000         
model.layers.21.mlp.experts.8.up_proj         torch.Size([0, 1408])          94.686653            95.245838            592.892739           3352.748433         
model.layers.21.mlp.experts.8.down_proj       torch.Size([0, 2048])          73.630913            74.244738            588.925746           3049.944338         
model.layers.21.mlp.experts.9.gate_proj       torch.Size([0, 1408])          99.418945            99.960566            618.461714           3027.858743         
model.layers.21.mlp.experts.9.act_fn          torch.Size([0, 1408])          0.621280             1.399040             621.568000           3468.992000         
model.layers.21.mlp.experts.9.up_proj         torch.Size([0, 1408])          86.224640            87.278366            617.258965           3297.398154         
model.layers.21.mlp.experts.9.down_proj       torch.Size([0, 2048])          81.593597            82.127810            621.650930           3262.028620         
model.layers.21.mlp.experts.10.gate_proj      torch.Size([0, 1408])          88.176323            88.655710            621.768503           3132.754350         
model.layers.21.mlp.experts.10.act_fn         torch.Size([0, 1408])          0.570016             1.326323             621.568000           3263.232000         
model.layers.21.mlp.experts.10.up_proj        torch.Size([0, 1408])          92.482018            93.129635            618.554811           3094.190703         
model.layers.21.mlp.experts.10.down_proj      torch.Size([0, 2048])          88.694206            89.270115            621.809159           3111.218087         
model.layers.21.mlp.experts.11.gate_proj      torch.Size([0, 1408])          85.455551            85.963726            621.657302           3145.040868         
model.layers.21.mlp.experts.11.act_fn         torch.Size([0, 1408])          0.411008             0.846148             621.568000           3107.840000         
model.layers.21.mlp.experts.11.up_proj        torch.Size([0, 1408])          87.652992            88.159800            621.627915           3283.711546         
model.layers.21.mlp.experts.11.down_proj      torch.Size([0, 2048])          86.872162            87.275267            621.569869           3414.158482         
model.layers.21.mlp.experts.12.gate_proj      torch.Size([0, 1408])          94.585854            95.108986            598.434051           4020.436513         
model.layers.21.mlp.experts.12.act_fn         torch.Size([0, 1408])          0.005664             1.306057             621.568000           3572.544000         
model.layers.21.mlp.experts.12.up_proj        torch.Size([0, 1408])          86.732193            87.123156            611.870222           3327.332889         
model.layers.21.mlp.experts.12.down_proj      torch.Size([0, 2048])          85.549187            86.100101            621.661257           3220.450286         
model.layers.21.mlp.experts.13.gate_proj      torch.Size([0, 1408])          90.522499            91.213465            621.651302           3244.139683         
model.layers.21.mlp.experts.13.act_fn         torch.Size([0, 1408])          0.612512             1.351833             621.568000           3417.216000         
model.layers.21.mlp.experts.13.up_proj        torch.Size([0, 1408])          87.437057            87.951422            621.648941           3249.134118         
model.layers.21.mlp.experts.13.down_proj      torch.Size([0, 2048])          85.866493            86.420536            621.672889           3133.738667         
model.layers.21.mlp.experts.14.gate_proj      torch.Size([0, 1408])          82.158211            82.819939            621.711515           3085.472970         
model.layers.21.mlp.experts.14.act_fn         torch.Size([0, 1408])          0.631264             1.454115             621.568000           3107.840000         
model.layers.21.mlp.experts.14.up_proj        torch.Size([0, 1408])          94.767776            95.374584            621.702446           3157.738360         
model.layers.21.mlp.experts.14.down_proj      torch.Size([0, 2048])          78.890114            79.369068            621.733415           3099.431877         
model.layers.21.mlp.experts.15.gate_proj      torch.Size([0, 1408])          83.466339            84.118128            621.704288           3214.935942         
model.layers.21.mlp.experts.15.act_fn         torch.Size([0, 1408])          0.354688             0.822306             621.568000           3263.232000         
model.layers.21.mlp.experts.15.up_proj        torch.Size([0, 1408])          77.397858            77.842236            621.715338           3193.750101         
model.layers.21.mlp.experts.15.down_proj      torch.Size([0, 2048])          96.335037            96.762180            621.612606           3235.722667         
model.layers.21.mlp.experts.16.gate_proj      torch.Size([0, 1408])          92.101410            92.515469            597.750725           3937.476174         
model.layers.21.mlp.experts.16.act_fn         torch.Size([0, 1408])          0.446176             0.986576             621.312000           4037.973333         
model.layers.21.mlp.experts.16.up_proj        torch.Size([0, 1408])          92.833282            93.577623            609.514366           3459.669183         
model.layers.21.mlp.experts.16.down_proj      torch.Size([0, 2048])          87.505760            87.932825            621.568000           3351.636060         
model.layers.21.mlp.experts.17.gate_proj      torch.Size([0, 1408])          103.525375           104.326487           621.755145           3071.475641         
model.layers.21.mlp.experts.17.act_fn         torch.Size([0, 1408])          0.708928             1.679420             621.568000           3263.232000         
model.layers.21.mlp.experts.17.up_proj        torch.Size([0, 1408])          99.723907            100.355148           612.895086           3073.518629         
model.layers.21.mlp.experts.17.down_proj      torch.Size([0, 2048])          88.540321            89.365721            621.777297           3118.339459         
model.layers.21.mlp.experts.18.gate_proj      torch.Size([0, 1408])          87.783775            88.387012            621.602743           3237.414857         
model.layers.21.mlp.experts.18.act_fn         torch.Size([0, 1408])          0.514144             1.313448             621.568000           3263.232000         
model.layers.21.mlp.experts.18.up_proj        torch.Size([0, 1408])          106.067520           106.575012           619.222962           3319.750351         
model.layers.21.mlp.experts.18.down_proj      torch.Size([0, 2048])          96.677315            97.184658            621.591273           3216.505734         
model.layers.21.mlp.experts.19.gate_proj      torch.Size([0, 1408])          89.487198            89.936018            621.781035           3102.406713         
model.layers.21.mlp.experts.19.act_fn         torch.Size([0, 1408])          0.614816             1.358509             621.824000           3107.840000         
model.layers.21.mlp.experts.19.up_proj        torch.Size([0, 1408])          96.767296            97.291708            621.649127           3141.763606         
model.layers.21.mlp.experts.19.down_proj      torch.Size([0, 2048])          91.482819            91.898918            621.492364           3516.426182         
model.layers.21.mlp.experts.20.gate_proj      torch.Size([0, 1408])          105.341537           105.932713           591.788408           3943.773170         
model.layers.21.mlp.experts.20.act_fn         torch.Size([0, 1408])          0.588320             1.361609             621.568000           3727.872000         
model.layers.21.mlp.experts.20.up_proj        torch.Size([0, 1408])          92.475937            93.093157            611.359766           3411.755445         
model.layers.21.mlp.experts.20.down_proj      torch.Size([0, 2048])          100.891327           101.279497           621.653333           3162.724030         
model.layers.21.mlp.experts.21.gate_proj      torch.Size([0, 1408])          137.278458           137.911081           621.676169           3096.896901         
model.layers.21.mlp.experts.21.act_fn         torch.Size([0, 1408])          0.473408             1.122952             621.568000           3107.840000         
model.layers.21.mlp.experts.21.up_proj        torch.Size([0, 1408])          100.023262           100.416899           621.689460           3186.668380         
model.layers.21.mlp.experts.21.down_proj      torch.Size([0, 2048])          93.585312            94.075203            621.674985           3224.618030         
model.layers.21.mlp.experts.22.gate_proj      torch.Size([0, 1408])          104.046974           104.546070           621.680000           3209.168889         
model.layers.21.mlp.experts.22.act_fn         torch.Size([0, 1408])          0.627072             1.447439             621.568000           3263.232000         
model.layers.21.mlp.experts.22.up_proj        torch.Size([0, 1408])          106.206207           106.806278           621.696000           3163.953778         
model.layers.21.mlp.experts.22.down_proj      torch.Size([0, 2048])          109.848801           110.567093           621.738667           3076.894865         
model.layers.21.mlp.experts.23.gate_proj      torch.Size([0, 1408])          99.540192            100.944996           621.760000           3073.238400         
model.layers.21.mlp.experts.23.act_fn         torch.Size([0, 1408])          0.005664             1.293182             621.568000           3676.096000         
model.layers.21.mlp.experts.23.up_proj        torch.Size([0, 1408])          87.733826            89.140892            621.734307           3282.176467         
model.layers.21.mlp.experts.23.down_proj      torch.Size([0, 2048])          101.097763           102.756977           621.566016           3480.147349         
model.layers.21.mlp.experts.24.gate_proj      torch.Size([0, 1408])          99.675331            101.415396           573.961412           3832.864753         
model.layers.21.mlp.experts.24.act_fn         torch.Size([0, 1408])          0.005664             1.385927             621.568000           3572.544000         
model.layers.21.mlp.experts.24.up_proj        torch.Size([0, 1408])          96.803551            98.314047            567.366713           3297.675189         
model.layers.21.mlp.experts.24.down_proj      torch.Size([0, 2048])          90.108803            91.758251            621.742873           3172.193352         
model.layers.21.mlp.experts.25.gate_proj      torch.Size([0, 1408])          90.484032            91.848850            621.581373           3313.868896         
model.layers.21.mlp.experts.25.act_fn         torch.Size([0, 1408])          0.005440             1.535654             621.568000           3417.216000         
model.layers.21.mlp.experts.25.up_proj        torch.Size([0, 1408])          83.578781            85.079193            621.747556           3239.374222         
model.layers.21.mlp.experts.25.down_proj      torch.Size([0, 2048])          82.758301            84.058046            621.772444           3141.272889         
model.layers.21.mlp.experts.26.gate_proj      torch.Size([1, 1408])          102.403969           103.900671           621.629134           3136.725970         
model.layers.21.mlp.experts.26.act_fn         torch.Size([1, 1408])          0.056160             1.404285             621.568000           3378.384000         
model.layers.21.mlp.experts.26.up_proj        torch.Size([1, 1408])          87.135651            88.488340            621.568000           3249.305043         
model.layers.21.mlp.experts.26.down_proj      torch.Size([1, 2048])          85.359100            86.006165            621.568000           3293.768272         
model.layers.21.mlp.experts.27.gate_proj      torch.Size([1, 1408])          82.155487            83.127022            621.605926           3234.757689         
model.layers.21.mlp.experts.27.act_fn         torch.Size([1, 1408])          0.648704             1.394272             621.568000           3261.888000         
model.layers.21.mlp.experts.27.up_proj        torch.Size([1, 1408])          100.293022           101.060867           621.593430           3156.198146         
model.layers.21.mlp.experts.27.down_proj      torch.Size([1, 2048])          94.137634            94.849825            621.502711           3398.633235         
model.layers.21.mlp.experts.28.gate_proj      torch.Size([0, 1408])          120.991646           121.618748           621.448101           3740.184709         
model.layers.21.mlp.experts.28.act_fn         torch.Size([0, 1408])          1.206880             1.913548             621.568000           3417.216000         
model.layers.21.mlp.experts.28.up_proj        torch.Size([0, 1408])          142.767426           143.329620           613.976168           3358.102378         
model.layers.21.mlp.experts.28.down_proj      torch.Size([0, 2048])          140.349152           140.911341           621.636638           3287.448116         
model.layers.21.mlp.experts.29.gate_proj      torch.Size([0, 1408])          151.261658           151.650906           621.648350           3187.237372         
model.layers.21.mlp.experts.29.act_fn         torch.Size([0, 1408])          0.356544             0.748396             621.568000           3263.232000         
model.layers.21.mlp.experts.29.up_proj        torch.Size([0, 1408])          150.525696           150.885344           621.643511           3182.741180         
model.layers.21.mlp.experts.29.down_proj      torch.Size([0, 2048])          139.812775           140.191555           621.660086           3157.028835         
model.layers.21.mlp.experts.30.gate_proj      torch.Size([2, 1408])          140.947205           141.964674           621.679059           3173.544941         
model.layers.21.mlp.experts.30.act_fn         torch.Size([2, 1408])          0.688864             1.417398             621.568000           3261.888000         
model.layers.21.mlp.experts.30.up_proj        torch.Size([2, 1408])          131.473053           132.167816           621.658245           3251.324317         
model.layers.21.mlp.experts.30.down_proj      torch.Size([2, 2048])          136.431015           137.129307           621.568000           3273.316507         
model.layers.21.mlp.experts.31.gate_proj      torch.Size([1, 1408])          140.250885           140.774727           621.625287           3189.672280         
model.layers.21.mlp.experts.31.act_fn         torch.Size([1, 1408])          0.463072             0.919342             621.568000           3261.888000         
model.layers.21.mlp.experts.31.up_proj        torch.Size([1, 1408])          143.287521           143.740892           621.687830           3105.113872         
model.layers.21.mlp.experts.31.down_proj      torch.Size([1, 2048])          135.154297           135.643959           621.536914           3432.880914         
model.layers.21.mlp.experts.32.gate_proj      torch.Size([1, 1408])          148.135880           148.756981           621.325213           4055.186581         
model.layers.21.mlp.experts.32.act_fn         torch.Size([1, 1408])          0.647360             1.353979             621.312000           3882.240000         
model.layers.21.mlp.experts.32.up_proj        torch.Size([1, 1408])          127.802399           128.384590           621.552219           3465.080110         
model.layers.21.mlp.experts.32.down_proj      torch.Size([1, 2048])          131.190430           131.686449           621.568000           3210.723265         
model.layers.21.mlp.experts.33.gate_proj      torch.Size([1, 1408])          129.236771           129.776239           621.695092           3076.457305         
model.layers.21.mlp.experts.33.act_fn         torch.Size([1, 1408])          0.435584             0.936985             621.568000           3230.822400         
model.layers.21.mlp.experts.33.up_proj        torch.Size([1, 1408])          137.132034           137.622118           621.713297           3137.875459         
model.layers.21.mlp.experts.33.down_proj      torch.Size([1, 2048])          135.269348           135.770082           621.707476           3209.140524         
model.layers.21.mlp.experts.34.gate_proj      torch.Size([0, 1408])          147.586853           148.041487           621.701333           3274.809778         
model.layers.21.mlp.experts.34.act_fn         torch.Size([0, 1408])          0.577664             1.365423             621.568000           3263.232000         
model.layers.21.mlp.experts.34.up_proj        torch.Size([0, 1408])          137.387100           137.980700           621.736229           3163.308343         
model.layers.21.mlp.experts.34.down_proj      torch.Size([0, 2048])          145.972549           146.441936           621.760901           3151.562817         
model.layers.21.mlp.experts.35.gate_proj      torch.Size([1, 1408])          128.142044           128.806353           621.759565           3084.499156         
model.layers.21.mlp.experts.35.act_fn         torch.Size([1, 1408])          0.416032             0.928879             621.568000           3533.712000         
model.layers.21.mlp.experts.35.up_proj        torch.Size([1, 1408])          78.880478            79.463482            621.568000           3294.272000         
model.layers.21.mlp.experts.35.down_proj      torch.Size([1, 2048])          78.879555            79.509974            621.473600           3631.368400         
model.layers.21.mlp.experts.36.gate_proj      torch.Size([1, 1408])          87.945854            88.700056            621.505600           3664.581600         
model.layers.21.mlp.experts.36.act_fn         torch.Size([1, 1408])          0.733088             1.531601             621.568000           3417.216000         
model.layers.21.mlp.experts.36.up_proj        torch.Size([1, 1408])          81.449120            82.104206            621.644626           3223.683918         
model.layers.21.mlp.experts.36.down_proj      torch.Size([1, 2048])          80.718399            81.324100            621.619200           3156.802648         
model.layers.21.mlp.experts.37.gate_proj      torch.Size([0, 1408])          89.590721            90.197802            621.643917           3237.137655         
model.layers.21.mlp.experts.37.act_fn         torch.Size([0, 1408])          0.599392             1.449585             621.568000           3417.216000         
model.layers.21.mlp.experts.37.up_proj        torch.Size([0, 1408])          90.392960            91.059923            621.584516           3275.294968         
model.layers.21.mlp.experts.37.down_proj      torch.Size([0, 2048])          86.649597            87.309599            621.523153           3140.641168         
model.layers.21.mlp.experts.38.gate_proj      torch.Size([1, 1408])          87.437309            88.260174            621.568000           3118.442353         
model.layers.21.mlp.experts.38.act_fn         torch.Size([1, 1408])          0.739936             1.568079             621.568000           3137.625600         
model.layers.21.mlp.experts.38.up_proj        torch.Size([1, 1408])          87.354652            88.150740            621.568000           3176.096681         
model.layers.21.mlp.experts.38.down_proj      torch.Size([1, 2048])          85.739677            86.640120            621.589943           3208.935314         
model.layers.21.mlp.experts.39.gate_proj      torch.Size([0, 1408])          88.624893            89.401960            621.580000           3275.465500         
model.layers.21.mlp.experts.39.act_fn         torch.Size([0, 1408])          0.488576             0.964880             621.568000           3261.888000         
model.layers.21.mlp.experts.39.up_proj        torch.Size([0, 1408])          83.831421            84.364653            621.568000           3243.273710         
model.layers.21.mlp.experts.39.down_proj      torch.Size([0, 2048])          79.845505            80.436468            601.377151           3503.192863         
model.layers.21.mlp.experts.40.gate_proj      torch.Size([0, 1408])          80.715843            81.340551            588.920216           3737.923892         
model.layers.21.mlp.experts.40.act_fn         torch.Size([0, 1408])          0.005472             1.346588             621.568000           3261.888000         
model.layers.21.mlp.experts.40.up_proj        torch.Size([0, 1408])          86.343521            86.993217            610.149176           3339.959059         
model.layers.21.mlp.experts.40.down_proj      torch.Size([0, 2048])          83.541634            84.285259            621.605647           3291.035294         
model.layers.21.mlp.experts.41.gate_proj      torch.Size([0, 1408])          84.181824            84.600210            621.609175           3275.335161         
model.layers.21.mlp.experts.41.act_fn         torch.Size([0, 1408])          0.621216             1.341105             621.568000           3417.216000         
model.layers.21.mlp.experts.41.up_proj        torch.Size([0, 1408])          82.310272            82.884312            618.286171           3233.670857         
model.layers.21.mlp.experts.41.down_proj      torch.Size([0, 2048])          81.134109            81.676006            621.655149           3097.921362         
model.layers.21.mlp.experts.42.gate_proj      torch.Size([1, 1408])          81.172356            81.742525            621.659944           3173.982648         
model.layers.21.mlp.experts.42.act_fn         torch.Size([1, 1408])          0.781216             1.435995             621.568000           3261.888000         
model.layers.21.mlp.experts.42.up_proj        torch.Size([1, 1408])          86.809021            87.516069            621.610667           3270.323014         
model.layers.21.mlp.experts.42.down_proj      torch.Size([1, 2048])          86.115677            86.774588            621.568000           3238.333296         
model.layers.21.mlp.experts.43.gate_proj      torch.Size([0, 1408])          91.522911            92.014074            621.684029           3115.051281         
model.layers.21.mlp.experts.43.act_fn         torch.Size([0, 1408])          0.434368             1.063585             621.568000           3261.888000         
model.layers.21.mlp.experts.43.up_proj        torch.Size([0, 1408])          72.731232            73.185444            621.712119           3095.983407         
model.layers.21.mlp.experts.43.down_proj      torch.Size([0, 2048])          103.018593           103.393793           592.031099           3419.755718         
model.layers.21.mlp.experts.44.gate_proj      torch.Size([0, 1408])          107.809891           108.380318           578.389827           3760.081757         
model.layers.21.mlp.experts.44.act_fn         torch.Size([0, 1408])          0.441152             0.984430             621.568000           3572.544000         
model.layers.21.mlp.experts.44.up_proj        torch.Size([0, 1408])          86.404449            86.913824            561.003836           3281.779726         
model.layers.21.mlp.experts.44.down_proj      torch.Size([0, 2048])          87.522430            87.910175            621.712119           3138.566637         
model.layers.21.mlp.experts.45.gate_proj      torch.Size([0, 1408])          94.715393            95.376015            613.187556           2936.525778         
model.layers.21.mlp.experts.45.act_fn         torch.Size([0, 1408])          0.815488             1.550436             621.568000           3107.840000         
model.layers.21.mlp.experts.45.up_proj        torch.Size([0, 1408])          83.410973            84.229231            602.481116           3097.970605         
model.layers.21.mlp.experts.45.down_proj      torch.Size([0, 2048])          103.374977           104.930401           621.736229           3112.219429         
model.layers.21.mlp.experts.46.gate_proj      torch.Size([0, 1408])          89.961060            90.590477            621.691396           3231.717295         
model.layers.21.mlp.experts.46.act_fn         torch.Size([0, 1408])          0.965664             1.813173             621.568000           3418.624000         
model.layers.21.mlp.experts.46.up_proj        torch.Size([0, 1408])          85.891235            86.569786            612.760116           3129.234551         
model.layers.21.mlp.experts.46.down_proj      torch.Size([0, 2048])          84.847328            85.355282            621.795343           3046.378985         
model.layers.21.mlp.experts.47.gate_proj      torch.Size([1, 1408])          82.962593            83.398342            621.784483           3028.579651         
model.layers.21.mlp.experts.47.act_fn         torch.Size([1, 1408])          0.427872             0.932932             621.568000           3107.840000         
model.layers.21.mlp.experts.47.up_proj        torch.Size([1, 1408])          90.611748            91.108561            621.568000           3291.057829         
model.layers.21.mlp.experts.47.down_proj      torch.Size([1, 2048])          97.694527            98.164797            621.406222           3764.768000         
model.layers.21.mlp.experts.48.gate_proj      torch.Size([0, 1408])          87.080383            87.538242            621.439141           3760.757262         
model.layers.21.mlp.experts.48.act_fn         torch.Size([0, 1408])          0.552224             1.276255             621.568000           3417.216000         
model.layers.21.mlp.experts.48.up_proj        torch.Size([0, 1408])          60.306686            60.882092            612.591182           3200.411095         
model.layers.21.mlp.experts.48.down_proj      torch.Size([0, 2048])          76.439362            77.059984            621.663299           3125.987971         
model.layers.21.mlp.experts.49.gate_proj      torch.Size([0, 1408])          47.990719            48.562765            621.691396           3157.964892         
model.layers.21.mlp.experts.49.act_fn         torch.Size([0, 1408])          0.005600             1.421213             621.824000           3107.840000         
model.layers.21.mlp.experts.49.up_proj        torch.Size([0, 1408])          90.488991            90.965033            603.715446           3223.358031         
model.layers.21.mlp.experts.49.down_proj      torch.Size([0, 2048])          98.798973            99.372387            621.655230           3158.486281         
model.layers.21.mlp.experts.50.gate_proj      torch.Size([0, 1408])          97.752289            98.402023            621.732978           3100.933689         
model.layers.21.mlp.experts.50.act_fn         torch.Size([0, 1408])          0.354272             0.779629             621.653333           3107.840000         
model.layers.21.mlp.experts.50.up_proj        torch.Size([0, 1408])          91.992828            92.478275            606.256113           3089.104794         
model.layers.21.mlp.experts.50.down_proj      torch.Size([0, 2048])          93.580765            94.075203            621.708146           3165.141956         
model.layers.21.mlp.experts.51.gate_proj      torch.Size([1, 1408])          73.807648            74.365139            621.683200           3181.703771         
model.layers.21.mlp.experts.51.act_fn         torch.Size([1, 1408])          0.526336             1.080275             621.568000           3417.216000         
model.layers.21.mlp.experts.51.up_proj        torch.Size([1, 1408])          79.699997            80.402851            621.596444           3285.194222         
model.layers.21.mlp.experts.51.down_proj      torch.Size([1, 2048])          97.524323            98.132133            621.530453           3577.579093         
model.layers.21.mlp.experts.52.gate_proj      torch.Size([0, 1408])          87.505600            88.027000            621.458538           3763.922538         
model.layers.21.mlp.experts.52.act_fn         torch.Size([0, 1408])          0.358912             0.741720             621.568000           3572.544000         
model.layers.21.mlp.experts.52.up_proj        torch.Size([0, 1408])          88.698975            89.140892            608.105739           3341.323130         
model.layers.21.mlp.experts.52.down_proj      torch.Size([0, 2048])          88.034592            88.809013            621.697855           3238.100406         
model.layers.21.mlp.experts.53.gate_proj      torch.Size([2, 1408])          90.136482            91.152668            619.560607           3200.630731         
model.layers.21.mlp.experts.53.act_fn         torch.Size([2, 1408])          0.667520             1.412392             621.568000           3417.216000         
model.layers.21.mlp.experts.53.up_proj        torch.Size([2, 1408])          74.073891            74.821472            621.690353           3205.584000         
model.layers.21.mlp.experts.53.down_proj      torch.Size([2, 2048])          90.580574            91.391325            621.715064           3067.822298         
model.layers.21.mlp.experts.54.gate_proj      torch.Size([1, 1408])          100.875137           101.651907           621.740883           2907.959273         
model.layers.21.mlp.experts.54.act_fn         torch.Size([1, 1408])          0.669472             1.449347             621.568000           3417.216000         
model.layers.21.mlp.experts.54.up_proj        torch.Size([1, 1408])          95.471008            96.045971            621.716303           3100.100414         
model.layers.21.mlp.experts.54.down_proj      torch.Size([1, 2048])          82.282173            82.738400            621.706521           3194.617425         
model.layers.21.mlp.experts.55.gate_proj      torch.Size([1, 1408])          87.760513            88.294506            621.699556           3138.850222         
model.layers.21.mlp.experts.55.act_fn         torch.Size([1, 1408])          0.426592             0.837564             621.568000           3292.953600         
model.layers.21.mlp.experts.55.up_proj        torch.Size([1, 1408])          86.476387            87.049961            621.605333           3142.046222         
model.layers.21.mlp.experts.55.down_proj      torch.Size([1, 2048])          89.318817            90.146065            621.502676           3500.597407         
model.layers.21.mlp.experts.56.gate_proj      torch.Size([0, 1408])          90.518883            91.327429            621.459242           3772.203503         
model.layers.21.mlp.experts.56.act_fn         torch.Size([0, 1408])          0.567104             1.387835             621.568000           3520.768000         
model.layers.21.mlp.experts.56.up_proj        torch.Size([0, 1408])          86.555168            87.160826            615.887059           3337.844706         
model.layers.21.mlp.experts.56.down_proj      torch.Size([0, 2048])          70.943199            71.354389            621.778097           3120.641766         
model.layers.21.mlp.experts.57.gate_proj      torch.Size([0, 1408])          91.466591            92.042923            621.770667           3092.300800         
model.layers.21.mlp.experts.57.act_fn         torch.Size([0, 1408])          0.633696             1.438618             621.824000           3056.042667         
model.layers.21.mlp.experts.57.up_proj        torch.Size([0, 1408])          86.065536            86.672544            609.539500           3157.614000         
model.layers.21.mlp.experts.57.down_proj      torch.Size([0, 2048])          88.601692            89.254618            621.646482           3186.907095         
model.layers.21.mlp.experts.58.gate_proj      torch.Size([0, 1408])          90.361923            90.956926            621.672642           3214.043562         
model.layers.21.mlp.experts.58.act_fn         torch.Size([0, 1408])          0.425792             0.802040             621.568000           3263.232000         
model.layers.21.mlp.experts.58.up_proj        torch.Size([0, 1408])          96.029633            96.405268            621.639218           3180.278376         
model.layers.21.mlp.experts.58.down_proj      torch.Size([0, 2048])          93.610596            94.176292            621.668571           3106.730057         
model.layers.21.mlp.experts.59.gate_proj      torch.Size([0, 1408])          89.411232            89.856148            621.718588           3071.277176         
model.layers.21.mlp.experts.59.act_fn         torch.Size([0, 1408])          0.424032             0.885248             621.568000           3107.840000         
model.layers.21.mlp.experts.59.up_proj        torch.Size([0, 1408])          66.153152            66.594124            618.198135           3196.088782         
model.layers.21.mlp.experts.59.down_proj      torch.Size([0, 2048])          90.241600            90.636730            590.914254           3480.874366         
model.layers.21.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          335.172089           335.570335           635.849560           3116.659651         
model.layers.21.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.560416             1.115084             776.960000           3003.008000         
model.layers.21.mlp.shared_expert.up_proj     torch.Size([5, 5632])          349.342194           349.806786           697.167068           3008.394856         
model.layers.21.mlp.shared_expert.down_proj   torch.Size([5, 2048])          340.714630           341.485023           707.418240           3058.994880         
model.layers.21.mlp.shared_expert_gate        torch.Size([5, 1])             13.037888            14.805555            685.165091           3251.972364         
model.layers.22.input_layernorm               torch.Size([1, 5, 2048])       11.842656            13.316870            527.301020           3327.467922         
model.layers.22.self_attn.q_proj              torch.Size([1, 5, 2048])       129.437180           130.945683           581.964800           3224.230044         
model.layers.22.self_attn.k_proj              torch.Size([1, 5, 2048])       105.367683           105.864763           617.101474           3580.010565         
model.layers.22.self_attn.v_proj              torch.Size([1, 5, 2048])       138.669189           140.599728           621.570753           3345.095570         
model.layers.22.self_attn.o_proj              torch.Size([1, 5, 2048])       123.879997           124.391556           621.630877           3211.713123         
model.layers.22.post_attention_layernorm      torch.Size([1, 5, 2048])       12.171456            12.596130            596.838400           3250.444800         
model.layers.22.mlp.gate                      torch.Size([5, 60])            11.011072            12.523890            466.368000           3241.553920         
model.layers.22.mlp.experts.0.gate_proj       torch.Size([0, 1408])          90.022751            90.411186            548.139141           3104.834844         
model.layers.22.mlp.experts.0.act_fn          torch.Size([0, 1408])          0.005728             1.555443             621.824000           3107.840000         
model.layers.22.mlp.experts.0.up_proj         torch.Size([0, 1408])          85.028290            86.728334            621.686725           3111.218087         
model.layers.22.mlp.experts.0.down_proj       torch.Size([0, 2048])          77.097885            78.492403            621.698803           3168.597022         
model.layers.22.mlp.experts.1.gate_proj       torch.Size([0, 1408])          94.515457            95.948696            621.686448           3236.033910         
model.layers.22.mlp.experts.1.act_fn          torch.Size([0, 1408])          0.005728             1.790524             621.568000           3417.216000         
model.layers.22.mlp.experts.1.up_proj         torch.Size([0, 1408])          94.901917            96.662998            615.894281           3250.322489         
model.layers.22.mlp.experts.1.down_proj       torch.Size([0, 2048])          103.622238           105.352879           621.720427           3088.840305         
model.layers.22.mlp.experts.2.gate_proj       torch.Size([0, 1408])          94.123390            95.683336            621.711883           3194.730044         
model.layers.22.mlp.experts.2.act_fn          torch.Size([0, 1408])          0.005408             1.523733             621.504000           3689.040000         
model.layers.22.mlp.experts.2.up_proj         torch.Size([0, 1408])          92.297188            93.882561            581.613949           3826.962462         
model.layers.22.mlp.experts.2.down_proj       torch.Size([0, 2048])          80.114883            81.665754            557.467733           3304.262827         
model.layers.22.mlp.experts.3.gate_proj       torch.Size([0, 1408])          98.039780            99.524021            611.567768           3219.162899         
model.layers.22.mlp.experts.3.act_fn          torch.Size([0, 1408])          0.011232             1.881838             621.653333           3418.624000         
model.layers.22.mlp.experts.3.up_proj         torch.Size([0, 1408])          106.173790           107.783318           603.316148           3198.773096         
model.layers.22.mlp.experts.3.down_proj       torch.Size([0, 2048])          96.685150            98.374128            621.758118           3065.564235         
model.layers.22.mlp.experts.4.gate_proj       torch.Size([1, 1408])          108.200096           108.845472           621.758270           3065.700324         
model.layers.22.mlp.experts.4.act_fn          torch.Size([1, 1408])          0.700640             1.413107             621.568000           3572.544000         
model.layers.22.mlp.experts.4.up_proj         torch.Size([1, 1408])          96.001022            96.774817            621.740408           3204.785197         
model.layers.22.mlp.experts.4.down_proj       torch.Size([1, 2048])          102.629761           103.243828           621.568000           3262.146370         
model.layers.22.mlp.experts.5.gate_proj       torch.Size([0, 1408])          93.080444            93.532801            621.618503           3175.240707         
model.layers.22.mlp.experts.5.act_fn          torch.Size([0, 1408])          0.005472             1.424789             621.568000           3263.232000         
model.layers.22.mlp.experts.5.up_proj         torch.Size([0, 1408])          96.801636            97.565651            611.867042           3152.706704         
model.layers.22.mlp.experts.5.down_proj       torch.Size([0, 2048])          92.629150            93.196392            621.731914           3125.726849         
model.layers.22.mlp.experts.6.gate_proj       torch.Size([0, 1408])          81.291359            82.012415            621.648239           3366.608239         
model.layers.22.mlp.experts.6.act_fn          torch.Size([0, 1408])          0.439040             0.906706             621.568000           3572.544000         
model.layers.22.mlp.experts.6.up_proj         torch.Size([0, 1408])          77.134460            77.547789            580.430222           3854.585778         
model.layers.22.mlp.experts.6.down_proj       torch.Size([0, 2048])          172.258972           172.703981           621.575367           3341.752173         
model.layers.22.mlp.experts.7.gate_proj       torch.Size([0, 1408])          179.959839           180.660486           621.657893           3118.515786         
model.layers.22.mlp.experts.7.act_fn          torch.Size([0, 1408])          0.389792             0.862360             621.568000           3159.637333         
model.layers.22.mlp.experts.7.up_proj         torch.Size([0, 1408])          169.510117           169.928074           621.690711           3132.240397         
model.layers.22.mlp.experts.7.down_proj       torch.Size([0, 2048])          151.215515           151.802301           621.706000           3162.124500         
model.layers.22.mlp.experts.8.gate_proj       torch.Size([0, 1408])          125.437920           126.089811           621.669254           3216.368716         
model.layers.22.mlp.experts.8.act_fn          torch.Size([0, 1408])          0.371744             0.779390             621.568000           3417.216000         
model.layers.22.mlp.experts.8.up_proj         torch.Size([0, 1408])          146.495483           146.929502           615.989255           3235.876905         
model.layers.22.mlp.experts.8.down_proj       torch.Size([0, 2048])          164.314621           164.803743           621.712361           3118.355248         
model.layers.22.mlp.experts.9.gate_proj       torch.Size([0, 1408])          167.283203           167.762756           621.744676           3079.387944         
model.layers.22.mlp.experts.9.act_fn          torch.Size([0, 1408])          0.432992             1.008272             621.568000           3263.232000         
model.layers.22.mlp.experts.9.up_proj         torch.Size([0, 1408])          147.609024           147.999763           621.760481           3109.916872         
model.layers.22.mlp.experts.9.down_proj       torch.Size([0, 2048])          178.486877           179.008484           621.731081           3187.022696         
model.layers.22.mlp.experts.10.gate_proj      torch.Size([0, 1408])          140.858597           141.367674           621.568000           3330.910365         
model.layers.22.mlp.experts.10.act_fn         torch.Size([0, 1408])          0.676096             1.516104             621.568000           3727.872000         
model.layers.22.mlp.experts.10.up_proj        torch.Size([0, 1408])          146.849762           147.439718           582.942497           3790.362201         
model.layers.22.mlp.experts.10.down_proj      torch.Size([0, 2048])          162.874878           163.489580           573.740247           3353.144099         
model.layers.22.mlp.experts.11.gate_proj      torch.Size([2, 1408])          149.730759           150.316715           604.494222           3093.826667         
model.layers.22.mlp.experts.11.act_fn         torch.Size([2, 1408])          0.477024             0.934839             621.568000           3417.216000         
model.layers.22.mlp.experts.11.up_proj        torch.Size([2, 1408])          145.485794           145.985603           621.694247           3231.980712         
model.layers.22.mlp.experts.11.down_proj      torch.Size([2, 2048])          122.697342           123.368025           621.688055           3271.325572         
model.layers.22.mlp.experts.12.gate_proj      torch.Size([0, 1408])          113.188545           113.802671           621.757762           3093.638266         
model.layers.22.mlp.experts.12.act_fn         torch.Size([0, 1408])          0.558688             1.571417             621.568000           3263.232000         
model.layers.22.mlp.experts.12.up_proj        torch.Size([0, 1408])          179.529861           180.140495           621.774979           3105.615887         
model.layers.22.mlp.experts.12.down_proj      torch.Size([0, 2048])          102.047234           102.543831           621.783111           3089.475556         
model.layers.22.mlp.experts.13.gate_proj      torch.Size([0, 1408])          95.002113            95.665932            621.641143           3214.210743         
model.layers.22.mlp.experts.13.act_fn         torch.Size([0, 1408])          0.321152             0.750780             621.653333           3211.434667         
model.layers.22.mlp.experts.13.up_proj        torch.Size([0, 1408])          92.587135            93.016386            621.590000           3308.889500         
model.layers.22.mlp.experts.13.down_proj      torch.Size([0, 2048])          99.382812            99.956036            621.630619           3201.745957         
model.layers.22.mlp.experts.14.gate_proj      torch.Size([1, 1408])          99.847038            100.383759           621.643189           3232.013874         
model.layers.22.mlp.experts.14.act_fn         torch.Size([1, 1408])          0.399328             0.813246             621.568000           3417.216000         
model.layers.22.mlp.experts.14.up_proj        torch.Size([1, 1408])          90.715424            91.147184            621.460800           3691.755200         
model.layers.22.mlp.experts.14.down_proj      torch.Size([1, 2048])          87.990402            88.592291            621.568000           3418.435343         
model.layers.22.mlp.experts.15.gate_proj      torch.Size([0, 1408])          102.829887           103.406906           621.593023           3331.330887         
model.layers.22.mlp.experts.15.act_fn         torch.Size([0, 1408])          0.587392             1.305342             621.568000           3263.232000         
model.layers.22.mlp.experts.15.up_proj        torch.Size([0, 1408])          98.698883            99.341631            621.684524           3208.576883         
model.layers.22.mlp.experts.15.down_proj      torch.Size([0, 2048])          98.087517            98.649979            621.728701           3095.363270         
model.layers.22.mlp.experts.16.gate_proj      torch.Size([0, 1408])          98.771362            99.415302            621.723748           3076.326937         
model.layers.22.mlp.experts.16.act_fn         torch.Size([0, 1408])          0.438944             1.010418             621.824000           3107.840000         
model.layers.22.mlp.experts.16.up_proj        torch.Size([0, 1408])          85.741150            86.247444            612.420776           3179.254448         
model.layers.22.mlp.experts.16.down_proj      torch.Size([0, 2048])          81.932800            82.574606            621.696000           3180.411224         
model.layers.22.mlp.experts.17.gate_proj      torch.Size([1, 1408])          90.083549            90.813637            621.674667           3210.838222         
model.layers.22.mlp.experts.17.act_fn         torch.Size([1, 1408])          0.740640             1.381159             621.568000           3261.888000         
model.layers.22.mlp.experts.17.up_proj        torch.Size([1, 1408])          95.406143            96.087217            621.707130           3160.310725         
model.layers.22.mlp.experts.17.down_proj      torch.Size([1, 2048])          84.727203            85.431337            621.741122           3019.223942         
model.layers.22.mlp.experts.18.gate_proj      torch.Size([0, 1408])          88.539902            89.059353            621.691115           3170.193588         
model.layers.22.mlp.experts.18.act_fn         torch.Size([0, 1408])          0.005728             1.252890             621.312000           4036.864000         
model.layers.22.mlp.experts.18.up_proj        torch.Size([0, 1408])          85.174751            85.710526            578.792575           3984.153098         
model.layers.22.mlp.experts.18.down_proj      torch.Size([0, 2048])          90.000511            90.434074            621.654561           3452.775137         
model.layers.22.mlp.experts.19.gate_proj      torch.Size([0, 1408])          102.547394           103.262424           621.748706           3066.706824         
model.layers.22.mlp.experts.19.act_fn         torch.Size([0, 1408])          0.451744             0.943184             621.568000           3263.232000         
model.layers.22.mlp.experts.19.up_proj        torch.Size([0, 1408])          73.092445            73.482752            621.761016           3181.836190         
model.layers.22.mlp.experts.19.down_proj      torch.Size([0, 2048])          81.657181            82.493782            621.776000           3052.793333         
model.layers.22.mlp.experts.20.gate_proj      torch.Size([0, 1408])          65.682243            66.356421            621.769269           3120.547752         
model.layers.22.mlp.experts.20.act_fn         torch.Size([0, 1408])          0.338304             0.716686             621.568000           3418.624000         
model.layers.22.mlp.experts.20.up_proj        torch.Size([0, 1408])          79.397949            79.837799            621.687591           3228.070307         
model.layers.22.mlp.experts.20.down_proj      torch.Size([0, 2048])          75.667229            77.077627            621.620245           3199.806694         
model.layers.22.mlp.experts.21.gate_proj      torch.Size([1, 1408])          99.437027            100.080252           621.581080           3127.122219         
model.layers.22.mlp.experts.21.act_fn         torch.Size([1, 1408])          0.797536             1.525402             621.568000           3107.840000         
model.layers.22.mlp.experts.21.up_proj        torch.Size([1, 1408])          84.822144            85.474968            621.623497           3108.926657         
model.layers.22.mlp.experts.21.down_proj      torch.Size([1, 2048])          91.461922            91.946125            621.628000           3188.319500         
model.layers.22.mlp.experts.22.gate_proj      torch.Size([0, 1408])          99.465858            100.037813           621.519145           3419.942107         
model.layers.22.mlp.experts.22.act_fn         torch.Size([0, 1408])          0.618912             1.551867             621.312000           3727.872000         
model.layers.22.mlp.experts.22.up_proj        torch.Size([0, 1408])          89.452606            90.076923            581.571692           3878.597744         
model.layers.22.mlp.experts.22.down_proj      torch.Size([0, 2048])          86.617889            87.280512            621.569790           3321.311776         
model.layers.22.mlp.experts.23.gate_proj      torch.Size([1, 1408])          95.944962            96.712589            621.664492           3105.449354         
model.layers.22.mlp.experts.23.act_fn         torch.Size([1, 1408])          0.718688             1.431704             621.568000           3107.840000         
model.layers.22.mlp.experts.23.up_proj        torch.Size([1, 1408])          92.979454            93.764305            621.648000           3255.164000         
model.layers.22.mlp.experts.23.down_proj      torch.Size([1, 2048])          85.257408            86.657047            621.568000           3294.958993         
model.layers.22.mlp.experts.24.gate_proj      torch.Size([0, 1408])          81.630783            82.014322            621.644255           3151.561078         
model.layers.22.mlp.experts.24.act_fn         torch.Size([0, 1408])          0.463392             1.062393             621.568000           3224.384000         
model.layers.22.mlp.experts.24.up_proj        torch.Size([0, 1408])          86.002625            86.479187            621.676169           3154.778141         
model.layers.22.mlp.experts.24.down_proj      torch.Size([0, 2048])          92.880989            93.565941            621.696000           3122.478377         
model.layers.22.mlp.experts.25.gate_proj      torch.Size([0, 1408])          101.311325           102.169514           621.726832           3138.077431         
model.layers.22.mlp.experts.25.act_fn         torch.Size([0, 1408])          0.496864             1.149416             621.568000           3417.216000         
model.layers.22.mlp.experts.25.up_proj        torch.Size([0, 1408])          87.609055            88.053226            621.726388           3182.554245         
model.layers.22.mlp.experts.25.down_proj      torch.Size([0, 2048])          90.372604            91.083527            621.721212           3241.921939         
model.layers.22.mlp.experts.26.gate_proj      torch.Size([0, 1408])          79.552605            80.176353            621.659847           3262.828458         
model.layers.22.mlp.experts.26.act_fn         torch.Size([0, 1408])          0.554912             1.303196             621.568000           3727.872000         
model.layers.22.mlp.experts.26.up_proj        torch.Size([0, 1408])          92.742813            93.314171            579.224816           3767.916408         
model.layers.22.mlp.experts.26.down_proj      torch.Size([0, 2048])          97.030754            97.730398            605.616390           3318.671220         
model.layers.22.mlp.experts.27.gate_proj      torch.Size([0, 1408])          94.538399            95.124245            591.593552           3164.629015         
model.layers.22.mlp.experts.27.act_fn         torch.Size([0, 1408])          0.441472             0.951767             621.568000           3572.544000         
model.layers.22.mlp.experts.27.up_proj        torch.Size([0, 1408])          90.318748            90.753317            609.173489           3292.394511         
model.layers.22.mlp.experts.27.down_proj      torch.Size([0, 2048])          80.530273            80.897570            621.759072           3218.109217         
model.layers.22.mlp.experts.28.gate_proj      torch.Size([3, 1408])          93.996864            94.752789            621.785600           3050.122971         
model.layers.22.mlp.experts.28.act_fn         torch.Size([3, 1408])          0.764224             1.535177             621.568000           3300.720000         
model.layers.22.mlp.experts.28.up_proj        torch.Size([3, 1408])          92.660767            93.522549            621.614703           3137.099676         
model.layers.22.mlp.experts.28.down_proj      torch.Size([3, 2048])          97.135742            97.774982            621.568000           3327.200000         
model.layers.22.mlp.experts.29.gate_proj      torch.Size([0, 1408])          96.067970            96.522570            621.568000           3300.712635         
model.layers.22.mlp.experts.29.act_fn         torch.Size([0, 1408])          0.626528             1.514435             621.568000           3211.434667         
model.layers.22.mlp.experts.29.up_proj        torch.Size([0, 1408])          87.209663            87.814093            621.624471           3192.391529         
model.layers.22.mlp.experts.29.down_proj      torch.Size([0, 2048])          100.737442           101.203442           621.665240           3127.113426         
model.layers.22.mlp.experts.30.gate_proj      torch.Size([0, 1408])          108.947586           109.538078           621.677147           3129.152000         
model.layers.22.mlp.experts.30.act_fn         torch.Size([0, 1408])          0.802240             1.876593             621.568000           3417.216000         
model.layers.22.mlp.experts.30.up_proj        torch.Size([0, 1408])          106.594627           107.280254           578.244662           3768.697219         
model.layers.22.mlp.experts.30.down_proj      torch.Size([0, 2048])          87.522209            88.094711            621.572031           3460.377701         
model.layers.22.mlp.experts.31.gate_proj      torch.Size([0, 1408])          85.961853            86.575270            621.650878           3143.613698         
model.layers.22.mlp.experts.31.act_fn         torch.Size([0, 1408])          0.351232             0.745296             621.653333           3107.840000         
model.layers.22.mlp.experts.31.up_proj        torch.Size([0, 1408])          96.890594            97.285032            621.673305           3151.922837         
model.layers.22.mlp.experts.31.down_proj      torch.Size([0, 2048])          96.900223            97.672701            621.690592           3099.085521         
model.layers.22.mlp.experts.32.gate_proj      torch.Size([0, 1408])          89.582718            90.212107            621.711284           3159.537672         
model.layers.22.mlp.experts.32.act_fn         torch.Size([0, 1408])          0.709888             1.493692             621.568000           3261.888000         
model.layers.22.mlp.experts.32.up_proj        torch.Size([0, 1408])          85.915459            86.575747            621.719704           3182.370607         
model.layers.22.mlp.experts.32.down_proj      torch.Size([0, 2048])          93.844353            94.461918            621.710015           3221.099445         
model.layers.22.mlp.experts.33.gate_proj      torch.Size([0, 1408])          89.597023            90.055704            621.739860           3138.236867         
model.layers.22.mlp.experts.33.act_fn         torch.Size([0, 1408])          0.560320             1.281738             621.568000           3263.232000         
model.layers.22.mlp.experts.33.up_proj        torch.Size([0, 1408])          99.761246            100.356102           621.760481           3058.896842         
model.layers.22.mlp.experts.33.down_proj      torch.Size([0, 2048])          91.200516            91.867447            621.789170           3044.335456         
model.layers.22.mlp.experts.34.gate_proj      torch.Size([0, 1408])          99.629921            100.271225           621.679389           3260.490748         
model.layers.22.mlp.experts.34.act_fn         torch.Size([0, 1408])          0.410080             1.005411             621.312000           3883.200000         
model.layers.22.mlp.experts.34.up_proj        torch.Size([0, 1408])          86.188286            86.722612            577.790158           4013.172489         
model.layers.22.mlp.experts.34.down_proj      torch.Size([0, 2048])          93.363297            93.760967            621.534609           3484.994783         
model.layers.22.mlp.experts.35.gate_proj      torch.Size([2, 1408])          91.054688            91.755867            621.568000           3167.129412         
model.layers.22.mlp.experts.35.act_fn         torch.Size([2, 1408])          0.624608             1.209259             621.568000           3261.888000         
model.layers.22.mlp.experts.35.up_proj        torch.Size([2, 1408])          59.685055            60.173750            621.568000           3160.220547         
model.layers.22.mlp.experts.35.down_proj      torch.Size([2, 2048])          106.266975           106.942892           621.565952           3302.012416         
model.layers.22.mlp.experts.36.gate_proj      torch.Size([1, 1408])          94.598877            95.468283            621.606957           3215.178667         
model.layers.22.mlp.experts.36.act_fn         torch.Size([1, 1408])          0.625504             1.453400             621.568000           3107.840000         
model.layers.22.mlp.experts.36.up_proj        torch.Size([1, 1408])          92.591072            93.367338            621.610000           3165.532000         
model.layers.22.mlp.experts.36.down_proj      torch.Size([1, 2048])          74.923904            75.647354            621.612201           3117.623252         
model.layers.22.mlp.experts.37.gate_proj      torch.Size([0, 1408])          90.923904            91.644526            621.731556           3058.200889         
model.layers.22.mlp.experts.37.act_fn         torch.Size([0, 1408])          0.005408             1.636744             621.824000           3107.840000         
model.layers.22.mlp.experts.37.up_proj        torch.Size([0, 1408])          94.673347            95.264435            621.660754           3182.993159         
model.layers.22.mlp.experts.37.down_proj      torch.Size([0, 2048])          86.663139            87.388039            621.667765           3229.436235         
model.layers.22.mlp.experts.38.gate_proj      torch.Size([0, 1408])          84.969276            85.492611            621.648457           3273.649829         
model.layers.22.mlp.experts.38.act_fn         torch.Size([0, 1408])          0.578944             1.137972             621.312000           3727.872000         
model.layers.22.mlp.experts.38.up_proj        torch.Size([0, 1408])          86.481697            87.032080            581.425820           3787.063569         
model.layers.22.mlp.experts.38.down_proj      torch.Size([0, 2048])          89.074013            89.547157            568.055523           3329.705960         
model.layers.22.mlp.experts.39.gate_proj      torch.Size([1, 1408])          94.574081            95.368385            621.672296           3206.098489         
model.layers.22.mlp.experts.39.act_fn         torch.Size([1, 1408])          0.625984             1.327038             621.568000           3261.888000         
model.layers.22.mlp.experts.39.up_proj        torch.Size([1, 1408])          89.127235            89.895010            621.644800           3291.335314         
model.layers.22.mlp.experts.39.down_proj      torch.Size([1, 2048])          105.095940           105.703354           621.643718           3218.739380         
model.layers.22.mlp.experts.40.gate_proj      torch.Size([0, 1408])          94.909508            95.555067            621.664464           3159.502841         
model.layers.22.mlp.experts.40.act_fn         torch.Size([0, 1408])          0.422208             0.872612             621.568000           3263.232000         
model.layers.22.mlp.experts.40.up_proj        torch.Size([0, 1408])          99.633789            100.215912           621.710629           3102.290286         
model.layers.22.mlp.experts.40.down_proj      torch.Size([0, 2048])          96.453217            97.052813            621.732571           3140.746514         
model.layers.22.mlp.experts.41.gate_proj      torch.Size([0, 1408])          93.147423            93.849897            621.728970           3202.912000         
model.layers.22.mlp.experts.41.act_fn         torch.Size([0, 1408])          0.359424             0.777006             621.568000           3727.872000         
model.layers.22.mlp.experts.41.up_proj        torch.Size([0, 1408])          101.766785           102.210283           621.715556           3266.223556         
model.layers.22.mlp.experts.41.down_proj      torch.Size([0, 2048])          93.194016            93.780279            621.753191           3163.936227         
model.layers.22.mlp.experts.42.gate_proj      torch.Size([1, 1408])          88.813438            89.531660            621.648559           3219.334266         
model.layers.22.mlp.experts.42.act_fn         torch.Size([1, 1408])          0.766336             1.652718             621.312000           3727.872000         
model.layers.22.mlp.experts.42.up_proj        torch.Size([1, 1408])          93.542305            94.342947            621.503147           3722.580907         
model.layers.22.mlp.experts.42.down_proj      torch.Size([1, 2048])          85.511230            86.143255            621.547886           3437.833600         
model.layers.22.mlp.experts.43.gate_proj      torch.Size([1, 1408])          94.745667            95.386744            621.688889           3276.629778         
model.layers.22.mlp.experts.43.act_fn         torch.Size([1, 1408])          0.562880             1.079798             621.568000           3339.552000         
model.layers.22.mlp.experts.43.up_proj        torch.Size([1, 1408])          87.117409            87.736845            621.668252           3166.277371         
model.layers.22.mlp.experts.43.down_proj      torch.Size([1, 2048])          94.419678            94.852686            621.582027           3090.580603         
model.layers.22.mlp.experts.44.gate_proj      torch.Size([0, 1408])          104.397278           105.025768           621.774904           3014.086575         
model.layers.22.mlp.experts.44.act_fn         torch.Size([0, 1408])          0.575264             1.282930             621.568000           3572.544000         
model.layers.22.mlp.experts.44.up_proj        torch.Size([0, 1408])          96.397568            96.979856            620.502891           3270.919942         
model.layers.22.mlp.experts.44.down_proj      torch.Size([0, 2048])          84.918625            85.553646            621.589173           3302.504902         
model.layers.22.mlp.experts.45.gate_proj      torch.Size([1, 1408])          79.535522            80.050945            621.628343           3162.958629         
model.layers.22.mlp.experts.45.act_fn         torch.Size([1, 1408])          0.494368             0.960827             621.568000           3107.840000         
model.layers.22.mlp.experts.45.up_proj        torch.Size([1, 1408])          90.512733            91.098309            621.585902           3142.392839         
model.layers.22.mlp.experts.45.down_proj      torch.Size([1, 2048])          100.341537           100.987434           621.626262           3108.186483         
model.layers.22.mlp.experts.46.gate_proj      torch.Size([1, 1408])          89.259682            89.756727            621.621706           3339.409455         
model.layers.22.mlp.experts.46.act_fn         torch.Size([1, 1408])          0.549856             1.067638             621.568000           3448.281600         
model.layers.22.mlp.experts.46.up_proj        torch.Size([1, 1408])          88.128098            88.576317            621.444923           3809.047795         
model.layers.22.mlp.experts.46.down_proj      torch.Size([1, 2048])          84.462563            85.002661            621.568000           3341.313790         
model.layers.22.mlp.experts.47.gate_proj      torch.Size([0, 1408])          93.227585            93.780518            621.568000           3135.824696         
model.layers.22.mlp.experts.47.act_fn         torch.Size([0, 1408])          0.630624             1.548290             621.568000           3106.560000         
model.layers.22.mlp.experts.47.up_proj        torch.Size([0, 1408])          96.339874            96.953630            621.630534           3126.339420         
model.layers.22.mlp.experts.47.down_proj      torch.Size([0, 2048])          85.138496            85.889101            621.663756           3163.076885         
model.layers.22.mlp.experts.48.gate_proj      torch.Size([0, 1408])          97.106590            97.742081            621.707636           3165.040000         
model.layers.22.mlp.experts.48.act_fn         torch.Size([0, 1408])          0.365728             0.783205             621.568000           3417.216000         
model.layers.22.mlp.experts.48.up_proj        torch.Size([0, 1408])          86.041153            86.478233            621.610346           3233.381534         
model.layers.22.mlp.experts.48.down_proj      torch.Size([0, 2048])          152.900864           153.373480           621.688580           3113.021217         
model.layers.22.mlp.experts.49.gate_proj      torch.Size([0, 1408])          165.221786           166.079998           621.735184           3047.576816         
model.layers.22.mlp.experts.49.act_fn         torch.Size([0, 1408])          0.687392             1.475573             621.568000           3263.232000         
model.layers.22.mlp.experts.49.up_proj        torch.Size([0, 1408])          187.311905           187.915564           621.744485           3173.475394         
model.layers.22.mlp.experts.49.down_proj      torch.Size([0, 2048])          158.215225           158.916950           621.736812           3167.164290         
model.layers.22.mlp.experts.50.gate_proj      torch.Size([0, 1408])          159.647552           160.305262           621.560415           3347.341748         
model.layers.22.mlp.experts.50.act_fn         torch.Size([0, 1408])          0.663584             1.411676             621.312000           3883.200000         
model.layers.22.mlp.experts.50.up_proj        torch.Size([0, 1408])          37.110657            37.710905            577.084952           3773.099973         
model.layers.22.mlp.experts.50.down_proj      torch.Size([0, 2048])          40.992001            41.680813            621.548028           3343.106723         
model.layers.22.mlp.experts.51.gate_proj      torch.Size([1, 1408])          34.827648            35.630226            621.663549           3050.738930         
model.layers.22.mlp.experts.51.act_fn         torch.Size([1, 1408])          0.573248             1.236916             621.568000           3727.872000         
model.layers.22.mlp.experts.51.up_proj        torch.Size([1, 1408])          26.601185            27.100801            621.568000           3234.825333         
model.layers.22.mlp.experts.51.down_proj      torch.Size([1, 2048])          34.874367            35.458326            621.568000           3294.703775         
model.layers.22.mlp.experts.52.gate_proj      torch.Size([0, 1408])          19.038496            19.549131            621.568000           3172.516571         
model.layers.22.mlp.experts.52.act_fn         torch.Size([0, 1408])          0.395392             1.051426             621.568000           3107.840000         
model.layers.22.mlp.experts.52.up_proj        torch.Size([0, 1408])          24.726849            25.215387            617.181257           3127.818971         
model.layers.22.mlp.experts.52.down_proj      torch.Size([0, 2048])          47.233921            47.737598            621.689645           3082.492369         
model.layers.22.mlp.experts.53.gate_proj      torch.Size([0, 1408])          13.563584            14.153957            621.634177           3166.412190         
model.layers.22.mlp.experts.53.act_fn         torch.Size([0, 1408])          0.594400             1.149178             621.568000           3107.840000         
model.layers.22.mlp.experts.53.up_proj        torch.Size([0, 1408])          21.700319            22.243738            614.933180           3224.524892         
model.layers.22.mlp.experts.53.down_proj      torch.Size([0, 2048])          28.461472            28.969765            621.634704           3144.885634         
model.layers.22.mlp.experts.54.gate_proj      torch.Size([0, 1408])          54.195103            54.745197            621.640624           3221.732766         
model.layers.22.mlp.experts.54.act_fn         torch.Size([0, 1408])          0.440768             0.932455             621.312000           3727.872000         
model.layers.22.mlp.experts.54.up_proj        torch.Size([0, 1408])          64.623520            65.068722            572.490473           3732.381867         
model.layers.22.mlp.experts.54.down_proj      torch.Size([0, 2048])          46.996513            47.934294            557.464000           3441.862400         
model.layers.22.mlp.experts.55.gate_proj      torch.Size([1, 1408])          40.825089            41.333914            612.818610           3224.969986         
model.layers.22.mlp.experts.55.act_fn         torch.Size([1, 1408])          0.371296             0.841379             621.568000           3261.888000         
model.layers.22.mlp.experts.55.up_proj        torch.Size([1, 1408])          19.014080            19.525528            621.611537           3166.189279         
model.layers.22.mlp.experts.55.down_proj      torch.Size([1, 2048])          22.595200            23.303509            621.629046           3104.694154         
model.layers.22.mlp.experts.56.gate_proj      torch.Size([0, 1408])          32.766911            33.291101            621.568000           3168.918825         
model.layers.22.mlp.experts.56.act_fn         torch.Size([0, 1408])          0.392512             0.836134             621.568000           3106.560000         
model.layers.22.mlp.experts.56.up_proj        torch.Size([0, 1408])          16.924000            17.358541            621.675594           3184.879768         
model.layers.22.mlp.experts.56.down_proj      torch.Size([0, 2048])          16.838783            17.320633            621.682215           3177.861908         
model.layers.22.mlp.experts.57.gate_proj      torch.Size([0, 1408])          26.245825            26.779413            621.686725           3211.995362         
model.layers.22.mlp.experts.57.act_fn         torch.Size([0, 1408])          0.415104             0.813484             621.568000           3159.637333         
model.layers.22.mlp.experts.57.up_proj        torch.Size([0, 1408])          42.107231            42.465925            570.356932           2848.908030         
model.layers.22.mlp.experts.57.down_proj      torch.Size([0, 2048])          29.768864            30.439854            621.729185           3062.618074         
model.layers.22.mlp.experts.58.gate_proj      torch.Size([0, 1408])          24.779808            25.253057            621.585067           3377.337363         
model.layers.22.mlp.experts.58.act_fn         torch.Size([0, 1408])          0.399616             0.814915             621.312000           4192.128000         
model.layers.22.mlp.experts.58.up_proj        torch.Size([0, 1408])          11.900896            12.318134            564.185333           4012.867111         
model.layers.22.mlp.experts.58.down_proj      torch.Size([0, 2048])          15.717504            16.129971            597.288397           3465.854638         
model.layers.22.mlp.experts.59.gate_proj      torch.Size([0, 1408])          22.305216            22.722721            595.085257           3092.254629         
model.layers.22.mlp.experts.59.act_fn         torch.Size([0, 1408])          0.304576             0.780344             621.568000           3263.232000         
model.layers.22.mlp.experts.59.up_proj        torch.Size([0, 1408])          24.355104            24.778843            600.442740           3147.050959         
model.layers.22.mlp.experts.59.down_proj      torch.Size([0, 2048])          26.745407            27.208805            608.912772           3049.837462         
model.layers.22.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          186.063110           186.450243           652.702720           3057.166607         
model.layers.22.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.637696             1.236200             776.960000           3013.363200         
model.layers.22.mlp.shared_expert.up_proj     torch.Size([5, 5632])          65.801086            66.251516            699.062271           3044.095088         
model.layers.22.mlp.shared_expert.down_proj   torch.Size([5, 2048])          68.586624            68.991184            688.756451           3339.188932         
model.layers.22.mlp.shared_expert_gate        torch.Size([5, 1])             11.029536            11.573076            621.604174           3174.789565         
model.layers.23.input_layernorm               torch.Size([1, 5, 2048])       5.728512             6.340981             466.368000           3253.718204         
model.layers.23.self_attn.q_proj              torch.Size([1, 5, 2048])       34.656895            35.086632            568.394203           3179.502377         
model.layers.23.self_attn.k_proj              torch.Size([1, 5, 2048])       22.519487            22.949934            621.618680           3204.251289         
model.layers.23.self_attn.v_proj              torch.Size([1, 5, 2048])       25.180449            25.640965            621.663373           3079.616627         
model.layers.23.self_attn.o_proj              torch.Size([1, 5, 2048])       20.999264            21.447659            621.637689           3010.872533         
model.layers.23.post_attention_layernorm      torch.Size([1, 5, 2048])       4.644064             5.057812             621.527843           3512.072784         
model.layers.23.mlp.gate                      torch.Size([5, 60])            7.292640             7.767439             486.866113           3187.001962         
model.layers.23.mlp.experts.0.gate_proj       torch.Size([0, 1408])          17.132223            17.616987            544.523411           3372.250791         
model.layers.23.mlp.experts.0.act_fn          torch.Size([0, 1408])          0.302400             0.668526             621.568000           3263.232000         
model.layers.23.mlp.experts.0.up_proj         torch.Size([0, 1408])          18.861343            19.263506            616.018286           3447.202286         
model.layers.23.mlp.experts.0.down_proj       torch.Size([0, 2048])          13.759904            14.155865            563.971068           3718.769534         
model.layers.23.mlp.experts.1.gate_proj       torch.Size([0, 1408])          15.216480            15.622854            589.764958           3554.987718         
model.layers.23.mlp.experts.1.act_fn          torch.Size([0, 1408])          0.309696             0.684500             621.568000           3263.232000         
model.layers.23.mlp.experts.1.up_proj         torch.Size([0, 1408])          13.735360            14.139175            585.642507           3262.463522         
model.layers.23.mlp.experts.1.down_proj       torch.Size([0, 2048])          18.513760            18.928051            613.310046           3249.418260         
model.layers.23.mlp.experts.2.gate_proj       torch.Size([0, 1408])          15.948064            16.359329            611.344471           3157.406118         
model.layers.23.mlp.experts.2.act_fn          torch.Size([0, 1408])          0.320032             0.697374             621.568000           3107.840000         
model.layers.23.mlp.experts.2.up_proj         torch.Size([0, 1408])          14.940000            15.392303            583.905829           3111.169829         
model.layers.23.mlp.experts.2.down_proj       torch.Size([0, 2048])          16.574816            16.966105            614.266340           3067.670639         
model.layers.23.mlp.experts.3.gate_proj       torch.Size([0, 1408])          13.309312            13.783932            603.860031           3148.713038         
model.layers.23.mlp.experts.3.act_fn          torch.Size([0, 1408])          0.359168             0.801563             621.568000           3261.888000         
model.layers.23.mlp.experts.3.up_proj         torch.Size([0, 1408])          11.215168            11.633158            585.440722           3233.446977         
model.layers.23.mlp.experts.3.down_proj       torch.Size([0, 2048])          13.401280            13.838291            598.200173           3226.916374         
model.layers.23.mlp.experts.4.gate_proj       torch.Size([1, 1408])          16.118113            16.566038            599.969119           3106.324587         
model.layers.23.mlp.experts.4.act_fn          torch.Size([1, 1408])          0.350336             0.734329             621.568000           3261.888000         
model.layers.23.mlp.experts.4.up_proj         torch.Size([1, 1408])          14.660256            15.047312            621.654535           3124.958197         
model.layers.23.mlp.experts.4.down_proj       torch.Size([1, 2048])          14.636288            14.969587            611.501128           3533.226256         
model.layers.23.mlp.experts.5.gate_proj       torch.Size([0, 1408])          31.668640            32.216311            579.014758           3720.838758         
model.layers.23.mlp.experts.5.act_fn          torch.Size([0, 1408])          0.472544             1.017809             621.568000           3572.544000         
model.layers.23.mlp.experts.5.up_proj         torch.Size([0, 1408])          21.609856            22.033453            575.535669           3274.396248         
model.layers.23.mlp.experts.5.down_proj       torch.Size([0, 2048])          48.135586            48.702478            591.063887           3093.538254         
model.layers.23.mlp.experts.6.gate_proj       torch.Size([0, 1408])          45.226112            45.654058            603.257287           3042.433790         
model.layers.23.mlp.experts.6.act_fn          torch.Size([0, 1408])          0.556064             1.083851             621.568000           3261.888000         
model.layers.23.mlp.experts.6.up_proj         torch.Size([0, 1408])          31.241472            31.623125            564.298667           3094.039188         
model.layers.23.mlp.experts.6.down_proj       torch.Size([0, 2048])          45.282719            45.875072            575.001958           3138.040392         
model.layers.23.mlp.experts.7.gate_proj       torch.Size([0, 1408])          18.102976            18.669128            592.292699           3227.089902         
model.layers.23.mlp.experts.7.act_fn          torch.Size([0, 1408])          0.348096             0.797987             621.568000           3417.216000         
model.layers.23.mlp.experts.7.up_proj         torch.Size([0, 1408])          16.246847            16.681194            576.313469           3099.354558         
model.layers.23.mlp.experts.7.down_proj       torch.Size([0, 2048])          15.508800            15.937805            610.893427           3115.446601         
model.layers.23.mlp.experts.8.gate_proj       torch.Size([0, 1408])          24.281216            24.711847            608.511504           3077.725271         
model.layers.23.mlp.experts.8.act_fn          torch.Size([0, 1408])          0.314144             0.684261             621.824000           2952.448000         
model.layers.23.mlp.experts.8.up_proj         torch.Size([0, 1408])          18.775423            19.178867            581.964709           3192.398071         
model.layers.23.mlp.experts.8.down_proj       torch.Size([0, 2048])          37.672543            38.103580            548.584867           3451.393928         
model.layers.23.mlp.experts.9.gate_proj       torch.Size([2, 1408])          21.844481            22.457123            544.719435           3703.702965         
model.layers.23.mlp.experts.9.act_fn          torch.Size([2, 1408])          0.484032             0.930071             621.568000           3417.216000         
model.layers.23.mlp.experts.9.up_proj         torch.Size([2, 1408])          26.871712            27.372837            621.568000           3185.057297         
model.layers.23.mlp.experts.9.down_proj       torch.Size([2, 2048])          21.013216            21.517515            621.599135           3176.607135         
model.layers.23.mlp.experts.10.gate_proj      torch.Size([0, 1408])          25.549343            26.104689            621.603382           3236.214634         
model.layers.23.mlp.experts.10.act_fn         torch.Size([0, 1408])          0.371264             0.828743             621.824000           3107.840000         
model.layers.23.mlp.experts.10.up_proj        torch.Size([0, 1408])          15.652576            16.061306            576.914909           3211.143273         
model.layers.23.mlp.experts.10.down_proj      torch.Size([0, 2048])          17.078144            17.581224            584.278423           3101.034511         
model.layers.23.mlp.experts.11.gate_proj      torch.Size([0, 1408])          19.957409            20.611525            580.800889           3005.412444         
model.layers.23.mlp.experts.11.act_fn         torch.Size([0, 1408])          0.377024             0.854254             621.824000           3107.840000         
model.layers.23.mlp.experts.11.up_proj        torch.Size([0, 1408])          16.916767            17.357588            577.936225           3079.387944         
model.layers.23.mlp.experts.11.down_proj      torch.Size([0, 2048])          18.351871            18.806219            588.896500           3128.211500         
model.layers.23.mlp.experts.12.gate_proj      torch.Size([0, 1408])          19.144735            19.567966            587.808241           3167.042406         
model.layers.23.mlp.experts.12.act_fn         torch.Size([0, 1408])          0.300288             0.668287             621.568000           3261.888000         
model.layers.23.mlp.experts.12.up_proj        torch.Size([0, 1408])          25.579552            25.988579            560.178187           3183.565353         
model.layers.23.mlp.experts.12.down_proj      torch.Size([0, 2048])          17.208704            17.603636            551.647785           3543.328644         
model.layers.23.mlp.experts.13.gate_proj      torch.Size([0, 1408])          17.060064            17.529011            549.341729           3676.618735         
model.layers.23.mlp.experts.13.act_fn         torch.Size([0, 1408])          0.338208             0.729322             621.568000           3263.232000         
model.layers.23.mlp.experts.13.up_proj        torch.Size([0, 1408])          27.638847            28.031588            562.795636           3247.390061         
model.layers.23.mlp.experts.13.down_proj      torch.Size([0, 2048])          15.863104            16.255140            593.333723           3182.286482         
model.layers.23.mlp.experts.14.gate_proj      torch.Size([0, 1408])          17.180351            17.639637            579.025127           3083.765183         
model.layers.23.mlp.experts.14.act_fn         torch.Size([0, 1408])          0.305696             0.667810             621.568000           3263.232000         
model.layers.23.mlp.experts.14.up_proj        torch.Size([0, 1408])          15.353952            15.786409            573.913063           3065.460364         
model.layers.23.mlp.experts.14.down_proj      torch.Size([0, 2048])          15.123168            15.509367            579.009391           2932.538435         
model.layers.23.mlp.experts.15.gate_proj      torch.Size([0, 1408])          20.615105            21.041155            584.551211           3031.198197         
model.layers.23.mlp.experts.15.act_fn         torch.Size([0, 1408])          0.312576             0.684261             621.568000           3418.624000         
model.layers.23.mlp.experts.15.up_proj        torch.Size([0, 1408])          16.699776            17.078638            572.987796           3072.616642         
model.layers.23.mlp.experts.15.down_proj      torch.Size([0, 2048])          23.388512            23.845434            599.455086           3254.112000         
model.layers.23.mlp.experts.16.gate_proj      torch.Size([0, 1408])          12.334304            12.748718            602.356235           3152.287059         
model.layers.23.mlp.experts.16.act_fn         torch.Size([0, 1408])          0.315744             0.681877             621.824000           3107.840000         
model.layers.23.mlp.experts.16.up_proj        torch.Size([0, 1408])          16.884447            17.269135            581.529324           3129.080633         
model.layers.23.mlp.experts.16.down_proj      torch.Size([0, 2048])          15.165568            15.574694            598.907569           3325.569477         
model.layers.23.mlp.experts.17.gate_proj      torch.Size([0, 1408])          25.016031            25.770664            547.421605           3904.625633         
model.layers.23.mlp.experts.17.act_fn         torch.Size([0, 1408])          0.567808             1.361370             621.568000           3417.216000         
model.layers.23.mlp.experts.17.up_proj        torch.Size([0, 1408])          34.691776            35.340309            570.975256           3391.293519         
model.layers.23.mlp.experts.17.down_proj      torch.Size([0, 2048])          26.634720            27.552605            593.919543           3172.085943         
model.layers.23.mlp.experts.18.gate_proj      torch.Size([1, 1408])          16.776224            17.302275            605.677151           3108.904329         
model.layers.23.mlp.experts.18.act_fn         torch.Size([1, 1408])          0.527552             1.005411             621.568000           3107.840000         
model.layers.23.mlp.experts.18.up_proj        torch.Size([1, 1408])          16.412096            16.917467            621.647515           3066.637576         
model.layers.23.mlp.experts.18.down_proj      torch.Size([1, 2048])          24.332705            24.835110            621.640624           3145.586383         
model.layers.23.mlp.experts.19.gate_proj      torch.Size([0, 1408])          21.271456            21.750689            621.650878           3205.504000         
model.layers.23.mlp.experts.19.act_fn         torch.Size([0, 1408])          0.355840             0.744581             621.568000           3261.888000         
model.layers.23.mlp.experts.19.up_proj        torch.Size([0, 1408])          22.397087            22.809982            595.573723           3169.069781         
model.layers.23.mlp.experts.19.down_proj      torch.Size([0, 2048])          22.072767            22.492170            592.556889           3070.071111         
model.layers.23.mlp.experts.20.gate_proj      torch.Size([0, 1408])          15.077344            15.502691            595.305796           3016.930395         
model.layers.23.mlp.experts.20.act_fn         torch.Size([0, 1408])          0.315136             0.760078             621.568000           3107.840000         
model.layers.23.mlp.experts.20.up_proj        torch.Size([0, 1408])          17.485537            17.863512            581.484662           3122.022216         
model.layers.23.mlp.experts.20.down_proj      torch.Size([0, 2048])          20.136000            20.592690            600.416970           3238.161455         
model.layers.23.mlp.experts.21.gate_proj      torch.Size([0, 1408])          18.579519            19.030333            547.159346           3927.696503         
model.layers.23.mlp.experts.21.act_fn         torch.Size([0, 1408])          0.301280             0.682354             621.397333           3883.200000         
model.layers.23.mlp.experts.21.up_proj        torch.Size([0, 1408])          25.684032            26.165962            566.409275           3392.961855         
model.layers.23.mlp.experts.21.down_proj      torch.Size([0, 2048])          28.197599            28.605938            593.304789           3047.613296         
model.layers.23.mlp.experts.22.gate_proj      torch.Size([1, 1408])          24.125248            24.601221            600.488329           3036.491397         
model.layers.23.mlp.experts.22.act_fn         torch.Size([1, 1408])          0.525632             1.053572             621.568000           3727.872000         
model.layers.23.mlp.experts.22.up_proj        torch.Size([1, 1408])          21.244192            21.678448            621.667155           3207.116169         
model.layers.23.mlp.experts.22.down_proj      torch.Size([1, 2048])          17.045856            17.465591            621.568000           3268.697252         
model.layers.23.mlp.experts.23.gate_proj      torch.Size([0, 1408])          17.624319            18.046379            621.723748           3139.130182         
model.layers.23.mlp.experts.23.act_fn         torch.Size([0, 1408])          0.298368             0.669956             621.568000           3263.232000         
model.layers.23.mlp.experts.23.up_proj        torch.Size([0, 1408])          23.590273            23.987055            587.187200           3127.407881         
model.layers.23.mlp.experts.23.down_proj      torch.Size([0, 2048])          31.813057            32.259703            610.636432           3060.887022         
model.layers.23.mlp.experts.24.gate_proj      torch.Size([1, 1408])          27.001120            27.535677            614.125021           3169.611476         
model.layers.23.mlp.experts.24.act_fn         torch.Size([1, 1408])          0.477216             0.932217             621.568000           3107.840000         
model.layers.23.mlp.experts.24.up_proj        torch.Size([1, 1408])          27.147488            27.594566            621.625927           3236.372555         
model.layers.23.mlp.experts.24.down_proj      torch.Size([1, 2048])          36.690464            37.149668            621.606676           3302.528921         
model.layers.23.mlp.experts.25.gate_proj      torch.Size([0, 1408])          32.358112            32.866716            611.303417           3562.526517         
model.layers.23.mlp.experts.25.act_fn         torch.Size([0, 1408])          0.409504             0.846386             621.568000           3572.544000         
model.layers.23.mlp.experts.25.up_proj        torch.Size([0, 1408])          17.928320            18.350840            573.867886           3345.042286         
model.layers.23.mlp.experts.25.down_proj      torch.Size([0, 2048])          37.391327            37.873507            595.154963           3240.934400         
model.layers.23.mlp.experts.26.gate_proj      torch.Size([1, 1408])          30.864063            31.409740            606.443413           3215.781147         
model.layers.23.mlp.experts.26.act_fn         torch.Size([1, 1408])          0.364224             0.813007             621.568000           3261.888000         
model.layers.23.mlp.experts.26.up_proj        torch.Size([1, 1408])          18.111872            18.522978            621.652114           3139.639314         
model.layers.23.mlp.experts.26.down_proj      torch.Size([1, 2048])          15.958144            16.400099            621.674667           3074.984000         
model.layers.23.mlp.experts.27.gate_proj      torch.Size([0, 1408])          12.420000            12.838840            621.693277           3046.124028         
model.layers.23.mlp.experts.27.act_fn         torch.Size([0, 1408])          0.304864             0.678062             621.568000           3107.840000         
model.layers.23.mlp.experts.27.up_proj        torch.Size([0, 1408])          21.936832            22.402525            593.764835           3158.857209         
model.layers.23.mlp.experts.27.down_proj      torch.Size([0, 2048])          35.158432            35.597801            610.221037           3165.134696         
model.layers.23.mlp.experts.28.gate_proj      torch.Size([0, 1408])          23.574753            24.042606            603.130141           3180.958197         
model.layers.23.mlp.experts.28.act_fn         torch.Size([0, 1408])          0.727904             1.444817             621.568000           3417.685333         
model.layers.23.mlp.experts.28.up_proj        torch.Size([0, 1408])          34.264191            34.799814            564.029714           3062.332343         
model.layers.23.mlp.experts.28.down_proj      torch.Size([0, 2048])          27.214081            27.758360            606.141257           3199.604571         
model.layers.23.mlp.experts.29.gate_proj      torch.Size([0, 1408])          32.192287            32.833099            492.189595           3771.922127         
model.layers.23.mlp.experts.29.act_fn         torch.Size([0, 1408])          0.005568             1.273394             517.973333           3883.200000         
model.layers.23.mlp.experts.29.up_proj        torch.Size([0, 1408])          39.799679            40.207624            538.037848           3436.207228         
model.layers.23.mlp.experts.29.down_proj      torch.Size([0, 2048])          37.700226            38.254023            583.107737           3316.181022         
model.layers.23.mlp.experts.30.gate_proj      torch.Size([1, 1408])          30.659103            31.302691            590.029497           3078.280272         
model.layers.23.mlp.experts.30.act_fn         torch.Size([1, 1408])          0.445440             0.841856             621.568000           3263.232000         
model.layers.23.mlp.experts.30.up_proj        torch.Size([1, 1408])          21.571424            22.018433            621.766713           3031.767720         
model.layers.23.mlp.experts.30.down_proj      torch.Size([1, 2048])          27.061888            27.629852            621.629370           3068.306411         
model.layers.23.mlp.experts.31.gate_proj      torch.Size([0, 1408])          28.492031            29.014587            621.658353           3155.544941         
model.layers.23.mlp.experts.31.act_fn         torch.Size([0, 1408])          0.380480             0.828505             621.568000           3211.434667         
model.layers.23.mlp.experts.31.up_proj        torch.Size([0, 1408])          24.033089            24.433136            590.757647           3318.708235         
model.layers.23.mlp.experts.31.down_proj      torch.Size([0, 2048])          21.073313            21.640301            605.051429           3127.818971         
model.layers.23.mlp.experts.32.gate_proj      torch.Size([0, 1408])          18.715073            19.146919            608.097882           3025.573647         
model.layers.23.mlp.experts.32.act_fn         torch.Size([0, 1408])          0.313184             0.704288             621.824000           2952.448000         
model.layers.23.mlp.experts.32.up_proj        torch.Size([0, 1408])          24.020416            24.477243            592.535188           3020.026435         
model.layers.23.mlp.experts.32.down_proj      torch.Size([0, 2048])          23.138176            23.658037            620.379803           3296.804197         
model.layers.23.mlp.experts.33.gate_proj      torch.Size([0, 1408])          22.633217            23.082733            556.363243           3846.003459         
model.layers.23.mlp.experts.33.act_fn         torch.Size([0, 1408])          0.309440             0.698566             621.397333           3883.200000         
model.layers.23.mlp.experts.33.up_proj        torch.Size([0, 1408])          32.087967            32.544613            521.295392           3357.137418         
model.layers.23.mlp.experts.33.down_proj      torch.Size([0, 2048])          22.220192            22.669077            580.859243           3075.291676         
model.layers.23.mlp.experts.34.gate_proj      torch.Size([0, 1408])          16.262560            16.801596            597.120000           3062.004950         
model.layers.23.mlp.experts.34.act_fn         torch.Size([0, 1408])          0.333728             0.738382             621.653333           3107.840000         
model.layers.23.mlp.experts.34.up_proj        torch.Size([0, 1408])          22.788511            23.245811            588.784584           3183.420263         
model.layers.23.mlp.experts.34.down_proj      torch.Size([0, 2048])          54.258530            54.608583            609.646140           3191.681984         
model.layers.23.mlp.experts.35.gate_proj      torch.Size([0, 1408])          42.577377            43.040991            599.179130           3183.173565         
model.layers.23.mlp.experts.35.act_fn         torch.Size([0, 1408])          0.464896             1.006842             621.568000           3263.232000         
model.layers.23.mlp.experts.35.up_proj        torch.Size([0, 1408])          26.379553            26.980639            581.230873           3084.859493         
model.layers.23.mlp.experts.35.down_proj      torch.Size([0, 2048])          26.181536            26.676416            602.326118           3050.710588         
model.layers.23.mlp.experts.36.gate_proj      torch.Size([0, 1408])          40.973217            41.615486            600.666057           3071.045486         
model.layers.23.mlp.experts.36.act_fn         torch.Size([0, 1408])          0.005696             1.368523             621.568000           3572.544000         
model.layers.23.mlp.experts.36.up_proj        torch.Size([0, 1408])          20.877279            21.431923            586.665915           3199.560113         
model.layers.23.mlp.experts.36.down_proj      torch.Size([0, 2048])          25.352287            25.900602            603.904000           3447.975273         
model.layers.23.mlp.experts.37.gate_proj      torch.Size([0, 1408])          24.172384            24.666309            561.816548           3929.190137         
model.layers.23.mlp.experts.37.act_fn         torch.Size([0, 1408])          0.324544             0.715256             621.312000           4450.901333         
model.layers.23.mlp.experts.37.up_proj        torch.Size([0, 1408])          31.076992            31.542063            560.490971           3612.554971         
model.layers.23.mlp.experts.37.down_proj      torch.Size([0, 2048])          19.263168            19.735813            599.599206           3165.100028         
model.layers.23.mlp.experts.38.gate_proj      torch.Size([1, 1408])          36.165985            36.632776            612.313600           3201.634987         
model.layers.23.mlp.experts.38.act_fn         torch.Size([1, 1408])          0.365952             0.779867             621.824000           3107.840000         
model.layers.23.mlp.experts.38.up_proj        torch.Size([1, 1408])          28.677055            29.107809            621.635148           3220.579672         
model.layers.23.mlp.experts.38.down_proj      torch.Size([1, 2048])          16.939137            17.497778            621.725808           3034.161973         
model.layers.23.mlp.experts.39.gate_proj      torch.Size([1, 1408])          18.144833            18.631935            621.663740           3026.985626         
model.layers.23.mlp.experts.39.act_fn         torch.Size([1, 1408])          0.396992             0.772953             621.632000           2952.448000         
model.layers.23.mlp.experts.39.up_proj        torch.Size([1, 1408])          22.516384            22.964001            621.644979           3063.287049         
model.layers.23.mlp.experts.39.down_proj      torch.Size([1, 2048])          25.983521            26.341915            621.634954           3162.082462         
model.layers.23.mlp.experts.40.gate_proj      torch.Size([0, 1408])          17.110785            17.574549            621.642440           3219.667972         
model.layers.23.mlp.experts.40.act_fn         torch.Size([0, 1408])          0.300768             0.681400             621.568000           3263.232000         
model.layers.23.mlp.experts.40.up_proj        torch.Size([0, 1408])          23.775328            24.196863            603.364235           3200.308706         
model.layers.23.mlp.experts.40.down_proj      torch.Size([0, 2048])          15.431840            15.837193            614.986590           3166.624230         
model.layers.23.mlp.experts.41.gate_proj      torch.Size([0, 1408])          19.151104            19.599915            562.956274           3596.830247         
model.layers.23.mlp.experts.41.act_fn         torch.Size([0, 1408])          0.299808             0.683784             621.312000           3883.200000         
model.layers.23.mlp.experts.41.up_proj        torch.Size([0, 1408])          21.873247            22.286892            541.425509           3481.299723         
model.layers.23.mlp.experts.41.down_proj      torch.Size([0, 2048])          17.163616            17.608643            576.640000           3219.783884         
model.layers.23.mlp.experts.42.gate_proj      torch.Size([0, 1408])          36.724609            37.113667            600.476606           3206.323394         
model.layers.23.mlp.experts.42.act_fn         torch.Size([0, 1408])          0.545152             1.266241             621.568000           3261.888000         
model.layers.23.mlp.experts.42.up_proj        torch.Size([0, 1408])          48.652161            49.227476            592.743283           3209.494952         
model.layers.23.mlp.experts.42.down_proj      torch.Size([0, 2048])          38.695042            39.463997            612.786647           3119.019281         
model.layers.23.mlp.experts.43.gate_proj      torch.Size([0, 1408])          30.667648            31.162739            619.415881           3181.742806         
model.layers.23.mlp.experts.43.act_fn         torch.Size([0, 1408])          0.537728             1.175642             621.568000           3417.216000         
model.layers.23.mlp.experts.43.up_proj        torch.Size([0, 1408])          33.872738            34.351110            596.601412           3217.251765         
model.layers.23.mlp.experts.43.down_proj      torch.Size([0, 2048])          31.905439            32.346487            607.526107           3219.101802         
model.layers.23.mlp.experts.44.gate_proj      torch.Size([2, 1408])          26.157408            26.826143            613.235726           3115.261370         
model.layers.23.mlp.experts.44.act_fn         torch.Size([2, 1408])          0.482208             0.992298             621.568000           3261.888000         
model.layers.23.mlp.experts.44.up_proj        torch.Size([2, 1408])          32.965088            33.499479            621.575062           3158.023945         
model.layers.23.mlp.experts.44.down_proj      torch.Size([2, 2048])          27.877983            28.379679            621.614873           3146.787606         
model.layers.23.mlp.experts.45.gate_proj      torch.Size([0, 1408])          26.854816            27.348280            621.423543           3699.551543         
model.layers.23.mlp.experts.45.act_fn         torch.Size([0, 1408])          0.417824             0.986099             621.312000           4192.128000         
model.layers.23.mlp.experts.45.up_proj        torch.Size([0, 1408])          36.049568            36.472321            586.291854           3836.124964         
model.layers.23.mlp.experts.45.down_proj      torch.Size([0, 2048])          41.433823            42.029142            601.779745           3244.187234         
model.layers.23.mlp.experts.46.gate_proj      torch.Size([0, 1408])          24.420992            24.900675            612.936113           3101.274141         
model.layers.23.mlp.experts.46.act_fn         torch.Size([0, 1408])          0.468960             0.918388             621.824000           2952.448000         
model.layers.23.mlp.experts.46.up_proj        torch.Size([0, 1408])          43.975521            44.318438            593.105702           3076.982014         
model.layers.23.mlp.experts.46.down_proj      torch.Size([0, 2048])          36.714622            37.133694            612.589314           3181.213431         
model.layers.23.mlp.experts.47.gate_proj      torch.Size([0, 1408])          19.102337            19.692659            608.311252           3136.656576         
model.layers.23.mlp.experts.47.act_fn         torch.Size([0, 1408])          0.389056             0.906467             621.824000           2953.664000         
model.layers.23.mlp.experts.47.up_proj        torch.Size([0, 1408])          20.149504            20.620823            574.700169           3055.785465         
model.layers.23.mlp.experts.47.down_proj      torch.Size([0, 2048])          27.374657            27.830362            615.003826           3060.546783         
model.layers.23.mlp.experts.48.gate_proj      torch.Size([0, 1408])          22.011456            22.458553            603.456000           3052.995765         
model.layers.23.mlp.experts.48.act_fn         torch.Size([0, 1408])          0.316960             0.717163             621.568000           3107.840000         
model.layers.23.mlp.experts.48.up_proj        torch.Size([0, 1408])          37.942112            38.406610            594.836692           3169.249203         
model.layers.23.mlp.experts.48.down_proj      torch.Size([0, 2048])          21.318464            21.777153            613.538165           3190.459188         
model.layers.23.mlp.experts.49.gate_proj      torch.Size([0, 1408])          27.406849            27.884722            557.921503           3715.270872         
model.layers.23.mlp.experts.49.act_fn         torch.Size([0, 1408])          0.384192             0.920296             621.312000           4399.146667         
model.layers.23.mlp.experts.49.up_proj        torch.Size([0, 1408])          16.960064            17.434359            553.556889           3627.966222         
model.layers.23.mlp.experts.49.down_proj      torch.Size([0, 2048])          18.239424            18.676281            604.707068           3083.360438         
model.layers.23.mlp.experts.50.gate_proj      torch.Size([0, 1408])          21.056543            21.470547            607.728602           3195.192301         
model.layers.23.mlp.experts.50.act_fn         torch.Size([0, 1408])          0.323360             0.689507             621.568000           3520.768000         
model.layers.23.mlp.experts.50.up_proj        torch.Size([0, 1408])          22.475361            22.863388            593.592580           3180.840812         
model.layers.23.mlp.experts.50.down_proj      torch.Size([0, 2048])          15.494208            15.895128            603.861943           3295.055086         
model.layers.23.mlp.experts.51.gate_proj      torch.Size([2, 1408])          33.283905            33.718348            609.897865           3162.710617         
model.layers.23.mlp.experts.51.act_fn         torch.Size([2, 1408])          0.376064             0.810862             621.568000           3261.888000         
model.layers.23.mlp.experts.51.up_proj        torch.Size([2, 1408])          38.269249            38.696289            621.569753           3150.287781         
model.layers.23.mlp.experts.51.down_proj      torch.Size([2, 2048])          31.055489            31.548262            621.568000           3105.571504         
model.layers.23.mlp.experts.52.gate_proj      torch.Size([2, 1408])          45.408577            45.935154            621.568000           3207.391556         
model.layers.23.mlp.experts.52.act_fn         torch.Size([2, 1408])          0.405440             0.869989             621.568000           3107.840000         
model.layers.23.mlp.experts.52.up_proj        torch.Size([2, 1408])          24.969824            25.428534            621.609759           3253.570270         
model.layers.23.mlp.experts.52.down_proj      torch.Size([2, 2048])          36.204414            36.676884            621.615543           3182.428343         
model.layers.23.mlp.experts.53.gate_proj      torch.Size([1, 1408])          15.983424            16.534567            621.496447           3515.443677         
model.layers.23.mlp.experts.53.act_fn         torch.Size([1, 1408])          0.450560             0.955343             621.312000           4192.128000         
model.layers.23.mlp.experts.53.up_proj        torch.Size([1, 1408])          36.215519            36.742210            610.124613           3670.971796         
model.layers.23.mlp.experts.53.down_proj      torch.Size([1, 2048])          46.390305            46.888590            621.589634           3287.423099         
model.layers.23.mlp.experts.54.gate_proj      torch.Size([2, 1408])          51.138367            51.818371            621.626514           3221.374629         
model.layers.23.mlp.experts.54.act_fn         torch.Size([2, 1408])          0.511680             1.089096             621.568000           3262.896000         
model.layers.23.mlp.experts.54.up_proj        torch.Size([2, 1408])          37.144897            37.671089            621.600865           3232.064000         
model.layers.23.mlp.experts.54.down_proj      torch.Size([2, 2048])          43.689793            44.306755            621.634302           3098.387799         
model.layers.23.mlp.experts.55.gate_proj      torch.Size([0, 1408])          43.533409            44.040442            621.648239           3085.806806         
model.layers.23.mlp.experts.55.act_fn         torch.Size([0, 1408])          0.431200             0.939131             621.568000           3107.840000         
model.layers.23.mlp.experts.55.up_proj        torch.Size([0, 1408])          35.628960            36.078930            621.676089           3207.448652         
model.layers.23.mlp.experts.55.down_proj      torch.Size([0, 2048])          24.300257            24.878025            621.695038           3185.637053         
model.layers.23.mlp.experts.56.gate_proj      torch.Size([0, 1408])          22.202047            22.715569            605.942261           3187.578435         
model.layers.23.mlp.experts.56.act_fn         torch.Size([0, 1408])          0.332064             0.742912             621.824000           2952.448000         
model.layers.23.mlp.experts.56.up_proj        torch.Size([0, 1408])          21.611488            22.047997            563.847662           2900.594028         
model.layers.23.mlp.experts.56.down_proj      torch.Size([0, 2048])          27.820801            28.318405            607.532620           3092.239324         
model.layers.23.mlp.experts.57.gate_proj      torch.Size([0, 1408])          27.991776            28.517008            567.715840           3526.180693         
model.layers.23.mlp.experts.57.act_fn         torch.Size([0, 1408])          0.397952             0.852108             621.226667           4502.656000         
model.layers.23.mlp.experts.57.up_proj        torch.Size([0, 1408])          26.524256            26.959181            524.295860           3726.267509         
model.layers.23.mlp.experts.57.down_proj      torch.Size([0, 2048])          24.850880            25.267363            552.266440           3122.166922         
model.layers.23.mlp.experts.58.gate_proj      torch.Size([0, 1408])          37.568481            38.138390            603.370222           3067.912889         
model.layers.23.mlp.experts.58.act_fn         torch.Size([0, 1408])          0.430880             1.040697             621.568000           3263.232000         
model.layers.23.mlp.experts.58.up_proj        torch.Size([0, 1408])          32.689568            33.278942            603.304770           3181.507319         
model.layers.23.mlp.experts.58.down_proj      torch.Size([0, 2048])          48.451233            48.969030            615.034475           3130.991885         
model.layers.23.mlp.experts.59.gate_proj      torch.Size([1, 1408])          28.124607            28.684139            616.305231           3165.209063         
model.layers.23.mlp.experts.59.act_fn         torch.Size([1, 1408])          0.402944             0.881672             621.568000           3603.609600         
model.layers.23.mlp.experts.59.up_proj        torch.Size([1, 1408])          27.554337            28.050423            621.590486           3261.827027         
model.layers.23.mlp.experts.59.down_proj      torch.Size([1, 2048])          19.675488            20.135403            621.631559           3162.256331         
model.layers.23.mlp.shared_expert.gate_proj   torch.Size([5, 5632])          51.137215            51.642418            668.415259           2966.045037         
model.layers.23.mlp.shared_expert.act_fn      torch.Size([5, 5632])          0.744416             1.349926             776.960000           3106.560000         
model.layers.23.mlp.shared_expert.up_proj     torch.Size([5, 5632])          99.449570            100.123405           675.728989           3489.520037         
model.layers.23.mlp.shared_expert.down_proj   torch.Size([5, 2048])          131.392380           132.273436           750.046766           3177.167465         
model.layers.23.mlp.shared_expert_gate        torch.Size([5, 1])             8.470432             9.502411             713.521778           3397.027556         
model.norm                                    torch.Size([1, 5, 2048])       7.796480             8.613825             621.778824           3150.622118         
lm_head                                       torch.Size([1, 5, 151936])     10119.367188         10121.451378         1159.940745          3416.099024         
